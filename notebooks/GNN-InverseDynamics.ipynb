{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import torch.autograd\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pybullet as p \n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pybullet \n",
    "import pybullet_envs.gym_pendulum_envs \n",
    "import pybullet_envs.gym_locomotion_envs\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import dgl\n",
    "import morphsim as m\n",
    "from graphenvs import HalfCheetahGraphEnv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        hidden_sizes,\n",
    "        batch_size,\n",
    "        with_batch_norm=True,\n",
    "        activation=None\n",
    "    ):\n",
    "        super(Network, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Linear(self.input_size, hidden_sizes[0]))\n",
    "        if with_batch_norm:\n",
    "            self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            if with_batch_norm:\n",
    "                self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_sizes[len(hidden_sizes) - 1], self.output_size))\n",
    "        \n",
    "        if activation is not None:\n",
    "            self.layers.append(activation())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputNetwork,\n",
    "        messageNetwork,\n",
    "        updateNetwork,\n",
    "        outputNetwork,\n",
    "        numMessagePassingIterations,\n",
    "        withInputNetwork = True\n",
    "    ):\n",
    "        \n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "                \n",
    "        self.inputNetwork = inputNetwork\n",
    "        self.messageNetwork = messageNetwork\n",
    "        self.updateNetwork = updateNetwork\n",
    "        self.outputNetwork = outputNetwork\n",
    "        \n",
    "        self.numMessagePassingIterations = numMessagePassingIterations\n",
    "        self.withInputNetwork = withInputNetwork\n",
    "        \n",
    "    def inputFunction(self, nodes):\n",
    "        return {'state' : self.inputNetwork(nodes.data['input'])}\n",
    "    \n",
    "    def messageFunction(self, edges):\n",
    "        \n",
    "        edgeData = edges.data['feature'].repeat(edges.src['state'].shape[1], 1).T.unsqueeze(-1)\n",
    "        \n",
    "        return {'m' : self.messageNetwork(torch.cat((edges.src['state'], edgeData), -1))}\n",
    "    \n",
    "    def updateFunction(self, nodes):\n",
    "        return {'state': self.updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}\n",
    "    \n",
    "    def outputFunction(self, nodes):\n",
    "        \n",
    "#         numNodes, batchSize, stateSize = graph.ndata['state'].shape\n",
    "#         return self.outputNetwork.forward(graph.ndata['state'])\n",
    "        return {'output': self.outputNetwork(nodes.data['state'])}\n",
    "\n",
    "\n",
    "    def forward(self, graph, state):\n",
    "        \n",
    "        self.update_states_in_graph(graph, state)\n",
    "        \n",
    "        if self.withInputNetwork:\n",
    "            graph.apply_nodes(self.inputFunction)\n",
    "        \n",
    "        for messagePassingIteration in range(self.numMessagePassingIterations):\n",
    "            graph.update_all(self.messageFunction, dgl.function.max('m', 'm_hat'), self.updateFunction)\n",
    "        \n",
    "        graph.apply_nodes(self.outputFunction)\n",
    "        \n",
    "        output = graph.ndata['output']\n",
    "        output = torch.transpose(output, dim0=0, dim1=1)\n",
    "        output = torch.squeeze(output, dim=-1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def update_states_in_graph(self, graph, state):\n",
    "        if len(state.shape) == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        \n",
    "        numGraphFeature = 6\n",
    "        numGlobalStateInformation = 5\n",
    "        numLocalStateInformation = 2\n",
    "        numStateVar = state.shape[1] // 2\n",
    "        globalInformation = torch.cat((state[:, 0:5], state[:, numStateVar:numStateVar+5]), -1)\n",
    "        \n",
    "        numNodes = (numStateVar - 5) // 2\n",
    "\n",
    "        nodeData = torch.empty((numNodes, state.shape[0], numGraphFeature + 2 * numGlobalStateInformation + 2 * numLocalStateInformation)).to(device)\n",
    "        for nodeIdx in range(numNodes):\n",
    "\n",
    "            # Assign global features from graph\n",
    "            nodeData[nodeIdx, :, :6] = graph.ndata['feature'][nodeIdx]\n",
    "            # Assign local state information\n",
    "            nodeData[nodeIdx, :, 16] = state[:, 5 + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 17] = state[:, 5 + numNodes + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 18] = state[:, numStateVar + 5 + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 19] = state[:, numStateVar + 5 + numNodes + nodeIdx]\n",
    "\n",
    "        # Assdign global state information\n",
    "        nodeData[:, :, 6:16] = globalInformation\n",
    "        \n",
    "        if self.withInputNetwork:\n",
    "            graph.ndata['input'] = nodeData        \n",
    "        \n",
    "        else:\n",
    "            graph.ndata['state'] = nodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovi/anaconda3/envs/honors-project/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n",
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n",
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n",
      "None\n",
      "*************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "states = {}\n",
    "actions = {}\n",
    "rewards = {}\n",
    "next_states = {}\n",
    "dones = {}\n",
    "env = {}\n",
    "\n",
    "for morphIdx in range(7):\n",
    "\n",
    "    prefix = '../datasets/{}/'.format(morphIdx)\n",
    "    \n",
    "    states[morphIdx] = np.load(prefix + 'states_array.npy')\n",
    "    actions[morphIdx] = np.load(prefix + 'actions_array.npy')\n",
    "    rewards[morphIdx] = np.load(prefix + 'rewards_array.npy')\n",
    "    next_states[morphIdx] = np.load(prefix + 'next_states_array.npy')\n",
    "    dones[morphIdx] = np.load(prefix + 'dones_array.npy')\n",
    "    \n",
    "    env[morphIdx] = HalfCheetahGraphEnv(None)\n",
    "    env[morphIdx].set_morphology(morphIdx)\n",
    "    env[morphIdx].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = {}\n",
    "X_train = {}\n",
    "Y_test = {}\n",
    "Y_train = {}\n",
    "\n",
    "for morphIdx in range(7):\n",
    "    X = np.concatenate((states[morphIdx], next_states[morphIdx]), -1)\n",
    "    Y = actions[morphIdx]\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    X_test[morphIdx] = torch.from_numpy(X[:100000]).float()\n",
    "    X_train[morphIdx] = torch.from_numpy(X[100000:]).float()\n",
    "    Y = Y[permutation]\n",
    "    Y_test[morphIdx] = torch.from_numpy(Y[:100000]).float()\n",
    "    Y_train[morphIdx] = torch.from_numpy(Y[100000:]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [64, 64]\n",
    "\n",
    "inputSize = 20\n",
    "stateSize = 64\n",
    "messageSize = 64\n",
    "outputSize = 1\n",
    "numMessagePassingIterations = 4\n",
    "batch_size = 1024\n",
    "with_batch_norm=False\n",
    "numBatchesPerTrainingStep = 4\n",
    "\n",
    "inputNetwork = Network(inputSize, stateSize, hidden_sizes, batch_size, with_batch_norm)\n",
    "messageNetwork = Network(stateSize + 1, messageSize, hidden_sizes, batch_size, with_batch_norm, nn.Tanh)\n",
    "updateNetwork = Network(stateSize + messageSize, stateSize, hidden_sizes, batch_size, with_batch_norm)\n",
    "outputNetwork = Network(stateSize, outputSize, hidden_sizes, batch_size, with_batch_norm, nn.Tanh)\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "numTrainingBatches = int(np.ceil(X_train[0].shape[0] / batch_size))\n",
    "numTestingBatches = int(np.ceil(X_test[0].shape[0] / batch_size))\n",
    "\n",
    "gnn = GraphNeuralNetwork(inputNetwork, messageNetwork, updateNetwork, outputNetwork, numMessagePassingIterations).to(device)\n",
    "\n",
    "optimizer = optim.Adam(itertools.chain(inputNetwork.parameters(), messageNetwork.parameters(), updateNetwork.parameters(), outputNetwork.parameters())\n",
    "                       , lr, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "lmbda = lambda epoch: 0.8\n",
    "lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lmbda)\n",
    "criterion  = nn.SmoothL1Loss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.46823787689208984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4218, 0.4377, 0.3843, 0.4393]) \n",
      "Test Loss tensor([0.4184, 0.4376, 0.3812, 0.4391])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4436650276184082 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4193, 0.4357, 0.3827, 0.4413]) \n",
      "Test Loss tensor([0.4187, 0.4368, 0.3792, 0.4384])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.45856547355651855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4204, 0.4352, 0.3779, 0.4392]) \n",
      "Test Loss tensor([0.4181, 0.4377, 0.3789, 0.4389])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5267989635467529 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4190, 0.4331, 0.3803, 0.4377]) \n",
      "Test Loss tensor([0.4175, 0.4375, 0.3781, 0.4386])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4843113422393799 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4215, 0.4337, 0.3804, 0.4386]) \n",
      "Test Loss tensor([0.4184, 0.4382, 0.3776, 0.4395])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4543790817260742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4173, 0.4371, 0.3794, 0.4384]) \n",
      "Test Loss tensor([0.4171, 0.4388, 0.3762, 0.4405])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4692096710205078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4150, 0.4411, 0.3784, 0.4413]) \n",
      "Test Loss tensor([0.4174, 0.4394, 0.3751, 0.4410])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4701516628265381 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4158, 0.4390, 0.3776, 0.4401]) \n",
      "Test Loss tensor([0.4180, 0.4390, 0.3751, 0.4413])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.48165297508239746 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4178, 0.4410, 0.3733, 0.4409]) \n",
      "Test Loss tensor([0.4159, 0.4394, 0.3758, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.48912835121154785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4168, 0.4375, 0.3769, 0.4414]) \n",
      "Test Loss tensor([0.4164, 0.4394, 0.3738, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5511965751647949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4163, 0.4393, 0.3712, 0.4425]) \n",
      "Test Loss tensor([0.4166, 0.4402, 0.3733, 0.4415])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5575010776519775 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4124, 0.4407, 0.3760, 0.4427]) \n",
      "Test Loss tensor([0.4160, 0.4409, 0.3724, 0.4422])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4758784770965576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4179, 0.4395, 0.3678, 0.4436]) \n",
      "Test Loss tensor([0.4165, 0.4408, 0.3724, 0.4425])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4789249897003174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4156, 0.4389, 0.3706, 0.4424]) \n",
      "Test Loss tensor([0.4161, 0.4407, 0.3705, 0.4430])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5351343154907227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4183, 0.4386, 0.3714, 0.4432]) \n",
      "Test Loss tensor([0.4147, 0.4408, 0.3708, 0.4438])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.47598767280578613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4159, 0.4416, 0.3713, 0.4433]) \n",
      "Test Loss tensor([0.4160, 0.4416, 0.3696, 0.4433])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5956060886383057 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4139, 0.4372, 0.3730, 0.4419]) \n",
      "Test Loss tensor([0.4155, 0.4418, 0.3701, 0.4444])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6607015132904053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4148, 0.4412, 0.3724, 0.4473]) \n",
      "Test Loss tensor([0.4145, 0.4429, 0.3684, 0.4449])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6517961025238037 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4130, 0.4433, 0.3672, 0.4475]) \n",
      "Test Loss tensor([0.4158, 0.4433, 0.3681, 0.4449])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5742695331573486 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4139, 0.4438, 0.3709, 0.4486]) \n",
      "Test Loss tensor([0.4152, 0.4423, 0.3679, 0.4442])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5474705696105957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4150, 0.4415, 0.3665, 0.4424]) \n",
      "Test Loss tensor([0.4154, 0.4436, 0.3673, 0.4452])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5569324493408203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4156, 0.4411, 0.3678, 0.4502]) \n",
      "Test Loss tensor([0.4137, 0.4440, 0.3669, 0.4457])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5509488582611084 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4129, 0.4431, 0.3647, 0.4450]) \n",
      "Test Loss tensor([0.4148, 0.4434, 0.3667, 0.4465])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4720621109008789 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4139, 0.4430, 0.3606, 0.4505]) \n",
      "Test Loss tensor([0.4132, 0.4435, 0.3655, 0.4469])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4400162696838379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4111, 0.4441, 0.3621, 0.4505]) \n",
      "Test Loss tensor([0.4140, 0.4446, 0.3658, 0.4471])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4552121162414551 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4131, 0.4419, 0.3674, 0.4460]) \n",
      "Test Loss tensor([0.4135, 0.4458, 0.3643, 0.4475])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.45003676414489746 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4146, 0.4420, 0.3650, 0.4459]) \n",
      "Test Loss tensor([0.4139, 0.4452, 0.3645, 0.4476])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4227426052093506 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4089, 0.4433, 0.3649, 0.4471]) \n",
      "Test Loss tensor([0.4127, 0.4441, 0.3645, 0.4484])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.47867321968078613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4126, 0.4432, 0.3651, 0.4487]) \n",
      "Test Loss tensor([0.4144, 0.4444, 0.3625, 0.4480])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5170814990997314 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4152, 0.4461, 0.3629, 0.4478]) \n",
      "Test Loss tensor([0.4141, 0.4447, 0.3631, 0.4489])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.46131062507629395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4128, 0.4439, 0.3620, 0.4481]) \n",
      "Test Loss tensor([0.4136, 0.4456, 0.3615, 0.4483])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4392218589782715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4198, 0.4455, 0.3645, 0.4516]) \n",
      "Test Loss tensor([0.4136, 0.4460, 0.3620, 0.4491])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5002579689025879 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4147, 0.4417, 0.3602, 0.4496]) \n",
      "Test Loss tensor([0.4124, 0.4481, 0.3613, 0.4496])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.45017480850219727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4139, 0.4467, 0.3600, 0.4505]) \n",
      "Test Loss tensor([0.4128, 0.4462, 0.3613, 0.4495])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4374070167541504 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4172, 0.4460, 0.3592, 0.4457]) \n",
      "Test Loss tensor([0.4127, 0.4458, 0.3598, 0.4498])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5068187713623047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4109, 0.4474, 0.3602, 0.4529]) \n",
      "Test Loss tensor([0.4126, 0.4473, 0.3590, 0.4499])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.46884655952453613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4116, 0.4490, 0.3599, 0.4526]) \n",
      "Test Loss tensor([0.4132, 0.4475, 0.3593, 0.4499])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4570801258087158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4089, 0.4462, 0.3596, 0.4544]) \n",
      "Test Loss tensor([0.4124, 0.4476, 0.3586, 0.4499])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4583244323730469 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4124, 0.4468, 0.3610, 0.4500]) \n",
      "Test Loss tensor([0.4120, 0.4465, 0.3588, 0.4508])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.45435380935668945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4116, 0.4454, 0.3607, 0.4526]) \n",
      "Test Loss tensor([0.4119, 0.4478, 0.3583, 0.4512])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.45331811904907227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4125, 0.4487, 0.3548, 0.4523]) \n",
      "Test Loss tensor([0.4117, 0.4475, 0.3579, 0.4516])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.46056652069091797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4120, 0.4481, 0.3614, 0.4488]) \n",
      "Test Loss tensor([0.4118, 0.4479, 0.3571, 0.4524])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.45537471771240234 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4114, 0.4467, 0.3589, 0.4539]) \n",
      "Test Loss tensor([0.4109, 0.4480, 0.3585, 0.4513])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.44817161560058594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4101, 0.4484, 0.3551, 0.4519]) \n",
      "Test Loss tensor([0.4108, 0.4486, 0.3568, 0.4523])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.4642305374145508 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4108, 0.4507, 0.3565, 0.4540]) \n",
      "Test Loss tensor([0.4111, 0.4493, 0.3555, 0.4530])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 180 in 0.47750210762023926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4115, 0.4497, 0.3566, 0.4535]) \n",
      "Test Loss tensor([0.4100, 0.4507, 0.3564, 0.4539])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5616567134857178 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4106, 0.4470, 0.3575, 0.4543]) \n",
      "Test Loss tensor([0.4115, 0.4488, 0.3549, 0.4531])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6731865406036377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4088, 0.4497, 0.3563, 0.4587]) \n",
      "Test Loss tensor([0.4109, 0.4488, 0.3547, 0.4527])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6644656658172607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4092, 0.4485, 0.3552, 0.4563]) \n",
      "Test Loss tensor([0.4100, 0.4489, 0.3558, 0.4535])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7000594139099121 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4137, 0.4471, 0.3540, 0.4518]) \n",
      "Test Loss tensor([0.4101, 0.4489, 0.3554, 0.4533])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6354672908782959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4094, 0.4519, 0.3543, 0.4512]) \n",
      "Test Loss tensor([0.4094, 0.4497, 0.3550, 0.4539])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6322345733642578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4089, 0.4469, 0.3548, 0.4533]) \n",
      "Test Loss tensor([0.4099, 0.4511, 0.3536, 0.4542])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5926127433776855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4109, 0.4490, 0.3531, 0.4518]) \n",
      "Test Loss tensor([0.4103, 0.4505, 0.3534, 0.4531])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.577674150466919 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4160, 0.4496, 0.3492, 0.4536]) \n",
      "Test Loss tensor([0.4089, 0.4510, 0.3528, 0.4544])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4989438056945801 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4080, 0.4497, 0.3564, 0.4548]) \n",
      "Test Loss tensor([0.4102, 0.4512, 0.3516, 0.4550])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4722154140472412 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4090, 0.4505, 0.3493, 0.4548]) \n",
      "Test Loss tensor([0.4108, 0.4510, 0.3519, 0.4549])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.41851305961608887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4097, 0.4494, 0.3537, 0.4556]) \n",
      "Test Loss tensor([0.4091, 0.4514, 0.3525, 0.4557])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.42885684967041016 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4091, 0.4505, 0.3550, 0.4534]) \n",
      "Test Loss tensor([0.4094, 0.4512, 0.3520, 0.4549])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.42063331604003906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4089, 0.4507, 0.3500, 0.4556]) \n",
      "Test Loss tensor([0.4100, 0.4518, 0.3512, 0.4546])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.42249512672424316 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4075, 0.4528, 0.3492, 0.4573]) \n",
      "Test Loss tensor([0.4090, 0.4513, 0.3517, 0.4561])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4192633628845215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4106, 0.4521, 0.3480, 0.4595]) \n",
      "Test Loss tensor([0.4088, 0.4518, 0.3503, 0.4556])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4370729923248291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4065, 0.4533, 0.3495, 0.4593]) \n",
      "Test Loss tensor([0.4093, 0.4528, 0.3507, 0.4570])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.48045802116394043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4075, 0.4543, 0.3501, 0.4558]) \n",
      "Test Loss tensor([0.4101, 0.4515, 0.3515, 0.4545])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.41433143615722656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4083, 0.4509, 0.3500, 0.4556]) \n",
      "Test Loss tensor([0.4094, 0.4531, 0.3490, 0.4563])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4353952407836914 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4094, 0.4501, 0.3480, 0.4553]) \n",
      "Test Loss tensor([0.4093, 0.4529, 0.3504, 0.4563])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4435279369354248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4080, 0.4518, 0.3464, 0.4572]) \n",
      "Test Loss tensor([0.4083, 0.4520, 0.3498, 0.4552])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5456218719482422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4102, 0.4513, 0.3506, 0.4572]) \n",
      "Test Loss tensor([0.4087, 0.4515, 0.3501, 0.4568])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.47411084175109863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4078, 0.4490, 0.3476, 0.4568]) \n",
      "Test Loss tensor([0.4097, 0.4516, 0.3493, 0.4563])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.47037792205810547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4092, 0.4514, 0.3484, 0.4579]) \n",
      "Test Loss tensor([0.4088, 0.4534, 0.3494, 0.4563])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4511380195617676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4065, 0.4544, 0.3521, 0.4563]) \n",
      "Test Loss tensor([0.4089, 0.4527, 0.3487, 0.4569])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.45680999755859375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4099, 0.4555, 0.3497, 0.4594]) \n",
      "Test Loss tensor([0.4087, 0.4537, 0.3486, 0.4563])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.47858524322509766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4064, 0.4527, 0.3481, 0.4558]) \n",
      "Test Loss tensor([0.4086, 0.4528, 0.3486, 0.4573])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5099377632141113 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4100, 0.4522, 0.3468, 0.4559]) \n",
      "Test Loss tensor([0.4091, 0.4519, 0.3471, 0.4570])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4521830081939697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4093, 0.4523, 0.3497, 0.4560]) \n",
      "Test Loss tensor([0.4069, 0.4544, 0.3475, 0.4570])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4375293254852295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4101, 0.4525, 0.3449, 0.4535]) \n",
      "Test Loss tensor([0.4082, 0.4527, 0.3475, 0.4572])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4577007293701172 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4087, 0.4523, 0.3494, 0.4589]) \n",
      "Test Loss tensor([0.4092, 0.4507, 0.3473, 0.4571])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47369956970214844 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4068, 0.4549, 0.3496, 0.4588]) \n",
      "Test Loss tensor([0.4084, 0.4529, 0.3470, 0.4580])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47150564193725586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4078, 0.4482, 0.3477, 0.4557]) \n",
      "Test Loss tensor([0.4088, 0.4529, 0.3470, 0.4572])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4448819160461426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4120, 0.4549, 0.3447, 0.4582]) \n",
      "Test Loss tensor([0.4076, 0.4533, 0.3468, 0.4582])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.44078636169433594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4055, 0.4588, 0.3465, 0.4608]) \n",
      "Test Loss tensor([0.4076, 0.4527, 0.3474, 0.4571])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4756748676300049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4065, 0.4576, 0.3499, 0.4567]) \n",
      "Test Loss tensor([0.4073, 0.4545, 0.3461, 0.4582])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4676187038421631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4059, 0.4521, 0.3460, 0.4592]) \n",
      "Test Loss tensor([0.4079, 0.4534, 0.3470, 0.4582])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4669156074523926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4094, 0.4536, 0.3494, 0.4581]) \n",
      "Test Loss tensor([0.4077, 0.4524, 0.3463, 0.4575])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5315070152282715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4076, 0.4494, 0.3422, 0.4572]) \n",
      "Test Loss tensor([0.4087, 0.4532, 0.3455, 0.4578])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.46408987045288086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4076, 0.4482, 0.3415, 0.4558]) \n",
      "Test Loss tensor([0.4077, 0.4545, 0.3455, 0.4584])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.44512939453125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4090, 0.4512, 0.3461, 0.4580]) \n",
      "Test Loss tensor([0.4072, 0.4529, 0.3443, 0.4583])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.45356059074401855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4065, 0.4542, 0.3401, 0.4616]) \n",
      "Test Loss tensor([0.4074, 0.4536, 0.3452, 0.4577])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4666566848754883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4064, 0.4488, 0.3469, 0.4573]) \n",
      "Test Loss tensor([0.4081, 0.4524, 0.3448, 0.4574])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.44924163818359375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4080, 0.4550, 0.3449, 0.4581]) \n",
      "Test Loss tensor([0.4079, 0.4526, 0.3447, 0.4571])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4406898021697998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4092, 0.4530, 0.3425, 0.4593]) \n",
      "Test Loss tensor([0.4071, 0.4537, 0.3436, 0.4577])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 360 in 0.4376974105834961 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4038, 0.4516, 0.3478, 0.4613]) \n",
      "Test Loss tensor([0.4077, 0.4539, 0.3440, 0.4582])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.505944013595581 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4068, 0.4559, 0.3437, 0.4610]) \n",
      "Test Loss tensor([0.4079, 0.4523, 0.3447, 0.4562])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4330728054046631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4064, 0.4570, 0.3434, 0.4595]) \n",
      "Test Loss tensor([0.4080, 0.4530, 0.3440, 0.4570])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.47205209732055664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4066, 0.4565, 0.3431, 0.4581]) \n",
      "Test Loss tensor([0.4076, 0.4525, 0.3443, 0.4584])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4558274745941162 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4076, 0.4534, 0.3424, 0.4560]) \n",
      "Test Loss tensor([0.4061, 0.4525, 0.3436, 0.4577])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.45651841163635254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4057, 0.4527, 0.3463, 0.4603]) \n",
      "Test Loss tensor([0.4071, 0.4525, 0.3422, 0.4569])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.45037150382995605 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4069, 0.4535, 0.3432, 0.4584]) \n",
      "Test Loss tensor([0.4062, 0.4526, 0.3423, 0.4576])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4625246524810791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4029, 0.4523, 0.3458, 0.4599]) \n",
      "Test Loss tensor([0.4061, 0.4538, 0.3429, 0.4586])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.45319128036499023 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4078, 0.4540, 0.3406, 0.4612]) \n",
      "Test Loss tensor([0.4057, 0.4529, 0.3428, 0.4579])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.44216322898864746 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4055, 0.4526, 0.3410, 0.4594]) \n",
      "Test Loss tensor([0.4070, 0.4531, 0.3428, 0.4564])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4635653495788574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4035, 0.4548, 0.3438, 0.4597]) \n",
      "Test Loss tensor([0.4057, 0.4522, 0.3428, 0.4570])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5086393356323242 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4053, 0.4520, 0.3436, 0.4593]) \n",
      "Test Loss tensor([0.4065, 0.4518, 0.3412, 0.4558])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.49129223823547363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4078, 0.4528, 0.3402, 0.4559]) \n",
      "Test Loss tensor([0.4067, 0.4519, 0.3407, 0.4566])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4817800521850586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4078, 0.4527, 0.3384, 0.4560]) \n",
      "Test Loss tensor([0.4072, 0.4514, 0.3416, 0.4554])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4383358955383301 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4073, 0.4543, 0.3401, 0.4596]) \n",
      "Test Loss tensor([0.4067, 0.4515, 0.3398, 0.4554])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5277981758117676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4049, 0.4544, 0.3391, 0.4557]) \n",
      "Test Loss tensor([0.4060, 0.4518, 0.3393, 0.4551])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.732337474822998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4041, 0.4481, 0.3427, 0.4566]) \n",
      "Test Loss tensor([0.4063, 0.4516, 0.3392, 0.4554])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6416432857513428 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4044, 0.4514, 0.3393, 0.4562]) \n",
      "Test Loss tensor([0.4056, 0.4514, 0.3395, 0.4553])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6520543098449707 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4080, 0.4516, 0.3404, 0.4572]) \n",
      "Test Loss tensor([0.4065, 0.4507, 0.3398, 0.4548])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6065914630889893 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4042, 0.4479, 0.3367, 0.4548]) \n",
      "Test Loss tensor([0.4049, 0.4490, 0.3388, 0.4540])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6210777759552002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4057, 0.4511, 0.3386, 0.4544]) \n",
      "Test Loss tensor([0.4043, 0.4494, 0.3387, 0.4534])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5712392330169678 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4050, 0.4505, 0.3403, 0.4553]) \n",
      "Test Loss tensor([0.4048, 0.4479, 0.3372, 0.4527])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5626039505004883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4054, 0.4480, 0.3401, 0.4529]) \n",
      "Test Loss tensor([0.4048, 0.4486, 0.3377, 0.4526])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6036267280578613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4028, 0.4481, 0.3367, 0.4569]) \n",
      "Test Loss tensor([0.4054, 0.4472, 0.3368, 0.4519])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6198830604553223 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4064, 0.4481, 0.3369, 0.4527]) \n",
      "Test Loss tensor([0.4046, 0.4474, 0.3362, 0.4510])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6343345642089844 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4047, 0.4467, 0.3360, 0.4533]) \n",
      "Test Loss tensor([0.4042, 0.4471, 0.3367, 0.4503])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5681285858154297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4033, 0.4452, 0.3391, 0.4507]) \n",
      "Test Loss tensor([0.4045, 0.4463, 0.3362, 0.4501])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5563342571258545 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4079, 0.4492, 0.3351, 0.4477]) \n",
      "Test Loss tensor([0.4039, 0.4458, 0.3343, 0.4488])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5401637554168701 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3999, 0.4460, 0.3329, 0.4510]) \n",
      "Test Loss tensor([0.4051, 0.4447, 0.3331, 0.4482])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5839190483093262 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4054, 0.4451, 0.3353, 0.4519]) \n",
      "Test Loss tensor([0.4051, 0.4440, 0.3339, 0.4466])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6417567729949951 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4070, 0.4401, 0.3316, 0.4473]) \n",
      "Test Loss tensor([0.4048, 0.4440, 0.3339, 0.4463])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6095836162567139 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4063, 0.4449, 0.3339, 0.4460]) \n",
      "Test Loss tensor([0.4032, 0.4428, 0.3323, 0.4460])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6022758483886719 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4024, 0.4446, 0.3350, 0.4437]) \n",
      "Test Loss tensor([0.4038, 0.4424, 0.3312, 0.4444])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6185710430145264 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4023, 0.4400, 0.3294, 0.4462]) \n",
      "Test Loss tensor([0.4038, 0.4413, 0.3311, 0.4432])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5514581203460693 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4043, 0.4416, 0.3295, 0.4441]) \n",
      "Test Loss tensor([0.4037, 0.4407, 0.3289, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5102677345275879 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4059, 0.4398, 0.3316, 0.4439]) \n",
      "Test Loss tensor([0.4029, 0.4392, 0.3295, 0.4418])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5083639621734619 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4002, 0.4380, 0.3302, 0.4416]) \n",
      "Test Loss tensor([0.4033, 0.4382, 0.3285, 0.4401])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.503485918045044 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4026, 0.4371, 0.3291, 0.4401]) \n",
      "Test Loss tensor([0.4010, 0.4392, 0.3291, 0.4393])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5051529407501221 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4016, 0.4373, 0.3307, 0.4431]) \n",
      "Test Loss tensor([0.4027, 0.4373, 0.3263, 0.4378])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5022265911102295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4034, 0.4359, 0.3268, 0.4349]) \n",
      "Test Loss tensor([0.4026, 0.4363, 0.3261, 0.4365])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5150618553161621 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3966, 0.4351, 0.3285, 0.4399]) \n",
      "Test Loss tensor([0.4019, 0.4351, 0.3254, 0.4359])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5180385112762451 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4034, 0.4333, 0.3253, 0.4361]) \n",
      "Test Loss tensor([0.4016, 0.4337, 0.3232, 0.4343])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5204849243164062 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4011, 0.4365, 0.3246, 0.4343]) \n",
      "Test Loss tensor([0.4003, 0.4331, 0.3232, 0.4331])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5205428600311279 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4014, 0.4320, 0.3261, 0.4325]) \n",
      "Test Loss tensor([0.4017, 0.4316, 0.3221, 0.4320])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5451114177703857 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4004, 0.4312, 0.3239, 0.4313]) \n",
      "Test Loss tensor([0.4009, 0.4311, 0.3212, 0.4304])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 540 in 0.5254976749420166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4011, 0.4325, 0.3179, 0.4318]) \n",
      "Test Loss tensor([0.4007, 0.4298, 0.3214, 0.4293])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5743727684020996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4006, 0.4256, 0.3227, 0.4294]) \n",
      "Test Loss tensor([0.4008, 0.4282, 0.3183, 0.4281])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6000645160675049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4016, 0.4269, 0.3197, 0.4303]) \n",
      "Test Loss tensor([0.4010, 0.4258, 0.3175, 0.4248])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.553377628326416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4005, 0.4276, 0.3166, 0.4277]) \n",
      "Test Loss tensor([0.3993, 0.4247, 0.3157, 0.4236])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5273697376251221 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3993, 0.4241, 0.3129, 0.4272]) \n",
      "Test Loss tensor([0.3999, 0.4229, 0.3146, 0.4222])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5755667686462402 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.4009, 0.4236, 0.3168, 0.4208]) \n",
      "Test Loss tensor([0.3992, 0.4218, 0.3130, 0.4201])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5283708572387695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3976, 0.4206, 0.3146, 0.4197]) \n",
      "Test Loss tensor([0.3976, 0.4208, 0.3106, 0.4182])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.531832218170166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3942, 0.4220, 0.3122, 0.4192]) \n",
      "Test Loss tensor([0.3982, 0.4181, 0.3102, 0.4159])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5175044536590576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3985, 0.4208, 0.3114, 0.4202]) \n",
      "Test Loss tensor([0.3980, 0.4189, 0.3073, 0.4143])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5260472297668457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3950, 0.4198, 0.3119, 0.4160]) \n",
      "Test Loss tensor([0.3984, 0.4161, 0.3057, 0.4132])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5363926887512207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3982, 0.4187, 0.3128, 0.4149]) \n",
      "Test Loss tensor([0.3978, 0.4150, 0.3038, 0.4109])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5519633293151855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3958, 0.4153, 0.3041, 0.4140]) \n",
      "Test Loss tensor([0.3978, 0.4141, 0.3029, 0.4098])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5631837844848633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3979, 0.4151, 0.3022, 0.4112]) \n",
      "Test Loss tensor([0.3967, 0.4121, 0.3012, 0.4074])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5581014156341553 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3993, 0.4122, 0.3015, 0.4077]) \n",
      "Test Loss tensor([0.3979, 0.4113, 0.2986, 0.4071])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5899147987365723 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3985, 0.4118, 0.3028, 0.4066]) \n",
      "Test Loss tensor([0.3953, 0.4098, 0.2963, 0.4037])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5408496856689453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3947, 0.4053, 0.2974, 0.4022]) \n",
      "Test Loss tensor([0.3953, 0.4078, 0.2940, 0.4027])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5179855823516846 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3958, 0.4095, 0.2974, 0.4079]) \n",
      "Test Loss tensor([0.3950, 0.4052, 0.2929, 0.4002])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5567405223846436 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3920, 0.4061, 0.2959, 0.3958]) \n",
      "Test Loss tensor([0.3940, 0.4048, 0.2909, 0.3984])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5188581943511963 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3962, 0.4006, 0.2874, 0.3984]) \n",
      "Test Loss tensor([0.3933, 0.4025, 0.2870, 0.3960])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5390856266021729 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3967, 0.4056, 0.2873, 0.3976]) \n",
      "Test Loss tensor([0.3928, 0.4010, 0.2843, 0.3941])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5026533603668213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3921, 0.3999, 0.2865, 0.3964]) \n",
      "Test Loss tensor([0.3905, 0.3996, 0.2811, 0.3897])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5381944179534912 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3912, 0.4031, 0.2813, 0.3913]) \n",
      "Test Loss tensor([0.3929, 0.3967, 0.2782, 0.3887])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5364437103271484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3866, 0.4019, 0.2812, 0.3850]) \n",
      "Test Loss tensor([0.3888, 0.3934, 0.2756, 0.3840])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5294842720031738 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3928, 0.3964, 0.2732, 0.3859]) \n",
      "Test Loss tensor([0.3903, 0.3931, 0.2733, 0.3816])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5199604034423828 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3914, 0.3917, 0.2705, 0.3851]) \n",
      "Test Loss tensor([0.3913, 0.3911, 0.2687, 0.3805])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5227031707763672 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3883, 0.3922, 0.2741, 0.3803]) \n",
      "Test Loss tensor([0.3889, 0.3914, 0.2660, 0.3761])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5322535037994385 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3891, 0.3921, 0.2653, 0.3766]) \n",
      "Test Loss tensor([0.3883, 0.3888, 0.2618, 0.3740])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5113255977630615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3815, 0.3812, 0.2609, 0.3717]) \n",
      "Test Loss tensor([0.3893, 0.3876, 0.2590, 0.3724])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.535470724105835 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3928, 0.3877, 0.2596, 0.3763]) \n",
      "Test Loss tensor([0.3894, 0.3862, 0.2554, 0.3705])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5198438167572021 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3926, 0.3895, 0.2553, 0.3716]) \n",
      "Test Loss tensor([0.3872, 0.3835, 0.2500, 0.3662])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5229692459106445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3896, 0.3779, 0.2505, 0.3659]) \n",
      "Test Loss tensor([0.3858, 0.3818, 0.2470, 0.3631])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5299482345581055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3791, 0.3775, 0.2483, 0.3571]) \n",
      "Test Loss tensor([0.3866, 0.3800, 0.2414, 0.3616])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.51405930519104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3840, 0.3797, 0.2426, 0.3566]) \n",
      "Test Loss tensor([0.3856, 0.3804, 0.2379, 0.3589])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6147139072418213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3931, 0.3765, 0.2432, 0.3637]) \n",
      "Test Loss tensor([0.3863, 0.3791, 0.2314, 0.3576])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5674426555633545 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3852, 0.3736, 0.2368, 0.3591]) \n",
      "Test Loss tensor([0.3874, 0.3787, 0.2277, 0.3588])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5893039703369141 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3873, 0.3752, 0.2291, 0.3566]) \n",
      "Test Loss tensor([0.3862, 0.3782, 0.2220, 0.3566])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5462229251861572 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3794, 0.3746, 0.2245, 0.3526]) \n",
      "Test Loss tensor([0.3863, 0.3754, 0.2170, 0.3548])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5429706573486328 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3884, 0.3707, 0.2243, 0.3564]) \n",
      "Test Loss tensor([0.3854, 0.3769, 0.2115, 0.3541])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5690038204193115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3856, 0.3729, 0.2076, 0.3537]) \n",
      "Test Loss tensor([0.3883, 0.3795, 0.2072, 0.3553])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5238502025604248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3834, 0.3724, 0.2082, 0.3580]) \n",
      "Test Loss tensor([0.3853, 0.3779, 0.2011, 0.3515])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5773875713348389 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3937, 0.3650, 0.2077, 0.3641]) \n",
      "Test Loss tensor([0.3886, 0.3772, 0.1989, 0.3566])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5537328720092773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3853, 0.3848, 0.1986, 0.3493]) \n",
      "Test Loss tensor([0.3879, 0.3770, 0.1949, 0.3539])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5909368991851807 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3881, 0.3731, 0.1988, 0.3546]) \n",
      "Test Loss tensor([0.3887, 0.3741, 0.1924, 0.3536])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.569260835647583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3860, 0.3768, 0.1862, 0.3538]) \n",
      "Test Loss tensor([0.3859, 0.3745, 0.1872, 0.3514])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5387320518493652 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3829, 0.3770, 0.1856, 0.3498]) \n",
      "Test Loss tensor([0.3856, 0.3684, 0.1865, 0.3497])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.5325465202331543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3873, 0.3735, 0.1845, 0.3583]) \n",
      "Test Loss tensor([0.3841, 0.3626, 0.1849, 0.3522])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5234763622283936 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3746, 0.3637, 0.1825, 0.3393]) \n",
      "Test Loss tensor([0.3772, 0.3597, 0.1819, 0.3483])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5228714942932129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3701, 0.3526, 0.1881, 0.3409]) \n",
      "Test Loss tensor([0.3694, 0.3491, 0.1821, 0.3426])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5243332386016846 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3794, 0.3520, 0.1838, 0.3472]) \n",
      "Test Loss tensor([0.3589, 0.3325, 0.1785, 0.3452])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5016317367553711 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3515, 0.3334, 0.1809, 0.3459]) \n",
      "Test Loss tensor([0.3367, 0.3070, 0.1772, 0.3445])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5144412517547607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3448, 0.3012, 0.1763, 0.3523]) \n",
      "Test Loss tensor([0.3086, 0.2770, 0.1751, 0.3407])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5216207504272461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.3052, 0.2734, 0.1778, 0.3381]) \n",
      "Test Loss tensor([0.2876, 0.2572, 0.1735, 0.3357])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5498883724212646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2826, 0.2618, 0.1800, 0.3321]) \n",
      "Test Loss tensor([0.2803, 0.2515, 0.1733, 0.3308])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5878517627716064 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2732, 0.2480, 0.1766, 0.3300]) \n",
      "Test Loss tensor([0.2788, 0.2403, 0.1771, 0.3341])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5371968746185303 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2876, 0.2389, 0.1853, 0.3357]) \n",
      "Test Loss tensor([0.2751, 0.2329, 0.1744, 0.3353])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5441794395446777 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2800, 0.2346, 0.1713, 0.3331]) \n",
      "Test Loss tensor([0.2718, 0.2239, 0.1745, 0.3330])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5478925704956055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2772, 0.2203, 0.1721, 0.3410]) \n",
      "Test Loss tensor([0.2639, 0.2153, 0.1737, 0.3319])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5476770401000977 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2657, 0.2104, 0.1753, 0.3310]) \n",
      "Test Loss tensor([0.2537, 0.2111, 0.1690, 0.3262])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5876474380493164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2605, 0.2136, 0.1693, 0.3283]) \n",
      "Test Loss tensor([0.2484, 0.2009, 0.1697, 0.3286])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6236472129821777 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2484, 0.1988, 0.1642, 0.3264]) \n",
      "Test Loss tensor([0.2440, 0.1957, 0.1682, 0.3265])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5833816528320312 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2469, 0.1951, 0.1713, 0.3316]) \n",
      "Test Loss tensor([0.2412, 0.1906, 0.1674, 0.3253])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.49187231063842773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2384, 0.2002, 0.1702, 0.3312]) \n",
      "Test Loss tensor([0.2362, 0.1897, 0.1668, 0.3242])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5083584785461426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2294, 0.1842, 0.1610, 0.3178]) \n",
      "Test Loss tensor([0.2389, 0.1834, 0.1629, 0.3255])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5051791667938232 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2333, 0.1885, 0.1698, 0.3234]) \n",
      "Test Loss tensor([0.2346, 0.1859, 0.1613, 0.3251])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4697437286376953 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2426, 0.1745, 0.1571, 0.3281]) \n",
      "Test Loss tensor([0.2338, 0.1853, 0.1615, 0.3228])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5430605411529541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2279, 0.1836, 0.1491, 0.3163]) \n",
      "Test Loss tensor([0.2336, 0.1846, 0.1597, 0.3229])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5388922691345215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2290, 0.1825, 0.1629, 0.3187]) \n",
      "Test Loss tensor([0.2324, 0.1804, 0.1585, 0.3190])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6633119583129883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2372, 0.1761, 0.1618, 0.3287]) \n",
      "Test Loss tensor([0.2306, 0.1797, 0.1561, 0.3183])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6144289970397949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2232, 0.1914, 0.1492, 0.3127]) \n",
      "Test Loss tensor([0.2308, 0.1809, 0.1530, 0.3127])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5537533760070801 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2230, 0.1759, 0.1609, 0.3164]) \n",
      "Test Loss tensor([0.2273, 0.1809, 0.1512, 0.3101])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5532619953155518 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2320, 0.1773, 0.1550, 0.3241]) \n",
      "Test Loss tensor([0.2242, 0.1813, 0.1519, 0.3070])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4794487953186035 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2145, 0.1748, 0.1531, 0.3088]) \n",
      "Test Loss tensor([0.2232, 0.1778, 0.1486, 0.3037])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4447031021118164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2226, 0.1742, 0.1490, 0.3008]) \n",
      "Test Loss tensor([0.2249, 0.1725, 0.1497, 0.3004])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4597811698913574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2210, 0.1802, 0.1488, 0.2879]) \n",
      "Test Loss tensor([0.2197, 0.1684, 0.1484, 0.2966])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4451265335083008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2235, 0.1689, 0.1510, 0.3041]) \n",
      "Test Loss tensor([0.2176, 0.1623, 0.1471, 0.2810])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4657895565032959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2133, 0.1606, 0.1444, 0.2797]) \n",
      "Test Loss tensor([0.2122, 0.1488, 0.1484, 0.2677])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4557642936706543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2135, 0.1541, 0.1469, 0.2618]) \n",
      "Test Loss tensor([0.2085, 0.1363, 0.1510, 0.2402])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.48139333724975586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2111, 0.1336, 0.1517, 0.2436]) \n",
      "Test Loss tensor([0.2085, 0.1315, 0.1542, 0.1956])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.47844862937927246 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2037, 0.1304, 0.1568, 0.1994]) \n",
      "Test Loss tensor([0.2020, 0.1315, 0.1557, 0.1538])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.502495288848877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2006, 0.1376, 0.1512, 0.1491]) \n",
      "Test Loss tensor([0.2034, 0.1414, 0.1601, 0.1404])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4571194648742676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2026, 0.1417, 0.1648, 0.1434]) \n",
      "Test Loss tensor([0.1967, 0.1542, 0.1613, 0.1384])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.46779775619506836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1973, 0.1543, 0.1609, 0.1338]) \n",
      "Test Loss tensor([0.1946, 0.1634, 0.1638, 0.1424])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4451596736907959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2008, 0.1703, 0.1692, 0.1397]) \n",
      "Test Loss tensor([0.1890, 0.1539, 0.1587, 0.1297])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4835214614868164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.2007, 0.1542, 0.1694, 0.1401]) \n",
      "Test Loss tensor([0.1921, 0.1388, 0.1630, 0.1176])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.43297791481018066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1403, 0.1020, 0.1168, 0.0863]) \n",
      "Test Loss tensor([0.1887, 0.1253, 0.1590, 0.1135])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.4763014316558838 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1857, 0.1284, 0.1560, 0.1098]) \n",
      "Test Loss tensor([0.1832, 0.1155, 0.1566, 0.1103])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4821133613586426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1924, 0.1167, 0.1544, 0.1106]) \n",
      "Test Loss tensor([0.1856, 0.1086, 0.1522, 0.1144])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5115776062011719 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1819, 0.1116, 0.1539, 0.1118]) \n",
      "Test Loss tensor([0.1843, 0.1069, 0.1496, 0.1178])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4535548686981201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1888, 0.1082, 0.1556, 0.1164]) \n",
      "Test Loss tensor([0.1830, 0.1072, 0.1489, 0.1210])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.44930195808410645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1835, 0.0992, 0.1466, 0.1176]) \n",
      "Test Loss tensor([0.1832, 0.1062, 0.1472, 0.1227])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 20 in 0.4401543140411377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1819, 0.1103, 0.1502, 0.1239]) \n",
      "Test Loss tensor([0.1777, 0.1038, 0.1440, 0.1189])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4804830551147461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1739, 0.1023, 0.1420, 0.1190]) \n",
      "Test Loss tensor([0.1803, 0.1008, 0.1459, 0.1198])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4698202610015869 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1775, 0.1061, 0.1460, 0.1185]) \n",
      "Test Loss tensor([0.1737, 0.1012, 0.1435, 0.1137])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4572482109069824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1816, 0.1033, 0.1383, 0.1131]) \n",
      "Test Loss tensor([0.1714, 0.1006, 0.1420, 0.1099])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.465191125869751 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1749, 0.0993, 0.1490, 0.1112]) \n",
      "Test Loss tensor([0.1683, 0.0952, 0.1413, 0.1043])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.44414305686950684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1682, 0.0994, 0.1489, 0.1051]) \n",
      "Test Loss tensor([0.1637, 0.0915, 0.1428, 0.0985])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5076987743377686 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1685, 0.0964, 0.1435, 0.0999]) \n",
      "Test Loss tensor([0.1588, 0.0911, 0.1431, 0.0935])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.43970489501953125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1655, 0.0928, 0.1519, 0.0934]) \n",
      "Test Loss tensor([0.1543, 0.0872, 0.1408, 0.0878])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.49022722244262695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1550, 0.0925, 0.1395, 0.0868]) \n",
      "Test Loss tensor([0.1480, 0.0913, 0.1427, 0.0850])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4274170398712158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1526, 0.0943, 0.1428, 0.0813]) \n",
      "Test Loss tensor([0.1423, 0.0945, 0.1406, 0.0813])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.41495752334594727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1456, 0.0964, 0.1513, 0.0804]) \n",
      "Test Loss tensor([0.1367, 0.0957, 0.1407, 0.0818])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.41688990592956543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1376, 0.0917, 0.1403, 0.0772]) \n",
      "Test Loss tensor([0.1261, 0.0907, 0.1370, 0.0803])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4169323444366455 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1266, 0.0901, 0.1465, 0.0837]) \n",
      "Test Loss tensor([0.1186, 0.0893, 0.1362, 0.0815])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.45308613777160645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1263, 0.0842, 0.1361, 0.0856]) \n",
      "Test Loss tensor([0.1115, 0.0861, 0.1340, 0.0830])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5671627521514893 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1146, 0.0830, 0.1326, 0.0852]) \n",
      "Test Loss tensor([0.0997, 0.0850, 0.1309, 0.0868])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4888279438018799 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.1014, 0.0847, 0.1338, 0.0864]) \n",
      "Test Loss tensor([0.0921, 0.0819, 0.1305, 0.0897])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.47883081436157227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0894, 0.0849, 0.1349, 0.0843]) \n",
      "Test Loss tensor([0.0825, 0.0810, 0.1288, 0.0907])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4224562644958496 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0799, 0.0822, 0.1311, 0.0875]) \n",
      "Test Loss tensor([0.0741, 0.0787, 0.1248, 0.0881])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.41903162002563477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0770, 0.0741, 0.1272, 0.0837]) \n",
      "Test Loss tensor([0.0695, 0.0752, 0.1222, 0.0862])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.413402795791626 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0664, 0.0750, 0.1282, 0.0845]) \n",
      "Test Loss tensor([0.0636, 0.0710, 0.1241, 0.0866])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4713420867919922 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0686, 0.0731, 0.1283, 0.0910]) \n",
      "Test Loss tensor([0.0591, 0.0683, 0.1260, 0.0889])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.43459391593933105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0558, 0.0693, 0.1262, 0.0960]) \n",
      "Test Loss tensor([0.0562, 0.0639, 0.1219, 0.0855])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5698251724243164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0553, 0.0619, 0.1277, 0.0959]) \n",
      "Test Loss tensor([0.0550, 0.0601, 0.1242, 0.0832])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4788687229156494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0537, 0.0591, 0.1289, 0.0771]) \n",
      "Test Loss tensor([0.0536, 0.0570, 0.1230, 0.0818])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6292562484741211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0497, 0.0564, 0.1156, 0.0763]) \n",
      "Test Loss tensor([0.0507, 0.0539, 0.1246, 0.0793])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6367154121398926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0480, 0.0535, 0.1189, 0.0823]) \n",
      "Test Loss tensor([0.0498, 0.0513, 0.1213, 0.0792])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5646495819091797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0478, 0.0483, 0.1237, 0.0793]) \n",
      "Test Loss tensor([0.0494, 0.0478, 0.1207, 0.0774])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.46890902519226074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0450, 0.0467, 0.1286, 0.0722]) \n",
      "Test Loss tensor([0.0471, 0.0441, 0.1227, 0.0755])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4719526767730713 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0502, 0.0439, 0.1240, 0.0773]) \n",
      "Test Loss tensor([0.0476, 0.0416, 0.1220, 0.0769])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.50404953956604 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0451, 0.0418, 0.1226, 0.0683]) \n",
      "Test Loss tensor([0.0453, 0.0403, 0.1186, 0.0732])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.457594633102417 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0454, 0.0395, 0.1108, 0.0751]) \n",
      "Test Loss tensor([0.0458, 0.0369, 0.1177, 0.0732])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5085482597351074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0434, 0.0369, 0.1121, 0.0724]) \n",
      "Test Loss tensor([0.0455, 0.0344, 0.1144, 0.0720])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5186655521392822 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0425, 0.0356, 0.1181, 0.0717]) \n",
      "Test Loss tensor([0.0434, 0.0337, 0.1141, 0.0737])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4899895191192627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0428, 0.0313, 0.1124, 0.0724]) \n",
      "Test Loss tensor([0.0440, 0.0324, 0.1135, 0.0716])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5408923625946045 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0403, 0.0277, 0.1208, 0.0682]) \n",
      "Test Loss tensor([0.0435, 0.0305, 0.1090, 0.0701])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4289979934692383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0439, 0.0296, 0.1170, 0.0752]) \n",
      "Test Loss tensor([0.0441, 0.0299, 0.1079, 0.0698])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.487027645111084 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0437, 0.0269, 0.1096, 0.0763]) \n",
      "Test Loss tensor([0.0435, 0.0292, 0.1063, 0.0702])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.551142692565918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0413, 0.0242, 0.1097, 0.0720]) \n",
      "Test Loss tensor([0.0434, 0.0292, 0.1016, 0.0706])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5391538143157959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0454, 0.0345, 0.1108, 0.0707]) \n",
      "Test Loss tensor([0.0418, 0.0286, 0.1045, 0.0694])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5602686405181885 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0428, 0.0280, 0.1078, 0.0644]) \n",
      "Test Loss tensor([0.0435, 0.0285, 0.0994, 0.0673])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6038649082183838 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0388, 0.0286, 0.1037, 0.0642]) \n",
      "Test Loss tensor([0.0434, 0.0275, 0.0972, 0.0674])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5509002208709717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0410, 0.0317, 0.1003, 0.0733]) \n",
      "Test Loss tensor([0.0426, 0.0277, 0.0976, 0.0645])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47702550888061523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0438, 0.0226, 0.0967, 0.0639]) \n",
      "Test Loss tensor([0.0414, 0.0268, 0.0932, 0.0646])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4937903881072998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0405, 0.0295, 0.0984, 0.0746]) \n",
      "Test Loss tensor([0.0423, 0.0271, 0.0912, 0.0623])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.44323062896728516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0389, 0.0261, 0.0933, 0.0631]) \n",
      "Test Loss tensor([0.0413, 0.0269, 0.0919, 0.0622])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 200 in 0.47280144691467285 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0400, 0.0273, 0.0921, 0.0633]) \n",
      "Test Loss tensor([0.0415, 0.0268, 0.0914, 0.0632])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.49572324752807617 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0396, 0.0271, 0.0935, 0.0614]) \n",
      "Test Loss tensor([0.0403, 0.0254, 0.0882, 0.0617])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5776612758636475 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0401, 0.0264, 0.0955, 0.0727]) \n",
      "Test Loss tensor([0.0428, 0.0271, 0.0862, 0.0619])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5547013282775879 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0448, 0.0280, 0.0864, 0.0573]) \n",
      "Test Loss tensor([0.0415, 0.0264, 0.0856, 0.0609])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.46498870849609375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0395, 0.0238, 0.0831, 0.0513]) \n",
      "Test Loss tensor([0.0416, 0.0257, 0.0852, 0.0577])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.45682334899902344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0402, 0.0262, 0.0905, 0.0617]) \n",
      "Test Loss tensor([0.0424, 0.0259, 0.0825, 0.0592])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.48389410972595215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0436, 0.0269, 0.0814, 0.0640]) \n",
      "Test Loss tensor([0.0422, 0.0256, 0.0831, 0.0599])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.43668174743652344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0457, 0.0255, 0.0812, 0.0572]) \n",
      "Test Loss tensor([0.0409, 0.0256, 0.0810, 0.0564])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4278228282928467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0405, 0.0236, 0.0787, 0.0615]) \n",
      "Test Loss tensor([0.0415, 0.0252, 0.0810, 0.0580])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.45180702209472656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0403, 0.0232, 0.0771, 0.0477]) \n",
      "Test Loss tensor([0.0427, 0.0250, 0.0784, 0.0555])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.48376893997192383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0427, 0.0232, 0.0846, 0.0560]) \n",
      "Test Loss tensor([0.0420, 0.0243, 0.0785, 0.0562])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5094215869903564 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0419, 0.0232, 0.0790, 0.0577]) \n",
      "Test Loss tensor([0.0421, 0.0236, 0.0773, 0.0580])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5393445491790771 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0429, 0.0230, 0.0806, 0.0565]) \n",
      "Test Loss tensor([0.0437, 0.0241, 0.0770, 0.0553])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5724391937255859 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0416, 0.0213, 0.0758, 0.0531]) \n",
      "Test Loss tensor([0.0420, 0.0229, 0.0724, 0.0534])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5396339893341064 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0430, 0.0223, 0.0714, 0.0500]) \n",
      "Test Loss tensor([0.0427, 0.0233, 0.0723, 0.0531])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6272635459899902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0426, 0.0232, 0.0735, 0.0526]) \n",
      "Test Loss tensor([0.0414, 0.0230, 0.0717, 0.0520])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.7219648361206055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0417, 0.0203, 0.0676, 0.0484]) \n",
      "Test Loss tensor([0.0427, 0.0229, 0.0700, 0.0506])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5268006324768066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0464, 0.0226, 0.0681, 0.0489]) \n",
      "Test Loss tensor([0.0426, 0.0227, 0.0676, 0.0524])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5314381122589111 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0457, 0.0233, 0.0656, 0.0465]) \n",
      "Test Loss tensor([0.0424, 0.0225, 0.0670, 0.0522])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5140683650970459 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0418, 0.0237, 0.0656, 0.0489]) \n",
      "Test Loss tensor([0.0420, 0.0229, 0.0652, 0.0509])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5135648250579834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0420, 0.0223, 0.0613, 0.0468]) \n",
      "Test Loss tensor([0.0424, 0.0218, 0.0654, 0.0517])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.46794724464416504 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0450, 0.0236, 0.0658, 0.0522]) \n",
      "Test Loss tensor([0.0431, 0.0216, 0.0622, 0.0491])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4296867847442627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0398, 0.0192, 0.0657, 0.0459]) \n",
      "Test Loss tensor([0.0429, 0.0210, 0.0618, 0.0495])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4258918762207031 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0440, 0.0211, 0.0582, 0.0484]) \n",
      "Test Loss tensor([0.0430, 0.0204, 0.0606, 0.0484])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4262425899505615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0404, 0.0223, 0.0548, 0.0464]) \n",
      "Test Loss tensor([0.0423, 0.0214, 0.0584, 0.0481])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.44585704803466797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0402, 0.0208, 0.0602, 0.0496]) \n",
      "Test Loss tensor([0.0423, 0.0202, 0.0560, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.45035576820373535 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0419, 0.0210, 0.0591, 0.0552]) \n",
      "Test Loss tensor([0.0419, 0.0200, 0.0540, 0.0477])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4365661144256592 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0412, 0.0211, 0.0571, 0.0407]) \n",
      "Test Loss tensor([0.0412, 0.0205, 0.0537, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4637577533721924 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0404, 0.0189, 0.0501, 0.0444]) \n",
      "Test Loss tensor([0.0415, 0.0200, 0.0533, 0.0472])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.46602582931518555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0434, 0.0186, 0.0483, 0.0426]) \n",
      "Test Loss tensor([0.0410, 0.0201, 0.0517, 0.0463])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.507159948348999 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0379, 0.0183, 0.0554, 0.0429]) \n",
      "Test Loss tensor([0.0399, 0.0197, 0.0520, 0.0458])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5607249736785889 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0395, 0.0178, 0.0484, 0.0438]) \n",
      "Test Loss tensor([0.0402, 0.0202, 0.0496, 0.0454])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4915316104888916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0411, 0.0201, 0.0497, 0.0440]) \n",
      "Test Loss tensor([0.0395, 0.0200, 0.0496, 0.0440])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.49244022369384766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0407, 0.0210, 0.0490, 0.0468]) \n",
      "Test Loss tensor([0.0416, 0.0200, 0.0482, 0.0443])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5161385536193848 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0396, 0.0193, 0.0442, 0.0456]) \n",
      "Test Loss tensor([0.0399, 0.0195, 0.0496, 0.0443])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5170867443084717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0370, 0.0199, 0.0453, 0.0379]) \n",
      "Test Loss tensor([0.0404, 0.0201, 0.0462, 0.0443])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5269598960876465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0391, 0.0183, 0.0434, 0.0485]) \n",
      "Test Loss tensor([0.0403, 0.0195, 0.0445, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5211379528045654 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0397, 0.0187, 0.0430, 0.0458]) \n",
      "Test Loss tensor([0.0409, 0.0196, 0.0438, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4909517765045166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0396, 0.0175, 0.0434, 0.0416]) \n",
      "Test Loss tensor([0.0399, 0.0184, 0.0439, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5109915733337402 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0416, 0.0196, 0.0420, 0.0398]) \n",
      "Test Loss tensor([0.0402, 0.0189, 0.0436, 0.0414])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5073590278625488 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0369, 0.0193, 0.0448, 0.0409]) \n",
      "Test Loss tensor([0.0385, 0.0190, 0.0421, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4966883659362793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0379, 0.0168, 0.0407, 0.0392]) \n",
      "Test Loss tensor([0.0391, 0.0188, 0.0416, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.46894121170043945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0351, 0.0198, 0.0441, 0.0401]) \n",
      "Test Loss tensor([0.0391, 0.0191, 0.0423, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.47338390350341797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0367, 0.0205, 0.0417, 0.0384]) \n",
      "Test Loss tensor([0.0380, 0.0188, 0.0403, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.473529577255249 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0392, 0.0189, 0.0408, 0.0377]) \n",
      "Test Loss tensor([0.0380, 0.0189, 0.0392, 0.0394])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 380 in 0.47976088523864746 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0387, 0.0218, 0.0376, 0.0338]) \n",
      "Test Loss tensor([0.0379, 0.0190, 0.0401, 0.0387])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4608490467071533 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0395, 0.0178, 0.0379, 0.0360]) \n",
      "Test Loss tensor([0.0387, 0.0193, 0.0385, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5243937969207764 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0368, 0.0193, 0.0355, 0.0353]) \n",
      "Test Loss tensor([0.0381, 0.0188, 0.0416, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.44870424270629883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0386, 0.0185, 0.0375, 0.0361]) \n",
      "Test Loss tensor([0.0376, 0.0195, 0.0373, 0.0388])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5684492588043213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0352, 0.0187, 0.0365, 0.0421]) \n",
      "Test Loss tensor([0.0359, 0.0192, 0.0386, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6379294395446777 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0370, 0.0193, 0.0395, 0.0334]) \n",
      "Test Loss tensor([0.0368, 0.0191, 0.0379, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5948135852813721 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0342, 0.0206, 0.0387, 0.0372]) \n",
      "Test Loss tensor([0.0367, 0.0196, 0.0373, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5254523754119873 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0385, 0.0194, 0.0351, 0.0378]) \n",
      "Test Loss tensor([0.0359, 0.0182, 0.0389, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5262477397918701 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0373, 0.0190, 0.0379, 0.0351]) \n",
      "Test Loss tensor([0.0356, 0.0187, 0.0388, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5118544101715088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0325, 0.0192, 0.0348, 0.0378]) \n",
      "Test Loss tensor([0.0358, 0.0192, 0.0374, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6573886871337891 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0321, 0.0175, 0.0398, 0.0359]) \n",
      "Test Loss tensor([0.0366, 0.0190, 0.0378, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.44557690620422363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0344, 0.0189, 0.0364, 0.0376]) \n",
      "Test Loss tensor([0.0356, 0.0192, 0.0365, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.48883581161499023 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0394, 0.0187, 0.0326, 0.0361]) \n",
      "Test Loss tensor([0.0357, 0.0197, 0.0362, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5598361492156982 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0339, 0.0201, 0.0349, 0.0292]) \n",
      "Test Loss tensor([0.0359, 0.0200, 0.0367, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.48637843132019043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0311, 0.0186, 0.0399, 0.0339]) \n",
      "Test Loss tensor([0.0351, 0.0194, 0.0381, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5560548305511475 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0344, 0.0205, 0.0360, 0.0320]) \n",
      "Test Loss tensor([0.0360, 0.0210, 0.0376, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5135838985443115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0363, 0.0199, 0.0344, 0.0333]) \n",
      "Test Loss tensor([0.0352, 0.0203, 0.0356, 0.0335])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.532045841217041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0355, 0.0191, 0.0354, 0.0320]) \n",
      "Test Loss tensor([0.0362, 0.0193, 0.0362, 0.0329])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5777268409729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0357, 0.0191, 0.0327, 0.0324]) \n",
      "Test Loss tensor([0.0356, 0.0190, 0.0352, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5484817028045654 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0369, 0.0188, 0.0332, 0.0325]) \n",
      "Test Loss tensor([0.0352, 0.0191, 0.0350, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.596771240234375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0350, 0.0191, 0.0332, 0.0317]) \n",
      "Test Loss tensor([0.0353, 0.0193, 0.0353, 0.0324])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5748355388641357 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0326, 0.0192, 0.0364, 0.0332]) \n",
      "Test Loss tensor([0.0338, 0.0195, 0.0355, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5930531024932861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0321, 0.0196, 0.0330, 0.0301]) \n",
      "Test Loss tensor([0.0341, 0.0196, 0.0364, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5501139163970947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0370, 0.0186, 0.0387, 0.0300]) \n",
      "Test Loss tensor([0.0342, 0.0200, 0.0354, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5644235610961914 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0327, 0.0196, 0.0332, 0.0274]) \n",
      "Test Loss tensor([0.0350, 0.0202, 0.0364, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.46077919006347656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0340, 0.0192, 0.0338, 0.0279]) \n",
      "Test Loss tensor([0.0337, 0.0202, 0.0352, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5787339210510254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0336, 0.0195, 0.0330, 0.0303]) \n",
      "Test Loss tensor([0.0349, 0.0197, 0.0348, 0.0297])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5719070434570312 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0305, 0.0186, 0.0346, 0.0305]) \n",
      "Test Loss tensor([0.0345, 0.0182, 0.0343, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5163919925689697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0311, 0.0181, 0.0335, 0.0286]) \n",
      "Test Loss tensor([0.0344, 0.0183, 0.0341, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.4961090087890625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0332, 0.0186, 0.0351, 0.0279]) \n",
      "Test Loss tensor([0.0346, 0.0180, 0.0344, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.49852585792541504 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0314, 0.0194, 0.0335, 0.0276]) \n",
      "Test Loss tensor([0.0336, 0.0184, 0.0353, 0.0287])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5324206352233887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0330, 0.0194, 0.0329, 0.0267]) \n",
      "Test Loss tensor([0.0344, 0.0184, 0.0351, 0.0285])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.49619531631469727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0329, 0.0208, 0.0336, 0.0276]) \n",
      "Test Loss tensor([0.0336, 0.0179, 0.0345, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5186254978179932 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0308, 0.0201, 0.0356, 0.0230]) \n",
      "Test Loss tensor([0.0337, 0.0180, 0.0347, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.42209768295288086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0302, 0.0178, 0.0343, 0.0265]) \n",
      "Test Loss tensor([0.0331, 0.0173, 0.0348, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.42324113845825195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0311, 0.0178, 0.0352, 0.0287]) \n",
      "Test Loss tensor([0.0333, 0.0178, 0.0343, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4197108745574951 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0328, 0.0175, 0.0330, 0.0297]) \n",
      "Test Loss tensor([0.0330, 0.0180, 0.0339, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.43484067916870117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0326, 0.0161, 0.0360, 0.0285]) \n",
      "Test Loss tensor([0.0329, 0.0177, 0.0359, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.48133015632629395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0332, 0.0164, 0.0378, 0.0254]) \n",
      "Test Loss tensor([0.0326, 0.0182, 0.0359, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5769319534301758 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0352, 0.0190, 0.0354, 0.0232]) \n",
      "Test Loss tensor([0.0326, 0.0181, 0.0342, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5553629398345947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0308, 0.0178, 0.0313, 0.0254]) \n",
      "Test Loss tensor([0.0335, 0.0174, 0.0331, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5692389011383057 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0314, 0.0189, 0.0316, 0.0251]) \n",
      "Test Loss tensor([0.0329, 0.0173, 0.0336, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5331075191497803 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0311, 0.0162, 0.0328, 0.0241]) \n",
      "Test Loss tensor([0.0337, 0.0163, 0.0334, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.49594855308532715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0343, 0.0177, 0.0337, 0.0259]) \n",
      "Test Loss tensor([0.0338, 0.0171, 0.0334, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4324207305908203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0187, 0.0322, 0.0242]) \n",
      "Test Loss tensor([0.0321, 0.0165, 0.0341, 0.0239])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 560 in 0.42973971366882324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0303, 0.0175, 0.0328, 0.0224]) \n",
      "Test Loss tensor([0.0325, 0.0173, 0.0326, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4227428436279297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0340, 0.0169, 0.0324, 0.0243]) \n",
      "Test Loss tensor([0.0319, 0.0176, 0.0336, 0.0237])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.42694950103759766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0351, 0.0160, 0.0303, 0.0204]) \n",
      "Test Loss tensor([0.0317, 0.0172, 0.0355, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.42528223991394043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0346, 0.0160, 0.0331, 0.0245]) \n",
      "Test Loss tensor([0.0322, 0.0174, 0.0344, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.435945987701416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0308, 0.0170, 0.0322, 0.0229]) \n",
      "Test Loss tensor([0.0328, 0.0178, 0.0329, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.42611193656921387 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0330, 0.0160, 0.0322, 0.0221]) \n",
      "Test Loss tensor([0.0314, 0.0167, 0.0327, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.42406606674194336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0317, 0.0173, 0.0341, 0.0238]) \n",
      "Test Loss tensor([0.0314, 0.0166, 0.0323, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4272279739379883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0311, 0.0151, 0.0304, 0.0228]) \n",
      "Test Loss tensor([0.0316, 0.0167, 0.0325, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.43969035148620605 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0296, 0.0165, 0.0332, 0.0257]) \n",
      "Test Loss tensor([0.0308, 0.0168, 0.0331, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.43540167808532715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0304, 0.0156, 0.0317, 0.0210]) \n",
      "Test Loss tensor([0.0320, 0.0174, 0.0323, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.42498016357421875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0291, 0.0174, 0.0298, 0.0225]) \n",
      "Test Loss tensor([0.0316, 0.0173, 0.0324, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4263648986816406 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0173, 0.0301, 0.0223]) \n",
      "Test Loss tensor([0.0322, 0.0168, 0.0323, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4207587242126465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0154, 0.0294, 0.0233]) \n",
      "Test Loss tensor([0.0314, 0.0164, 0.0331, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4346160888671875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0333, 0.0180, 0.0301, 0.0200]) \n",
      "Test Loss tensor([0.0317, 0.0164, 0.0319, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.42330384254455566 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0293, 0.0167, 0.0310, 0.0223]) \n",
      "Test Loss tensor([0.0313, 0.0163, 0.0320, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.42359423637390137 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0290, 0.0164, 0.0320, 0.0225]) \n",
      "Test Loss tensor([0.0312, 0.0165, 0.0314, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4267995357513428 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0304, 0.0170, 0.0312, 0.0201]) \n",
      "Test Loss tensor([0.0316, 0.0158, 0.0315, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4263126850128174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0278, 0.0162, 0.0320, 0.0197]) \n",
      "Test Loss tensor([0.0313, 0.0163, 0.0321, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.423020601272583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0301, 0.0167, 0.0297, 0.0223]) \n",
      "Test Loss tensor([0.0309, 0.0165, 0.0325, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.42652058601379395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0320, 0.0176, 0.0304, 0.0207]) \n",
      "Test Loss tensor([0.0316, 0.0161, 0.0313, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.43828463554382324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0325, 0.0142, 0.0293, 0.0211]) \n",
      "Test Loss tensor([0.0308, 0.0162, 0.0315, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4230155944824219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0275, 0.0166, 0.0335, 0.0200]) \n",
      "Test Loss tensor([0.0301, 0.0161, 0.0307, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4915201663970947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0323, 0.0161, 0.0363, 0.0218]) \n",
      "Test Loss tensor([0.0313, 0.0162, 0.0310, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.48687005043029785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0299, 0.0146, 0.0331, 0.0203]) \n",
      "Test Loss tensor([0.0313, 0.0164, 0.0318, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4928159713745117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0295, 0.0161, 0.0331, 0.0204]) \n",
      "Test Loss tensor([0.0303, 0.0158, 0.0319, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5753037929534912 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0317, 0.0174, 0.0302, 0.0200]) \n",
      "Test Loss tensor([0.0303, 0.0162, 0.0317, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5246474742889404 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0150, 0.0309, 0.0189]) \n",
      "Test Loss tensor([0.0313, 0.0162, 0.0309, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5580503940582275 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0283, 0.0147, 0.0301, 0.0202]) \n",
      "Test Loss tensor([0.0302, 0.0164, 0.0313, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5303153991699219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0260, 0.0168, 0.0286, 0.0200]) \n",
      "Test Loss tensor([0.0310, 0.0162, 0.0308, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5244936943054199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0309, 0.0163, 0.0294, 0.0203]) \n",
      "Test Loss tensor([0.0302, 0.0162, 0.0312, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.583855152130127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0293, 0.0152, 0.0321, 0.0237]) \n",
      "Test Loss tensor([0.0303, 0.0161, 0.0303, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.47679758071899414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0287, 0.0167, 0.0300, 0.0206]) \n",
      "Test Loss tensor([0.0298, 0.0162, 0.0305, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4218769073486328 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0287, 0.0155, 0.0277, 0.0194]) \n",
      "Test Loss tensor([0.0309, 0.0164, 0.0301, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.42194366455078125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0306, 0.0172, 0.0314, 0.0218]) \n",
      "Test Loss tensor([0.0303, 0.0164, 0.0307, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4218788146972656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0299, 0.0172, 0.0289, 0.0195]) \n",
      "Test Loss tensor([0.0298, 0.0165, 0.0302, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4524695873260498 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0170, 0.0280, 0.0201]) \n",
      "Test Loss tensor([0.0301, 0.0165, 0.0299, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5214660167694092 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0279, 0.0162, 0.0303, 0.0205]) \n",
      "Test Loss tensor([0.0297, 0.0162, 0.0299, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5105879306793213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0302, 0.0163, 0.0277, 0.0185]) \n",
      "Test Loss tensor([0.0292, 0.0161, 0.0292, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.546344518661499 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0303, 0.0170, 0.0296, 0.0190]) \n",
      "Test Loss tensor([0.0304, 0.0160, 0.0292, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4865760803222656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0339, 0.0170, 0.0293, 0.0200]) \n",
      "Test Loss tensor([0.0304, 0.0159, 0.0296, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4818997383117676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0302, 0.0160, 0.0283, 0.0215]) \n",
      "Test Loss tensor([0.0296, 0.0162, 0.0296, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.45319056510925293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0289, 0.0174, 0.0266, 0.0184]) \n",
      "Test Loss tensor([0.0307, 0.0163, 0.0282, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5204401016235352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0266, 0.0159, 0.0289, 0.0194]) \n",
      "Test Loss tensor([0.0297, 0.0162, 0.0295, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5758976936340332 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0340, 0.0170, 0.0311, 0.0213]) \n",
      "Test Loss tensor([0.0296, 0.0169, 0.0285, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5310919284820557 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0305, 0.0153, 0.0282, 0.0217]) \n",
      "Test Loss tensor([0.0291, 0.0166, 0.0301, 0.0197])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 740 in 0.4842803478240967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0283, 0.0174, 0.0278, 0.0173]) \n",
      "Test Loss tensor([0.0292, 0.0158, 0.0287, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.545621395111084 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0279, 0.0163, 0.0272, 0.0195]) \n",
      "Test Loss tensor([0.0281, 0.0160, 0.0294, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.484485387802124 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0306, 0.0176, 0.0305, 0.0198]) \n",
      "Test Loss tensor([0.0290, 0.0153, 0.0297, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.48317408561706543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0293, 0.0151, 0.0265, 0.0197]) \n",
      "Test Loss tensor([0.0289, 0.0155, 0.0289, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5145330429077148 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0312, 0.0159, 0.0278, 0.0196]) \n",
      "Test Loss tensor([0.0287, 0.0154, 0.0289, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.486922025680542 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0285, 0.0153, 0.0286, 0.0199]) \n",
      "Test Loss tensor([0.0283, 0.0158, 0.0287, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5060882568359375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0260, 0.0149, 0.0277, 0.0164]) \n",
      "Test Loss tensor([0.0275, 0.0155, 0.0291, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5213515758514404 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0269, 0.0146, 0.0289, 0.0197]) \n",
      "Test Loss tensor([0.0288, 0.0159, 0.0293, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5653860569000244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0294, 0.0178, 0.0263, 0.0198]) \n",
      "Test Loss tensor([0.0274, 0.0158, 0.0293, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.61521315574646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0288, 0.0146, 0.0317, 0.0188]) \n",
      "Test Loss tensor([0.0279, 0.0162, 0.0298, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6584455966949463 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0288, 0.0156, 0.0267, 0.0203]) \n",
      "Test Loss tensor([0.0293, 0.0161, 0.0286, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5023288726806641 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0158, 0.0270, 0.0208]) \n",
      "Test Loss tensor([0.0280, 0.0157, 0.0288, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4969327449798584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0276, 0.0163, 0.0258, 0.0180]) \n",
      "Test Loss tensor([0.0287, 0.0156, 0.0277, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.48757457733154297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0280, 0.0163, 0.0267, 0.0201]) \n",
      "Test Loss tensor([0.0284, 0.0158, 0.0279, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47407078742980957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0267, 0.0154, 0.0292, 0.0199]) \n",
      "Test Loss tensor([0.0282, 0.0155, 0.0285, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.578078031539917 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0278, 0.0149, 0.0286, 0.0193]) \n",
      "Test Loss tensor([0.0286, 0.0155, 0.0277, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.43690919876098633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0145, 0.0267, 0.0177]) \n",
      "Test Loss tensor([0.0283, 0.0150, 0.0282, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.479931116104126 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0283, 0.0159, 0.0252, 0.0198]) \n",
      "Test Loss tensor([0.0287, 0.0156, 0.0278, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5344703197479248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0289, 0.0161, 0.0264, 0.0175]) \n",
      "Test Loss tensor([0.0281, 0.0151, 0.0268, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5668833255767822 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0257, 0.0162, 0.0273, 0.0189]) \n",
      "Test Loss tensor([0.0284, 0.0157, 0.0278, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.511991024017334 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0277, 0.0148, 0.0257, 0.0185]) \n",
      "Test Loss tensor([0.0279, 0.0156, 0.0279, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5757994651794434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0270, 0.0149, 0.0281, 0.0219]) \n",
      "Test Loss tensor([0.0286, 0.0160, 0.0271, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6025333404541016 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0275, 0.0156, 0.0295, 0.0187]) \n",
      "Test Loss tensor([0.0280, 0.0156, 0.0283, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.49422121047973633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0263, 0.0172, 0.0270, 0.0189]) \n",
      "Test Loss tensor([0.0283, 0.0159, 0.0272, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.527031660079956 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0298, 0.0150, 0.0255, 0.0183]) \n",
      "Test Loss tensor([0.0284, 0.0154, 0.0275, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5741128921508789 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0282, 0.0164, 0.0279, 0.0186]) \n",
      "Test Loss tensor([0.0273, 0.0156, 0.0283, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.46384286880493164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0274, 0.0155, 0.0267, 0.0182]) \n",
      "Test Loss tensor([0.0283, 0.0153, 0.0264, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5805623531341553 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0283, 0.0155, 0.0262, 0.0169]) \n",
      "Test Loss tensor([0.0269, 0.0154, 0.0274, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4998302459716797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0301, 0.0163, 0.0245, 0.0182]) \n",
      "Test Loss tensor([0.0280, 0.0154, 0.0278, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47847628593444824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0266, 0.0154, 0.0235, 0.0171]) \n",
      "Test Loss tensor([0.0270, 0.0156, 0.0268, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.42580342292785645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0273, 0.0141, 0.0266, 0.0179]) \n",
      "Test Loss tensor([0.0273, 0.0156, 0.0271, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4855813980102539 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0259, 0.0141, 0.0272, 0.0163]) \n",
      "Test Loss tensor([0.0277, 0.0160, 0.0276, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47768330574035645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0267, 0.0153, 0.0268, 0.0175]) \n",
      "Test Loss tensor([0.0271, 0.0154, 0.0273, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4280538558959961 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0282, 0.0171, 0.0277, 0.0170]) \n",
      "Test Loss tensor([0.0275, 0.0152, 0.0264, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.42859506607055664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0187, 0.0125, 0.0192, 0.0130]) \n",
      "Test Loss tensor([0.0273, 0.0151, 0.0263, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.4453108310699463 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0264, 0.0151, 0.0250, 0.0163]) \n",
      "Test Loss tensor([0.0276, 0.0152, 0.0263, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.42566561698913574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0296, 0.0169, 0.0283, 0.0212]) \n",
      "Test Loss tensor([0.0277, 0.0157, 0.0260, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4230380058288574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0244, 0.0168, 0.0265, 0.0168]) \n",
      "Test Loss tensor([0.0275, 0.0152, 0.0272, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.42488694190979004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0275, 0.0157, 0.0264, 0.0172]) \n",
      "Test Loss tensor([0.0271, 0.0156, 0.0259, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4249401092529297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0269, 0.0138, 0.0282, 0.0175]) \n",
      "Test Loss tensor([0.0273, 0.0153, 0.0257, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.41905641555786133 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0285, 0.0146, 0.0278, 0.0187]) \n",
      "Test Loss tensor([0.0265, 0.0154, 0.0265, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.42417383193969727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0246, 0.0137, 0.0297, 0.0163]) \n",
      "Test Loss tensor([0.0269, 0.0156, 0.0260, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4211087226867676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0278, 0.0157, 0.0281, 0.0199]) \n",
      "Test Loss tensor([0.0273, 0.0154, 0.0259, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4213416576385498 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0256, 0.0142, 0.0279, 0.0168]) \n",
      "Test Loss tensor([0.0275, 0.0153, 0.0271, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.42417311668395996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0272, 0.0159, 0.0260, 0.0204]) \n",
      "Test Loss tensor([0.0278, 0.0152, 0.0263, 0.0182])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 40 in 0.4217073917388916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0268, 0.0142, 0.0265, 0.0181]) \n",
      "Test Loss tensor([0.0271, 0.0152, 0.0271, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5125246047973633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0250, 0.0134, 0.0282, 0.0164]) \n",
      "Test Loss tensor([0.0263, 0.0149, 0.0262, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5152380466461182 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0263, 0.0146, 0.0249, 0.0169]) \n",
      "Test Loss tensor([0.0262, 0.0150, 0.0264, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.49943065643310547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0239, 0.0158, 0.0261, 0.0166]) \n",
      "Test Loss tensor([0.0266, 0.0153, 0.0266, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5000095367431641 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0282, 0.0147, 0.0242, 0.0167]) \n",
      "Test Loss tensor([0.0266, 0.0156, 0.0258, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.49236178398132324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0266, 0.0160, 0.0256, 0.0167]) \n",
      "Test Loss tensor([0.0266, 0.0156, 0.0260, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5777647495269775 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0246, 0.0146, 0.0267, 0.0172]) \n",
      "Test Loss tensor([0.0260, 0.0156, 0.0264, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6105587482452393 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0237, 0.0150, 0.0241, 0.0160]) \n",
      "Test Loss tensor([0.0267, 0.0154, 0.0254, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5508568286895752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0297, 0.0165, 0.0232, 0.0171]) \n",
      "Test Loss tensor([0.0265, 0.0151, 0.0260, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.42833662033081055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0281, 0.0157, 0.0250, 0.0179]) \n",
      "Test Loss tensor([0.0268, 0.0151, 0.0253, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5294876098632812 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0247, 0.0160, 0.0275, 0.0180]) \n",
      "Test Loss tensor([0.0260, 0.0147, 0.0260, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5884342193603516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0264, 0.0152, 0.0253, 0.0173]) \n",
      "Test Loss tensor([0.0272, 0.0153, 0.0260, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6374020576477051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0269, 0.0140, 0.0239, 0.0173]) \n",
      "Test Loss tensor([0.0260, 0.0155, 0.0266, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.48667454719543457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0267, 0.0150, 0.0278, 0.0160]) \n",
      "Test Loss tensor([0.0264, 0.0150, 0.0260, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5727357864379883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0269, 0.0157, 0.0288, 0.0175]) \n",
      "Test Loss tensor([0.0262, 0.0151, 0.0256, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5602724552154541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0257, 0.0159, 0.0238, 0.0185]) \n",
      "Test Loss tensor([0.0260, 0.0150, 0.0261, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5008876323699951 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0300, 0.0133, 0.0264, 0.0178]) \n",
      "Test Loss tensor([0.0262, 0.0151, 0.0254, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5544614791870117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0257, 0.0166, 0.0235, 0.0172]) \n",
      "Test Loss tensor([0.0262, 0.0149, 0.0257, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5486645698547363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0263, 0.0140, 0.0254, 0.0152]) \n",
      "Test Loss tensor([0.0255, 0.0150, 0.0257, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6066117286682129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0264, 0.0148, 0.0264, 0.0162]) \n",
      "Test Loss tensor([0.0264, 0.0151, 0.0256, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.511772871017456 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0231, 0.0144, 0.0240, 0.0193]) \n",
      "Test Loss tensor([0.0261, 0.0151, 0.0248, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5161995887756348 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0270, 0.0163, 0.0232, 0.0174]) \n",
      "Test Loss tensor([0.0255, 0.0150, 0.0252, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.42696690559387207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0296, 0.0167, 0.0232, 0.0149]) \n",
      "Test Loss tensor([0.0258, 0.0150, 0.0251, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4361696243286133 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0244, 0.0161, 0.0269, 0.0186]) \n",
      "Test Loss tensor([0.0248, 0.0150, 0.0251, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5372335910797119 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0249, 0.0160, 0.0252, 0.0153]) \n",
      "Test Loss tensor([0.0250, 0.0154, 0.0256, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5715007781982422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0261, 0.0174, 0.0268, 0.0183]) \n",
      "Test Loss tensor([0.0255, 0.0153, 0.0252, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.448336124420166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0269, 0.0158, 0.0242, 0.0164]) \n",
      "Test Loss tensor([0.0255, 0.0149, 0.0246, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4357907772064209 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0273, 0.0134, 0.0239, 0.0153]) \n",
      "Test Loss tensor([0.0262, 0.0150, 0.0253, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5665278434753418 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0259, 0.0153, 0.0243, 0.0151]) \n",
      "Test Loss tensor([0.0248, 0.0151, 0.0247, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.46784448623657227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0230, 0.0159, 0.0255, 0.0172]) \n",
      "Test Loss tensor([0.0264, 0.0154, 0.0248, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6370177268981934 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0241, 0.0155, 0.0235, 0.0151]) \n",
      "Test Loss tensor([0.0259, 0.0153, 0.0247, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5259454250335693 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0283, 0.0160, 0.0243, 0.0164]) \n",
      "Test Loss tensor([0.0251, 0.0154, 0.0249, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.45004892349243164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0247, 0.0165, 0.0250, 0.0161]) \n",
      "Test Loss tensor([0.0259, 0.0154, 0.0247, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.46579933166503906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0244, 0.0150, 0.0271, 0.0162]) \n",
      "Test Loss tensor([0.0248, 0.0148, 0.0248, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.43940281867980957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0238, 0.0169, 0.0249, 0.0161]) \n",
      "Test Loss tensor([0.0249, 0.0152, 0.0253, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5146768093109131 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0237, 0.0158, 0.0255, 0.0173]) \n",
      "Test Loss tensor([0.0255, 0.0151, 0.0245, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5503289699554443 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0230, 0.0150, 0.0240, 0.0145]) \n",
      "Test Loss tensor([0.0254, 0.0149, 0.0244, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5683157444000244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0247, 0.0157, 0.0238, 0.0181]) \n",
      "Test Loss tensor([0.0254, 0.0148, 0.0250, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.581906795501709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0259, 0.0132, 0.0257, 0.0165]) \n",
      "Test Loss tensor([0.0251, 0.0147, 0.0248, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5945539474487305 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0216, 0.0143, 0.0237, 0.0158]) \n",
      "Test Loss tensor([0.0248, 0.0149, 0.0243, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5589785575866699 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0227, 0.0137, 0.0217, 0.0161]) \n",
      "Test Loss tensor([0.0252, 0.0155, 0.0243, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5253527164459229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0284, 0.0148, 0.0214, 0.0163]) \n",
      "Test Loss tensor([0.0249, 0.0154, 0.0241, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4497721195220947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0216, 0.0140, 0.0249, 0.0160]) \n",
      "Test Loss tensor([0.0243, 0.0148, 0.0244, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4586055278778076 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0242, 0.0163, 0.0236, 0.0151]) \n",
      "Test Loss tensor([0.0244, 0.0147, 0.0240, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4331662654876709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0252, 0.0148, 0.0237, 0.0155]) \n",
      "Test Loss tensor([0.0250, 0.0152, 0.0241, 0.0168])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 220 in 0.5517339706420898 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0267, 0.0139, 0.0220, 0.0156]) \n",
      "Test Loss tensor([0.0247, 0.0152, 0.0242, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5181190967559814 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0251, 0.0147, 0.0236, 0.0164]) \n",
      "Test Loss tensor([0.0251, 0.0149, 0.0237, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.457988977432251 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0254, 0.0163, 0.0231, 0.0169]) \n",
      "Test Loss tensor([0.0253, 0.0151, 0.0237, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5070798397064209 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0262, 0.0139, 0.0237, 0.0158]) \n",
      "Test Loss tensor([0.0252, 0.0148, 0.0236, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.49970555305480957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0250, 0.0161, 0.0240, 0.0159]) \n",
      "Test Loss tensor([0.0245, 0.0151, 0.0233, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.43244433403015137 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0227, 0.0142, 0.0228, 0.0152]) \n",
      "Test Loss tensor([0.0246, 0.0149, 0.0244, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6103198528289795 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0242, 0.0140, 0.0222, 0.0153]) \n",
      "Test Loss tensor([0.0240, 0.0150, 0.0250, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5341143608093262 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0239, 0.0144, 0.0222, 0.0138]) \n",
      "Test Loss tensor([0.0238, 0.0151, 0.0241, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4630861282348633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0239, 0.0158, 0.0238, 0.0162]) \n",
      "Test Loss tensor([0.0248, 0.0151, 0.0231, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.42752790451049805 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0234, 0.0139, 0.0220, 0.0167]) \n",
      "Test Loss tensor([0.0253, 0.0147, 0.0239, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.446181058883667 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0266, 0.0155, 0.0214, 0.0147]) \n",
      "Test Loss tensor([0.0246, 0.0150, 0.0241, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4547412395477295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0221, 0.0148, 0.0226, 0.0166]) \n",
      "Test Loss tensor([0.0243, 0.0148, 0.0239, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.42990612983703613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0256, 0.0154, 0.0214, 0.0155]) \n",
      "Test Loss tensor([0.0245, 0.0149, 0.0245, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5130360126495361 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0241, 0.0140, 0.0255, 0.0156]) \n",
      "Test Loss tensor([0.0243, 0.0149, 0.0236, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5271480083465576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0219, 0.0128, 0.0232, 0.0160]) \n",
      "Test Loss tensor([0.0234, 0.0148, 0.0240, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.49511146545410156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0252, 0.0157, 0.0233, 0.0158]) \n",
      "Test Loss tensor([0.0241, 0.0149, 0.0234, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5191781520843506 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0237, 0.0159, 0.0233, 0.0147]) \n",
      "Test Loss tensor([0.0240, 0.0149, 0.0240, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4719715118408203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0240, 0.0153, 0.0219, 0.0158]) \n",
      "Test Loss tensor([0.0237, 0.0151, 0.0229, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4708397388458252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0228, 0.0153, 0.0239, 0.0166]) \n",
      "Test Loss tensor([0.0241, 0.0148, 0.0240, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.54974365234375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0206, 0.0143, 0.0252, 0.0154]) \n",
      "Test Loss tensor([0.0239, 0.0151, 0.0235, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5306298732757568 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0217, 0.0146, 0.0229, 0.0156]) \n",
      "Test Loss tensor([0.0230, 0.0144, 0.0238, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5055289268493652 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0252, 0.0154, 0.0240, 0.0137]) \n",
      "Test Loss tensor([0.0231, 0.0143, 0.0236, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4735381603240967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0254, 0.0151, 0.0220, 0.0168]) \n",
      "Test Loss tensor([0.0238, 0.0144, 0.0237, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4362940788269043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0216, 0.0161, 0.0228, 0.0161]) \n",
      "Test Loss tensor([0.0234, 0.0154, 0.0225, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4299051761627197 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0237, 0.0143, 0.0245, 0.0168]) \n",
      "Test Loss tensor([0.0241, 0.0151, 0.0226, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5615079402923584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0221, 0.0148, 0.0219, 0.0178]) \n",
      "Test Loss tensor([0.0228, 0.0146, 0.0233, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5159900188446045 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0240, 0.0148, 0.0224, 0.0155]) \n",
      "Test Loss tensor([0.0236, 0.0146, 0.0232, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.43206334114074707 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0221, 0.0155, 0.0236, 0.0176]) \n",
      "Test Loss tensor([0.0240, 0.0150, 0.0228, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.42958760261535645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0215, 0.0136, 0.0230, 0.0151]) \n",
      "Test Loss tensor([0.0236, 0.0149, 0.0232, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4272439479827881 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0209, 0.0177, 0.0214, 0.0161]) \n",
      "Test Loss tensor([0.0242, 0.0148, 0.0222, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4260416030883789 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0236, 0.0157, 0.0221, 0.0151]) \n",
      "Test Loss tensor([0.0236, 0.0141, 0.0232, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.42574143409729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0213, 0.0147, 0.0248, 0.0145]) \n",
      "Test Loss tensor([0.0233, 0.0148, 0.0229, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4262259006500244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0226, 0.0159, 0.0239, 0.0155]) \n",
      "Test Loss tensor([0.0226, 0.0147, 0.0231, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4346764087677002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0243, 0.0132, 0.0221, 0.0162]) \n",
      "Test Loss tensor([0.0238, 0.0145, 0.0230, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.614260196685791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0204, 0.0160, 0.0238, 0.0164]) \n",
      "Test Loss tensor([0.0229, 0.0140, 0.0233, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4822683334350586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0216, 0.0149, 0.0232, 0.0163]) \n",
      "Test Loss tensor([0.0248, 0.0147, 0.0221, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.44287776947021484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0160, 0.0206, 0.0160]) \n",
      "Test Loss tensor([0.0234, 0.0147, 0.0225, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.44800233840942383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0220, 0.0131, 0.0227, 0.0148]) \n",
      "Test Loss tensor([0.0232, 0.0142, 0.0231, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5321474075317383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0215, 0.0146, 0.0215, 0.0153]) \n",
      "Test Loss tensor([0.0235, 0.0145, 0.0232, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5048737525939941 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0240, 0.0143, 0.0200, 0.0162]) \n",
      "Test Loss tensor([0.0236, 0.0146, 0.0227, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4631493091583252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0241, 0.0149, 0.0230, 0.0147]) \n",
      "Test Loss tensor([0.0230, 0.0149, 0.0227, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.43921756744384766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0236, 0.0152, 0.0211, 0.0160]) \n",
      "Test Loss tensor([0.0230, 0.0147, 0.0227, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4441063404083252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0230, 0.0157, 0.0228, 0.0150]) \n",
      "Test Loss tensor([0.0224, 0.0148, 0.0224, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4443953037261963 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0258, 0.0146, 0.0239, 0.0167]) \n",
      "Test Loss tensor([0.0224, 0.0147, 0.0228, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4311237335205078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0238, 0.0133, 0.0227, 0.0159]) \n",
      "Test Loss tensor([0.0225, 0.0146, 0.0225, 0.0156])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.5625872611999512 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0252, 0.0155, 0.0234, 0.0166]) \n",
      "Test Loss tensor([0.0218, 0.0147, 0.0233, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6634864807128906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0248, 0.0161, 0.0216, 0.0153]) \n",
      "Test Loss tensor([0.0226, 0.0143, 0.0224, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5716352462768555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0209, 0.0144, 0.0215, 0.0146]) \n",
      "Test Loss tensor([0.0224, 0.0146, 0.0223, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4762880802154541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0235, 0.0149, 0.0235, 0.0151]) \n",
      "Test Loss tensor([0.0229, 0.0144, 0.0221, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.45775461196899414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0226, 0.0139, 0.0222, 0.0140]) \n",
      "Test Loss tensor([0.0227, 0.0145, 0.0223, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.62227463722229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0212, 0.0149, 0.0218, 0.0149]) \n",
      "Test Loss tensor([0.0218, 0.0145, 0.0223, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5597224235534668 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0194, 0.0127, 0.0223, 0.0155]) \n",
      "Test Loss tensor([0.0219, 0.0145, 0.0225, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5857257843017578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0166, 0.0243, 0.0155]) \n",
      "Test Loss tensor([0.0227, 0.0147, 0.0221, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5425617694854736 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0246, 0.0143, 0.0230, 0.0159]) \n",
      "Test Loss tensor([0.0222, 0.0145, 0.0229, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.528590202331543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0241, 0.0153, 0.0213, 0.0151]) \n",
      "Test Loss tensor([0.0229, 0.0151, 0.0215, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5319721698760986 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0222, 0.0141, 0.0225, 0.0156]) \n",
      "Test Loss tensor([0.0226, 0.0148, 0.0219, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5262057781219482 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0215, 0.0155, 0.0224, 0.0153]) \n",
      "Test Loss tensor([0.0226, 0.0143, 0.0223, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4593229293823242 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0208, 0.0155, 0.0203, 0.0149]) \n",
      "Test Loss tensor([0.0223, 0.0143, 0.0220, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.45435571670532227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0213, 0.0144, 0.0203, 0.0141]) \n",
      "Test Loss tensor([0.0217, 0.0142, 0.0216, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4844791889190674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0245, 0.0148, 0.0208, 0.0146]) \n",
      "Test Loss tensor([0.0229, 0.0146, 0.0222, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5144412517547607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0220, 0.0140, 0.0204, 0.0131]) \n",
      "Test Loss tensor([0.0223, 0.0142, 0.0221, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5328896045684814 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0217, 0.0150, 0.0208, 0.0145]) \n",
      "Test Loss tensor([0.0220, 0.0145, 0.0216, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5117135047912598 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0236, 0.0157, 0.0231, 0.0147]) \n",
      "Test Loss tensor([0.0222, 0.0142, 0.0221, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4968607425689697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0191, 0.0140, 0.0188, 0.0151]) \n",
      "Test Loss tensor([0.0226, 0.0146, 0.0213, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.44431281089782715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0236, 0.0142, 0.0225, 0.0153]) \n",
      "Test Loss tensor([0.0217, 0.0148, 0.0215, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4421384334564209 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0229, 0.0141, 0.0219, 0.0159]) \n",
      "Test Loss tensor([0.0224, 0.0144, 0.0218, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4551692008972168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0225, 0.0155, 0.0238, 0.0136]) \n",
      "Test Loss tensor([0.0229, 0.0146, 0.0213, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4633355140686035 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0232, 0.0145, 0.0202, 0.0149]) \n",
      "Test Loss tensor([0.0219, 0.0145, 0.0213, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4357798099517822 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0226, 0.0139, 0.0209, 0.0157]) \n",
      "Test Loss tensor([0.0220, 0.0145, 0.0214, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5007877349853516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0142, 0.0198, 0.0153]) \n",
      "Test Loss tensor([0.0218, 0.0144, 0.0216, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4252767562866211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0206, 0.0142, 0.0210, 0.0135]) \n",
      "Test Loss tensor([0.0223, 0.0147, 0.0211, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.44042110443115234 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0205, 0.0137, 0.0206, 0.0156]) \n",
      "Test Loss tensor([0.0214, 0.0144, 0.0214, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4767618179321289 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0147, 0.0215, 0.0144]) \n",
      "Test Loss tensor([0.0217, 0.0140, 0.0213, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4289827346801758 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0227, 0.0164, 0.0222, 0.0141]) \n",
      "Test Loss tensor([0.0218, 0.0149, 0.0211, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4819602966308594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0203, 0.0144, 0.0220, 0.0139]) \n",
      "Test Loss tensor([0.0216, 0.0144, 0.0215, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.42777252197265625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0206, 0.0130, 0.0230, 0.0149]) \n",
      "Test Loss tensor([0.0209, 0.0143, 0.0217, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4918370246887207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0217, 0.0150, 0.0225, 0.0142]) \n",
      "Test Loss tensor([0.0220, 0.0142, 0.0221, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4560530185699463 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0198, 0.0148, 0.0199, 0.0142]) \n",
      "Test Loss tensor([0.0220, 0.0144, 0.0210, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5042600631713867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0217, 0.0147, 0.0182, 0.0163]) \n",
      "Test Loss tensor([0.0215, 0.0145, 0.0206, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5084049701690674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0204, 0.0150, 0.0212, 0.0166]) \n",
      "Test Loss tensor([0.0210, 0.0141, 0.0218, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5113584995269775 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0211, 0.0159, 0.0202, 0.0163]) \n",
      "Test Loss tensor([0.0209, 0.0146, 0.0215, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.45272207260131836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0192, 0.0148, 0.0203, 0.0147]) \n",
      "Test Loss tensor([0.0210, 0.0147, 0.0210, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.45304203033447266 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0200, 0.0136, 0.0225, 0.0145]) \n",
      "Test Loss tensor([0.0213, 0.0144, 0.0209, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.44200921058654785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0134, 0.0196, 0.0135]) \n",
      "Test Loss tensor([0.0216, 0.0138, 0.0212, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47690629959106445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0214, 0.0148, 0.0201, 0.0149]) \n",
      "Test Loss tensor([0.0216, 0.0141, 0.0212, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4598672389984131 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0221, 0.0120, 0.0201, 0.0152]) \n",
      "Test Loss tensor([0.0214, 0.0141, 0.0203, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4488029479980469 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0167, 0.0147, 0.0197, 0.0134]) \n",
      "Test Loss tensor([0.0208, 0.0141, 0.0216, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4229910373687744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0225, 0.0150, 0.0198, 0.0141]) \n",
      "Test Loss tensor([0.0212, 0.0143, 0.0208, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.509282112121582 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0206, 0.0146, 0.0207, 0.0137]) \n",
      "Test Loss tensor([0.0205, 0.0145, 0.0206, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4879732131958008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0181, 0.0141, 0.0211, 0.0154]) \n",
      "Test Loss tensor([0.0212, 0.0146, 0.0203, 0.0149])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 580 in 0.4622194766998291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0236, 0.0152, 0.0205, 0.0151]) \n",
      "Test Loss tensor([0.0208, 0.0142, 0.0208, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4355635643005371 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0219, 0.0142, 0.0215, 0.0156]) \n",
      "Test Loss tensor([0.0208, 0.0142, 0.0207, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.45485377311706543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0208, 0.0141, 0.0201, 0.0136]) \n",
      "Test Loss tensor([0.0214, 0.0139, 0.0206, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47161293029785156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0132, 0.0203, 0.0160]) \n",
      "Test Loss tensor([0.0217, 0.0142, 0.0200, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4375033378601074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0205, 0.0128, 0.0190, 0.0145]) \n",
      "Test Loss tensor([0.0210, 0.0143, 0.0210, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4198634624481201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0191, 0.0138, 0.0199, 0.0144]) \n",
      "Test Loss tensor([0.0198, 0.0138, 0.0207, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5433666706085205 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0156, 0.0201, 0.0154]) \n",
      "Test Loss tensor([0.0217, 0.0140, 0.0206, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5611939430236816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0193, 0.0146, 0.0214, 0.0164]) \n",
      "Test Loss tensor([0.0206, 0.0140, 0.0203, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.590533971786499 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0198, 0.0147, 0.0210, 0.0147]) \n",
      "Test Loss tensor([0.0204, 0.0143, 0.0210, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5896341800689697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0185, 0.0133, 0.0182, 0.0145]) \n",
      "Test Loss tensor([0.0214, 0.0141, 0.0204, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5220818519592285 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0209, 0.0146, 0.0217, 0.0135]) \n",
      "Test Loss tensor([0.0212, 0.0142, 0.0197, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.53639817237854 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0165, 0.0196, 0.0150]) \n",
      "Test Loss tensor([0.0212, 0.0139, 0.0205, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.46361398696899414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0226, 0.0138, 0.0189, 0.0140]) \n",
      "Test Loss tensor([0.0204, 0.0137, 0.0211, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.551987886428833 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0195, 0.0129, 0.0183, 0.0147]) \n",
      "Test Loss tensor([0.0210, 0.0139, 0.0204, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5749926567077637 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0121, 0.0198, 0.0139]) \n",
      "Test Loss tensor([0.0203, 0.0138, 0.0202, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5336430072784424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0215, 0.0141, 0.0202, 0.0118]) \n",
      "Test Loss tensor([0.0206, 0.0140, 0.0197, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5206503868103027 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0197, 0.0135, 0.0193, 0.0137]) \n",
      "Test Loss tensor([0.0207, 0.0138, 0.0210, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5280077457427979 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0208, 0.0150, 0.0202, 0.0147]) \n",
      "Test Loss tensor([0.0197, 0.0140, 0.0198, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.48404479026794434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0210, 0.0133, 0.0210, 0.0140]) \n",
      "Test Loss tensor([0.0207, 0.0141, 0.0199, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4715695381164551 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0220, 0.0139, 0.0203, 0.0156]) \n",
      "Test Loss tensor([0.0199, 0.0139, 0.0201, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5062382221221924 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0208, 0.0151, 0.0208, 0.0131]) \n",
      "Test Loss tensor([0.0203, 0.0142, 0.0202, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4576590061187744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0193, 0.0141, 0.0202, 0.0139]) \n",
      "Test Loss tensor([0.0205, 0.0142, 0.0196, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5804216861724854 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0192, 0.0135, 0.0197, 0.0166]) \n",
      "Test Loss tensor([0.0198, 0.0139, 0.0200, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5929288864135742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0209, 0.0134, 0.0207, 0.0142]) \n",
      "Test Loss tensor([0.0201, 0.0138, 0.0198, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6100492477416992 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0142, 0.0184, 0.0150]) \n",
      "Test Loss tensor([0.0196, 0.0135, 0.0205, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5845077037811279 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0139, 0.0201, 0.0142]) \n",
      "Test Loss tensor([0.0203, 0.0139, 0.0203, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.48445916175842285 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0188, 0.0137, 0.0195, 0.0164]) \n",
      "Test Loss tensor([0.0199, 0.0135, 0.0199, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.49911952018737793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0178, 0.0146, 0.0195, 0.0146]) \n",
      "Test Loss tensor([0.0202, 0.0139, 0.0200, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.48024559020996094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0210, 0.0144, 0.0211, 0.0151]) \n",
      "Test Loss tensor([0.0195, 0.0134, 0.0202, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4831373691558838 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0196, 0.0129, 0.0183, 0.0146]) \n",
      "Test Loss tensor([0.0202, 0.0136, 0.0195, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5297596454620361 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0196, 0.0138, 0.0177, 0.0121]) \n",
      "Test Loss tensor([0.0200, 0.0134, 0.0198, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5131633281707764 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0117, 0.0198, 0.0127]) \n",
      "Test Loss tensor([0.0195, 0.0135, 0.0199, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5094459056854248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0133, 0.0200, 0.0140]) \n",
      "Test Loss tensor([0.0197, 0.0139, 0.0194, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4853675365447998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0186, 0.0150, 0.0188, 0.0133]) \n",
      "Test Loss tensor([0.0203, 0.0137, 0.0194, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.55637526512146 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0207, 0.0131, 0.0189, 0.0158]) \n",
      "Test Loss tensor([0.0196, 0.0138, 0.0189, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4907677173614502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0194, 0.0144, 0.0186, 0.0150]) \n",
      "Test Loss tensor([0.0201, 0.0137, 0.0190, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4757990837097168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0203, 0.0132, 0.0200, 0.0131]) \n",
      "Test Loss tensor([0.0203, 0.0134, 0.0193, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4618403911590576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0185, 0.0128, 0.0186, 0.0151]) \n",
      "Test Loss tensor([0.0199, 0.0140, 0.0193, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.501471996307373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0146, 0.0175, 0.0161]) \n",
      "Test Loss tensor([0.0200, 0.0136, 0.0192, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6356494426727295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0175, 0.0137, 0.0184, 0.0139]) \n",
      "Test Loss tensor([0.0194, 0.0134, 0.0194, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5255398750305176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0153, 0.0201, 0.0127]) \n",
      "Test Loss tensor([0.0194, 0.0139, 0.0194, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6712288856506348 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0214, 0.0143, 0.0179, 0.0143]) \n",
      "Test Loss tensor([0.0193, 0.0140, 0.0191, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6073923110961914 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0205, 0.0138, 0.0199, 0.0161]) \n",
      "Test Loss tensor([0.0193, 0.0136, 0.0195, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5837445259094238 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0220, 0.0137, 0.0186, 0.0129]) \n",
      "Test Loss tensor([0.0189, 0.0136, 0.0197, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5649681091308594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0204, 0.0136, 0.0175, 0.0139]) \n",
      "Test Loss tensor([0.0201, 0.0135, 0.0191, 0.0140])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 760 in 0.5357744693756104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0177, 0.0118, 0.0199, 0.0130]) \n",
      "Test Loss tensor([0.0189, 0.0136, 0.0189, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5601799488067627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0141, 0.0191, 0.0135]) \n",
      "Test Loss tensor([0.0198, 0.0137, 0.0188, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5870411396026611 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0138, 0.0172, 0.0134]) \n",
      "Test Loss tensor([0.0194, 0.0133, 0.0191, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.560720682144165 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0183, 0.0131, 0.0193, 0.0126]) \n",
      "Test Loss tensor([0.0192, 0.0134, 0.0194, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5354697704315186 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0195, 0.0140, 0.0179, 0.0132]) \n",
      "Test Loss tensor([0.0198, 0.0132, 0.0182, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.536841630935669 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0192, 0.0130, 0.0169, 0.0129]) \n",
      "Test Loss tensor([0.0193, 0.0132, 0.0188, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.48905372619628906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0211, 0.0140, 0.0172, 0.0128]) \n",
      "Test Loss tensor([0.0195, 0.0136, 0.0193, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.48293209075927734 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0187, 0.0139, 0.0189, 0.0137]) \n",
      "Test Loss tensor([0.0193, 0.0139, 0.0180, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4707789421081543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0200, 0.0134, 0.0182, 0.0128]) \n",
      "Test Loss tensor([0.0186, 0.0134, 0.0190, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4806678295135498 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0187, 0.0145, 0.0193, 0.0141]) \n",
      "Test Loss tensor([0.0190, 0.0134, 0.0192, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.48995399475097656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0203, 0.0133, 0.0175, 0.0120]) \n",
      "Test Loss tensor([0.0190, 0.0137, 0.0193, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.507347583770752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0182, 0.0133, 0.0198, 0.0141]) \n",
      "Test Loss tensor([0.0183, 0.0133, 0.0188, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5261402130126953 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0179, 0.0134, 0.0187, 0.0127]) \n",
      "Test Loss tensor([0.0193, 0.0138, 0.0186, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5196986198425293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0134, 0.0175, 0.0144]) \n",
      "Test Loss tensor([0.0190, 0.0135, 0.0178, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.500601053237915 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0177, 0.0138, 0.0174, 0.0139]) \n",
      "Test Loss tensor([0.0190, 0.0139, 0.0179, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.588200569152832 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0199, 0.0127, 0.0195, 0.0139]) \n",
      "Test Loss tensor([0.0188, 0.0132, 0.0183, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.43198728561401367 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0184, 0.0119, 0.0197, 0.0132]) \n",
      "Test Loss tensor([0.0190, 0.0133, 0.0181, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.506248950958252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0188, 0.0127, 0.0166, 0.0138]) \n",
      "Test Loss tensor([0.0194, 0.0136, 0.0181, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5404458045959473 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0194, 0.0148, 0.0169, 0.0142]) \n",
      "Test Loss tensor([0.0186, 0.0133, 0.0176, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.42861199378967285 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0188, 0.0127, 0.0169, 0.0141]) \n",
      "Test Loss tensor([0.0188, 0.0134, 0.0180, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.43671298027038574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0179, 0.0141, 0.0163, 0.0138]) \n",
      "Test Loss tensor([0.0187, 0.0133, 0.0182, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.7730979919433594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0175, 0.0149, 0.0177, 0.0138]) \n",
      "Test Loss tensor([0.0189, 0.0137, 0.0177, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6318366527557373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0143, 0.0182, 0.0137]) \n",
      "Test Loss tensor([0.0185, 0.0135, 0.0176, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6173770427703857 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0119, 0.0161, 0.0137]) \n",
      "Test Loss tensor([0.0191, 0.0134, 0.0178, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5728375911712646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0177, 0.0138, 0.0170, 0.0147]) \n",
      "Test Loss tensor([0.0182, 0.0132, 0.0175, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4982643127441406 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0193, 0.0144, 0.0190, 0.0127]) \n",
      "Test Loss tensor([0.0186, 0.0131, 0.0181, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5048604011535645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0142, 0.0194, 0.0140]) \n",
      "Test Loss tensor([0.0178, 0.0136, 0.0180, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6519920825958252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0175, 0.0141, 0.0183, 0.0123]) \n",
      "Test Loss tensor([0.0180, 0.0132, 0.0175, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6709182262420654 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0163, 0.0144, 0.0182, 0.0133]) \n",
      "Test Loss tensor([0.0182, 0.0133, 0.0179, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5884149074554443 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0127, 0.0097, 0.0150, 0.0097]) \n",
      "Test Loss tensor([0.0182, 0.0134, 0.0181, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5742049217224121 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0120, 0.0170, 0.0120]) \n",
      "Test Loss tensor([0.0177, 0.0133, 0.0174, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.7326221466064453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0188, 0.0142, 0.0170, 0.0136]) \n",
      "Test Loss tensor([0.0180, 0.0135, 0.0175, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6644699573516846 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0184, 0.0149, 0.0178, 0.0140]) \n",
      "Test Loss tensor([0.0182, 0.0135, 0.0172, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.594735860824585 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0125, 0.0177, 0.0145]) \n",
      "Test Loss tensor([0.0177, 0.0133, 0.0178, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6275668144226074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0190, 0.0130, 0.0187, 0.0137]) \n",
      "Test Loss tensor([0.0186, 0.0130, 0.0175, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6892678737640381 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0171, 0.0136, 0.0162, 0.0138]) \n",
      "Test Loss tensor([0.0184, 0.0130, 0.0175, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.666217565536499 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0165, 0.0143, 0.0173, 0.0123]) \n",
      "Test Loss tensor([0.0182, 0.0132, 0.0176, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6139206886291504 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0168, 0.0131, 0.0179, 0.0143]) \n",
      "Test Loss tensor([0.0184, 0.0132, 0.0176, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5472159385681152 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0181, 0.0128, 0.0157, 0.0144]) \n",
      "Test Loss tensor([0.0186, 0.0133, 0.0173, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5477204322814941 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0175, 0.0133, 0.0161, 0.0127]) \n",
      "Test Loss tensor([0.0183, 0.0131, 0.0178, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5276949405670166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0188, 0.0130, 0.0164, 0.0124]) \n",
      "Test Loss tensor([0.0182, 0.0132, 0.0170, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6026613712310791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0164, 0.0149, 0.0170, 0.0134]) \n",
      "Test Loss tensor([0.0185, 0.0132, 0.0169, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5500712394714355 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0170, 0.0135, 0.0180, 0.0133]) \n",
      "Test Loss tensor([0.0178, 0.0137, 0.0171, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5281352996826172 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0178, 0.0135, 0.0186, 0.0136]) \n",
      "Test Loss tensor([0.0181, 0.0135, 0.0173, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5835471153259277 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0187, 0.0126, 0.0162, 0.0131]) \n",
      "Test Loss tensor([0.0179, 0.0133, 0.0172, 0.0131])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 60 in 0.47144079208374023 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0189, 0.0150, 0.0159, 0.0133]) \n",
      "Test Loss tensor([0.0179, 0.0134, 0.0169, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.46727705001831055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0167, 0.0133, 0.0185, 0.0120]) \n",
      "Test Loss tensor([0.0176, 0.0133, 0.0172, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4685657024383545 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0182, 0.0137, 0.0173, 0.0133]) \n",
      "Test Loss tensor([0.0185, 0.0130, 0.0171, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4670741558074951 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0180, 0.0141, 0.0170, 0.0135]) \n",
      "Test Loss tensor([0.0186, 0.0134, 0.0163, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4621751308441162 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0164, 0.0123, 0.0160, 0.0128]) \n",
      "Test Loss tensor([0.0167, 0.0132, 0.0176, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4518609046936035 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0170, 0.0119, 0.0163, 0.0134]) \n",
      "Test Loss tensor([0.0172, 0.0131, 0.0171, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.44982266426086426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0173, 0.0129, 0.0157, 0.0136]) \n",
      "Test Loss tensor([0.0182, 0.0135, 0.0168, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4577045440673828 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0174, 0.0129, 0.0177, 0.0132]) \n",
      "Test Loss tensor([0.0179, 0.0132, 0.0173, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.686486005783081 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0167, 0.0128, 0.0166, 0.0116]) \n",
      "Test Loss tensor([0.0179, 0.0130, 0.0180, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6070654392242432 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0168, 0.0123, 0.0172, 0.0127]) \n",
      "Test Loss tensor([0.0177, 0.0133, 0.0174, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5342786312103271 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0186, 0.0123, 0.0169, 0.0134]) \n",
      "Test Loss tensor([0.0174, 0.0131, 0.0172, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6103203296661377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0171, 0.0131, 0.0160, 0.0124]) \n",
      "Test Loss tensor([0.0174, 0.0129, 0.0170, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6864266395568848 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0164, 0.0163, 0.0169, 0.0145]) \n",
      "Test Loss tensor([0.0182, 0.0132, 0.0172, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6190595626831055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0150, 0.0125, 0.0171, 0.0133]) \n",
      "Test Loss tensor([0.0171, 0.0132, 0.0170, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6870551109313965 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0180, 0.0124, 0.0172, 0.0126]) \n",
      "Test Loss tensor([0.0176, 0.0131, 0.0167, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6144895553588867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0139, 0.0161, 0.0129]) \n",
      "Test Loss tensor([0.0173, 0.0130, 0.0168, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6018073558807373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0121, 0.0167, 0.0120]) \n",
      "Test Loss tensor([0.0171, 0.0131, 0.0169, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6362793445587158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0165, 0.0142, 0.0166, 0.0133]) \n",
      "Test Loss tensor([0.0175, 0.0134, 0.0164, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6201794147491455 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0168, 0.0126, 0.0165, 0.0125]) \n",
      "Test Loss tensor([0.0172, 0.0131, 0.0168, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6682956218719482 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0160, 0.0122, 0.0175, 0.0131]) \n",
      "Test Loss tensor([0.0171, 0.0132, 0.0165, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6704027652740479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0157, 0.0125, 0.0153, 0.0140]) \n",
      "Test Loss tensor([0.0168, 0.0133, 0.0164, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.584970235824585 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0186, 0.0129, 0.0152, 0.0128]) \n",
      "Test Loss tensor([0.0176, 0.0132, 0.0166, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4382956027984619 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0192, 0.0122, 0.0169, 0.0115]) \n",
      "Test Loss tensor([0.0170, 0.0131, 0.0170, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.440140962600708 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0177, 0.0128, 0.0178, 0.0134]) \n",
      "Test Loss tensor([0.0173, 0.0126, 0.0165, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.48572421073913574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0167, 0.0123, 0.0157, 0.0128]) \n",
      "Test Loss tensor([0.0173, 0.0132, 0.0167, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4412362575531006 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0184, 0.0142, 0.0163, 0.0134]) \n",
      "Test Loss tensor([0.0175, 0.0131, 0.0168, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.47588491439819336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0127, 0.0157, 0.0134]) \n",
      "Test Loss tensor([0.0174, 0.0132, 0.0166, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.45270419120788574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0138, 0.0166, 0.0135]) \n",
      "Test Loss tensor([0.0168, 0.0132, 0.0166, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6837265491485596 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0180, 0.0143, 0.0171, 0.0132]) \n",
      "Test Loss tensor([0.0163, 0.0134, 0.0163, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.654026985168457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0165, 0.0130, 0.0152, 0.0128]) \n",
      "Test Loss tensor([0.0169, 0.0131, 0.0162, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5648281574249268 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0160, 0.0134, 0.0156, 0.0125]) \n",
      "Test Loss tensor([0.0175, 0.0129, 0.0165, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5680086612701416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0184, 0.0141, 0.0158, 0.0141]) \n",
      "Test Loss tensor([0.0165, 0.0129, 0.0162, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.48573994636535645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0173, 0.0131, 0.0169, 0.0132]) \n",
      "Test Loss tensor([0.0169, 0.0130, 0.0162, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6099953651428223 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0173, 0.0127, 0.0176, 0.0134]) \n",
      "Test Loss tensor([0.0168, 0.0133, 0.0159, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4941282272338867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0131, 0.0166, 0.0125]) \n",
      "Test Loss tensor([0.0168, 0.0128, 0.0162, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47995567321777344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0126, 0.0157, 0.0127]) \n",
      "Test Loss tensor([0.0164, 0.0130, 0.0160, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.46718645095825195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0178, 0.0130, 0.0148, 0.0127]) \n",
      "Test Loss tensor([0.0168, 0.0133, 0.0162, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.556894063949585 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0159, 0.0125, 0.0166, 0.0130]) \n",
      "Test Loss tensor([0.0167, 0.0128, 0.0162, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.573361873626709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0160, 0.0121, 0.0155, 0.0133]) \n",
      "Test Loss tensor([0.0167, 0.0130, 0.0160, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5562789440155029 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0131, 0.0148, 0.0113]) \n",
      "Test Loss tensor([0.0167, 0.0132, 0.0156, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5687224864959717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0163, 0.0124, 0.0164, 0.0118]) \n",
      "Test Loss tensor([0.0165, 0.0131, 0.0161, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7144169807434082 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0180, 0.0123, 0.0181, 0.0135]) \n",
      "Test Loss tensor([0.0166, 0.0129, 0.0162, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5659091472625732 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0149, 0.0125, 0.0182, 0.0132]) \n",
      "Test Loss tensor([0.0166, 0.0130, 0.0161, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6493825912475586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0146, 0.0127, 0.0153, 0.0121]) \n",
      "Test Loss tensor([0.0169, 0.0131, 0.0157, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5269172191619873 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0171, 0.0134, 0.0150, 0.0134]) \n",
      "Test Loss tensor([0.0164, 0.0129, 0.0159, 0.0128])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 240 in 0.5050029754638672 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0134, 0.0144, 0.0120]) \n",
      "Test Loss tensor([0.0163, 0.0132, 0.0163, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4725666046142578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0161, 0.0132, 0.0160, 0.0117]) \n",
      "Test Loss tensor([0.0159, 0.0132, 0.0164, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47648143768310547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0129, 0.0161, 0.0115]) \n",
      "Test Loss tensor([0.0169, 0.0133, 0.0165, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6533584594726562 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0166, 0.0123, 0.0159, 0.0133]) \n",
      "Test Loss tensor([0.0162, 0.0132, 0.0161, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.49926066398620605 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0163, 0.0125, 0.0152, 0.0128]) \n",
      "Test Loss tensor([0.0166, 0.0129, 0.0158, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4719383716583252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0149, 0.0121, 0.0150, 0.0132]) \n",
      "Test Loss tensor([0.0156, 0.0130, 0.0157, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4585433006286621 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0156, 0.0132, 0.0147, 0.0126]) \n",
      "Test Loss tensor([0.0169, 0.0128, 0.0164, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.46893906593322754 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0159, 0.0122, 0.0162, 0.0140]) \n",
      "Test Loss tensor([0.0161, 0.0131, 0.0158, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.49489903450012207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0127, 0.0152, 0.0126]) \n",
      "Test Loss tensor([0.0161, 0.0129, 0.0157, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6191082000732422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0176, 0.0134, 0.0147, 0.0123]) \n",
      "Test Loss tensor([0.0169, 0.0131, 0.0154, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5065984725952148 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0150, 0.0134, 0.0168, 0.0131]) \n",
      "Test Loss tensor([0.0164, 0.0130, 0.0155, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4533076286315918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0152, 0.0137, 0.0147, 0.0125]) \n",
      "Test Loss tensor([0.0159, 0.0126, 0.0156, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4437747001647949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0129, 0.0177, 0.0128]) \n",
      "Test Loss tensor([0.0162, 0.0132, 0.0161, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4605543613433838 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0163, 0.0129, 0.0150, 0.0125]) \n",
      "Test Loss tensor([0.0158, 0.0128, 0.0156, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.44955897331237793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0158, 0.0138, 0.0154, 0.0115]) \n",
      "Test Loss tensor([0.0164, 0.0126, 0.0155, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4894871711730957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0153, 0.0127, 0.0162, 0.0131]) \n",
      "Test Loss tensor([0.0165, 0.0130, 0.0155, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4451565742492676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0156, 0.0131, 0.0144, 0.0133]) \n",
      "Test Loss tensor([0.0160, 0.0129, 0.0157, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47623181343078613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0151, 0.0132, 0.0153, 0.0118]) \n",
      "Test Loss tensor([0.0161, 0.0130, 0.0161, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4562532901763916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0146, 0.0129, 0.0144, 0.0117]) \n",
      "Test Loss tensor([0.0157, 0.0129, 0.0155, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4992959499359131 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0152, 0.0128, 0.0160, 0.0123]) \n",
      "Test Loss tensor([0.0159, 0.0129, 0.0159, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4535508155822754 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0137, 0.0147, 0.0123]) \n",
      "Test Loss tensor([0.0158, 0.0127, 0.0155, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4845387935638428 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0168, 0.0132, 0.0141, 0.0115]) \n",
      "Test Loss tensor([0.0159, 0.0128, 0.0157, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.45069289207458496 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0159, 0.0121, 0.0157, 0.0127]) \n",
      "Test Loss tensor([0.0156, 0.0129, 0.0158, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.47048521041870117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0126, 0.0138, 0.0131]) \n",
      "Test Loss tensor([0.0162, 0.0131, 0.0152, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4568765163421631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0140, 0.0108, 0.0157, 0.0115]) \n",
      "Test Loss tensor([0.0161, 0.0130, 0.0155, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4965333938598633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0163, 0.0121, 0.0137, 0.0129]) \n",
      "Test Loss tensor([0.0159, 0.0130, 0.0153, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4682180881500244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0150, 0.0137, 0.0157, 0.0114]) \n",
      "Test Loss tensor([0.0159, 0.0123, 0.0160, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.483431339263916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0160, 0.0123, 0.0160, 0.0106]) \n",
      "Test Loss tensor([0.0153, 0.0126, 0.0152, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4626762866973877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0129, 0.0157, 0.0133]) \n",
      "Test Loss tensor([0.0155, 0.0126, 0.0153, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.45145368576049805 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0169, 0.0122, 0.0127, 0.0118]) \n",
      "Test Loss tensor([0.0153, 0.0128, 0.0155, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.47445154190063477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0138, 0.0128, 0.0139, 0.0114]) \n",
      "Test Loss tensor([0.0154, 0.0132, 0.0151, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.544590950012207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0150, 0.0139, 0.0164, 0.0119]) \n",
      "Test Loss tensor([0.0157, 0.0125, 0.0154, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4639561176300049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0153, 0.0117, 0.0160, 0.0126]) \n",
      "Test Loss tensor([0.0150, 0.0128, 0.0149, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.622624397277832 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0147, 0.0122, 0.0152, 0.0129]) \n",
      "Test Loss tensor([0.0157, 0.0123, 0.0150, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5345947742462158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0162, 0.0137, 0.0148, 0.0118]) \n",
      "Test Loss tensor([0.0151, 0.0125, 0.0155, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6826305389404297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0116, 0.0146, 0.0113]) \n",
      "Test Loss tensor([0.0153, 0.0131, 0.0150, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6094412803649902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0145, 0.0144, 0.0150, 0.0116]) \n",
      "Test Loss tensor([0.0156, 0.0126, 0.0151, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6338107585906982 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0162, 0.0124, 0.0140, 0.0115]) \n",
      "Test Loss tensor([0.0152, 0.0128, 0.0148, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7011628150939941 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0149, 0.0125, 0.0162, 0.0117]) \n",
      "Test Loss tensor([0.0155, 0.0128, 0.0147, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6781802177429199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0151, 0.0119, 0.0149, 0.0121]) \n",
      "Test Loss tensor([0.0147, 0.0123, 0.0150, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6280601024627686 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0149, 0.0130, 0.0127, 0.0134]) \n",
      "Test Loss tensor([0.0151, 0.0129, 0.0148, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7087080478668213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0153, 0.0131, 0.0137, 0.0118]) \n",
      "Test Loss tensor([0.0153, 0.0129, 0.0150, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5138487815856934 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0168, 0.0128, 0.0143, 0.0118]) \n",
      "Test Loss tensor([0.0146, 0.0128, 0.0152, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5529458522796631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0144, 0.0135, 0.0159, 0.0125]) \n",
      "Test Loss tensor([0.0149, 0.0124, 0.0148, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.507866382598877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0162, 0.0123, 0.0153, 0.0142]) \n",
      "Test Loss tensor([0.0153, 0.0128, 0.0150, 0.0123])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 420 in 0.4752366542816162 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0158, 0.0124, 0.0138, 0.0132]) \n",
      "Test Loss tensor([0.0151, 0.0123, 0.0154, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.42881226539611816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0165, 0.0128, 0.0155, 0.0121]) \n",
      "Test Loss tensor([0.0154, 0.0126, 0.0147, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6702988147735596 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0161, 0.0136, 0.0163, 0.0122]) \n",
      "Test Loss tensor([0.0154, 0.0125, 0.0147, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5953974723815918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0161, 0.0126, 0.0161, 0.0124]) \n",
      "Test Loss tensor([0.0148, 0.0126, 0.0149, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5650119781494141 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0149, 0.0108, 0.0146, 0.0131]) \n",
      "Test Loss tensor([0.0150, 0.0127, 0.0149, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5486276149749756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0143, 0.0135, 0.0165, 0.0127]) \n",
      "Test Loss tensor([0.0150, 0.0128, 0.0146, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5185286998748779 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0130, 0.0124, 0.0154, 0.0125]) \n",
      "Test Loss tensor([0.0148, 0.0126, 0.0149, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5120260715484619 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0134, 0.0135, 0.0147, 0.0124]) \n",
      "Test Loss tensor([0.0145, 0.0126, 0.0149, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5322809219360352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0141, 0.0133, 0.0139, 0.0120]) \n",
      "Test Loss tensor([0.0149, 0.0128, 0.0143, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6367523670196533 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0151, 0.0124, 0.0151, 0.0123]) \n",
      "Test Loss tensor([0.0144, 0.0128, 0.0150, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6372826099395752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0138, 0.0126, 0.0159, 0.0116]) \n",
      "Test Loss tensor([0.0147, 0.0124, 0.0148, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5262291431427002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0139, 0.0120, 0.0144, 0.0110]) \n",
      "Test Loss tensor([0.0149, 0.0128, 0.0148, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.636192798614502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0142, 0.0118, 0.0149, 0.0116]) \n",
      "Test Loss tensor([0.0151, 0.0124, 0.0146, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7346923351287842 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0138, 0.0139, 0.0158, 0.0137]) \n",
      "Test Loss tensor([0.0148, 0.0127, 0.0148, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5423369407653809 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0158, 0.0129, 0.0149, 0.0117]) \n",
      "Test Loss tensor([0.0152, 0.0126, 0.0147, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5487442016601562 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0151, 0.0134, 0.0131, 0.0115]) \n",
      "Test Loss tensor([0.0149, 0.0129, 0.0148, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5102880001068115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0154, 0.0142, 0.0152, 0.0125]) \n",
      "Test Loss tensor([0.0145, 0.0123, 0.0146, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5061624050140381 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0164, 0.0132, 0.0133, 0.0117]) \n",
      "Test Loss tensor([0.0148, 0.0128, 0.0148, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4696540832519531 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0122, 0.0126, 0.0141, 0.0118]) \n",
      "Test Loss tensor([0.0144, 0.0124, 0.0145, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5381791591644287 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0147, 0.0119, 0.0147, 0.0116]) \n",
      "Test Loss tensor([0.0148, 0.0127, 0.0145, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4959895610809326 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0131, 0.0128, 0.0138, 0.0125]) \n",
      "Test Loss tensor([0.0143, 0.0124, 0.0144, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5512027740478516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0140, 0.0129, 0.0136, 0.0117]) \n",
      "Test Loss tensor([0.0147, 0.0129, 0.0147, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.603987455368042 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0156, 0.0140, 0.0149, 0.0128]) \n",
      "Test Loss tensor([0.0144, 0.0122, 0.0144, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6533112525939941 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0147, 0.0134, 0.0143, 0.0117]) \n",
      "Test Loss tensor([0.0144, 0.0126, 0.0148, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.511850118637085 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0146, 0.0115, 0.0131, 0.0114]) \n",
      "Test Loss tensor([0.0144, 0.0122, 0.0143, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5337324142456055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0139, 0.0131, 0.0135, 0.0120]) \n",
      "Test Loss tensor([0.0142, 0.0122, 0.0143, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5237083435058594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0142, 0.0118, 0.0146, 0.0119]) \n",
      "Test Loss tensor([0.0144, 0.0123, 0.0148, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5331563949584961 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0140, 0.0129, 0.0140, 0.0117]) \n",
      "Test Loss tensor([0.0145, 0.0121, 0.0144, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5139591693878174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0142, 0.0126, 0.0133, 0.0151]) \n",
      "Test Loss tensor([0.0140, 0.0124, 0.0144, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5229365825653076 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0143, 0.0107, 0.0153, 0.0120]) \n",
      "Test Loss tensor([0.0141, 0.0125, 0.0147, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4424118995666504 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0136, 0.0145, 0.0130, 0.0116]) \n",
      "Test Loss tensor([0.0140, 0.0121, 0.0144, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4245116710662842 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0130, 0.0124, 0.0140, 0.0117]) \n",
      "Test Loss tensor([0.0138, 0.0123, 0.0148, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4458458423614502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0146, 0.0127, 0.0137, 0.0120]) \n",
      "Test Loss tensor([0.0138, 0.0126, 0.0144, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4358196258544922 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0147, 0.0117, 0.0129, 0.0113]) \n",
      "Test Loss tensor([0.0142, 0.0125, 0.0143, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.43491387367248535 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0146, 0.0126, 0.0135, 0.0125]) \n",
      "Test Loss tensor([0.0140, 0.0123, 0.0145, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.43975043296813965 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0150, 0.0125, 0.0134, 0.0121]) \n",
      "Test Loss tensor([0.0142, 0.0124, 0.0145, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4481527805328369 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0130, 0.0130, 0.0135, 0.0119]) \n",
      "Test Loss tensor([0.0142, 0.0126, 0.0137, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5027122497558594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0138, 0.0136, 0.0138, 0.0128]) \n",
      "Test Loss tensor([0.0138, 0.0123, 0.0143, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.42253661155700684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0126, 0.0122, 0.0138, 0.0131]) \n",
      "Test Loss tensor([0.0136, 0.0127, 0.0142, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.43387389183044434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0132, 0.0110, 0.0141, 0.0111]) \n",
      "Test Loss tensor([0.0133, 0.0125, 0.0143, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.43080735206604004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0130, 0.0138, 0.0126]) \n",
      "Test Loss tensor([0.0140, 0.0123, 0.0141, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4385972023010254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0155, 0.0126, 0.0151, 0.0131]) \n",
      "Test Loss tensor([0.0139, 0.0121, 0.0139, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4264357089996338 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0129, 0.0140, 0.0119]) \n",
      "Test Loss tensor([0.0139, 0.0125, 0.0144, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47154736518859863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0121, 0.0117, 0.0138, 0.0121]) \n",
      "Test Loss tensor([0.0136, 0.0120, 0.0142, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4308609962463379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0135, 0.0136, 0.0139, 0.0121]) \n",
      "Test Loss tensor([0.0139, 0.0124, 0.0141, 0.0119])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 600 in 0.45747828483581543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0127, 0.0146, 0.0113]) \n",
      "Test Loss tensor([0.0139, 0.0122, 0.0136, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4920682907104492 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0137, 0.0124, 0.0128, 0.0109]) \n",
      "Test Loss tensor([0.0134, 0.0123, 0.0151, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5109047889709473 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0142, 0.0131, 0.0130, 0.0122]) \n",
      "Test Loss tensor([0.0135, 0.0121, 0.0142, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.48867177963256836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0135, 0.0107, 0.0144, 0.0121]) \n",
      "Test Loss tensor([0.0135, 0.0121, 0.0138, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4664347171783447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0130, 0.0114, 0.0142, 0.0112]) \n",
      "Test Loss tensor([0.0135, 0.0126, 0.0139, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4751396179199219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0138, 0.0122, 0.0138, 0.0110]) \n",
      "Test Loss tensor([0.0137, 0.0123, 0.0142, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4624309539794922 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0131, 0.0116, 0.0144, 0.0117]) \n",
      "Test Loss tensor([0.0135, 0.0120, 0.0140, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5335710048675537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0121, 0.0130, 0.0117]) \n",
      "Test Loss tensor([0.0136, 0.0124, 0.0140, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.48331761360168457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0143, 0.0117, 0.0144, 0.0142]) \n",
      "Test Loss tensor([0.0133, 0.0122, 0.0140, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4588315486907959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0132, 0.0124, 0.0132, 0.0114]) \n",
      "Test Loss tensor([0.0135, 0.0121, 0.0150, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.423492431640625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0127, 0.0119, 0.0146, 0.0122]) \n",
      "Test Loss tensor([0.0131, 0.0120, 0.0142, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.45490241050720215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0124, 0.0122, 0.0102]) \n",
      "Test Loss tensor([0.0140, 0.0124, 0.0145, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.43324923515319824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0139, 0.0120, 0.0126, 0.0117]) \n",
      "Test Loss tensor([0.0134, 0.0126, 0.0136, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.46054816246032715 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0136, 0.0130, 0.0151, 0.0131]) \n",
      "Test Loss tensor([0.0131, 0.0122, 0.0145, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5584380626678467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0125, 0.0132, 0.0118]) \n",
      "Test Loss tensor([0.0132, 0.0123, 0.0149, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5006899833679199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0126, 0.0156, 0.0129]) \n",
      "Test Loss tensor([0.0132, 0.0126, 0.0136, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4701077938079834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0132, 0.0112, 0.0138, 0.0124]) \n",
      "Test Loss tensor([0.0132, 0.0124, 0.0151, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4675593376159668 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0125, 0.0133, 0.0160, 0.0106]) \n",
      "Test Loss tensor([0.0130, 0.0120, 0.0136, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47503662109375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0122, 0.0123, 0.0123, 0.0113]) \n",
      "Test Loss tensor([0.0135, 0.0125, 0.0146, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4634673595428467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0134, 0.0133, 0.0138, 0.0125]) \n",
      "Test Loss tensor([0.0129, 0.0123, 0.0135, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5283472537994385 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0133, 0.0127, 0.0141, 0.0116]) \n",
      "Test Loss tensor([0.0135, 0.0122, 0.0139, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5628364086151123 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0128, 0.0124, 0.0151, 0.0113]) \n",
      "Test Loss tensor([0.0129, 0.0119, 0.0137, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.45322227478027344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0121, 0.0126, 0.0119]) \n",
      "Test Loss tensor([0.0129, 0.0123, 0.0136, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4729185104370117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0123, 0.0149, 0.0127]) \n",
      "Test Loss tensor([0.0130, 0.0124, 0.0139, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5797162055969238 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0139, 0.0109, 0.0144, 0.0110]) \n",
      "Test Loss tensor([0.0132, 0.0123, 0.0144, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.52142333984375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0121, 0.0132, 0.0143, 0.0110]) \n",
      "Test Loss tensor([0.0130, 0.0119, 0.0138, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47549867630004883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0128, 0.0137, 0.0108]) \n",
      "Test Loss tensor([0.0127, 0.0117, 0.0143, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5094099044799805 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0132, 0.0132, 0.0109]) \n",
      "Test Loss tensor([0.0122, 0.0121, 0.0143, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5815737247467041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0137, 0.0124, 0.0150, 0.0108]) \n",
      "Test Loss tensor([0.0130, 0.0118, 0.0137, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4710574150085449 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0131, 0.0127, 0.0123, 0.0109]) \n",
      "Test Loss tensor([0.0127, 0.0120, 0.0139, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.558387041091919 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0127, 0.0127, 0.0130, 0.0122]) \n",
      "Test Loss tensor([0.0129, 0.0118, 0.0137, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4370458126068115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0148, 0.0126, 0.0129, 0.0122]) \n",
      "Test Loss tensor([0.0127, 0.0119, 0.0141, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.48180651664733887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0127, 0.0147, 0.0113]) \n",
      "Test Loss tensor([0.0129, 0.0124, 0.0131, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5066738128662109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0120, 0.0133, 0.0136, 0.0112]) \n",
      "Test Loss tensor([0.0129, 0.0120, 0.0139, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.46112871170043945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0122, 0.0118, 0.0121, 0.0115]) \n",
      "Test Loss tensor([0.0128, 0.0119, 0.0135, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.44307827949523926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0113, 0.0148, 0.0122]) \n",
      "Test Loss tensor([0.0125, 0.0122, 0.0136, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6121070384979248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0122, 0.0130, 0.0113]) \n",
      "Test Loss tensor([0.0126, 0.0123, 0.0136, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6084887981414795 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0108, 0.0141, 0.0112]) \n",
      "Test Loss tensor([0.0124, 0.0122, 0.0133, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5573699474334717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0104, 0.0134, 0.0117]) \n",
      "Test Loss tensor([0.0126, 0.0122, 0.0133, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.630448579788208 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0127, 0.0134, 0.0106]) \n",
      "Test Loss tensor([0.0126, 0.0121, 0.0134, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7131640911102295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0121, 0.0114, 0.0130, 0.0115]) \n",
      "Test Loss tensor([0.0126, 0.0119, 0.0138, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5579981803894043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0125, 0.0117, 0.0138, 0.0114]) \n",
      "Test Loss tensor([0.0125, 0.0121, 0.0132, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6228847503662109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0128, 0.0126, 0.0134, 0.0111]) \n",
      "Test Loss tensor([0.0124, 0.0123, 0.0136, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.553311824798584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0119, 0.0116, 0.0126, 0.0117]) \n",
      "Test Loss tensor([0.0128, 0.0122, 0.0135, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.54768967628479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0134, 0.0121, 0.0128, 0.0108]) \n",
      "Test Loss tensor([0.0123, 0.0120, 0.0134, 0.0119])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 780 in 0.5574789047241211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0136, 0.0121, 0.0119, 0.0119]) \n",
      "Test Loss tensor([0.0124, 0.0121, 0.0134, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.539299488067627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0128, 0.0122, 0.0150, 0.0113]) \n",
      "Test Loss tensor([0.0129, 0.0120, 0.0129, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5441677570343018 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0139, 0.0123, 0.0131, 0.0103]) \n",
      "Test Loss tensor([0.0123, 0.0118, 0.0129, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5592052936553955 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0120, 0.0128, 0.0136, 0.0105]) \n",
      "Test Loss tensor([0.0123, 0.0123, 0.0132, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.55898118019104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0130, 0.0124, 0.0126, 0.0123]) \n",
      "Test Loss tensor([0.0125, 0.0120, 0.0134, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5543270111083984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0127, 0.0116, 0.0130, 0.0117]) \n",
      "Test Loss tensor([0.0123, 0.0121, 0.0137, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5178835391998291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0129, 0.0142, 0.0122]) \n",
      "Test Loss tensor([0.0126, 0.0123, 0.0132, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.560755729675293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0120, 0.0111, 0.0134, 0.0120]) \n",
      "Test Loss tensor([0.0122, 0.0119, 0.0131, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5593862533569336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0126, 0.0140, 0.0101]) \n",
      "Test Loss tensor([0.0123, 0.0121, 0.0133, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5009448528289795 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0127, 0.0115, 0.0129, 0.0116]) \n",
      "Test Loss tensor([0.0120, 0.0119, 0.0135, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6032257080078125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0118, 0.0130, 0.0132, 0.0117]) \n",
      "Test Loss tensor([0.0118, 0.0115, 0.0133, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6665358543395996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0125, 0.0143, 0.0124, 0.0108]) \n",
      "Test Loss tensor([0.0120, 0.0123, 0.0135, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6104204654693604 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0120, 0.0127, 0.0118]) \n",
      "Test Loss tensor([0.0123, 0.0122, 0.0129, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5850589275360107 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0132, 0.0121, 0.0145, 0.0107]) \n",
      "Test Loss tensor([0.0116, 0.0118, 0.0132, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6123757362365723 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0119, 0.0131, 0.0118]) \n",
      "Test Loss tensor([0.0119, 0.0122, 0.0131, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5274591445922852 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0115, 0.0130, 0.0103]) \n",
      "Test Loss tensor([0.0121, 0.0117, 0.0132, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4703044891357422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0129, 0.0123, 0.0130, 0.0131]) \n",
      "Test Loss tensor([0.0123, 0.0121, 0.0130, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5841338634490967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0124, 0.0120, 0.0120]) \n",
      "Test Loss tensor([0.0117, 0.0118, 0.0134, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6771354675292969 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0125, 0.0124, 0.0149, 0.0108]) \n",
      "Test Loss tensor([0.0119, 0.0121, 0.0129, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5907905101776123 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0122, 0.0130, 0.0127, 0.0101]) \n",
      "Test Loss tensor([0.0118, 0.0114, 0.0137, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6195671558380127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0118, 0.0127, 0.0102]) \n",
      "Test Loss tensor([0.0121, 0.0122, 0.0128, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6088247299194336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0119, 0.0118, 0.0122, 0.0104]) \n",
      "Test Loss tensor([0.0119, 0.0118, 0.0138, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5947372913360596 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0112, 0.0132, 0.0118]) \n",
      "Test Loss tensor([0.0117, 0.0117, 0.0131, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.587390661239624 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0128, 0.0116, 0.0134, 0.0111]) \n",
      "Test Loss tensor([0.0121, 0.0116, 0.0135, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5788438320159912 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0084, 0.0108, 0.0095]) \n",
      "Test Loss tensor([0.0118, 0.0114, 0.0136, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5529212951660156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0125, 0.0136, 0.0115]) \n",
      "Test Loss tensor([0.0118, 0.0118, 0.0134, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5189530849456787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0122, 0.0122, 0.0127, 0.0114]) \n",
      "Test Loss tensor([0.0117, 0.0122, 0.0139, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5058760643005371 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0124, 0.0119, 0.0112]) \n",
      "Test Loss tensor([0.0119, 0.0122, 0.0127, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5042827129364014 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0124, 0.0109, 0.0138, 0.0125]) \n",
      "Test Loss tensor([0.0118, 0.0123, 0.0125, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5091238021850586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0120, 0.0132, 0.0117]) \n",
      "Test Loss tensor([0.0114, 0.0118, 0.0130, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5310115814208984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0116, 0.0121, 0.0120]) \n",
      "Test Loss tensor([0.0117, 0.0120, 0.0136, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5232479572296143 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0121, 0.0137, 0.0107]) \n",
      "Test Loss tensor([0.0115, 0.0115, 0.0130, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5043847560882568 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0125, 0.0109, 0.0109]) \n",
      "Test Loss tensor([0.0116, 0.0120, 0.0135, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5165834426879883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0127, 0.0143, 0.0110]) \n",
      "Test Loss tensor([0.0119, 0.0123, 0.0125, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5213830471038818 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0119, 0.0121, 0.0117, 0.0111]) \n",
      "Test Loss tensor([0.0120, 0.0119, 0.0128, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5101232528686523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0126, 0.0116, 0.0123, 0.0121]) \n",
      "Test Loss tensor([0.0115, 0.0118, 0.0129, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5132036209106445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0119, 0.0124, 0.0134, 0.0116]) \n",
      "Test Loss tensor([0.0116, 0.0122, 0.0136, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4955451488494873 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0116, 0.0124, 0.0131, 0.0116]) \n",
      "Test Loss tensor([0.0112, 0.0118, 0.0129, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5146212577819824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0119, 0.0114, 0.0136, 0.0125]) \n",
      "Test Loss tensor([0.0114, 0.0120, 0.0137, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5261833667755127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0119, 0.0146, 0.0117]) \n",
      "Test Loss tensor([0.0114, 0.0119, 0.0130, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5132596492767334 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0129, 0.0147, 0.0110]) \n",
      "Test Loss tensor([0.0119, 0.0118, 0.0127, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5192883014678955 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0119, 0.0141, 0.0114]) \n",
      "Test Loss tensor([0.0110, 0.0118, 0.0129, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5025227069854736 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0116, 0.0121, 0.0104]) \n",
      "Test Loss tensor([0.0116, 0.0119, 0.0129, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5052964687347412 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0118, 0.0128, 0.0119, 0.0109]) \n",
      "Test Loss tensor([0.0116, 0.0117, 0.0128, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5167078971862793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0127, 0.0129, 0.0123]) \n",
      "Test Loss tensor([0.0114, 0.0119, 0.0130, 0.0112])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 80 in 0.5052998065948486 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0121, 0.0126, 0.0133, 0.0119]) \n",
      "Test Loss tensor([0.0114, 0.0118, 0.0136, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5116524696350098 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0114, 0.0143, 0.0112]) \n",
      "Test Loss tensor([0.0114, 0.0116, 0.0128, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4986579418182373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0124, 0.0131, 0.0115]) \n",
      "Test Loss tensor([0.0116, 0.0117, 0.0130, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5110073089599609 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0125, 0.0128, 0.0116]) \n",
      "Test Loss tensor([0.0115, 0.0117, 0.0125, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5070459842681885 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0119, 0.0121, 0.0121]) \n",
      "Test Loss tensor([0.0117, 0.0122, 0.0124, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5252580642700195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0113, 0.0127, 0.0107]) \n",
      "Test Loss tensor([0.0110, 0.0117, 0.0125, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5099637508392334 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0110, 0.0130, 0.0113]) \n",
      "Test Loss tensor([0.0112, 0.0115, 0.0126, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5111856460571289 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0129, 0.0131, 0.0102]) \n",
      "Test Loss tensor([0.0112, 0.0116, 0.0128, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5036237239837646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0119, 0.0119, 0.0117]) \n",
      "Test Loss tensor([0.0110, 0.0116, 0.0130, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5150184631347656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0116, 0.0111, 0.0105]) \n",
      "Test Loss tensor([0.0111, 0.0116, 0.0126, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5016336441040039 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0129, 0.0118, 0.0110]) \n",
      "Test Loss tensor([0.0116, 0.0118, 0.0128, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5330226421356201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0116, 0.0112, 0.0112]) \n",
      "Test Loss tensor([0.0112, 0.0117, 0.0127, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5072765350341797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0115, 0.0113, 0.0112]) \n",
      "Test Loss tensor([0.0115, 0.0119, 0.0128, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5240955352783203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0116, 0.0127, 0.0123]) \n",
      "Test Loss tensor([0.0112, 0.0117, 0.0133, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5019679069519043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0124, 0.0124, 0.0114]) \n",
      "Test Loss tensor([0.0111, 0.0117, 0.0124, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5146839618682861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0106, 0.0115, 0.0123, 0.0104]) \n",
      "Test Loss tensor([0.0108, 0.0117, 0.0125, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5044198036193848 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0126, 0.0125, 0.0111]) \n",
      "Test Loss tensor([0.0108, 0.0115, 0.0126, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5249872207641602 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0113, 0.0130, 0.0102]) \n",
      "Test Loss tensor([0.0112, 0.0116, 0.0128, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4986119270324707 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0110, 0.0116, 0.0115]) \n",
      "Test Loss tensor([0.0113, 0.0119, 0.0125, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5196449756622314 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0120, 0.0121, 0.0116]) \n",
      "Test Loss tensor([0.0110, 0.0116, 0.0126, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5003809928894043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0106, 0.0125, 0.0115]) \n",
      "Test Loss tensor([0.0113, 0.0115, 0.0128, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.541010856628418 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0109, 0.0123, 0.0093]) \n",
      "Test Loss tensor([0.0112, 0.0118, 0.0127, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5476500988006592 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0125, 0.0113, 0.0123, 0.0095]) \n",
      "Test Loss tensor([0.0107, 0.0114, 0.0132, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5515015125274658 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0105, 0.0133, 0.0104]) \n",
      "Test Loss tensor([0.0109, 0.0117, 0.0124, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5433108806610107 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0118, 0.0130, 0.0112]) \n",
      "Test Loss tensor([0.0111, 0.0118, 0.0131, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5424549579620361 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0127, 0.0122, 0.0108]) \n",
      "Test Loss tensor([0.0109, 0.0117, 0.0130, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5406186580657959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0119, 0.0151, 0.0110]) \n",
      "Test Loss tensor([0.0107, 0.0115, 0.0129, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.7195312976837158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0123, 0.0126, 0.0102]) \n",
      "Test Loss tensor([0.0114, 0.0119, 0.0127, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5595312118530273 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0114, 0.0125, 0.0110]) \n",
      "Test Loss tensor([0.0109, 0.0118, 0.0123, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7268381118774414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0106, 0.0124, 0.0133, 0.0120]) \n",
      "Test Loss tensor([0.0108, 0.0119, 0.0121, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6584494113922119 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0116, 0.0114, 0.0109, 0.0112]) \n",
      "Test Loss tensor([0.0108, 0.0118, 0.0129, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7143325805664062 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0109, 0.0122, 0.0108]) \n",
      "Test Loss tensor([0.0107, 0.0116, 0.0132, 0.0115])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6960585117340088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0111, 0.0131, 0.0097]) \n",
      "Test Loss tensor([0.0107, 0.0116, 0.0125, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6425237655639648 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0128, 0.0118, 0.0109]) \n",
      "Test Loss tensor([0.0108, 0.0116, 0.0123, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5998635292053223 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0123, 0.0124, 0.0126, 0.0114]) \n",
      "Test Loss tensor([0.0108, 0.0114, 0.0127, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5255184173583984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0118, 0.0110, 0.0111]) \n",
      "Test Loss tensor([0.0106, 0.0116, 0.0128, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4768102169036865 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0120, 0.0123, 0.0108]) \n",
      "Test Loss tensor([0.0107, 0.0117, 0.0123, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.46446847915649414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0114, 0.0108, 0.0110]) \n",
      "Test Loss tensor([0.0109, 0.0117, 0.0123, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.45894455909729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0106, 0.0124, 0.0107]) \n",
      "Test Loss tensor([0.0106, 0.0119, 0.0125, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4523344039916992 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0117, 0.0116, 0.0115, 0.0120]) \n",
      "Test Loss tensor([0.0112, 0.0117, 0.0129, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4591410160064697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0119, 0.0115, 0.0110]) \n",
      "Test Loss tensor([0.0109, 0.0118, 0.0125, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4475889205932617 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0115, 0.0097, 0.0120, 0.0112]) \n",
      "Test Loss tensor([0.0111, 0.0118, 0.0127, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4706411361694336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0115, 0.0138, 0.0115]) \n",
      "Test Loss tensor([0.0109, 0.0115, 0.0125, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4943387508392334 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0114, 0.0125, 0.0114, 0.0118]) \n",
      "Test Loss tensor([0.0105, 0.0118, 0.0126, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4896705150604248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0116, 0.0136, 0.0122]) \n",
      "Test Loss tensor([0.0106, 0.0117, 0.0121, 0.0111])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 260 in 0.46097803115844727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0106, 0.0112, 0.0127, 0.0108]) \n",
      "Test Loss tensor([0.0106, 0.0117, 0.0126, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.45272111892700195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0115, 0.0117, 0.0119]) \n",
      "Test Loss tensor([0.0106, 0.0117, 0.0121, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4515702724456787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0121, 0.0125, 0.0106]) \n",
      "Test Loss tensor([0.0108, 0.0115, 0.0129, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4644443988800049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0120, 0.0133, 0.0115]) \n",
      "Test Loss tensor([0.0104, 0.0114, 0.0131, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4550437927246094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0111, 0.0121, 0.0121, 0.0126]) \n",
      "Test Loss tensor([0.0105, 0.0115, 0.0126, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4768078327178955 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0125, 0.0125, 0.0106]) \n",
      "Test Loss tensor([0.0107, 0.0116, 0.0121, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.484738826751709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0134, 0.0136, 0.0121]) \n",
      "Test Loss tensor([0.0108, 0.0115, 0.0122, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4878373146057129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0101, 0.0128, 0.0106]) \n",
      "Test Loss tensor([0.0104, 0.0113, 0.0134, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.48981308937072754 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0105, 0.0111, 0.0109]) \n",
      "Test Loss tensor([0.0109, 0.0112, 0.0126, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4727466106414795 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0123, 0.0116, 0.0113]) \n",
      "Test Loss tensor([0.0109, 0.0113, 0.0123, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4802224636077881 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0121, 0.0116, 0.0117, 0.0129]) \n",
      "Test Loss tensor([0.0107, 0.0113, 0.0126, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4542570114135742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0105, 0.0123, 0.0126, 0.0114]) \n",
      "Test Loss tensor([0.0109, 0.0118, 0.0124, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4824042320251465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0105, 0.0107, 0.0140, 0.0105]) \n",
      "Test Loss tensor([0.0106, 0.0117, 0.0130, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4526095390319824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0113, 0.0123, 0.0112]) \n",
      "Test Loss tensor([0.0109, 0.0113, 0.0136, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.46642112731933594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0115, 0.0126, 0.0109]) \n",
      "Test Loss tensor([0.0111, 0.0117, 0.0127, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4496629238128662 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0123, 0.0110, 0.0112]) \n",
      "Test Loss tensor([0.0109, 0.0119, 0.0126, 0.0116])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4666757583618164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0120, 0.0113, 0.0123, 0.0118]) \n",
      "Test Loss tensor([0.0104, 0.0115, 0.0126, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4487133026123047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0126, 0.0143, 0.0128]) \n",
      "Test Loss tensor([0.0108, 0.0115, 0.0133, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4768226146697998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0121, 0.0119, 0.0106]) \n",
      "Test Loss tensor([0.0107, 0.0114, 0.0124, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47359561920166016 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0110, 0.0117, 0.0108]) \n",
      "Test Loss tensor([0.0107, 0.0117, 0.0136, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4494144916534424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0114, 0.0154, 0.0102]) \n",
      "Test Loss tensor([0.0105, 0.0120, 0.0118, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47412729263305664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0121, 0.0133, 0.0104]) \n",
      "Test Loss tensor([0.0109, 0.0116, 0.0134, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4477405548095703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0105, 0.0122, 0.0118]) \n",
      "Test Loss tensor([0.0103, 0.0118, 0.0121, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.47135305404663086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0130, 0.0105, 0.0112]) \n",
      "Test Loss tensor([0.0105, 0.0117, 0.0129, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.466738224029541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0122, 0.0135, 0.0118]) \n",
      "Test Loss tensor([0.0103, 0.0113, 0.0126, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4980921745300293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0113, 0.0114, 0.0118]) \n",
      "Test Loss tensor([0.0106, 0.0116, 0.0127, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4662132263183594 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0113, 0.0124, 0.0116]) \n",
      "Test Loss tensor([0.0103, 0.0116, 0.0119, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4715454578399658 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0120, 0.0118, 0.0110]) \n",
      "Test Loss tensor([0.0105, 0.0116, 0.0127, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4390122890472412 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0121, 0.0114, 0.0105]) \n",
      "Test Loss tensor([0.0105, 0.0118, 0.0124, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4559311866760254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0120, 0.0122, 0.0112]) \n",
      "Test Loss tensor([0.0104, 0.0116, 0.0120, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4631080627441406 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0116, 0.0117, 0.0109]) \n",
      "Test Loss tensor([0.0102, 0.0120, 0.0118, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.463733434677124 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0120, 0.0114, 0.0103]) \n",
      "Test Loss tensor([0.0101, 0.0118, 0.0116, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4475550651550293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0107, 0.0142, 0.0119]) \n",
      "Test Loss tensor([0.0102, 0.0116, 0.0122, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.46004390716552734 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0113, 0.0115, 0.0106]) \n",
      "Test Loss tensor([0.0102, 0.0114, 0.0120, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.452038049697876 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0108, 0.0113, 0.0115]) \n",
      "Test Loss tensor([0.0103, 0.0112, 0.0124, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4639918804168701 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0115, 0.0116, 0.0103]) \n",
      "Test Loss tensor([0.0103, 0.0115, 0.0122, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4535946846008301 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0117, 0.0116, 0.0106]) \n",
      "Test Loss tensor([0.0101, 0.0116, 0.0121, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4859504699707031 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0116, 0.0122, 0.0118]) \n",
      "Test Loss tensor([0.0103, 0.0116, 0.0120, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47756481170654297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0106, 0.0129, 0.0115]) \n",
      "Test Loss tensor([0.0101, 0.0115, 0.0120, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.46488046646118164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0103, 0.0124, 0.0112]) \n",
      "Test Loss tensor([0.0103, 0.0116, 0.0122, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.47040605545043945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0115, 0.0117, 0.0105]) \n",
      "Test Loss tensor([0.0101, 0.0113, 0.0121, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.49906349182128906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0103, 0.0126, 0.0112]) \n",
      "Test Loss tensor([0.0103, 0.0111, 0.0127, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.511883020401001 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0099, 0.0123, 0.0112]) \n",
      "Test Loss tensor([0.0098, 0.0118, 0.0121, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5025725364685059 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0111, 0.0126, 0.0106]) \n",
      "Test Loss tensor([0.0105, 0.0113, 0.0124, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5023477077484131 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0113, 0.0117, 0.0108, 0.0100]) \n",
      "Test Loss tensor([0.0102, 0.0115, 0.0120, 0.0113])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 440 in 0.4847285747528076 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0112, 0.0112, 0.0107]) \n",
      "Test Loss tensor([0.0099, 0.0118, 0.0120, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5098645687103271 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0109, 0.0112, 0.0105]) \n",
      "Test Loss tensor([0.0105, 0.0114, 0.0120, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.48624515533447266 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0119, 0.0116, 0.0106]) \n",
      "Test Loss tensor([0.0102, 0.0113, 0.0121, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5007309913635254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0106, 0.0122, 0.0125, 0.0118]) \n",
      "Test Loss tensor([0.0102, 0.0115, 0.0123, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.49608659744262695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0116, 0.0116, 0.0100]) \n",
      "Test Loss tensor([0.0100, 0.0114, 0.0120, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4925990104675293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0114, 0.0138, 0.0099]) \n",
      "Test Loss tensor([0.0103, 0.0119, 0.0125, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.49340009689331055 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0111, 0.0125, 0.0114]) \n",
      "Test Loss tensor([0.0099, 0.0117, 0.0122, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4938926696777344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0112, 0.0107, 0.0124, 0.0099]) \n",
      "Test Loss tensor([0.0099, 0.0112, 0.0121, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5549807548522949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0115, 0.0133, 0.0108]) \n",
      "Test Loss tensor([0.0101, 0.0116, 0.0121, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.48368096351623535 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0112, 0.0117, 0.0109]) \n",
      "Test Loss tensor([0.0104, 0.0117, 0.0124, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.48670077323913574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0122, 0.0133, 0.0100]) \n",
      "Test Loss tensor([0.0100, 0.0113, 0.0122, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5006425380706787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0117, 0.0114, 0.0097]) \n",
      "Test Loss tensor([0.0104, 0.0114, 0.0125, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4976816177368164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0109, 0.0096, 0.0109]) \n",
      "Test Loss tensor([0.0102, 0.0113, 0.0120, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5010974407196045 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0114, 0.0116, 0.0108]) \n",
      "Test Loss tensor([0.0098, 0.0114, 0.0120, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.4863016605377197 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0117, 0.0115, 0.0115]) \n",
      "Test Loss tensor([0.0098, 0.0112, 0.0120, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4999077320098877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0114, 0.0118, 0.0105]) \n",
      "Test Loss tensor([0.0099, 0.0114, 0.0121, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4873085021972656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0112, 0.0105, 0.0115]) \n",
      "Test Loss tensor([0.0097, 0.0115, 0.0121, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4878044128417969 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0105, 0.0135, 0.0113]) \n",
      "Test Loss tensor([0.0103, 0.0116, 0.0121, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4681427478790283 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0127, 0.0118, 0.0116]) \n",
      "Test Loss tensor([0.0098, 0.0115, 0.0117, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.49263978004455566 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0113, 0.0107, 0.0116]) \n",
      "Test Loss tensor([0.0099, 0.0114, 0.0123, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4903075695037842 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0123, 0.0124, 0.0109]) \n",
      "Test Loss tensor([0.0100, 0.0114, 0.0115, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.49952149391174316 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0111, 0.0108, 0.0106]) \n",
      "Test Loss tensor([0.0102, 0.0114, 0.0122, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.501467227935791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0100, 0.0114, 0.0106]) \n",
      "Test Loss tensor([0.0097, 0.0110, 0.0121, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.48483872413635254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0114, 0.0123, 0.0111]) \n",
      "Test Loss tensor([0.0104, 0.0115, 0.0126, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6928439140319824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0122, 0.0122, 0.0112]) \n",
      "Test Loss tensor([0.0099, 0.0115, 0.0115, 0.0113])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5003280639648438 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0111, 0.0107, 0.0115]) \n",
      "Test Loss tensor([0.0102, 0.0113, 0.0121, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5250160694122314 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0107, 0.0115, 0.0103]) \n",
      "Test Loss tensor([0.0100, 0.0114, 0.0119, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5378947257995605 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0107, 0.0117, 0.0111, 0.0110]) \n",
      "Test Loss tensor([0.0099, 0.0112, 0.0124, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6148478984832764 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0121, 0.0115, 0.0112]) \n",
      "Test Loss tensor([0.0097, 0.0112, 0.0118, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5475788116455078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0110, 0.0112, 0.0112, 0.0105]) \n",
      "Test Loss tensor([0.0097, 0.0112, 0.0117, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5731201171875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0112, 0.0122, 0.0118]) \n",
      "Test Loss tensor([0.0099, 0.0113, 0.0112, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4985787868499756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0116, 0.0116, 0.0107]) \n",
      "Test Loss tensor([0.0095, 0.0112, 0.0117, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.49952197074890137 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0109, 0.0131, 0.0097]) \n",
      "Test Loss tensor([0.0095, 0.0111, 0.0116, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.47963666915893555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0108, 0.0113, 0.0124]) \n",
      "Test Loss tensor([0.0100, 0.0113, 0.0119, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5933492183685303 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0107, 0.0122, 0.0109]) \n",
      "Test Loss tensor([0.0098, 0.0115, 0.0116, 0.0112])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5874507427215576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0106, 0.0125, 0.0122, 0.0112]) \n",
      "Test Loss tensor([0.0100, 0.0113, 0.0116, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4972553253173828 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0114, 0.0112, 0.0115]) \n",
      "Test Loss tensor([0.0098, 0.0115, 0.0113, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5443260669708252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0108, 0.0123, 0.0119, 0.0112]) \n",
      "Test Loss tensor([0.0097, 0.0111, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5554306507110596 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0105, 0.0116, 0.0104, 0.0098]) \n",
      "Test Loss tensor([0.0096, 0.0111, 0.0116, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5277457237243652 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0116, 0.0116, 0.0117]) \n",
      "Test Loss tensor([0.0100, 0.0116, 0.0115, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4819459915161133 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0120, 0.0132, 0.0105]) \n",
      "Test Loss tensor([0.0097, 0.0111, 0.0114, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4722282886505127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0127, 0.0110, 0.0118]) \n",
      "Test Loss tensor([0.0099, 0.0117, 0.0116, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4612894058227539 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0125, 0.0112, 0.0112]) \n",
      "Test Loss tensor([0.0095, 0.0113, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.500680685043335 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0104, 0.0103, 0.0109]) \n",
      "Test Loss tensor([0.0098, 0.0113, 0.0117, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4724903106689453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0108, 0.0122, 0.0108]) \n",
      "Test Loss tensor([0.0099, 0.0113, 0.0113, 0.0111])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 620 in 0.45944690704345703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0098, 0.0112, 0.0103]) \n",
      "Test Loss tensor([0.0101, 0.0110, 0.0114, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4801905155181885 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0108, 0.0101, 0.0116]) \n",
      "Test Loss tensor([0.0101, 0.0116, 0.0119, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.46025633811950684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0115, 0.0104, 0.0105]) \n",
      "Test Loss tensor([0.0098, 0.0111, 0.0118, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.48314690589904785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0120, 0.0113, 0.0108]) \n",
      "Test Loss tensor([0.0097, 0.0116, 0.0116, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.46019625663757324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0115, 0.0121, 0.0101, 0.0097]) \n",
      "Test Loss tensor([0.0095, 0.0113, 0.0114, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47212934494018555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0125, 0.0122, 0.0108]) \n",
      "Test Loss tensor([0.0097, 0.0111, 0.0112, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.46581387519836426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0109, 0.0110, 0.0111, 0.0108]) \n",
      "Test Loss tensor([0.0096, 0.0110, 0.0115, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5118131637573242 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0105, 0.0122, 0.0125, 0.0106]) \n",
      "Test Loss tensor([0.0096, 0.0111, 0.0117, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5020442008972168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0108, 0.0122, 0.0098]) \n",
      "Test Loss tensor([0.0095, 0.0113, 0.0115, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.492445707321167 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0134, 0.0114, 0.0108]) \n",
      "Test Loss tensor([0.0097, 0.0114, 0.0117, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.483518123626709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0111, 0.0120, 0.0106]) \n",
      "Test Loss tensor([0.0096, 0.0114, 0.0113, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4743161201477051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0125, 0.0125, 0.0117]) \n",
      "Test Loss tensor([0.0098, 0.0115, 0.0122, 0.0114])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.45960235595703125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0106, 0.0113, 0.0116]) \n",
      "Test Loss tensor([0.0099, 0.0113, 0.0116, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47672128677368164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0111, 0.0117, 0.0116]) \n",
      "Test Loss tensor([0.0097, 0.0111, 0.0112, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4645097255706787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0109, 0.0125, 0.0114]) \n",
      "Test Loss tensor([0.0099, 0.0113, 0.0118, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5183854103088379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0117, 0.0098, 0.0111]) \n",
      "Test Loss tensor([0.0100, 0.0114, 0.0117, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.48545384407043457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0113, 0.0129, 0.0104]) \n",
      "Test Loss tensor([0.0098, 0.0113, 0.0116, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.502920389175415 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0109, 0.0119, 0.0097]) \n",
      "Test Loss tensor([0.0094, 0.0115, 0.0118, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4854166507720947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0127, 0.0100, 0.0110]) \n",
      "Test Loss tensor([0.0096, 0.0109, 0.0117, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.48557114601135254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0107, 0.0100, 0.0108]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0123, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.45768094062805176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0113, 0.0124, 0.0111]) \n",
      "Test Loss tensor([0.0096, 0.0112, 0.0114, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47593069076538086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0117, 0.0108, 0.0108]) \n",
      "Test Loss tensor([0.0096, 0.0113, 0.0115, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.46454906463623047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0114, 0.0098, 0.0106]) \n",
      "Test Loss tensor([0.0095, 0.0108, 0.0118, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.46711087226867676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0115, 0.0120, 0.0106]) \n",
      "Test Loss tensor([0.0095, 0.0107, 0.0119, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4680445194244385 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0118, 0.0109, 0.0103]) \n",
      "Test Loss tensor([0.0096, 0.0114, 0.0114, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4586966037750244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0108, 0.0123, 0.0103]) \n",
      "Test Loss tensor([0.0095, 0.0112, 0.0115, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4664614200592041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0118, 0.0123, 0.0108]) \n",
      "Test Loss tensor([0.0099, 0.0112, 0.0115, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.45838427543640137 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0105, 0.0118, 0.0126, 0.0105]) \n",
      "Test Loss tensor([0.0095, 0.0108, 0.0114, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4736354351043701 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0120, 0.0113, 0.0104]) \n",
      "Test Loss tensor([0.0098, 0.0115, 0.0115, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4591050148010254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0109, 0.0116, 0.0110]) \n",
      "Test Loss tensor([0.0100, 0.0116, 0.0117, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.48067688941955566 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0120, 0.0112, 0.0111]) \n",
      "Test Loss tensor([0.0097, 0.0111, 0.0115, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.46155333518981934 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0121, 0.0114, 0.0106]) \n",
      "Test Loss tensor([0.0094, 0.0111, 0.0116, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.48168349266052246 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0113, 0.0103, 0.0101]) \n",
      "Test Loss tensor([0.0096, 0.0113, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4855048656463623 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0126, 0.0119, 0.0116]) \n",
      "Test Loss tensor([0.0094, 0.0108, 0.0118, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4801900386810303 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0109, 0.0119, 0.0113]) \n",
      "Test Loss tensor([0.0096, 0.0110, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.46783876419067383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0110, 0.0119, 0.0110]) \n",
      "Test Loss tensor([0.0094, 0.0112, 0.0117, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47905468940734863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0125, 0.0110, 0.0112]) \n",
      "Test Loss tensor([0.0093, 0.0108, 0.0115, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4725477695465088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0116, 0.0112, 0.0105]) \n",
      "Test Loss tensor([0.0092, 0.0112, 0.0114, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.48941922187805176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0104, 0.0122, 0.0103]) \n",
      "Test Loss tensor([0.0094, 0.0111, 0.0115, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.46014952659606934 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0112, 0.0130, 0.0107]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0113, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47457265853881836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0111, 0.0109, 0.0098]) \n",
      "Test Loss tensor([0.0094, 0.0110, 0.0113, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.46875810623168945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0109, 0.0101, 0.0103]) \n",
      "Test Loss tensor([0.0094, 0.0113, 0.0115, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.48871541023254395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0112, 0.0108, 0.0112]) \n",
      "Test Loss tensor([0.0094, 0.0111, 0.0114, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4647233486175537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0123, 0.0115, 0.0113]) \n",
      "Test Loss tensor([0.0092, 0.0112, 0.0116, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.46073293685913086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0101, 0.0105, 0.0099]) \n",
      "Test Loss tensor([0.0098, 0.0111, 0.0118, 0.0108])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 800 in 0.4746119976043701 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0111, 0.0125, 0.0105]) \n",
      "Test Loss tensor([0.0096, 0.0115, 0.0113, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.46309614181518555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0115, 0.0103, 0.0110]) \n",
      "Test Loss tensor([0.0093, 0.0110, 0.0115, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.46961545944213867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0106, 0.0128, 0.0094]) \n",
      "Test Loss tensor([0.0096, 0.0113, 0.0113, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4530904293060303 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0102, 0.0121, 0.0106, 0.0108]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0118, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.46402835845947266 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0111, 0.0103, 0.0098]) \n",
      "Test Loss tensor([0.0090, 0.0113, 0.0111, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.46380186080932617 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0115, 0.0117, 0.0117]) \n",
      "Test Loss tensor([0.0095, 0.0114, 0.0114, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.466296911239624 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0123, 0.0105, 0.0106]) \n",
      "Test Loss tensor([0.0095, 0.0114, 0.0114, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.45585012435913086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0101, 0.0106, 0.0109]) \n",
      "Test Loss tensor([0.0094, 0.0108, 0.0114, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5035943984985352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0111, 0.0124, 0.0102]) \n",
      "Test Loss tensor([0.0093, 0.0110, 0.0111, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.48282861709594727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0115, 0.0118, 0.0097]) \n",
      "Test Loss tensor([0.0093, 0.0111, 0.0112, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.49495601654052734 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0120, 0.0108, 0.0105]) \n",
      "Test Loss tensor([0.0094, 0.0111, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4621129035949707 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0111, 0.0130, 0.0097]) \n",
      "Test Loss tensor([0.0095, 0.0115, 0.0112, 0.0111])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4720802307128906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0119, 0.0111, 0.0116]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0116, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4585304260253906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0115, 0.0108, 0.0099]) \n",
      "Test Loss tensor([0.0099, 0.0113, 0.0116, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5017900466918945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0111, 0.0115, 0.0109]) \n",
      "Test Loss tensor([0.0094, 0.0109, 0.0115, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4703505039215088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0104, 0.0109, 0.0106]) \n",
      "Test Loss tensor([0.0095, 0.0110, 0.0113, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.45754218101501465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0112, 0.0104, 0.0111]) \n",
      "Test Loss tensor([0.0094, 0.0112, 0.0117, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4763765335083008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0103, 0.0110, 0.0110, 0.0103]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0111, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4860825538635254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0115, 0.0115, 0.0110]) \n",
      "Test Loss tensor([0.0094, 0.0109, 0.0114, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4750831127166748 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0083, 0.0076, 0.0083]) \n",
      "Test Loss tensor([0.0094, 0.0109, 0.0111, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.462221622467041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0107, 0.0111, 0.0099]) \n",
      "Test Loss tensor([0.0093, 0.0114, 0.0110, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4635617733001709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0116, 0.0106, 0.0117]) \n",
      "Test Loss tensor([0.0090, 0.0111, 0.0112, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.49298858642578125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0114, 0.0118, 0.0107]) \n",
      "Test Loss tensor([0.0092, 0.0111, 0.0110, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4899749755859375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0119, 0.0110, 0.0110]) \n",
      "Test Loss tensor([0.0093, 0.0111, 0.0114, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.49579763412475586 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0114, 0.0103, 0.0104]) \n",
      "Test Loss tensor([0.0092, 0.0111, 0.0114, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.49786829948425293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0114, 0.0121, 0.0110]) \n",
      "Test Loss tensor([0.0092, 0.0113, 0.0111, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.500791072845459 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0111, 0.0092, 0.0107]) \n",
      "Test Loss tensor([0.0089, 0.0113, 0.0111, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4941539764404297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0108, 0.0100, 0.0110]) \n",
      "Test Loss tensor([0.0093, 0.0112, 0.0108, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.47141313552856445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0121, 0.0109, 0.0112]) \n",
      "Test Loss tensor([0.0094, 0.0112, 0.0110, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.47286462783813477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0100, 0.0116, 0.0095]) \n",
      "Test Loss tensor([0.0091, 0.0111, 0.0114, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.46367907524108887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0108, 0.0105, 0.0109]) \n",
      "Test Loss tensor([0.0092, 0.0109, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.493088960647583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0092, 0.0101, 0.0116]) \n",
      "Test Loss tensor([0.0090, 0.0107, 0.0109, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.45984864234924316 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0110, 0.0120, 0.0101]) \n",
      "Test Loss tensor([0.0091, 0.0110, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47498178482055664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0104, 0.0114, 0.0100]) \n",
      "Test Loss tensor([0.0090, 0.0110, 0.0112, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4674830436706543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0114, 0.0108, 0.0108]) \n",
      "Test Loss tensor([0.0092, 0.0110, 0.0114, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4805622100830078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0109, 0.0107, 0.0106]) \n",
      "Test Loss tensor([0.0092, 0.0108, 0.0110, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.46265411376953125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0113, 0.0103, 0.0089]) \n",
      "Test Loss tensor([0.0090, 0.0110, 0.0111, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.47124266624450684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0121, 0.0102, 0.0112]) \n",
      "Test Loss tensor([0.0089, 0.0111, 0.0110, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.46129798889160156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0111, 0.0107, 0.0106]) \n",
      "Test Loss tensor([0.0092, 0.0113, 0.0109, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.47762107849121094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0121, 0.0109, 0.0097]) \n",
      "Test Loss tensor([0.0091, 0.0110, 0.0108, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.46094679832458496 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0108, 0.0109, 0.0103]) \n",
      "Test Loss tensor([0.0091, 0.0111, 0.0108, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.46389341354370117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0107, 0.0126, 0.0099]) \n",
      "Test Loss tensor([0.0092, 0.0111, 0.0107, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4750094413757324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0113, 0.0098, 0.0106]) \n",
      "Test Loss tensor([0.0090, 0.0112, 0.0113, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.46239590644836426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0107, 0.0104, 0.0112]) \n",
      "Test Loss tensor([0.0089, 0.0111, 0.0112, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47947072982788086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0110, 0.0119, 0.0107]) \n",
      "Test Loss tensor([0.0093, 0.0110, 0.0112, 0.0106])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 100 in 0.49456000328063965 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0099, 0.0111, 0.0105, 0.0088]) \n",
      "Test Loss tensor([0.0092, 0.0113, 0.0110, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4802849292755127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0120, 0.0106, 0.0105]) \n",
      "Test Loss tensor([0.0088, 0.0109, 0.0111, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.48924875259399414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0116, 0.0104, 0.0109]) \n",
      "Test Loss tensor([0.0092, 0.0109, 0.0109, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4750058650970459 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0110, 0.0115, 0.0112]) \n",
      "Test Loss tensor([0.0094, 0.0109, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4455685615539551 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0097, 0.0106, 0.0108, 0.0097]) \n",
      "Test Loss tensor([0.0089, 0.0112, 0.0111, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4530785083770752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0117, 0.0109, 0.0113]) \n",
      "Test Loss tensor([0.0089, 0.0109, 0.0106, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.43706417083740234 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0117, 0.0101, 0.0100]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0113, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.44944238662719727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0106, 0.0108, 0.0103]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0109, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.43805980682373047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0112, 0.0114, 0.0104]) \n",
      "Test Loss tensor([0.0093, 0.0111, 0.0113, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.45798206329345703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0115, 0.0112, 0.0108]) \n",
      "Test Loss tensor([0.0091, 0.0110, 0.0108, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.435776948928833 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0109, 0.0107, 0.0102]) \n",
      "Test Loss tensor([0.0091, 0.0111, 0.0113, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.43356943130493164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0107, 0.0127, 0.0106]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0107, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4691896438598633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0111, 0.0112, 0.0105]) \n",
      "Test Loss tensor([0.0092, 0.0109, 0.0114, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.46425771713256836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0100, 0.0107, 0.0104]) \n",
      "Test Loss tensor([0.0092, 0.0108, 0.0111, 0.0109])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.49051856994628906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0105, 0.0114, 0.0111]) \n",
      "Test Loss tensor([0.0090, 0.0113, 0.0109, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.44478678703308105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0102, 0.0104, 0.0103]) \n",
      "Test Loss tensor([0.0090, 0.0110, 0.0112, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4628434181213379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0103, 0.0098, 0.0112]) \n",
      "Test Loss tensor([0.0091, 0.0110, 0.0109, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4437108039855957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0106, 0.0098, 0.0100]) \n",
      "Test Loss tensor([0.0090, 0.0110, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4749796390533447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0104, 0.0102, 0.0108]) \n",
      "Test Loss tensor([0.0091, 0.0108, 0.0108, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47153401374816895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0116, 0.0102, 0.0100]) \n",
      "Test Loss tensor([0.0090, 0.0111, 0.0110, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.49437952041625977 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0108, 0.0103, 0.0111]) \n",
      "Test Loss tensor([0.0091, 0.0111, 0.0110, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.48595452308654785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0105, 0.0107, 0.0096]) \n",
      "Test Loss tensor([0.0091, 0.0109, 0.0112, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.497631311416626 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0125, 0.0122, 0.0113]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0107, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5588116645812988 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0105, 0.0113, 0.0101]) \n",
      "Test Loss tensor([0.0088, 0.0111, 0.0110, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5292384624481201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0104, 0.0106, 0.0105]) \n",
      "Test Loss tensor([0.0091, 0.0110, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.48144960403442383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0120, 0.0114, 0.0105]) \n",
      "Test Loss tensor([0.0093, 0.0111, 0.0109, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5399067401885986 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0113, 0.0101, 0.0112]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0109, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5186495780944824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0106, 0.0117, 0.0105]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0111, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5073060989379883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0121, 0.0108, 0.0102]) \n",
      "Test Loss tensor([0.0091, 0.0109, 0.0109, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5344071388244629 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0114, 0.0112, 0.0105]) \n",
      "Test Loss tensor([0.0092, 0.0113, 0.0109, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5311233997344971 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0109, 0.0109, 0.0087]) \n",
      "Test Loss tensor([0.0091, 0.0111, 0.0110, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4620957374572754 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0109, 0.0100, 0.0108]) \n",
      "Test Loss tensor([0.0086, 0.0107, 0.0107, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4637017250061035 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0103, 0.0116, 0.0099]) \n",
      "Test Loss tensor([0.0089, 0.0112, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4573543071746826 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0100, 0.0128, 0.0099]) \n",
      "Test Loss tensor([0.0089, 0.0111, 0.0110, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47884511947631836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0106, 0.0107, 0.0106]) \n",
      "Test Loss tensor([0.0088, 0.0112, 0.0108, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4781372547149658 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0100, 0.0106, 0.0107, 0.0105]) \n",
      "Test Loss tensor([0.0088, 0.0112, 0.0113, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.49654078483581543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0107, 0.0110, 0.0103]) \n",
      "Test Loss tensor([0.0090, 0.0106, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.48221850395202637 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0104, 0.0115, 0.0106]) \n",
      "Test Loss tensor([0.0086, 0.0105, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.495131254196167 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0098, 0.0112, 0.0113]) \n",
      "Test Loss tensor([0.0087, 0.0111, 0.0108, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4583287239074707 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0112, 0.0098, 0.0092]) \n",
      "Test Loss tensor([0.0088, 0.0107, 0.0105, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5553293228149414 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0108, 0.0109, 0.0108]) \n",
      "Test Loss tensor([0.0090, 0.0107, 0.0107, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4690265655517578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0108, 0.0108, 0.0104]) \n",
      "Test Loss tensor([0.0090, 0.0110, 0.0103, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4919869899749756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0115, 0.0107, 0.0105]) \n",
      "Test Loss tensor([0.0088, 0.0106, 0.0106, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.48677563667297363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0103, 0.0100, 0.0106]) \n",
      "Test Loss tensor([0.0087, 0.0107, 0.0109, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4992859363555908 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0099, 0.0098, 0.0106]) \n",
      "Test Loss tensor([0.0092, 0.0106, 0.0112, 0.0106])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 280 in 0.4695718288421631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0113, 0.0106, 0.0108]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0106, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.48418569564819336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0110, 0.0101, 0.0105]) \n",
      "Test Loss tensor([0.0092, 0.0110, 0.0110, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.46587157249450684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0110, 0.0111, 0.0102]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0101, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4787294864654541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0100, 0.0110, 0.0093]) \n",
      "Test Loss tensor([0.0091, 0.0108, 0.0109, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47884273529052734 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0111, 0.0098, 0.0104]) \n",
      "Test Loss tensor([0.0090, 0.0108, 0.0109, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4764747619628906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0099, 0.0101, 0.0100]) \n",
      "Test Loss tensor([0.0088, 0.0111, 0.0103, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.48015689849853516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0116, 0.0096, 0.0097]) \n",
      "Test Loss tensor([0.0087, 0.0107, 0.0107, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47754931449890137 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0108, 0.0107, 0.0098]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0105, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.47723889350891113 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0122, 0.0111, 0.0105]) \n",
      "Test Loss tensor([0.0088, 0.0110, 0.0108, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.48779749870300293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0103, 0.0108, 0.0108]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0105, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5208413600921631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0112, 0.0098, 0.0103]) \n",
      "Test Loss tensor([0.0091, 0.0108, 0.0110, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.44890475273132324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0123, 0.0098, 0.0100]) \n",
      "Test Loss tensor([0.0088, 0.0109, 0.0105, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5109126567840576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0109, 0.0113, 0.0092]) \n",
      "Test Loss tensor([0.0088, 0.0111, 0.0109, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5237553119659424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0112, 0.0108, 0.0104]) \n",
      "Test Loss tensor([0.0090, 0.0107, 0.0107, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.549567699432373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0112, 0.0125, 0.0105]) \n",
      "Test Loss tensor([0.0087, 0.0110, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.47391748428344727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0116, 0.0106, 0.0104]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0106, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4807116985321045 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0106, 0.0116, 0.0109]) \n",
      "Test Loss tensor([0.0091, 0.0109, 0.0109, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5388333797454834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0115, 0.0104, 0.0102]) \n",
      "Test Loss tensor([0.0087, 0.0105, 0.0103, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4675133228302002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0101, 0.0104, 0.0104]) \n",
      "Test Loss tensor([0.0094, 0.0112, 0.0107, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.48087120056152344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0102, 0.0097, 0.0102]) \n",
      "Test Loss tensor([0.0087, 0.0109, 0.0111, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.48500728607177734 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0109, 0.0105, 0.0102]) \n",
      "Test Loss tensor([0.0092, 0.0107, 0.0116, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.46758294105529785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0108, 0.0104, 0.0111]) \n",
      "Test Loss tensor([0.0088, 0.0109, 0.0105, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4731936454772949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0110, 0.0107, 0.0101]) \n",
      "Test Loss tensor([0.0092, 0.0110, 0.0109, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4610781669616699 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0103, 0.0106, 0.0100]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0106, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4792788028717041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0108, 0.0099, 0.0104]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0113, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4733235836029053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0110, 0.0104, 0.0108]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0105, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.485731840133667 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0108, 0.0095, 0.0107]) \n",
      "Test Loss tensor([0.0090, 0.0106, 0.0109, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.511939287185669 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0104, 0.0115, 0.0091]) \n",
      "Test Loss tensor([0.0088, 0.0106, 0.0104, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5014581680297852 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0129, 0.0113, 0.0096]) \n",
      "Test Loss tensor([0.0086, 0.0108, 0.0105, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4881322383880615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0105, 0.0096, 0.0102]) \n",
      "Test Loss tensor([0.0088, 0.0107, 0.0102, 0.0110])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.49330568313598633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0107, 0.0109, 0.0105]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0106, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5524489879608154 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0109, 0.0104, 0.0096]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6366438865661621 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0118, 0.0105, 0.0103]) \n",
      "Test Loss tensor([0.0089, 0.0108, 0.0102, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7337884902954102 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0102, 0.0101, 0.0102]) \n",
      "Test Loss tensor([0.0087, 0.0108, 0.0105, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5803322792053223 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0117, 0.0093, 0.0101]) \n",
      "Test Loss tensor([0.0088, 0.0105, 0.0107, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5640413761138916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0120, 0.0112, 0.0095]) \n",
      "Test Loss tensor([0.0088, 0.0109, 0.0104, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.588998556137085 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0112, 0.0093, 0.0105]) \n",
      "Test Loss tensor([0.0087, 0.0108, 0.0104, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6117095947265625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0110, 0.0106, 0.0111]) \n",
      "Test Loss tensor([0.0086, 0.0108, 0.0106, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5239198207855225 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0109, 0.0108, 0.0099]) \n",
      "Test Loss tensor([0.0088, 0.0108, 0.0105, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6081416606903076 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0099, 0.0105, 0.0112]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0106, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.597092866897583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0110, 0.0092, 0.0101]) \n",
      "Test Loss tensor([0.0087, 0.0109, 0.0107, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5789763927459717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0117, 0.0111, 0.0106]) \n",
      "Test Loss tensor([0.0089, 0.0106, 0.0106, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5603470802307129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0106, 0.0106, 0.0104]) \n",
      "Test Loss tensor([0.0085, 0.0107, 0.0106, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5486712455749512 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0113, 0.0112, 0.0099]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0104, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.574260950088501 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0101, 0.0121, 0.0096]) \n",
      "Test Loss tensor([0.0087, 0.0104, 0.0107, 0.0104])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 460 in 0.6270492076873779 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0113, 0.0100, 0.0106]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0104, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5450341701507568 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0106, 0.0106, 0.0104]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0106, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5412049293518066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0104, 0.0095, 0.0106]) \n",
      "Test Loss tensor([0.0087, 0.0110, 0.0102, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5244753360748291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0107, 0.0109, 0.0097]) \n",
      "Test Loss tensor([0.0089, 0.0104, 0.0107, 0.0107])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5434696674346924 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0108, 0.0105, 0.0104]) \n",
      "Test Loss tensor([0.0086, 0.0107, 0.0114, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5272016525268555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0106, 0.0095, 0.0105]) \n",
      "Test Loss tensor([0.0087, 0.0110, 0.0112, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5421781539916992 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0106, 0.0107, 0.0106]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0108, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5218937397003174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0096, 0.0110, 0.0107]) \n",
      "Test Loss tensor([0.0087, 0.0107, 0.0108, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5528774261474609 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0105, 0.0106, 0.0099]) \n",
      "Test Loss tensor([0.0084, 0.0109, 0.0110, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5758719444274902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0117, 0.0105, 0.0105]) \n",
      "Test Loss tensor([0.0089, 0.0109, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5231623649597168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0101, 0.0111, 0.0119, 0.0106]) \n",
      "Test Loss tensor([0.0088, 0.0105, 0.0112, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5427334308624268 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0107, 0.0107, 0.0102]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0104, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5432522296905518 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0110, 0.0101, 0.0088]) \n",
      "Test Loss tensor([0.0086, 0.0105, 0.0109, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5557608604431152 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0109, 0.0107, 0.0102]) \n",
      "Test Loss tensor([0.0087, 0.0107, 0.0106, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5193932056427002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0096, 0.0098, 0.0107, 0.0097]) \n",
      "Test Loss tensor([0.0087, 0.0110, 0.0109, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5306315422058105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0104, 0.0113, 0.0113, 0.0104]) \n",
      "Test Loss tensor([0.0085, 0.0107, 0.0106, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5663778781890869 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0108, 0.0102, 0.0105]) \n",
      "Test Loss tensor([0.0088, 0.0106, 0.0108, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.598421573638916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0112, 0.0097, 0.0097]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0106, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.57126784324646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0101, 0.0103, 0.0110]) \n",
      "Test Loss tensor([0.0089, 0.0110, 0.0113, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.559453010559082 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0107, 0.0100, 0.0103]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0107, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5872147083282471 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0109, 0.0085, 0.0103]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0107, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5395298004150391 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0101, 0.0111, 0.0104]) \n",
      "Test Loss tensor([0.0088, 0.0109, 0.0104, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5514986515045166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0111, 0.0113, 0.0107]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0102, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5440120697021484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0116, 0.0110, 0.0094]) \n",
      "Test Loss tensor([0.0091, 0.0105, 0.0106, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5535721778869629 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0111, 0.0110, 0.0106]) \n",
      "Test Loss tensor([0.0082, 0.0107, 0.0103, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5548884868621826 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0100, 0.0094, 0.0112]) \n",
      "Test Loss tensor([0.0088, 0.0107, 0.0106, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5805411338806152 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0110, 0.0105, 0.0110]) \n",
      "Test Loss tensor([0.0087, 0.0109, 0.0103, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5602896213531494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0107, 0.0102, 0.0098]) \n",
      "Test Loss tensor([0.0084, 0.0108, 0.0102, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.563262939453125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0103, 0.0101, 0.0094]) \n",
      "Test Loss tensor([0.0084, 0.0106, 0.0106, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5533089637756348 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0107, 0.0104, 0.0108]) \n",
      "Test Loss tensor([0.0085, 0.0105, 0.0105, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5491116046905518 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0109, 0.0104, 0.0105]) \n",
      "Test Loss tensor([0.0084, 0.0101, 0.0107, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5520470142364502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0109, 0.0104, 0.0099]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0105, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5880422592163086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0104, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0085, 0.0103, 0.0101, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5861067771911621 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0105, 0.0093, 0.0110]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0104, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6275081634521484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0103, 0.0107, 0.0101]) \n",
      "Test Loss tensor([0.0085, 0.0108, 0.0105, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6055729389190674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0108, 0.0093, 0.0106]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0105, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5977270603179932 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0107, 0.0092, 0.0103]) \n",
      "Test Loss tensor([0.0085, 0.0107, 0.0103, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6057665348052979 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0111, 0.0105, 0.0110]) \n",
      "Test Loss tensor([0.0086, 0.0104, 0.0103, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6102495193481445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0106, 0.0101, 0.0094]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0101, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6155848503112793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0114, 0.0102, 0.0108]) \n",
      "Test Loss tensor([0.0085, 0.0103, 0.0100, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6398286819458008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0109, 0.0097, 0.0102]) \n",
      "Test Loss tensor([0.0083, 0.0107, 0.0105, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5811505317687988 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0102, 0.0106, 0.0090]) \n",
      "Test Loss tensor([0.0083, 0.0105, 0.0101, 0.0106])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5755999088287354 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0109, 0.0098, 0.0091]) \n",
      "Test Loss tensor([0.0084, 0.0106, 0.0105, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6154115200042725 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0105, 0.0093, 0.0102]) \n",
      "Test Loss tensor([0.0084, 0.0105, 0.0101, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5956499576568604 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0108, 0.0106, 0.0102]) \n",
      "Test Loss tensor([0.0083, 0.0109, 0.0106, 0.0101])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 640 in 0.5622439384460449 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0114, 0.0107, 0.0111]) \n",
      "Test Loss tensor([0.0084, 0.0105, 0.0101, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5854854583740234 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0103, 0.0096, 0.0111]) \n",
      "Test Loss tensor([0.0084, 0.0103, 0.0110, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.535794734954834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0114, 0.0099, 0.0090]) \n",
      "Test Loss tensor([0.0086, 0.0106, 0.0103, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5587294101715088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0099, 0.0107, 0.0096]) \n",
      "Test Loss tensor([0.0086, 0.0108, 0.0104, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5591716766357422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0111, 0.0099, 0.0108]) \n",
      "Test Loss tensor([0.0085, 0.0109, 0.0110, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5462982654571533 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0112, 0.0107, 0.0094]) \n",
      "Test Loss tensor([0.0085, 0.0104, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5360763072967529 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0098, 0.0095, 0.0104]) \n",
      "Test Loss tensor([0.0085, 0.0109, 0.0104, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5460515022277832 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0107, 0.0102, 0.0100]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0105, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.563814640045166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0101, 0.0105, 0.0115]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0104, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5402283668518066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0111, 0.0096, 0.0109]) \n",
      "Test Loss tensor([0.0088, 0.0106, 0.0104, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5787627696990967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0102, 0.0105, 0.0107]) \n",
      "Test Loss tensor([0.0087, 0.0106, 0.0104, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5615530014038086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0111, 0.0112, 0.0102]) \n",
      "Test Loss tensor([0.0086, 0.0105, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5685324668884277 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0109, 0.0099, 0.0092]) \n",
      "Test Loss tensor([0.0087, 0.0104, 0.0114, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5543818473815918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0103, 0.0103, 0.0103]) \n",
      "Test Loss tensor([0.0084, 0.0106, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5688676834106445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0105, 0.0106, 0.0085]) \n",
      "Test Loss tensor([0.0089, 0.0104, 0.0107, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5513904094696045 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0095, 0.0112, 0.0119, 0.0109]) \n",
      "Test Loss tensor([0.0085, 0.0102, 0.0106, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5592267513275146 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0099, 0.0101, 0.0119]) \n",
      "Test Loss tensor([0.0087, 0.0104, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5657544136047363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0105, 0.0110, 0.0098]) \n",
      "Test Loss tensor([0.0085, 0.0105, 0.0106, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5406994819641113 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0098, 0.0105, 0.0106, 0.0099]) \n",
      "Test Loss tensor([0.0085, 0.0103, 0.0104, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.552513599395752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0100, 0.0095, 0.0105]) \n",
      "Test Loss tensor([0.0085, 0.0104, 0.0103, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5593836307525635 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0118, 0.0104, 0.0096]) \n",
      "Test Loss tensor([0.0084, 0.0105, 0.0101, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5915622711181641 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0106, 0.0108, 0.0098]) \n",
      "Test Loss tensor([0.0085, 0.0105, 0.0103, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5366604328155518 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0102, 0.0105, 0.0109]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0100, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5482103824615479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0109, 0.0090, 0.0095]) \n",
      "Test Loss tensor([0.0085, 0.0102, 0.0102, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.543593168258667 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0113, 0.0111, 0.0103]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0102, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5461604595184326 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0110, 0.0093, 0.0096]) \n",
      "Test Loss tensor([0.0085, 0.0105, 0.0101, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5506043434143066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0116, 0.0107, 0.0099]) \n",
      "Test Loss tensor([0.0085, 0.0102, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5584447383880615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0105, 0.0111, 0.0110]) \n",
      "Test Loss tensor([0.0085, 0.0104, 0.0103, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.556220531463623 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0106, 0.0100, 0.0096]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0101, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5372748374938965 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0106, 0.0107, 0.0099]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5432205200195312 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0105, 0.0100, 0.0096]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0100, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5404717922210693 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0094, 0.0118, 0.0102, 0.0096]) \n",
      "Test Loss tensor([0.0082, 0.0103, 0.0101, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5657801628112793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0109, 0.0098, 0.0112]) \n",
      "Test Loss tensor([0.0085, 0.0106, 0.0104, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5570619106292725 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0105, 0.0096, 0.0101]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0105, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5456767082214355 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0102, 0.0097, 0.0094]) \n",
      "Test Loss tensor([0.0085, 0.0107, 0.0102, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5410702228546143 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0115, 0.0113, 0.0096]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0102, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5370023250579834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0100, 0.0096, 0.0101]) \n",
      "Test Loss tensor([0.0085, 0.0105, 0.0099, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5467538833618164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0109, 0.0105, 0.0106]) \n",
      "Test Loss tensor([0.0086, 0.0104, 0.0102, 0.0105])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.533458948135376 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0101, 0.0096, 0.0101]) \n",
      "Test Loss tensor([0.0081, 0.0105, 0.0099, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5653016567230225 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0098, 0.0096, 0.0103]) \n",
      "Test Loss tensor([0.0081, 0.0103, 0.0105, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5428760051727295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0106, 0.0106, 0.0099]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0103, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5573720932006836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0117, 0.0103, 0.0102]) \n",
      "Test Loss tensor([0.0088, 0.0103, 0.0098, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5387918949127197 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0098, 0.0096, 0.0089]) \n",
      "Test Loss tensor([0.0083, 0.0102, 0.0102, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5525591373443604 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0104, 0.0097, 0.0102]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0103, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.553382396697998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0126, 0.0102, 0.0096]) \n",
      "Test Loss tensor([0.0080, 0.0104, 0.0108, 0.0101])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 820 in 0.5642163753509521 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0099, 0.0096]) \n",
      "Test Loss tensor([0.0083, 0.0106, 0.0102, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5650594234466553 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0105, 0.0102, 0.0094]) \n",
      "Test Loss tensor([0.0082, 0.0107, 0.0103, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5577883720397949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0105, 0.0093, 0.0108]) \n",
      "Test Loss tensor([0.0081, 0.0101, 0.0104, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5572540760040283 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0111, 0.0102, 0.0118]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0104, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5428042411804199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0099, 0.0100, 0.0096]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0103, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.556572437286377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0119, 0.0113, 0.0099]) \n",
      "Test Loss tensor([0.0086, 0.0103, 0.0099, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5390462875366211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0102, 0.0089, 0.0099]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0098, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5507252216339111 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0110, 0.0107, 0.0104]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0103, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.573584794998169 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0100, 0.0101, 0.0094]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0103, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5561943054199219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0101, 0.0109, 0.0101]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0105, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5418946743011475 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0107, 0.0101, 0.0096]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0104, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5381929874420166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0099, 0.0094]) \n",
      "Test Loss tensor([0.0082, 0.0106, 0.0099, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5506789684295654 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0096, 0.0112, 0.0096]) \n",
      "Test Loss tensor([0.0081, 0.0106, 0.0102, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5348141193389893 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0111, 0.0104, 0.0106]) \n",
      "Test Loss tensor([0.0083, 0.0109, 0.0103, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5383844375610352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0072, 0.0075, 0.0073]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0106, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5776586532592773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0096, 0.0099, 0.0096]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0105, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5484104156494141 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0101, 0.0102, 0.0101]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0107, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5503315925598145 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0099, 0.0094, 0.0106]) \n",
      "Test Loss tensor([0.0082, 0.0103, 0.0098, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5512833595275879 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0105, 0.0107, 0.0090]) \n",
      "Test Loss tensor([0.0082, 0.0106, 0.0106, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5283088684082031 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0117, 0.0096, 0.0093]) \n",
      "Test Loss tensor([0.0082, 0.0106, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5224411487579346 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0098, 0.0093, 0.0095]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0103, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5438532829284668 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0112, 0.0106, 0.0108]) \n",
      "Test Loss tensor([0.0084, 0.0098, 0.0101, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5568289756774902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0113, 0.0089, 0.0102]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0105, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5371742248535156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0105, 0.0093, 0.0083]) \n",
      "Test Loss tensor([0.0084, 0.0102, 0.0103, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5462944507598877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0096, 0.0085, 0.0094]) \n",
      "Test Loss tensor([0.0082, 0.0107, 0.0104, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5357155799865723 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0101, 0.0090, 0.0098]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0100, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5287835597991943 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0106, 0.0097, 0.0095]) \n",
      "Test Loss tensor([0.0083, 0.0103, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5208954811096191 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0110, 0.0123, 0.0107]) \n",
      "Test Loss tensor([0.0080, 0.0104, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5330591201782227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0104, 0.0102, 0.0107]) \n",
      "Test Loss tensor([0.0082, 0.0103, 0.0102, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5344886779785156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0107, 0.0094, 0.0106]) \n",
      "Test Loss tensor([0.0082, 0.0104, 0.0101, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5626161098480225 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0095, 0.0094, 0.0094]) \n",
      "Test Loss tensor([0.0081, 0.0103, 0.0102, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.538646936416626 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0099, 0.0089, 0.0091]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5411741733551025 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0106, 0.0098, 0.0096]) \n",
      "Test Loss tensor([0.0081, 0.0104, 0.0100, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5277881622314453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0112, 0.0095, 0.0088]) \n",
      "Test Loss tensor([0.0083, 0.0106, 0.0103, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5370450019836426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0106, 0.0109, 0.0098]) \n",
      "Test Loss tensor([0.0081, 0.0105, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5302822589874268 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0112, 0.0082, 0.0102]) \n",
      "Test Loss tensor([0.0081, 0.0103, 0.0099, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5503864288330078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0107, 0.0092, 0.0102]) \n",
      "Test Loss tensor([0.0081, 0.0106, 0.0098, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5312306880950928 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0097, 0.0091, 0.0086]) \n",
      "Test Loss tensor([0.0083, 0.0107, 0.0101, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5556609630584717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0106, 0.0089, 0.0103]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5477316379547119 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0103, 0.0105, 0.0099]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0102, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5424015522003174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0110, 0.0096, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5253188610076904 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0111, 0.0088, 0.0103]) \n",
      "Test Loss tensor([0.0081, 0.0103, 0.0102, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5226049423217773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0098, 0.0104, 0.0095]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0106, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5343568325042725 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0099, 0.0091, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5264134407043457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0105, 0.0100, 0.0105]) \n",
      "Test Loss tensor([0.0080, 0.0105, 0.0097, 0.0098])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 120 in 0.5317296981811523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0111, 0.0101, 0.0092]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0101, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.519524097442627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0116, 0.0098, 0.0095]) \n",
      "Test Loss tensor([0.0081, 0.0100, 0.0100, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5309615135192871 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0101, 0.0105, 0.0104]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0099, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.517078161239624 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0103, 0.0109, 0.0106]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0105, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5411984920501709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0105, 0.0103, 0.0104]) \n",
      "Test Loss tensor([0.0084, 0.0101, 0.0102, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5204317569732666 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0098, 0.0105]) \n",
      "Test Loss tensor([0.0080, 0.0105, 0.0098, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5343186855316162 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0098, 0.0091, 0.0106]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0102, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5232634544372559 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0106, 0.0106, 0.0096]) \n",
      "Test Loss tensor([0.0083, 0.0105, 0.0098, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5353164672851562 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0104, 0.0093, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0105, 0.0097, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.522130012512207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0109, 0.0093, 0.0086]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5386407375335693 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0085, 0.0094, 0.0093]) \n",
      "Test Loss tensor([0.0084, 0.0105, 0.0099, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5424883365631104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0095, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0081, 0.0099, 0.0100, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5385847091674805 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0106, 0.0097, 0.0100]) \n",
      "Test Loss tensor([0.0079, 0.0100, 0.0101, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5268652439117432 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0103, 0.0097, 0.0097]) \n",
      "Test Loss tensor([0.0083, 0.0103, 0.0098, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.519017219543457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0109, 0.0091, 0.0095]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0098, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5366373062133789 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0096, 0.0108, 0.0099]) \n",
      "Test Loss tensor([0.0084, 0.0104, 0.0103, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5352592468261719 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0100, 0.0092, 0.0105]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5383789539337158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0108, 0.0096, 0.0095]) \n",
      "Test Loss tensor([0.0081, 0.0101, 0.0104, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5192325115203857 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0107, 0.0102, 0.0092]) \n",
      "Test Loss tensor([0.0081, 0.0104, 0.0100, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5402750968933105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0104, 0.0103, 0.0099]) \n",
      "Test Loss tensor([0.0083, 0.0101, 0.0102, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5272362232208252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0102, 0.0104, 0.0095]) \n",
      "Test Loss tensor([0.0083, 0.0103, 0.0101, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5560302734375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0107, 0.0099, 0.0102]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5329186916351318 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0105, 0.0092, 0.0102]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0105, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5443305969238281 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0092, 0.0111, 0.0097]) \n",
      "Test Loss tensor([0.0078, 0.0102, 0.0100, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5293636322021484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0118, 0.0110, 0.0107]) \n",
      "Test Loss tensor([0.0085, 0.0109, 0.0105, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5707461833953857 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0101, 0.0111, 0.0095]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0103, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5332660675048828 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0106, 0.0096, 0.0103]) \n",
      "Test Loss tensor([0.0081, 0.0100, 0.0100, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5305349826812744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0105, 0.0103, 0.0093]) \n",
      "Test Loss tensor([0.0081, 0.0104, 0.0103, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5320148468017578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0097, 0.0105, 0.0097]) \n",
      "Test Loss tensor([0.0081, 0.0099, 0.0099, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5252783298492432 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0103, 0.0107, 0.0095]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5294270515441895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0097, 0.0101, 0.0104]) \n",
      "Test Loss tensor([0.0081, 0.0101, 0.0100, 0.0103])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5314478874206543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0102, 0.0092, 0.0093]) \n",
      "Test Loss tensor([0.0080, 0.0104, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5314710140228271 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0106, 0.0098, 0.0098]) \n",
      "Test Loss tensor([0.0079, 0.0105, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5386080741882324 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0106, 0.0091, 0.0101]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0100, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5395369529724121 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0097, 0.0112, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0102, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5411450862884521 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0100, 0.0106, 0.0100]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5230469703674316 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0099, 0.0101, 0.0095]) \n",
      "Test Loss tensor([0.0079, 0.0104, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5201015472412109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0099, 0.0084, 0.0101]) \n",
      "Test Loss tensor([0.0078, 0.0104, 0.0099, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5190949440002441 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0113, 0.0114, 0.0100]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0097, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5144336223602295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0090, 0.0095, 0.0098]) \n",
      "Test Loss tensor([0.0079, 0.0101, 0.0096, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.519310712814331 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0105, 0.0081, 0.0096]) \n",
      "Test Loss tensor([0.0079, 0.0105, 0.0098, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5256497859954834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0102, 0.0098, 0.0099]) \n",
      "Test Loss tensor([0.0083, 0.0104, 0.0099, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.535386323928833 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0106, 0.0101, 0.0095]) \n",
      "Test Loss tensor([0.0078, 0.0102, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5409927368164062 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0093, 0.0120, 0.0101, 0.0102]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.542830228805542 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0106, 0.0096, 0.0103]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0101, 0.0095])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 300 in 0.5264744758605957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0101, 0.0104, 0.0100]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.522493839263916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0103, 0.0096, 0.0089]) \n",
      "Test Loss tensor([0.0079, 0.0101, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5287346839904785 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0100, 0.0096, 0.0110]) \n",
      "Test Loss tensor([0.0082, 0.0105, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5250203609466553 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0094, 0.0102, 0.0094]) \n",
      "Test Loss tensor([0.0080, 0.0098, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.54671311378479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0098, 0.0097, 0.0096]) \n",
      "Test Loss tensor([0.0075, 0.0102, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5257513523101807 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0107, 0.0095, 0.0101]) \n",
      "Test Loss tensor([0.0079, 0.0100, 0.0100, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5270705223083496 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0104, 0.0094, 0.0096]) \n",
      "Test Loss tensor([0.0079, 0.0104, 0.0097, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.531123161315918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0099, 0.0095, 0.0099]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5370931625366211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0105, 0.0094, 0.0091]) \n",
      "Test Loss tensor([0.0081, 0.0101, 0.0099, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5169878005981445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0099, 0.0101, 0.0096]) \n",
      "Test Loss tensor([0.0077, 0.0098, 0.0099, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5108509063720703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0110, 0.0096, 0.0100]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0098, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5330867767333984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0109, 0.0096, 0.0097]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5260255336761475 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0099, 0.0091, 0.0096]) \n",
      "Test Loss tensor([0.0082, 0.0103, 0.0096, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5242598056793213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0093, 0.0102, 0.0100]) \n",
      "Test Loss tensor([0.0078, 0.0099, 0.0098, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5182607173919678 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0115, 0.0093, 0.0094]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5300085544586182 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0100, 0.0092, 0.0101]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0099, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5342662334442139 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0103, 0.0086]) \n",
      "Test Loss tensor([0.0076, 0.0104, 0.0099, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5381202697753906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0088, 0.0098, 0.0094, 0.0100]) \n",
      "Test Loss tensor([0.0080, 0.0099, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5232663154602051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0104, 0.0104, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0102, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5197973251342773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0107, 0.0107, 0.0102]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0097, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5176541805267334 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0088, 0.0101]) \n",
      "Test Loss tensor([0.0080, 0.0101, 0.0097, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5374526977539062 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0109, 0.0093, 0.0102]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0099, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5215160846710205 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0112, 0.0096, 0.0099]) \n",
      "Test Loss tensor([0.0078, 0.0103, 0.0103, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5197622776031494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0106, 0.0092, 0.0095]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0102, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.537102222442627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0103, 0.0088, 0.0097]) \n",
      "Test Loss tensor([0.0081, 0.0104, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.532132625579834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0102, 0.0104, 0.0087]) \n",
      "Test Loss tensor([0.0084, 0.0103, 0.0100, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5196130275726318 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0108, 0.0102, 0.0100]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5417308807373047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0101, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0101, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5274181365966797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0101, 0.0103, 0.0104]) \n",
      "Test Loss tensor([0.0078, 0.0099, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5223846435546875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0105, 0.0090, 0.0096]) \n",
      "Test Loss tensor([0.0079, 0.0104, 0.0099, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.519129753112793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0118, 0.0094, 0.0094]) \n",
      "Test Loss tensor([0.0079, 0.0103, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5258791446685791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0105, 0.0090, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0097, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5221378803253174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0117, 0.0086, 0.0093]) \n",
      "Test Loss tensor([0.0079, 0.0101, 0.0103, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.517573356628418 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0108, 0.0094, 0.0102]) \n",
      "Test Loss tensor([0.0080, 0.0100, 0.0097, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5216283798217773 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0108, 0.0091, 0.0096]) \n",
      "Test Loss tensor([0.0081, 0.0100, 0.0099, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5192453861236572 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0104, 0.0087, 0.0091]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5165493488311768 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0100, 0.0103, 0.0094]) \n",
      "Test Loss tensor([0.0080, 0.0100, 0.0102, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.549551248550415 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0116, 0.0102, 0.0093]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0094, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5115587711334229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0101, 0.0093, 0.0105]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0096, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5190894603729248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0087, 0.0098, 0.0098]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0096, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5216259956359863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0100, 0.0093, 0.0105]) \n",
      "Test Loss tensor([0.0080, 0.0102, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5255739688873291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0105, 0.0103, 0.0096]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5401825904846191 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0102, 0.0089, 0.0091]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5516197681427002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0104, 0.0095, 0.0100]) \n",
      "Test Loss tensor([0.0078, 0.0102, 0.0096, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5408473014831543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0103, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0078, 0.0102, 0.0098, 0.0096])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 480 in 0.5257177352905273 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0110, 0.0092, 0.0094]) \n",
      "Test Loss tensor([0.0080, 0.0100, 0.0096, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5245769023895264 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0107, 0.0103, 0.0100]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0100, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5243661403656006 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0112, 0.0100, 0.0091]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5274057388305664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0108, 0.0085, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0100, 0.0098, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.523242712020874 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0096, 0.0107, 0.0090]) \n",
      "Test Loss tensor([0.0080, 0.0103, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5261878967285156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0100, 0.0094, 0.0094]) \n",
      "Test Loss tensor([0.0081, 0.0103, 0.0095, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5243520736694336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0101, 0.0095, 0.0102]) \n",
      "Test Loss tensor([0.0078, 0.0099, 0.0095, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5244936943054199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0100, 0.0103, 0.0093]) \n",
      "Test Loss tensor([0.0078, 0.0103, 0.0095, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5326826572418213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0101, 0.0092, 0.0095]) \n",
      "Test Loss tensor([0.0078, 0.0099, 0.0099, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5232670307159424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0098, 0.0102, 0.0100]) \n",
      "Test Loss tensor([0.0076, 0.0103, 0.0096, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5246310234069824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0097, 0.0099, 0.0091]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0096, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5220134258270264 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0096, 0.0106, 0.0100]) \n",
      "Test Loss tensor([0.0079, 0.0105, 0.0094, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5217177867889404 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0104, 0.0119, 0.0098]) \n",
      "Test Loss tensor([0.0077, 0.0103, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5269160270690918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0091, 0.0095]) \n",
      "Test Loss tensor([0.0076, 0.0102, 0.0099, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5200405120849609 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0096, 0.0086, 0.0109]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0098, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5235273838043213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0103, 0.0099, 0.0092]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0094, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5273840427398682 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0097, 0.0095, 0.0097]) \n",
      "Test Loss tensor([0.0079, 0.0100, 0.0097, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5297937393188477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0109, 0.0099, 0.0098]) \n",
      "Test Loss tensor([0.0078, 0.0103, 0.0097, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5168972015380859 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0097, 0.0091, 0.0090]) \n",
      "Test Loss tensor([0.0077, 0.0097, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.521582841873169 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0100, 0.0090, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0098, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5221767425537109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0104, 0.0090, 0.0103]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5483579635620117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0094, 0.0081, 0.0101]) \n",
      "Test Loss tensor([0.0079, 0.0100, 0.0095, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5249481201171875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0089, 0.0103, 0.0092, 0.0094]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0097, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.535919189453125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0103, 0.0092, 0.0095]) \n",
      "Test Loss tensor([0.0079, 0.0104, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5501787662506104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0110, 0.0091]) \n",
      "Test Loss tensor([0.0079, 0.0101, 0.0096, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5188531875610352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0107, 0.0094, 0.0104]) \n",
      "Test Loss tensor([0.0079, 0.0100, 0.0094, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5244510173797607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0095, 0.0094, 0.0104]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0095, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5291953086853027 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0112, 0.0091, 0.0098]) \n",
      "Test Loss tensor([0.0076, 0.0103, 0.0096, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5256922245025635 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0103, 0.0097, 0.0094]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0095, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5200607776641846 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0096, 0.0098, 0.0095]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.544971227645874 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0107, 0.0097, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0103, 0.0093, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5347723960876465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0093, 0.0091, 0.0091]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0092, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5359392166137695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0109, 0.0090, 0.0104]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5344231128692627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0115, 0.0095, 0.0095]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0099, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5218760967254639 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0107, 0.0099, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0098, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5264079570770264 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0109, 0.0087, 0.0097]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0094, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5242328643798828 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0106, 0.0096, 0.0111]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0095, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5263164043426514 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0107, 0.0088, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5304841995239258 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0093, 0.0106, 0.0087]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0091, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5232522487640381 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0100, 0.0092, 0.0105]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0095, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.513784646987915 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0096, 0.0095, 0.0089]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5343465805053711 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0098, 0.0093, 0.0107]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5261831283569336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0093, 0.0090, 0.0098]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5152268409729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0105, 0.0091, 0.0107]) \n",
      "Test Loss tensor([0.0076, 0.0100, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5176846981048584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0091, 0.0113, 0.0094]) \n",
      "Test Loss tensor([0.0079, 0.0098, 0.0097, 0.0096])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 660 in 0.5175142288208008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0100, 0.0083, 0.0104]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0092, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5105020999908447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0100, 0.0099, 0.0096]) \n",
      "Test Loss tensor([0.0077, 0.0097, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5379595756530762 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0097, 0.0094, 0.0095]) \n",
      "Test Loss tensor([0.0075, 0.0097, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5335948467254639 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0104, 0.0083, 0.0103]) \n",
      "Test Loss tensor([0.0075, 0.0102, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5324475765228271 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0108, 0.0094, 0.0106]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5177373886108398 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0107, 0.0101, 0.0096]) \n",
      "Test Loss tensor([0.0079, 0.0099, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5218777656555176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0099, 0.0089, 0.0094]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5275845527648926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0103, 0.0098, 0.0097]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5114040374755859 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0104, 0.0088, 0.0100]) \n",
      "Test Loss tensor([0.0080, 0.0104, 0.0102, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.524749755859375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0106, 0.0102, 0.0091]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0100, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5221452713012695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0111, 0.0092, 0.0093]) \n",
      "Test Loss tensor([0.0078, 0.0102, 0.0096, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5201802253723145 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0108, 0.0105, 0.0102]) \n",
      "Test Loss tensor([0.0079, 0.0102, 0.0096, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5210113525390625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0093, 0.0103, 0.0091]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5193490982055664 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0104, 0.0091, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5414907932281494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0100, 0.0098, 0.0102]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5368301868438721 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0097, 0.0088, 0.0101]) \n",
      "Test Loss tensor([0.0075, 0.0096, 0.0097, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.525383710861206 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0093, 0.0096, 0.0099]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5255095958709717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0098, 0.0094, 0.0091]) \n",
      "Test Loss tensor([0.0075, 0.0102, 0.0095, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5321497917175293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0097, 0.0083, 0.0095]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0093, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5399680137634277 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0102, 0.0082, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.529545783996582 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0105, 0.0087, 0.0101]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0094, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5195455551147461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0094, 0.0092, 0.0104]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5399916172027588 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0100, 0.0091, 0.0091]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0093, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5334579944610596 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0101, 0.0094, 0.0092]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0098, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5305197238922119 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0117, 0.0088, 0.0100]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0095, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5433003902435303 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0111, 0.0094, 0.0101]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0093, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5266809463500977 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0106, 0.0098, 0.0101]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5229723453521729 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0111, 0.0086, 0.0101]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0096, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5270655155181885 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0094, 0.0093, 0.0100]) \n",
      "Test Loss tensor([0.0078, 0.0098, 0.0099, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.542971134185791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0096, 0.0087, 0.0106]) \n",
      "Test Loss tensor([0.0076, 0.0103, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.526299238204956 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0112, 0.0094, 0.0103]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5253496170043945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0084, 0.0097]) \n",
      "Test Loss tensor([0.0077, 0.0102, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5336644649505615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0096, 0.0085, 0.0102]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5344297885894775 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0113, 0.0100, 0.0092]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0093, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5117449760437012 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0101, 0.0096, 0.0100]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0095, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5246665477752686 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0101, 0.0082, 0.0102]) \n",
      "Test Loss tensor([0.0076, 0.0098, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5109777450561523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0091, 0.0101, 0.0094, 0.0094]) \n",
      "Test Loss tensor([0.0076, 0.0100, 0.0097, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5244982242584229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0107, 0.0084, 0.0098]) \n",
      "Test Loss tensor([0.0078, 0.0095, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5116193294525146 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0107, 0.0094, 0.0089]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0095, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5182397365570068 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0107, 0.0092, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0100, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.536583423614502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0107, 0.0084, 0.0099]) \n",
      "Test Loss tensor([0.0075, 0.0102, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.528522253036499 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0105, 0.0090, 0.0095]) \n",
      "Test Loss tensor([0.0079, 0.0098, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5238392353057861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0095, 0.0098, 0.0100]) \n",
      "Test Loss tensor([0.0076, 0.0103, 0.0093, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5303668975830078 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0105, 0.0093, 0.0102]) \n",
      "Test Loss tensor([0.0076, 0.0098, 0.0090, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5213968753814697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0103, 0.0085, 0.0102]) \n",
      "Test Loss tensor([0.0076, 0.0102, 0.0095, 0.0097])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 840 in 0.5183556079864502 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0095, 0.0097, 0.0098]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5188722610473633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0093, 0.0098, 0.0098]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.545457124710083 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0101, 0.0090, 0.0095]) \n",
      "Test Loss tensor([0.0075, 0.0102, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5211606025695801 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0098, 0.0087, 0.0096]) \n",
      "Test Loss tensor([0.0075, 0.0103, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5273876190185547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0103, 0.0089, 0.0086]) \n",
      "Test Loss tensor([0.0077, 0.0098, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5207443237304688 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0092, 0.0098, 0.0089]) \n",
      "Test Loss tensor([0.0075, 0.0097, 0.0093, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5224959850311279 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0105, 0.0096, 0.0092]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0092, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5213282108306885 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0108, 0.0091, 0.0092]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5244097709655762 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0091, 0.0095, 0.0105]) \n",
      "Test Loss tensor([0.0077, 0.0099, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5003178119659424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0079, 0.0062, 0.0072]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5629205703735352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0102, 0.0088, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0099, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5273916721343994 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0098, 0.0087, 0.0096]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5318191051483154 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0112, 0.0091, 0.0101]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5268843173980713 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0099, 0.0096, 0.0102]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0095, 0.0100])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5254979133605957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0098, 0.0094, 0.0089]) \n",
      "Test Loss tensor([0.0074, 0.0102, 0.0092, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5360565185546875 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0092, 0.0100, 0.0105, 0.0103]) \n",
      "Test Loss tensor([0.0077, 0.0101, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5337910652160645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0097, 0.0081, 0.0092]) \n",
      "Test Loss tensor([0.0077, 0.0098, 0.0090, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5302095413208008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0095, 0.0092, 0.0093]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0104, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.510958194732666 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0110, 0.0099, 0.0096]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0093, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5244467258453369 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0089, 0.0095, 0.0090]) \n",
      "Test Loss tensor([0.0079, 0.0099, 0.0100, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5331182479858398 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0107, 0.0093, 0.0100]) \n",
      "Test Loss tensor([0.0074, 0.0100, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5378541946411133 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0104, 0.0099, 0.0093]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5523302555084229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0100, 0.0086, 0.0085]) \n",
      "Test Loss tensor([0.0078, 0.0103, 0.0101, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5289297103881836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0099, 0.0099, 0.0094]) \n",
      "Test Loss tensor([0.0074, 0.0100, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5344841480255127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0102, 0.0082, 0.0098]) \n",
      "Test Loss tensor([0.0076, 0.0102, 0.0092, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5207235813140869 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0092, 0.0098, 0.0086]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0095, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5195894241333008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0092, 0.0110, 0.0085]) \n",
      "Test Loss tensor([0.0076, 0.0100, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.515631914138794 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0086, 0.0098, 0.0095]) \n",
      "Test Loss tensor([0.0080, 0.0099, 0.0098, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.518887996673584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0098, 0.0096, 0.0098]) \n",
      "Test Loss tensor([0.0077, 0.0097, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5236485004425049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0094, 0.0096, 0.0094]) \n",
      "Test Loss tensor([0.0076, 0.0102, 0.0096, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5376722812652588 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0106, 0.0086, 0.0096]) \n",
      "Test Loss tensor([0.0075, 0.0097, 0.0100, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5219323635101318 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0096, 0.0098, 0.0107]) \n",
      "Test Loss tensor([0.0076, 0.0098, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5203666687011719 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0108, 0.0088, 0.0087]) \n",
      "Test Loss tensor([0.0081, 0.0102, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5188915729522705 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0102, 0.0098, 0.0112]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5236246585845947 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0076, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0100, 0.0102, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5309090614318848 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0093, 0.0104, 0.0105]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0098, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5148518085479736 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0097, 0.0094, 0.0094]) \n",
      "Test Loss tensor([0.0077, 0.0098, 0.0097, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5492064952850342 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0092, 0.0087, 0.0091]) \n",
      "Test Loss tensor([0.0079, 0.0099, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.510434627532959 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0098, 0.0097, 0.0092]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0093, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5360124111175537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0096, 0.0082, 0.0094]) \n",
      "Test Loss tensor([0.0078, 0.0100, 0.0096, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5219824314117432 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0105, 0.0091, 0.0109]) \n",
      "Test Loss tensor([0.0074, 0.0100, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5204083919525146 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0109, 0.0095, 0.0090]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0095, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5206925868988037 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0106, 0.0095, 0.0089]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0093, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5228443145751953 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0097, 0.0089, 0.0098]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0092, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5198473930358887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0090, 0.0101]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0094, 0.0097])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 140 in 0.5381274223327637 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0090, 0.0092, 0.0089, 0.0099]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0088, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.532616376876831 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0098, 0.0100, 0.0089]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5185689926147461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0093, 0.0087, 0.0095]) \n",
      "Test Loss tensor([0.0073, 0.0096, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5098052024841309 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0106, 0.0111, 0.0093]) \n",
      "Test Loss tensor([0.0076, 0.0098, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5131828784942627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0097, 0.0090, 0.0098]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0092, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5101096630096436 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0084, 0.0096, 0.0089, 0.0103]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0093, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.512474775314331 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0097, 0.0089, 0.0088]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5196096897125244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0091, 0.0093, 0.0084]) \n",
      "Test Loss tensor([0.0072, 0.0100, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5186588764190674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0102, 0.0094, 0.0098]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0095, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.530529260635376 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0091, 0.0082, 0.0095]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5218853950500488 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0107, 0.0086, 0.0098]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0087, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5192592144012451 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0099, 0.0096, 0.0108]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0087, 0.0101])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5294945240020752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0102, 0.0079, 0.0103]) \n",
      "Test Loss tensor([0.0076, 0.0101, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5202999114990234 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0099, 0.0086, 0.0093]) \n",
      "Test Loss tensor([0.0077, 0.0098, 0.0097, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.528026819229126 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0106, 0.0089, 0.0104]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5254225730895996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0103, 0.0089, 0.0101]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5200817584991455 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0106, 0.0088, 0.0101]) \n",
      "Test Loss tensor([0.0073, 0.0095, 0.0097, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5842688083648682 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0105, 0.0092, 0.0106]) \n",
      "Test Loss tensor([0.0073, 0.0101, 0.0092, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5302243232727051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0113, 0.0087, 0.0098]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.545647382736206 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0098, 0.0088, 0.0087]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5790019035339355 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0106, 0.0086, 0.0087]) \n",
      "Test Loss tensor([0.0075, 0.0096, 0.0093, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5958864688873291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0093, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0089, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5347635746002197 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0095, 0.0094, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0095, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5236268043518066 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0106, 0.0090, 0.0094]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0092, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5538163185119629 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0090, 0.0083, 0.0092]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0093, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5993719100952148 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0098, 0.0083, 0.0098]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5599207878112793 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0105, 0.0090, 0.0095]) \n",
      "Test Loss tensor([0.0075, 0.0095, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6749584674835205 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0087, 0.0087, 0.0094]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0093, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6657378673553467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0103, 0.0108, 0.0088]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.613093376159668 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0116, 0.0098, 0.0096]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0093, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5789196491241455 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0092, 0.0097, 0.0093]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6072359085083008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0094, 0.0096]) \n",
      "Test Loss tensor([0.0075, 0.0100, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5775501728057861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0081, 0.0092]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5658085346221924 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0098, 0.0094, 0.0095]) \n",
      "Test Loss tensor([0.0072, 0.0099, 0.0090, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5850448608398438 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0096, 0.0095, 0.0086]) \n",
      "Test Loss tensor([0.0073, 0.0101, 0.0095, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5853235721588135 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0102, 0.0092, 0.0105]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5830411911010742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0105, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0073, 0.0096, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5762827396392822 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0106, 0.0089, 0.0095]) \n",
      "Test Loss tensor([0.0074, 0.0101, 0.0093, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5899448394775391 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0110, 0.0087, 0.0093]) \n",
      "Test Loss tensor([0.0072, 0.0100, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5929446220397949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0101, 0.0086, 0.0098]) \n",
      "Test Loss tensor([0.0073, 0.0094, 0.0094, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5882472991943359 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0108, 0.0095, 0.0092]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5731260776519775 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0110, 0.0091, 0.0100]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0094, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5677111148834229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0106, 0.0099, 0.0092]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0088, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5639853477478027 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0105, 0.0087, 0.0098]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0091, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5851044654846191 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0101, 0.0083, 0.0095]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0095, 0.0095])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 320 in 0.5834035873413086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0090, 0.0092, 0.0092]) \n",
      "Test Loss tensor([0.0073, 0.0095, 0.0096, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5826609134674072 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0098, 0.0090]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0099, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5728836059570312 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0110, 0.0103, 0.0087]) \n",
      "Test Loss tensor([0.0072, 0.0093, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5630202293395996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0103, 0.0079, 0.0091]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5847432613372803 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0096, 0.0102, 0.0092]) \n",
      "Test Loss tensor([0.0077, 0.0100, 0.0092, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5960922241210938 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0106, 0.0093, 0.0091]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5927269458770752 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0111, 0.0084, 0.0094]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0103, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.640434980392456 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0096, 0.0094, 0.0089]) \n",
      "Test Loss tensor([0.0074, 0.0095, 0.0091, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7063829898834229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0095, 0.0092, 0.0092]) \n",
      "Test Loss tensor([0.0076, 0.0097, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.713693380355835 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0103, 0.0093, 0.0099]) \n",
      "Test Loss tensor([0.0076, 0.0096, 0.0096, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6543262004852295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0093, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0094, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5670211315155029 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0102, 0.0101, 0.0097]) \n",
      "Test Loss tensor([0.0075, 0.0099, 0.0096, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5922846794128418 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0098, 0.0093, 0.0097]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0095, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5437254905700684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0084, 0.0091, 0.0088]) \n",
      "Test Loss tensor([0.0075, 0.0101, 0.0089, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5676310062408447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0094, 0.0093, 0.0091]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5533006191253662 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0092, 0.0094, 0.0093]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0091, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6994302272796631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0109, 0.0088, 0.0108]) \n",
      "Test Loss tensor([0.0078, 0.0101, 0.0089, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6454300880432129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0097, 0.0093, 0.0095]) \n",
      "Test Loss tensor([0.0074, 0.0099, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6076850891113281 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0111, 0.0087, 0.0101]) \n",
      "Test Loss tensor([0.0075, 0.0097, 0.0096, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6076860427856445 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0111, 0.0093, 0.0098]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0095, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5786759853363037 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0097, 0.0102, 0.0114]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0095, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6371569633483887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0091, 0.0100, 0.0095]) \n",
      "Test Loss tensor([0.0073, 0.0096, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5630724430084229 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0095, 0.0097, 0.0091]) \n",
      "Test Loss tensor([0.0073, 0.0093, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5947422981262207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0100, 0.0089, 0.0092]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0092, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6324501037597656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0105, 0.0088, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5978531837463379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0103, 0.0080, 0.0098]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6126883029937744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0113, 0.0094, 0.0090]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0096, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5708904266357422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0098, 0.0085, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0089, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6114354133605957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0091, 0.0079, 0.0091]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6035292148590088 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0101, 0.0083, 0.0101]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5743741989135742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0103, 0.0091, 0.0095]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0092, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6054909229278564 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0096, 0.0087, 0.0091]) \n",
      "Test Loss tensor([0.0069, 0.0098, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.596672534942627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0104, 0.0092, 0.0101]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0092, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5950362682342529 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0094, 0.0090, 0.0094]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.594712495803833 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0098, 0.0082, 0.0098]) \n",
      "Test Loss tensor([0.0074, 0.0094, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6117761135101318 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0096, 0.0075, 0.0097]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0091, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.599663496017456 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0102, 0.0099, 0.0092]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.555065393447876 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0109, 0.0090, 0.0098]) \n",
      "Test Loss tensor([0.0073, 0.0100, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6119139194488525 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0088, 0.0089]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5811684131622314 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0100, 0.0092, 0.0087]) \n",
      "Test Loss tensor([0.0072, 0.0094, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6006860733032227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0093, 0.0081, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5952720642089844 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0114, 0.0091, 0.0091]) \n",
      "Test Loss tensor([0.0072, 0.0100, 0.0092, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5936832427978516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0086, 0.0097, 0.0098]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0089, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5779051780700684 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0099, 0.0095, 0.0091]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0092, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5610182285308838 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0110, 0.0089, 0.0093]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0089, 0.0095])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 500 in 0.5667641162872314 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0086, 0.0106, 0.0093, 0.0101]) \n",
      "Test Loss tensor([0.0072, 0.0098, 0.0089, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5654165744781494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0087, 0.0095]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5457537174224854 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0100, 0.0078, 0.0085]) \n",
      "Test Loss tensor([0.0075, 0.0095, 0.0090, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5619237422943115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0107, 0.0082, 0.0097]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5608832836151123 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0104, 0.0079, 0.0088]) \n",
      "Test Loss tensor([0.0070, 0.0099, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5690605640411377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0097, 0.0089, 0.0094]) \n",
      "Test Loss tensor([0.0073, 0.0100, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.564760684967041 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0100, 0.0101, 0.0089]) \n",
      "Test Loss tensor([0.0071, 0.0099, 0.0089, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5620326995849609 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0100, 0.0082, 0.0091]) \n",
      "Test Loss tensor([0.0072, 0.0101, 0.0095, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.557636022567749 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0110, 0.0086, 0.0095]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5739078521728516 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0090, 0.0085, 0.0096]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0094, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5751523971557617 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0104, 0.0077, 0.0106]) \n",
      "Test Loss tensor([0.0073, 0.0097, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5751454830169678 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0098, 0.0089, 0.0094]) \n",
      "Test Loss tensor([0.0070, 0.0098, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6033730506896973 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0091, 0.0093, 0.0100]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0091, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5586833953857422 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0093, 0.0095, 0.0103]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0088, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.579171895980835 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0084, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0072, 0.0102, 0.0091, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5898098945617676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0099, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0069, 0.0097, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5747768878936768 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0091, 0.0091, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.576805591583252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0099, 0.0088, 0.0095]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0093, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6689260005950928 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0091, 0.0087, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5442557334899902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0107, 0.0085, 0.0095]) \n",
      "Test Loss tensor([0.0074, 0.0095, 0.0090, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5206530094146729 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0100, 0.0097, 0.0089]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5553686618804932 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0086, 0.0102, 0.0089]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0097, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6005814075469971 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0101, 0.0086, 0.0089]) \n",
      "Test Loss tensor([0.0072, 0.0093, 0.0086, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6905591487884521 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0109, 0.0080, 0.0091]) \n",
      "Test Loss tensor([0.0073, 0.0096, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5461902618408203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0083, 0.0109, 0.0096, 0.0103]) \n",
      "Test Loss tensor([0.0070, 0.0100, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5747568607330322 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0093, 0.0092, 0.0090]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5518238544464111 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0097, 0.0084, 0.0091]) \n",
      "Test Loss tensor([0.0073, 0.0095, 0.0091, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5351498126983643 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0087, 0.0106, 0.0104]) \n",
      "Test Loss tensor([0.0076, 0.0099, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5129008293151855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0099, 0.0100]) \n",
      "Test Loss tensor([0.0073, 0.0097, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5578899383544922 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0103, 0.0099, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0091, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5696709156036377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0093, 0.0096, 0.0089]) \n",
      "Test Loss tensor([0.0075, 0.0098, 0.0094, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.566199779510498 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0085, 0.0095, 0.0098, 0.0101]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0093, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.547274112701416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0101, 0.0089, 0.0099]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0090, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5506992340087891 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0095, 0.0093, 0.0091]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6030211448669434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0098, 0.0092, 0.0089]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0090, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.61358642578125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0101, 0.0088, 0.0094]) \n",
      "Test Loss tensor([0.0073, 0.0100, 0.0092, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5699033737182617 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0103, 0.0100, 0.0095]) \n",
      "Test Loss tensor([0.0072, 0.0091, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5837128162384033 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0092, 0.0085, 0.0086]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0087, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5854489803314209 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0100, 0.0089, 0.0100]) \n",
      "Test Loss tensor([0.0073, 0.0095, 0.0091, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5606510639190674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0099, 0.0100, 0.0104]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5282571315765381 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0093, 0.0080, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0087, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5343832969665527 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0103, 0.0088, 0.0096]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6279397010803223 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0104, 0.0095, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6288926601409912 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0087, 0.0099]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6663672924041748 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0086, 0.0085, 0.0100]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0090, 0.0091])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 680 in 0.6118648052215576 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0092, 0.0093, 0.0100]) \n",
      "Test Loss tensor([0.0072, 0.0093, 0.0089, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6557483673095703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0091, 0.0085, 0.0094]) \n",
      "Test Loss tensor([0.0075, 0.0096, 0.0085, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5525364875793457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0103, 0.0074, 0.0091]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6162130832672119 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0095, 0.0092, 0.0100]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6120266914367676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0101, 0.0086, 0.0096]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5668351650238037 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0087, 0.0080, 0.0090]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0089, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5016601085662842 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0113, 0.0081, 0.0084]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0086, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5247044563293457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0098, 0.0085, 0.0099]) \n",
      "Test Loss tensor([0.0073, 0.0098, 0.0088, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4650442600250244 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0098, 0.0084, 0.0096]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4569389820098877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0099, 0.0082, 0.0095]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0090, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4405393600463867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0089, 0.0085, 0.0088]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4534580707550049 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0097, 0.0093, 0.0092]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5061368942260742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0100, 0.0092, 0.0084]) \n",
      "Test Loss tensor([0.0071, 0.0100, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.48415493965148926 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0089, 0.0090, 0.0094]) \n",
      "Test Loss tensor([0.0069, 0.0097, 0.0087, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47212982177734375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0086, 0.0090]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5053372383117676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0090, 0.0092, 0.0090]) \n",
      "Test Loss tensor([0.0073, 0.0093, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.45713281631469727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0095, 0.0068, 0.0085]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.456256628036499 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0086, 0.0096]) \n",
      "Test Loss tensor([0.0071, 0.0099, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.44146084785461426 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0107, 0.0083, 0.0101]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.45835280418395996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0094, 0.0089, 0.0096]) \n",
      "Test Loss tensor([0.0072, 0.0094, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4579653739929199 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0091, 0.0087, 0.0095]) \n",
      "Test Loss tensor([0.0073, 0.0095, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.44258570671081543 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0093, 0.0084, 0.0088]) \n",
      "Test Loss tensor([0.0071, 0.0100, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4442310333251953 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0103, 0.0084, 0.0095]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.43961668014526367 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0091, 0.0097, 0.0097]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.48460888862609863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0093, 0.0082, 0.0097]) \n",
      "Test Loss tensor([0.0071, 0.0099, 0.0090, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4568309783935547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0100, 0.0088, 0.0085]) \n",
      "Test Loss tensor([0.0075, 0.0094, 0.0090, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4775078296661377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0096, 0.0085, 0.0093]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.44141149520874023 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0099, 0.0089, 0.0103]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0091, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4553353786468506 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0095, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.44125986099243164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0104, 0.0103, 0.0099]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.45808982849121094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0097, 0.0082, 0.0091]) \n",
      "Test Loss tensor([0.0073, 0.0099, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.43990063667297363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0079, 0.0088]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0092, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4378011226654053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0099, 0.0076, 0.0090]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47232818603515625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0097, 0.0099, 0.0091]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.49178385734558105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0095, 0.0090, 0.0095]) \n",
      "Test Loss tensor([0.0072, 0.0091, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5143444538116455 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0101, 0.0085, 0.0102]) \n",
      "Test Loss tensor([0.0073, 0.0094, 0.0085, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.46206212043762207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0099, 0.0099, 0.0091]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4929642677307129 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0100, 0.0086, 0.0107]) \n",
      "Test Loss tensor([0.0075, 0.0096, 0.0096, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4317038059234619 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0094, 0.0093, 0.0088]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4836862087249756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0087, 0.0087, 0.0104]) \n",
      "Test Loss tensor([0.0073, 0.0097, 0.0094, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4704253673553467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0103, 0.0094, 0.0090]) \n",
      "Test Loss tensor([0.0070, 0.0098, 0.0092, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.44544100761413574 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0105, 0.0094, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.43223047256469727 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0093, 0.0085, 0.0095]) \n",
      "Test Loss tensor([0.0078, 0.0099, 0.0094, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.44596171379089355 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0091, 0.0094, 0.0102]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0094, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4352242946624756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0107, 0.0094, 0.0093]) \n",
      "Test Loss tensor([0.0073, 0.0101, 0.0089, 0.0095])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 860 in 0.47891664505004883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0109, 0.0078, 0.0097]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0096, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.49906063079833984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0106, 0.0093, 0.0103]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4674258232116699 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0094, 0.0079, 0.0099]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.44193196296691895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0104, 0.0087, 0.0080]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4069340229034424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0069, 0.0058, 0.0077]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.4981863498687744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0095, 0.0079, 0.0105]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4670290946960449 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0103, 0.0093, 0.0096]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0088, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5253844261169434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0097, 0.0091, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5534229278564453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0103, 0.0091, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0093, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5076913833618164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0089, 0.0085, 0.0090]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0088, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4542064666748047 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0102, 0.0087, 0.0090]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0088, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4792935848236084 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0098, 0.0100, 0.0086]) \n",
      "Test Loss tensor([0.0074, 0.0098, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4342787265777588 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0087, 0.0095, 0.0092, 0.0102]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.44481348991394043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0096, 0.0077, 0.0090]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4560258388519287 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0103, 0.0095, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0097, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.49617576599121094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0096, 0.0088, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0100, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4675297737121582 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0101, 0.0098, 0.0096]) \n",
      "Test Loss tensor([0.0071, 0.0099, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4537510871887207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0109, 0.0077, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0098, 0.0087, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.43340563774108887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0096, 0.0083, 0.0085]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4514334201812744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0096, 0.0092, 0.0092]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4607992172241211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0098, 0.0077, 0.0098]) \n",
      "Test Loss tensor([0.0069, 0.0098, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4386599063873291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0089, 0.0079, 0.0094]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4752228260040283 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0098, 0.0075, 0.0100]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4585249423980713 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0092, 0.0093, 0.0100]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0089, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5174174308776855 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0096, 0.0087, 0.0088]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4682130813598633 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0088, 0.0087, 0.0082]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0082, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.47214674949645996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0092, 0.0078, 0.0095]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4811208248138428 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0093, 0.0086, 0.0096]) \n",
      "Test Loss tensor([0.0071, 0.0096, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.45742034912109375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0076, 0.0096]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.43021225929260254 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0092, 0.0072, 0.0101]) \n",
      "Test Loss tensor([0.0070, 0.0098, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4410820007324219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0100, 0.0084, 0.0098]) \n",
      "Test Loss tensor([0.0074, 0.0097, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4362599849700928 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0100, 0.0084, 0.0095]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4504976272583008 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0101, 0.0085, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.45082783699035645 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0095, 0.0078, 0.0083]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4314396381378174 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0096, 0.0086, 0.0091]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.48355579376220703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0083, 0.0087]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4402809143066406 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0105, 0.0075, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.44165778160095215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0102, 0.0082, 0.0107]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.44197988510131836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0092, 0.0078, 0.0099]) \n",
      "Test Loss tensor([0.0073, 0.0093, 0.0087, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.48331379890441895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0107, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0085, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.48083019256591797 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0092, 0.0081, 0.0089]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.471757173538208 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0095, 0.0084, 0.0087]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.467057466506958 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0100, 0.0088, 0.0095]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0084, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.48289036750793457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0098, 0.0084, 0.0095]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.43784642219543457 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0093, 0.0089]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0086, 0.0096])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 160 in 0.5378475189208984 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0077, 0.0106]) \n",
      "Test Loss tensor([0.0071, 0.0092, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4776935577392578 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0092, 0.0081, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4532136917114258 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0088, 0.0090, 0.0092]) \n",
      "Test Loss tensor([0.0072, 0.0091, 0.0090, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5428066253662109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0089, 0.0085, 0.0100]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0086, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.67384934425354 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0092, 0.0090, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0085, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7470600605010986 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0086, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7087996006011963 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0084, 0.0081, 0.0093]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0087, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6233937740325928 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0100, 0.0083, 0.0097]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5681726932525635 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0091, 0.0093, 0.0088]) \n",
      "Test Loss tensor([0.0069, 0.0097, 0.0088, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5765054225921631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0091, 0.0077, 0.0094]) \n",
      "Test Loss tensor([0.0073, 0.0096, 0.0091, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6408743858337402 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0103, 0.0082, 0.0094]) \n",
      "Test Loss tensor([0.0071, 0.0097, 0.0085, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5492730140686035 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0094, 0.0092, 0.0094]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5687248706817627 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0100, 0.0084, 0.0094]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0093, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5426511764526367 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0080, 0.0095, 0.0093, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5461599826812744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0088, 0.0081, 0.0088]) \n",
      "Test Loss tensor([0.0071, 0.0093, 0.0088, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5272371768951416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0105, 0.0087, 0.0093]) \n",
      "Test Loss tensor([0.0073, 0.0094, 0.0089, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5356359481811523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0098, 0.0090, 0.0085]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.540642499923706 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0096, 0.0094, 0.0092]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5469045639038086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0095, 0.0082, 0.0090]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5199246406555176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0122, 0.0086, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5718250274658203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0091, 0.0074, 0.0104]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5782110691070557 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0101, 0.0092, 0.0091]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0087, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5238540172576904 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0088, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0085, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5507612228393555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0094, 0.0085, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5337281227111816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0102, 0.0082, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0095, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.581916093826294 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0077, 0.0096]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5549170970916748 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0098, 0.0081, 0.0084]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5235929489135742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0091, 0.0087, 0.0100]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0092, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5173945426940918 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0095, 0.0085, 0.0086]) \n",
      "Test Loss tensor([0.0070, 0.0092, 0.0092, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.547252893447876 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0095, 0.0085]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5091671943664551 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0104, 0.0087, 0.0090]) \n",
      "Test Loss tensor([0.0072, 0.0094, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5111937522888184 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0099, 0.0082, 0.0089]) \n",
      "Test Loss tensor([0.0070, 0.0092, 0.0086, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.511441707611084 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0085, 0.0075, 0.0097]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5426735877990723 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0077, 0.0090]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0088, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5250794887542725 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0093, 0.0085, 0.0105]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5100743770599365 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0083, 0.0076, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5215179920196533 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0088, 0.0100]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5029585361480713 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0100, 0.0084, 0.0091]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0091, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.52774977684021 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0094, 0.0084, 0.0095]) \n",
      "Test Loss tensor([0.0067, 0.0090, 0.0085, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5100452899932861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0102, 0.0085, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5845897197723389 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0091, 0.0083, 0.0086]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5704700946807861 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0095, 0.0081, 0.0104]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5686089992523193 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0106, 0.0084, 0.0088]) \n",
      "Test Loss tensor([0.0067, 0.0095, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5368692874908447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0094, 0.0095, 0.0085]) \n",
      "Test Loss tensor([0.0070, 0.0092, 0.0085, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5646662712097168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0095, 0.0085, 0.0099]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0085, 0.0094])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 340 in 0.5498766899108887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0080, 0.0089]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5419700145721436 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0101, 0.0090, 0.0097]) \n",
      "Test Loss tensor([0.0069, 0.0098, 0.0087, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5537204742431641 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0092, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0090, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5607297420501709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0094, 0.0089, 0.0104]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0086, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5477714538574219 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0097, 0.0091, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.537024736404419 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0096, 0.0080, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0087, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5185844898223877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0082, 0.0099, 0.0074, 0.0103]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.523949384689331 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0099, 0.0080, 0.0096]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5231678485870361 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0098, 0.0092, 0.0088]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0089, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5087714195251465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0098, 0.0095, 0.0093]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0086, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5163073539733887 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0088, 0.0086, 0.0092]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0085, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5333483219146729 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0078, 0.0086, 0.0099]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5469856262207031 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0094, 0.0088, 0.0089]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5354020595550537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0094, 0.0097, 0.0089]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5088291168212891 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0093, 0.0090, 0.0105]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5216829776763916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0103, 0.0089, 0.0096]) \n",
      "Test Loss tensor([0.0067, 0.0095, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5072362422943115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0110, 0.0083, 0.0091]) \n",
      "Test Loss tensor([0.0070, 0.0097, 0.0090, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5146491527557373 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0085, 0.0092, 0.0094]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0084, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5084881782531738 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0093, 0.0087, 0.0103]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0091, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5147662162780762 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0097, 0.0078, 0.0096]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5136325359344482 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0098, 0.0085, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5197818279266357 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0098, 0.0080, 0.0089]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5398130416870117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0091, 0.0089, 0.0091]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0092, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5217723846435547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0095, 0.0089, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0085, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5204901695251465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0100, 0.0091, 0.0099]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0096, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5293149948120117 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0107, 0.0085, 0.0091]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.534365177154541 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0095, 0.0077, 0.0083]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0089, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5211341381072998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0091, 0.0084]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0087, 0.0097])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5026280879974365 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0094, 0.0078, 0.0094]) \n",
      "Test Loss tensor([0.0067, 0.0095, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5166964530944824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0099, 0.0086, 0.0087]) \n",
      "Test Loss tensor([0.0073, 0.0094, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5102794170379639 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0094, 0.0082, 0.0094]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5206952095031738 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0109, 0.0090, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5222747325897217 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0105, 0.0091, 0.0091]) \n",
      "Test Loss tensor([0.0071, 0.0095, 0.0093, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5176131725311279 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0111, 0.0102, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5092270374298096 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0093, 0.0087, 0.0086]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0095, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5219066143035889 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0097, 0.0085, 0.0094]) \n",
      "Test Loss tensor([0.0072, 0.0092, 0.0091, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5053796768188477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0093, 0.0092, 0.0084]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5137808322906494 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0081, 0.0074, 0.0092]) \n",
      "Test Loss tensor([0.0072, 0.0099, 0.0093, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5058887004852295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0101, 0.0088, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5229544639587402 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0105, 0.0084, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0094, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5214877128601074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0093, 0.0090, 0.0094]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0089, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5080442428588867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0091, 0.0087, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0095, 0.0088, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5439064502716064 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0099, 0.0101, 0.0090]) \n",
      "Test Loss tensor([0.0071, 0.0098, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5136892795562744 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0105, 0.0083, 0.0088]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.520909309387207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0094, 0.0090, 0.0086]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0087, 0.0097])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 520 in 0.5076942443847656 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0099, 0.0089, 0.0092]) \n",
      "Test Loss tensor([0.0072, 0.0095, 0.0098, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5162856578826904 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0093, 0.0101, 0.0092]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0088, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.507249116897583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0084, 0.0076, 0.0101]) \n",
      "Test Loss tensor([0.0074, 0.0096, 0.0097, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5332796573638916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0092, 0.0093, 0.0095]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0081, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5207068920135498 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0101, 0.0078, 0.0100]) \n",
      "Test Loss tensor([0.0072, 0.0096, 0.0092, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5324676036834717 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0103, 0.0089, 0.0106]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0091, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5161988735198975 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0091, 0.0084, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0090, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.514298677444458 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0102, 0.0085, 0.0097]) \n",
      "Test Loss tensor([0.0072, 0.0097, 0.0090, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5109472274780273 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0085, 0.0093, 0.0106]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5304067134857178 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0090, 0.0080, 0.0088]) \n",
      "Test Loss tensor([0.0072, 0.0093, 0.0096, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5099821090698242 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0085, 0.0086, 0.0097]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5229678153991699 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0087, 0.0098]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5171511173248291 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0089, 0.0083, 0.0093]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5318756103515625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0104, 0.0089, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5259490013122559 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0100, 0.0073, 0.0100]) \n",
      "Test Loss tensor([0.0070, 0.0094, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.522507905960083 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0101, 0.0093, 0.0091]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5205352306365967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0099, 0.0091, 0.0093]) \n",
      "Test Loss tensor([0.0071, 0.0094, 0.0089, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5382733345031738 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0101, 0.0095, 0.0106]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5542151927947998 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0090, 0.0083, 0.0086]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0090, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5157516002655029 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0103, 0.0086, 0.0089]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0086, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5273783206939697 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0085, 0.0092, 0.0092]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0085, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5292985439300537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0093, 0.0083, 0.0089]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.524362325668335 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0100, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5258066654205322 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0098, 0.0078, 0.0085]) \n",
      "Test Loss tensor([0.0067, 0.0097, 0.0086, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5262212753295898 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0087, 0.0081, 0.0085]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5022284984588623 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0084, 0.0090, 0.0089]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5196938514709473 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0096, 0.0076, 0.0088]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0088, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5170578956604004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0092, 0.0092, 0.0090]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0086, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5163428783416748 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0099, 0.0092, 0.0087]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.547050952911377 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0094, 0.0086, 0.0084]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5496649742126465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0082, 0.0083, 0.0083]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5823574066162109 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0089, 0.0092, 0.0090]) \n",
      "Test Loss tensor([0.0069, 0.0091, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5522868633270264 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0089, 0.0076, 0.0088]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0083, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5726232528686523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0106, 0.0088, 0.0093]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5640325546264648 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0088, 0.0090, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0086, 0.0096])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5814282894134521 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0096, 0.0089, 0.0095]) \n",
      "Test Loss tensor([0.0069, 0.0091, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5678567886352539 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0092, 0.0080, 0.0099]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5750174522399902 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0102, 0.0083, 0.0086]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6909909248352051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0089, 0.0074, 0.0090]) \n",
      "Test Loss tensor([0.0070, 0.0096, 0.0085, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5113751888275146 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0099, 0.0092, 0.0082]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5372135639190674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0085, 0.0084, 0.0087]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5587713718414307 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0097, 0.0077, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0090, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6493299007415771 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0091, 0.0083, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0095, 0.0086, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5707061290740967 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0054, 0.0092, 0.0085, 0.0085]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.560227632522583 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0091, 0.0083, 0.0096]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0085, 0.0092])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 700 in 0.5847489833831787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0093, 0.0081, 0.0082]) \n",
      "Test Loss tensor([0.0070, 0.0093, 0.0088, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5605626106262207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0091, 0.0089, 0.0105]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5870208740234375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0084, 0.0091, 0.0081]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5632579326629639 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0104, 0.0083, 0.0088]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5741798877716064 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0096, 0.0084, 0.0095]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0089, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5401098728179932 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0103, 0.0084, 0.0082]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0082, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5683033466339111 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0095, 0.0080, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5579323768615723 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0101, 0.0090, 0.0082]) \n",
      "Test Loss tensor([0.0069, 0.0097, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5700931549072266 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0092, 0.0082, 0.0093]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0084, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5695278644561768 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0105, 0.0097, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5446925163269043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0094, 0.0077, 0.0096]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5563628673553467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0094, 0.0093, 0.0097]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5495245456695557 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0087, 0.0074, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5752546787261963 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0104, 0.0086, 0.0091]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5705037117004395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0093, 0.0082, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5428507328033447 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0098, 0.0084, 0.0090]) \n",
      "Test Loss tensor([0.0069, 0.0098, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.573613166809082 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0092, 0.0088, 0.0105]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5571656227111816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0098, 0.0083, 0.0094]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0087, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5710546970367432 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0098, 0.0082, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5572509765625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0089, 0.0080, 0.0097]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5765502452850342 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0096, 0.0079, 0.0086]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5532433986663818 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0096, 0.0090, 0.0085]) \n",
      "Test Loss tensor([0.0069, 0.0095, 0.0084, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5988724231719971 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0081, 0.0092, 0.0081, 0.0099]) \n",
      "Test Loss tensor([0.0069, 0.0096, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5685944557189941 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0096, 0.0093, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5468099117279053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0087, 0.0080, 0.0092]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0087, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5662665367126465 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0085, 0.0088, 0.0084]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5737166404724121 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0092, 0.0077, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0093, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5745964050292969 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0094, 0.0082, 0.0095]) \n",
      "Test Loss tensor([0.0066, 0.0088, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5522737503051758 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0088, 0.0084, 0.0088]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5613269805908203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0097, 0.0079, 0.0089]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5405642986297607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0100, 0.0076, 0.0092]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5618975162506104 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0106, 0.0080, 0.0086]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0085, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.573103666305542 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0079, 0.0093]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0087, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.547316312789917 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0089, 0.0094, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5352003574371338 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0101, 0.0076, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0088, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5757548809051514 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0100, 0.0099, 0.0091]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0086, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5665578842163086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0055, 0.0089, 0.0090, 0.0090]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0087, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5490810871124268 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0100, 0.0088, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0088, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5519893169403076 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0092, 0.0081, 0.0095]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5783913135528564 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0091, 0.0078, 0.0093]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.569674015045166 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0088, 0.0093, 0.0090]) \n",
      "Test Loss tensor([0.0066, 0.0096, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5584537982940674 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0098, 0.0084, 0.0087]) \n",
      "Test Loss tensor([0.0065, 0.0095, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.555898904800415 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0091, 0.0096, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0096, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5320193767547607 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0088, 0.0079, 0.0086]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0085, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5166702270507812 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0046, 0.0068, 0.0063, 0.0066]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0082, 0.0094])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.5598058700561523 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0099, 0.0085, 0.0088]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0083, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5505003929138184 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0098, 0.0091, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0079, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5903892517089844 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0085, 0.0073, 0.0100]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5766041278839111 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0079, 0.0084]) \n",
      "Test Loss tensor([0.0070, 0.0091, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5493485927581787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0095, 0.0103, 0.0103]) \n",
      "Test Loss tensor([0.0067, 0.0096, 0.0089, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5644457340240479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0094, 0.0093, 0.0087]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5426909923553467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0086, 0.0085, 0.0096]) \n",
      "Test Loss tensor([0.0065, 0.0093, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5627975463867188 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0100, 0.0083, 0.0084]) \n",
      "Test Loss tensor([0.0067, 0.0090, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5657856464385986 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0098, 0.0086, 0.0092]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5738232135772705 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0092, 0.0089, 0.0088]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0083, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5709967613220215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0098, 0.0082, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5365979671478271 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0096, 0.0081, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0097, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5838768482208252 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0089, 0.0086, 0.0078]) \n",
      "Test Loss tensor([0.0066, 0.0090, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5685551166534424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0088, 0.0084, 0.0102]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5696649551391602 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0087, 0.0073, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0081, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5663793087005615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0087, 0.0079, 0.0094]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5692393779754639 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0097, 0.0091, 0.0102]) \n",
      "Test Loss tensor([0.0065, 0.0096, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5577318668365479 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0090, 0.0083, 0.0088]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0085, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5393948554992676 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0093, 0.0085, 0.0093]) \n",
      "Test Loss tensor([0.0069, 0.0094, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5805625915527344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0114, 0.0077, 0.0094]) \n",
      "Test Loss tensor([0.0070, 0.0095, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5552327632904053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0083, 0.0078]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5981218814849854 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0091, 0.0087, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0089, 0.0091, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5249567031860352 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0079, 0.0093, 0.0087, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0085, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5568192005157471 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0089, 0.0087]) \n",
      "Test Loss tensor([0.0069, 0.0087, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5247981548309326 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0097, 0.0083, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5845003128051758 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0095, 0.0087, 0.0087]) \n",
      "Test Loss tensor([0.0065, 0.0087, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5808260440826416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0088, 0.0086, 0.0091]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0083, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5391006469726562 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0090, 0.0083, 0.0100]) \n",
      "Test Loss tensor([0.0067, 0.0090, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5819065570831299 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0091, 0.0093, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0079, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.534644603729248 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0085, 0.0090, 0.0102]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0085, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5568428039550781 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0090, 0.0075, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.56150221824646 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0088, 0.0076, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5981335639953613 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0087, 0.0090, 0.0084]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5552864074707031 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0085, 0.0078, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0089, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5672054290771484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0092, 0.0080, 0.0088]) \n",
      "Test Loss tensor([0.0064, 0.0096, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5799291133880615 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0084, 0.0091]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.557736873626709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0105, 0.0077, 0.0104]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5750668048858643 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0094, 0.0077, 0.0098]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5646953582763672 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0092, 0.0084, 0.0099]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5644984245300293 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0086, 0.0073, 0.0095]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0079, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5726644992828369 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0082, 0.0090, 0.0093]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5437154769897461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0102, 0.0083, 0.0087]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5360286235809326 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0090, 0.0081, 0.0085]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0085, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5666549205780029 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0089, 0.0081, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0081, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5859653949737549 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0072, 0.0087]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0079, 0.0093])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 180 in 0.568988561630249 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0095, 0.0075, 0.0088]) \n",
      "Test Loss tensor([0.0066, 0.0095, 0.0080, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5710480213165283 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0056, 0.0104, 0.0076, 0.0093]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5731415748596191 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0094, 0.0080, 0.0101]) \n",
      "Test Loss tensor([0.0063, 0.0091, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5799703598022461 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0083, 0.0079, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5509049892425537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0090, 0.0079, 0.0095]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0078, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5550177097320557 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0092, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0093, 0.0081, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5754787921905518 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0091, 0.0079, 0.0088]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5458371639251709 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0092, 0.0078, 0.0080]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5763633251190186 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0096, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5713000297546387 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0091, 0.0077, 0.0095]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0082, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5601646900177002 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0091, 0.0092, 0.0088]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6036241054534912 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0084, 0.0081, 0.0099]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0082, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5476851463317871 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0094, 0.0095, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5945119857788086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0087, 0.0085, 0.0093]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6308927536010742 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0101, 0.0079, 0.0089]) \n",
      "Test Loss tensor([0.0068, 0.0094, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6022598743438721 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0088, 0.0079, 0.0084]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.579265832901001 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0096, 0.0078, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5721116065979004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0102, 0.0089, 0.0094]) \n",
      "Test Loss tensor([0.0064, 0.0094, 0.0081, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5691230297088623 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0096, 0.0074, 0.0084]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0078, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5660066604614258 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0096, 0.0074, 0.0091]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0082, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5777113437652588 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0082, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0078, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5630135536193848 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0096, 0.0067, 0.0098]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0084, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6054294109344482 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0093, 0.0069, 0.0095]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5642566680908203 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0090, 0.0088, 0.0096]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0080, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5767555236816406 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0102, 0.0083, 0.0091]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5650436878204346 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0098, 0.0078, 0.0089]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0085, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5746638774871826 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0079, 0.0086, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5712497234344482 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0100, 0.0088, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0093, 0.0080, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5704834461212158 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0089, 0.0078, 0.0082]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0082, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5850341320037842 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0100, 0.0089, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0078, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5886960029602051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0089, 0.0082, 0.0101]) \n",
      "Test Loss tensor([0.0066, 0.0090, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5454952716827393 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0093, 0.0075, 0.0096]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.573430061340332 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0085, 0.0084, 0.0082]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5750565528869629 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0095, 0.0085, 0.0084]) \n",
      "Test Loss tensor([0.0066, 0.0090, 0.0083, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5872883796691895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0092, 0.0077, 0.0096]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5623824596405029 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0095, 0.0081, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0080, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6410140991210938 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0078, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0088, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5687839984893799 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0093, 0.0089, 0.0085]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0077, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5381350517272949 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0103, 0.0074, 0.0087]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.483506441116333 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0094, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0064, 0.0093, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4837310314178467 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0097, 0.0088, 0.0102]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.48311614990234375 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0095, 0.0088, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4833948612213135 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0087, 0.0079, 0.0093]) \n",
      "Test Loss tensor([0.0063, 0.0091, 0.0081, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.47977638244628906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0091, 0.0076, 0.0081]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0080, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.49515533447265625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0090, 0.0075, 0.0088]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0080, 0.0092])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 360 in 0.48886585235595703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0093, 0.0078, 0.0085]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.48149609565734863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0084, 0.0090, 0.0087]) \n",
      "Test Loss tensor([0.0063, 0.0092, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4909543991088867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0093, 0.0084, 0.0086]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4604659080505371 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0092, 0.0087, 0.0089]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0091, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.46972036361694336 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0088, 0.0095, 0.0097]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0080, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4824512004852295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0091, 0.0070, 0.0087]) \n",
      "Test Loss tensor([0.0064, 0.0094, 0.0085, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4547545909881592 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0095, 0.0083, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0089, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4817821979522705 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0087, 0.0075, 0.0090]) \n",
      "Test Loss tensor([0.0063, 0.0089, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4547867774963379 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0088, 0.0077, 0.0101]) \n",
      "Test Loss tensor([0.0067, 0.0097, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4846010208129883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0094, 0.0081, 0.0084]) \n",
      "Test Loss tensor([0.0065, 0.0095, 0.0081, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.47059082984924316 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0086, 0.0076, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4792494773864746 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0075, 0.0083, 0.0087, 0.0092]) \n",
      "Test Loss tensor([0.0069, 0.0091, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.44846343994140625 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0082, 0.0102]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4733889102935791 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0092, 0.0075, 0.0087]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0083, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.47715282440185547 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0090, 0.0077, 0.0095]) \n",
      "Test Loss tensor([0.0068, 0.0096, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.46121907234191895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0096, 0.0085, 0.0085]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0079, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.43019962310791016 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0088, 0.0084, 0.0089]) \n",
      "Test Loss tensor([0.0067, 0.0093, 0.0087, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4406547546386719 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0092, 0.0086, 0.0085]) \n",
      "Test Loss tensor([0.0064, 0.0094, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4280679225921631 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0087, 0.0094, 0.0099]) \n",
      "Test Loss tensor([0.0063, 0.0091, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4288630485534668 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0100, 0.0075, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0090, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.45046257972717285 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0087, 0.0088, 0.0092]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0080, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.4235715866088867 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0054, 0.0098, 0.0087, 0.0086]) \n",
      "Test Loss tensor([0.0067, 0.0090, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4430427551269531 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0100, 0.0075, 0.0089]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.42229199409484863 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0087, 0.0081, 0.0096]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0085, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.45395874977111816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0089, 0.0082, 0.0080]) \n",
      "Test Loss tensor([0.0064, 0.0088, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4253966808319092 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0076, 0.0098, 0.0083, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.42200517654418945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0087, 0.0078, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.42813587188720703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0096, 0.0084, 0.0105]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4215238094329834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0091, 0.0081, 0.0095]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.44038987159729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0096, 0.0076, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0081, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4391608238220215 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0090, 0.0074, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.43686795234680176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0098, 0.0082, 0.0083]) \n",
      "Test Loss tensor([0.0066, 0.0095, 0.0086, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.426300048828125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0105, 0.0083, 0.0103]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0080, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4198119640350342 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0088, 0.0080, 0.0093]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0080, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.43500828742980957 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0079, 0.0084]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.41918349266052246 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0098, 0.0077, 0.0100]) \n",
      "Test Loss tensor([0.0065, 0.0093, 0.0081, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4368858337402344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0096, 0.0079, 0.0091]) \n",
      "Test Loss tensor([0.0066, 0.0093, 0.0079, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.42031240463256836 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0089, 0.0075, 0.0083]) \n",
      "Test Loss tensor([0.0068, 0.0090, 0.0084, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.44597291946411133 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0095, 0.0087, 0.0097]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.42489147186279297 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0054, 0.0098, 0.0086, 0.0096]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0085, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4206960201263428 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0103, 0.0088, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0082, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4403712749481201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0101, 0.0078, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0085, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.42005252838134766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0100, 0.0078, 0.0087]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.43415117263793945 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0103, 0.0075, 0.0097]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4191572666168213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0084, 0.0073, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0086, 0.0089])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 540 in 0.4333174228668213 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0090, 0.0080, 0.0095]) \n",
      "Test Loss tensor([0.0062, 0.0090, 0.0082, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4214296340942383 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0091, 0.0084, 0.0093]) \n",
      "Test Loss tensor([0.0067, 0.0092, 0.0080, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4212062358856201 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0089, 0.0083, 0.0084]) \n",
      "Test Loss tensor([0.0066, 0.0090, 0.0081, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4368124008178711 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0100, 0.0083, 0.0086]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.41983914375305176 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0094, 0.0072, 0.0084]) \n",
      "Test Loss tensor([0.0064, 0.0090, 0.0078, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.43883752822875977 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0099, 0.0089, 0.0089]) \n",
      "Test Loss tensor([0.0064, 0.0088, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4215385913848877 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0084, 0.0086, 0.0086]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.430570125579834 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0093, 0.0081, 0.0087]) \n",
      "Test Loss tensor([0.0063, 0.0091, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.42379069328308105 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0091, 0.0088, 0.0082]) \n",
      "Test Loss tensor([0.0068, 0.0093, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.42090511322021484 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0107, 0.0087, 0.0095]) \n",
      "Test Loss tensor([0.0062, 0.0088, 0.0086, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.4416806697845459 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0094, 0.0086, 0.0088]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4221839904785156 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0077, 0.0092, 0.0081, 0.0084]) \n",
      "Test Loss tensor([0.0068, 0.0091, 0.0086, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.43415164947509766 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0088, 0.0078, 0.0086]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0081, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4224236011505127 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0094, 0.0073, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.43278074264526367 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0086, 0.0077, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0079, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.42395734786987305 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0095, 0.0080, 0.0088]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4187583923339844 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0072, 0.0097, 0.0097, 0.0093]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4466874599456787 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0088, 0.0087, 0.0085]) \n",
      "Test Loss tensor([0.0066, 0.0094, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.41887712478637695 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0087, 0.0068, 0.0085]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0080, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4405679702758789 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0059, 0.0088, 0.0080, 0.0099]) \n",
      "Test Loss tensor([0.0065, 0.0095, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.42226147651672363 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0089, 0.0072, 0.0088]) \n",
      "Test Loss tensor([0.0065, 0.0090, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4366333484649658 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0096, 0.0088, 0.0094]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0078, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.42647314071655273 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0086, 0.0080, 0.0084]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0081, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4245717525482178 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0055, 0.0096, 0.0081, 0.0089]) \n",
      "Test Loss tensor([0.0063, 0.0090, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.44880151748657227 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0095, 0.0075, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0093, 0.0081, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4221928119659424 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0074, 0.0087, 0.0072, 0.0086]) \n",
      "Test Loss tensor([0.0066, 0.0089, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4385085105895996 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0093, 0.0088, 0.0086]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0078, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.41970372200012207 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0055, 0.0084, 0.0085, 0.0090]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0079, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.43378210067749023 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0092, 0.0075, 0.0092]) \n",
      "Test Loss tensor([0.0063, 0.0091, 0.0080, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.43792128562927246 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0105, 0.0081, 0.0091]) \n",
      "Test Loss tensor([0.0065, 0.0088, 0.0084, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4414021968841553 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0105, 0.0083, 0.0084]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4262843132019043 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0089, 0.0087, 0.0087]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0079, 0.0095])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4195065498352051 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0096, 0.0073, 0.0086]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0080, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.43796753883361816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0104, 0.0076, 0.0088]) \n",
      "Test Loss tensor([0.0061, 0.0089, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.42043542861938477 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0098, 0.0079, 0.0094]) \n",
      "Test Loss tensor([0.0064, 0.0088, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.43594980239868164 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0089, 0.0088, 0.0090]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0084, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4316592216491699 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0091, 0.0086, 0.0088]) \n",
      "Test Loss tensor([0.0064, 0.0088, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.43135881423950195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0082, 0.0075, 0.0095]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0082, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4246554374694824 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0073, 0.0099, 0.0081, 0.0091]) \n",
      "Test Loss tensor([0.0068, 0.0092, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4215998649597168 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0071, 0.0094, 0.0081, 0.0091]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0081, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4264218807220459 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0083, 0.0083, 0.0082]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0086, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.42154359817504883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0086, 0.0089, 0.0095]) \n",
      "Test Loss tensor([0.0063, 0.0090, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4248216152191162 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0083, 0.0090]) \n",
      "Test Loss tensor([0.0062, 0.0090, 0.0082, 0.0093])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.42227888107299805 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0099, 0.0076, 0.0098]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0083, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4215428829193115 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0085, 0.0075, 0.0087]) \n",
      "Test Loss tensor([0.0066, 0.0092, 0.0080, 0.0091])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.4231393337249756 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0093, 0.0081, 0.0088]) \n",
      "Test Loss tensor([0.0064, 0.0090, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4234733581542969 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0093, 0.0075, 0.0086]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0085, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4269726276397705 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0090, 0.0079, 0.0092]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4349935054779053 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0088, 0.0076, 0.0084]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0079, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4321250915527344 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0090, 0.0086, 0.0090]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0087, 0.0094])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.43005871772766113 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0099, 0.0090, 0.0094]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0083, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.42856788635253906 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0088, 0.0083, 0.0086]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4292879104614258 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0070, 0.0098, 0.0085, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0083, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4310457706451416 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0091, 0.0088, 0.0082]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0079, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.43292999267578125 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0082, 0.0073, 0.0085]) \n",
      "Test Loss tensor([0.0063, 0.0090, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4282801151275635 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0087, 0.0085, 0.0087]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.43477582931518555 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0102, 0.0076, 0.0084]) \n",
      "Test Loss tensor([0.0063, 0.0093, 0.0080, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4282243251800537 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0056, 0.0087, 0.0080, 0.0084]) \n",
      "Test Loss tensor([0.0065, 0.0088, 0.0082, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.43118834495544434 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0092, 0.0074, 0.0084]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0084, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4297962188720703 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0064, 0.0096, 0.0087, 0.0085]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.42856478691101074 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0069, 0.0085, 0.0073, 0.0092]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0081, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.43214893341064453 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0083, 0.0078, 0.0089]) \n",
      "Test Loss tensor([0.0065, 0.0091, 0.0085, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.42691731452941895 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0079, 0.0090]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.46116018295288086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0091, 0.0079, 0.0096]) \n",
      "Test Loss tensor([0.0064, 0.0089, 0.0081, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4438924789428711 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0063, 0.0102, 0.0074, 0.0084]) \n",
      "Test Loss tensor([0.0069, 0.0092, 0.0090, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4304492473602295 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0078, 0.0097, 0.0078, 0.0099]) \n",
      "Test Loss tensor([0.0064, 0.0093, 0.0081, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.43062424659729004 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0099, 0.0090, 0.0083]) \n",
      "Test Loss tensor([0.0064, 0.0093, 0.0084, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.42763566970825195 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0057, 0.0091, 0.0075, 0.0091]) \n",
      "Test Loss tensor([0.0064, 0.0090, 0.0084, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.43268370628356934 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0088, 0.0077, 0.0093]) \n",
      "Test Loss tensor([0.0064, 0.0092, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.42829298973083496 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0088, 0.0069, 0.0091]) \n",
      "Test Loss tensor([0.0067, 0.0091, 0.0082, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.430509090423584 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0099, 0.0078, 0.0091]) \n",
      "Test Loss tensor([0.0066, 0.0091, 0.0085, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.43291449546813965 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0091, 0.0081, 0.0092]) \n",
      "Test Loss tensor([0.0062, 0.0089, 0.0078, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4473533630371094 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0084, 0.0077, 0.0082]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0084, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.43271303176879883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0068, 0.0083, 0.0079, 0.0091]) \n",
      "Test Loss tensor([0.0064, 0.0091, 0.0082, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.43033862113952637 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0096, 0.0084, 0.0081]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4289095401763916 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0061, 0.0083, 0.0093, 0.0084]) \n",
      "Test Loss tensor([0.0067, 0.0094, 0.0086, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.42722463607788086 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0058, 0.0099, 0.0082, 0.0090]) \n",
      "Test Loss tensor([0.0065, 0.0087, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4300374984741211 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0082, 0.0097]) \n",
      "Test Loss tensor([0.0065, 0.0092, 0.0081, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.42880678176879883 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0065, 0.0083, 0.0083, 0.0085]) \n",
      "Test Loss tensor([0.0063, 0.0092, 0.0080, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.42978882789611816 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0055, 0.0088, 0.0072, 0.0084]) \n",
      "Test Loss tensor([0.0064, 0.0088, 0.0082, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4293026924133301 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0062, 0.0100, 0.0067, 0.0087]) \n",
      "Test Loss tensor([0.0063, 0.0088, 0.0079, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4276895523071289 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0101, 0.0078, 0.0082]) \n",
      "Test Loss tensor([0.0063, 0.0089, 0.0079, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.42999958992004395 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0067, 0.0105, 0.0077, 0.0083]) \n",
      "Test Loss tensor([0.0063, 0.0092, 0.0080, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4276769161224365 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0060, 0.0095, 0.0080, 0.0084]) \n",
      "Test Loss tensor([0.0064, 0.0090, 0.0080, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.41802144050598145 **************\n",
      "\n",
      "Training Idx 1 \n",
      "Train Loss tensor([0.0047, 0.0061, 0.0067, 0.0064]) \n",
      "Test Loss tensor([0.0065, 0.0089, 0.0079, 0.0090])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.5038232803344727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4324, 0.4503, 0.5266, 0.4290, 0.4426]) \n",
      "Test Loss tensor([0.4297, 0.4525, 0.5254, 0.4251, 0.4462])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.47156214714050293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4321, 0.4515, 0.5242, 0.4236, 0.4447]) \n",
      "Test Loss tensor([0.4288, 0.4521, 0.5236, 0.4258, 0.4464])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47851085662841797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4286, 0.4539, 0.5236, 0.4266, 0.4481]) \n",
      "Test Loss tensor([0.4299, 0.4505, 0.5226, 0.4239, 0.4457])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47497010231018066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4333, 0.4511, 0.5223, 0.4256, 0.4464]) \n",
      "Test Loss tensor([0.4293, 0.4516, 0.5209, 0.4261, 0.4459])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4635884761810303 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4282, 0.4531, 0.5220, 0.4253, 0.4478]) \n",
      "Test Loss tensor([0.4285, 0.4512, 0.5192, 0.4259, 0.4451])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.48103976249694824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4292, 0.4511, 0.5200, 0.4251, 0.4465]) \n",
      "Test Loss tensor([0.4281, 0.4519, 0.5175, 0.4275, 0.4458])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4645826816558838 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4324, 0.4511, 0.5164, 0.4270, 0.4468]) \n",
      "Test Loss tensor([0.4267, 0.4514, 0.5163, 0.4275, 0.4458])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4675123691558838 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4258, 0.4528, 0.5173, 0.4276, 0.4448]) \n",
      "Test Loss tensor([0.4275, 0.4513, 0.5145, 0.4276, 0.4446])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4648430347442627 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4292, 0.4545, 0.5151, 0.4282, 0.4480]) \n",
      "Test Loss tensor([0.4270, 0.4518, 0.5134, 0.4277, 0.4447])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4708716869354248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4309, 0.4504, 0.5121, 0.4278, 0.4440]) \n",
      "Test Loss tensor([0.4268, 0.4515, 0.5120, 0.4284, 0.4453])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4642188549041748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4238, 0.4511, 0.5136, 0.4289, 0.4461]) \n",
      "Test Loss tensor([0.4268, 0.4514, 0.5102, 0.4293, 0.4455])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4691624641418457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4287, 0.4519, 0.5116, 0.4269, 0.4437]) \n",
      "Test Loss tensor([0.4257, 0.4517, 0.5091, 0.4302, 0.4458])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4666409492492676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4241, 0.4513, 0.5098, 0.4296, 0.4467]) \n",
      "Test Loss tensor([0.4247, 0.4516, 0.5075, 0.4298, 0.4454])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47197961807250977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4231, 0.4498, 0.5077, 0.4325, 0.4442]) \n",
      "Test Loss tensor([0.4252, 0.4519, 0.5055, 0.4306, 0.4441])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.46503758430480957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4243, 0.4511, 0.5058, 0.4315, 0.4448]) \n",
      "Test Loss tensor([0.4252, 0.4521, 0.5044, 0.4308, 0.4444])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4682631492614746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4259, 0.4505, 0.5036, 0.4301, 0.4419]) \n",
      "Test Loss tensor([0.4234, 0.4520, 0.5026, 0.4314, 0.4438])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4667050838470459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4243, 0.4518, 0.5030, 0.4345, 0.4456]) \n",
      "Test Loss tensor([0.4231, 0.4517, 0.5010, 0.4322, 0.4447])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.47098851203918457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4223, 0.4530, 0.5020, 0.4323, 0.4456]) \n",
      "Test Loss tensor([0.4235, 0.4521, 0.4997, 0.4324, 0.4447])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.46764254570007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4227, 0.4511, 0.5015, 0.4322, 0.4420]) \n",
      "Test Loss tensor([0.4235, 0.4515, 0.4986, 0.4337, 0.4442])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4645962715148926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4248, 0.4515, 0.4989, 0.4313, 0.4439]) \n",
      "Test Loss tensor([0.4219, 0.4521, 0.4973, 0.4335, 0.4438])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4678018093109131 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4236, 0.4494, 0.4980, 0.4337, 0.4434]) \n",
      "Test Loss tensor([0.4226, 0.4521, 0.4954, 0.4345, 0.4443])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.46883320808410645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4227, 0.4516, 0.4975, 0.4336, 0.4421]) \n",
      "Test Loss tensor([0.4215, 0.4521, 0.4937, 0.4349, 0.4436])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.48076486587524414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4225, 0.4530, 0.4941, 0.4370, 0.4419]) \n",
      "Test Loss tensor([0.4212, 0.4524, 0.4926, 0.4350, 0.4436])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4669325351715088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4225, 0.4511, 0.4922, 0.4362, 0.4430]) \n",
      "Test Loss tensor([0.4208, 0.4518, 0.4910, 0.4355, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.46955037117004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4224, 0.4491, 0.4917, 0.4333, 0.4459]) \n",
      "Test Loss tensor([0.4196, 0.4525, 0.4891, 0.4366, 0.4437])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4691460132598877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4181, 0.4515, 0.4902, 0.4364, 0.4416]) \n",
      "Test Loss tensor([0.4203, 0.4522, 0.4879, 0.4371, 0.4434])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4725930690765381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4180, 0.4519, 0.4876, 0.4347, 0.4459]) \n",
      "Test Loss tensor([0.4193, 0.4521, 0.4861, 0.4366, 0.4438])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4759402275085449 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4182, 0.4536, 0.4865, 0.4391, 0.4429]) \n",
      "Test Loss tensor([0.4195, 0.4526, 0.4848, 0.4378, 0.4433])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.473675012588501 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4160, 0.4529, 0.4852, 0.4365, 0.4430]) \n",
      "Test Loss tensor([0.4187, 0.4525, 0.4823, 0.4384, 0.4438])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4683563709259033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4217, 0.4508, 0.4839, 0.4343, 0.4441]) \n",
      "Test Loss tensor([0.4176, 0.4526, 0.4813, 0.4391, 0.4433])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.46907997131347656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4159, 0.4546, 0.4812, 0.4392, 0.4434]) \n",
      "Test Loss tensor([0.4174, 0.4529, 0.4801, 0.4394, 0.4430])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.46794915199279785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4202, 0.4514, 0.4802, 0.4405, 0.4403]) \n",
      "Test Loss tensor([0.4173, 0.4526, 0.4786, 0.4392, 0.4430])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.47650623321533203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4134, 0.4527, 0.4777, 0.4393, 0.4433]) \n",
      "Test Loss tensor([0.4183, 0.4526, 0.4769, 0.4397, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.47028589248657227 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4179, 0.4529, 0.4766, 0.4417, 0.4447]) \n",
      "Test Loss tensor([0.4175, 0.4526, 0.4753, 0.4415, 0.4437])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4659874439239502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4159, 0.4511, 0.4748, 0.4412, 0.4434]) \n",
      "Test Loss tensor([0.4168, 0.4525, 0.4734, 0.4423, 0.4428])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4765322208404541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4155, 0.4524, 0.4758, 0.4393, 0.4434]) \n",
      "Test Loss tensor([0.4159, 0.4530, 0.4718, 0.4420, 0.4427])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4702637195587158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4188, 0.4513, 0.4727, 0.4411, 0.4453]) \n",
      "Test Loss tensor([0.4161, 0.4526, 0.4705, 0.4421, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4763638973236084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4128, 0.4508, 0.4706, 0.4400, 0.4411]) \n",
      "Test Loss tensor([0.4153, 0.4525, 0.4688, 0.4435, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4786975383758545 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4140, 0.4522, 0.4685, 0.4433, 0.4410]) \n",
      "Test Loss tensor([0.4143, 0.4531, 0.4673, 0.4440, 0.4426])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.46965694427490234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4150, 0.4511, 0.4685, 0.4439, 0.4429]) \n",
      "Test Loss tensor([0.4147, 0.4533, 0.4652, 0.4444, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4637424945831299 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4132, 0.4524, 0.4653, 0.4442, 0.4431]) \n",
      "Test Loss tensor([0.4140, 0.4533, 0.4640, 0.4452, 0.4431])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 164 in 0.46633124351501465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4139, 0.4541, 0.4643, 0.4441, 0.4425]) \n",
      "Test Loss tensor([0.4140, 0.4535, 0.4621, 0.4461, 0.4432])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4681246280670166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4124, 0.4525, 0.4614, 0.4457, 0.4400]) \n",
      "Test Loss tensor([0.4125, 0.4532, 0.4606, 0.4457, 0.4426])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4666018486022949 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4140, 0.4529, 0.4608, 0.4450, 0.4454]) \n",
      "Test Loss tensor([0.4125, 0.4535, 0.4588, 0.4468, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.46266603469848633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4150, 0.4509, 0.4597, 0.4474, 0.4420]) \n",
      "Test Loss tensor([0.4121, 0.4533, 0.4580, 0.4466, 0.4425])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4677417278289795 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4126, 0.4515, 0.4567, 0.4468, 0.4413]) \n",
      "Test Loss tensor([0.4123, 0.4533, 0.4553, 0.4481, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.46487855911254883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4112, 0.4532, 0.4565, 0.4466, 0.4423]) \n",
      "Test Loss tensor([0.4128, 0.4546, 0.4535, 0.4498, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4654266834259033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4122, 0.4519, 0.4548, 0.4473, 0.4388]) \n",
      "Test Loss tensor([0.4113, 0.4539, 0.4521, 0.4500, 0.4430])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4649481773376465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4078, 0.4524, 0.4529, 0.4503, 0.4413]) \n",
      "Test Loss tensor([0.4116, 0.4537, 0.4505, 0.4496, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4673037528991699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4084, 0.4534, 0.4502, 0.4492, 0.4463]) \n",
      "Test Loss tensor([0.4102, 0.4545, 0.4491, 0.4502, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4739522933959961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4129, 0.4533, 0.4493, 0.4483, 0.4410]) \n",
      "Test Loss tensor([0.4103, 0.4539, 0.4471, 0.4510, 0.4413])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.46988558769226074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4085, 0.4522, 0.4488, 0.4521, 0.4419]) \n",
      "Test Loss tensor([0.4091, 0.4546, 0.4455, 0.4518, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.46773838996887207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4113, 0.4533, 0.4448, 0.4498, 0.4409]) \n",
      "Test Loss tensor([0.4090, 0.4546, 0.4435, 0.4531, 0.4425])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4658999443054199 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4070, 0.4532, 0.4437, 0.4503, 0.4449]) \n",
      "Test Loss tensor([0.4091, 0.4546, 0.4421, 0.4533, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4656541347503662 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4059, 0.4539, 0.4428, 0.4517, 0.4408]) \n",
      "Test Loss tensor([0.4083, 0.4548, 0.4404, 0.4536, 0.4418])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4677083492279053 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4074, 0.4525, 0.4409, 0.4520, 0.4410]) \n",
      "Test Loss tensor([0.4087, 0.4552, 0.4384, 0.4541, 0.4422])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47182726860046387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4079, 0.4559, 0.4387, 0.4532, 0.4425]) \n",
      "Test Loss tensor([0.4075, 0.4557, 0.4369, 0.4553, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4650580883026123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4062, 0.4545, 0.4369, 0.4559, 0.4394]) \n",
      "Test Loss tensor([0.4074, 0.4548, 0.4349, 0.4556, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.46941065788269043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4094, 0.4532, 0.4367, 0.4519, 0.4394]) \n",
      "Test Loss tensor([0.4066, 0.4553, 0.4333, 0.4561, 0.4428])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4663562774658203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4096, 0.4541, 0.4341, 0.4572, 0.4398]) \n",
      "Test Loss tensor([0.4061, 0.4554, 0.4315, 0.4574, 0.4422])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.46682047843933105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4002, 0.4539, 0.4297, 0.4581, 0.4392]) \n",
      "Test Loss tensor([0.4067, 0.4554, 0.4299, 0.4582, 0.4426])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4669060707092285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4071, 0.4523, 0.4301, 0.4597, 0.4402]) \n",
      "Test Loss tensor([0.4054, 0.4561, 0.4280, 0.4582, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4687199592590332 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4035, 0.4535, 0.4285, 0.4585, 0.4435]) \n",
      "Test Loss tensor([0.4046, 0.4563, 0.4264, 0.4598, 0.4407])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.46512532234191895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4075, 0.4560, 0.4258, 0.4575, 0.4397]) \n",
      "Test Loss tensor([0.4052, 0.4564, 0.4247, 0.4601, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47012853622436523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4051, 0.4557, 0.4258, 0.4585, 0.4414]) \n",
      "Test Loss tensor([0.4041, 0.4567, 0.4235, 0.4611, 0.4422])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4769625663757324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4065, 0.4558, 0.4215, 0.4633, 0.4394]) \n",
      "Test Loss tensor([0.4044, 0.4564, 0.4215, 0.4611, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.46756744384765625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4009, 0.4563, 0.4216, 0.4602, 0.4412]) \n",
      "Test Loss tensor([0.4033, 0.4563, 0.4196, 0.4620, 0.4422])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.470414400100708 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4036, 0.4562, 0.4200, 0.4612, 0.4401]) \n",
      "Test Loss tensor([0.4044, 0.4570, 0.4185, 0.4633, 0.4428])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4687056541442871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4051, 0.4544, 0.4183, 0.4607, 0.4395]) \n",
      "Test Loss tensor([0.4033, 0.4569, 0.4168, 0.4637, 0.4418])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4666461944580078 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4035, 0.4556, 0.4171, 0.4635, 0.4401]) \n",
      "Test Loss tensor([0.4018, 0.4568, 0.4150, 0.4645, 0.4415])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4642777442932129 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4030, 0.4544, 0.4167, 0.4631, 0.4416]) \n",
      "Test Loss tensor([0.4028, 0.4565, 0.4143, 0.4639, 0.4412])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.46907901763916016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4056, 0.4560, 0.4139, 0.4637, 0.4410]) \n",
      "Test Loss tensor([0.4009, 0.4574, 0.4119, 0.4653, 0.4408])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.46699047088623047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4031, 0.4553, 0.4120, 0.4649, 0.4433]) \n",
      "Test Loss tensor([0.4013, 0.4573, 0.4098, 0.4656, 0.4418])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4701197147369385 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4001, 0.4566, 0.4110, 0.4679, 0.4405]) \n",
      "Test Loss tensor([0.4011, 0.4581, 0.4079, 0.4677, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4663660526275635 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4028, 0.4546, 0.4080, 0.4663, 0.4408]) \n",
      "Test Loss tensor([0.4016, 0.4581, 0.4063, 0.4682, 0.4432])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4671139717102051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3992, 0.4558, 0.4062, 0.4664, 0.4424]) \n",
      "Test Loss tensor([0.4008, 0.4580, 0.4048, 0.4692, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.463059663772583 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3983, 0.4592, 0.4063, 0.4671, 0.4419]) \n",
      "Test Loss tensor([0.4002, 0.4578, 0.4027, 0.4691, 0.4412])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.46778059005737305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4018, 0.4569, 0.4022, 0.4691, 0.4402]) \n",
      "Test Loss tensor([0.3999, 0.4579, 0.4008, 0.4708, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.46826171875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4021, 0.4578, 0.4021, 0.4684, 0.4394]) \n",
      "Test Loss tensor([0.3999, 0.4586, 0.3994, 0.4703, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4663047790527344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3987, 0.4596, 0.4006, 0.4707, 0.4406]) \n",
      "Test Loss tensor([0.3981, 0.4578, 0.3976, 0.4705, 0.4414])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4658827781677246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3975, 0.4581, 0.3981, 0.4699, 0.4399]) \n",
      "Test Loss tensor([0.3983, 0.4586, 0.3959, 0.4728, 0.4416])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.46817898750305176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.4012, 0.4592, 0.3956, 0.4737, 0.4420]) \n",
      "Test Loss tensor([0.3995, 0.4596, 0.3936, 0.4735, 0.4426])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 328 in 0.46441030502319336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3987, 0.4579, 0.3944, 0.4740, 0.4426]) \n",
      "Test Loss tensor([0.3981, 0.4592, 0.3918, 0.4740, 0.4421])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.465252161026001 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3985, 0.4595, 0.3922, 0.4721, 0.4411]) \n",
      "Test Loss tensor([0.3971, 0.4594, 0.3898, 0.4748, 0.4427])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.46486353874206543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3992, 0.4610, 0.3906, 0.4768, 0.4451]) \n",
      "Test Loss tensor([0.3970, 0.4592, 0.3881, 0.4761, 0.4418])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.46789097785949707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3998, 0.4589, 0.3889, 0.4743, 0.4407]) \n",
      "Test Loss tensor([0.3972, 0.4605, 0.3858, 0.4775, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.46787405014038086 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3952, 0.4610, 0.3872, 0.4771, 0.4430]) \n",
      "Test Loss tensor([0.3966, 0.4605, 0.3840, 0.4772, 0.4423])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4642817974090576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3976, 0.4606, 0.3845, 0.4782, 0.4435]) \n",
      "Test Loss tensor([0.3964, 0.4606, 0.3820, 0.4783, 0.4429])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.465360164642334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3941, 0.4618, 0.3836, 0.4798, 0.4424]) \n",
      "Test Loss tensor([0.3962, 0.4608, 0.3804, 0.4790, 0.4425])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4650757312774658 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3980, 0.4579, 0.3815, 0.4805, 0.4406]) \n",
      "Test Loss tensor([0.3960, 0.4611, 0.3775, 0.4801, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.46827268600463867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3982, 0.4594, 0.3784, 0.4777, 0.4415]) \n",
      "Test Loss tensor([0.3959, 0.4616, 0.3756, 0.4813, 0.4430])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.46397924423217773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3943, 0.4587, 0.3763, 0.4830, 0.4395]) \n",
      "Test Loss tensor([0.3961, 0.4615, 0.3738, 0.4810, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4666762351989746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3910, 0.4608, 0.3728, 0.4799, 0.4412]) \n",
      "Test Loss tensor([0.3947, 0.4614, 0.3716, 0.4825, 0.4429])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4663853645324707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3969, 0.4608, 0.3716, 0.4832, 0.4435]) \n",
      "Test Loss tensor([0.3938, 0.4634, 0.3695, 0.4854, 0.4443])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4683384895324707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3975, 0.4611, 0.3704, 0.4818, 0.4417]) \n",
      "Test Loss tensor([0.3941, 0.4623, 0.3671, 0.4848, 0.4447])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.46625709533691406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3957, 0.4644, 0.3665, 0.4839, 0.4464]) \n",
      "Test Loss tensor([0.3934, 0.4636, 0.3646, 0.4866, 0.4432])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.46813178062438965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3914, 0.4630, 0.3658, 0.4881, 0.4425]) \n",
      "Test Loss tensor([0.3922, 0.4627, 0.3624, 0.4874, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.466494083404541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3953, 0.4592, 0.3623, 0.4853, 0.4411]) \n",
      "Test Loss tensor([0.3921, 0.4635, 0.3600, 0.4881, 0.4437])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4664480686187744 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3898, 0.4606, 0.3608, 0.4858, 0.4420]) \n",
      "Test Loss tensor([0.3927, 0.4636, 0.3579, 0.4888, 0.4446])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.46866822242736816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3924, 0.4626, 0.3587, 0.4912, 0.4455]) \n",
      "Test Loss tensor([0.3920, 0.4645, 0.3555, 0.4914, 0.4444])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.46720194816589355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3873, 0.4647, 0.3565, 0.4885, 0.4447]) \n",
      "Test Loss tensor([0.3935, 0.4640, 0.3531, 0.4913, 0.4440])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4672420024871826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3945, 0.4646, 0.3514, 0.4927, 0.4453]) \n",
      "Test Loss tensor([0.3918, 0.4645, 0.3506, 0.4924, 0.4442])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.46477675437927246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3955, 0.4673, 0.3518, 0.4933, 0.4450]) \n",
      "Test Loss tensor([0.3905, 0.4653, 0.3484, 0.4948, 0.4451])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4667983055114746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3901, 0.4616, 0.3488, 0.4896, 0.4453]) \n",
      "Test Loss tensor([0.3912, 0.4663, 0.3454, 0.4955, 0.4444])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4667038917541504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3896, 0.4636, 0.3459, 0.4931, 0.4455]) \n",
      "Test Loss tensor([0.3916, 0.4658, 0.3431, 0.4970, 0.4445])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4687459468841553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3875, 0.4633, 0.3434, 0.4935, 0.4452]) \n",
      "Test Loss tensor([0.3895, 0.4655, 0.3399, 0.4976, 0.4445])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4668445587158203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3860, 0.4669, 0.3394, 0.4977, 0.4472]) \n",
      "Test Loss tensor([0.3891, 0.4664, 0.3376, 0.4988, 0.4446])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.47296571731567383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3847, 0.4623, 0.3372, 0.4966, 0.4406]) \n",
      "Test Loss tensor([0.3890, 0.4673, 0.3351, 0.5000, 0.4458])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4802711009979248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3868, 0.4699, 0.3345, 0.5027, 0.4450]) \n",
      "Test Loss tensor([0.3890, 0.4675, 0.3324, 0.5019, 0.4454])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4745187759399414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3888, 0.4678, 0.3320, 0.5000, 0.4422]) \n",
      "Test Loss tensor([0.3882, 0.4672, 0.3296, 0.5023, 0.4450])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.47078418731689453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3904, 0.4636, 0.3287, 0.4998, 0.4435]) \n",
      "Test Loss tensor([0.3876, 0.4686, 0.3268, 0.5042, 0.4464])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47129344940185547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3897, 0.4698, 0.3285, 0.5062, 0.4469]) \n",
      "Test Loss tensor([0.3874, 0.4690, 0.3237, 0.5059, 0.4454])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.47068214416503906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3923, 0.4623, 0.3247, 0.5013, 0.4440]) \n",
      "Test Loss tensor([0.3863, 0.4701, 0.3209, 0.5070, 0.4465])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4729294776916504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3926, 0.4673, 0.3193, 0.5083, 0.4449]) \n",
      "Test Loss tensor([0.3875, 0.4704, 0.3179, 0.5085, 0.4470])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5287458896636963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3864, 0.4721, 0.3176, 0.5115, 0.4487]) \n",
      "Test Loss tensor([0.3856, 0.4714, 0.3148, 0.5102, 0.4477])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5288114547729492 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3830, 0.4749, 0.3144, 0.5129, 0.4523]) \n",
      "Test Loss tensor([0.3850, 0.4721, 0.3123, 0.5129, 0.4488])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4706578254699707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3849, 0.4715, 0.3128, 0.5120, 0.4466]) \n",
      "Test Loss tensor([0.3847, 0.4725, 0.3090, 0.5131, 0.4478])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.471343994140625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3834, 0.4698, 0.3102, 0.5127, 0.4468]) \n",
      "Test Loss tensor([0.3859, 0.4731, 0.3063, 0.5150, 0.4492])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4836759567260742 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3878, 0.4686, 0.3055, 0.5138, 0.4472]) \n",
      "Test Loss tensor([0.3843, 0.4735, 0.3029, 0.5163, 0.4489])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.471743106842041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3838, 0.4641, 0.3021, 0.5118, 0.4435]) \n",
      "Test Loss tensor([0.3846, 0.4724, 0.3003, 0.5180, 0.4481])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47345566749572754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3851, 0.4719, 0.3006, 0.5153, 0.4488]) \n",
      "Test Loss tensor([0.3835, 0.4727, 0.2969, 0.5187, 0.4485])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4711647033691406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3836, 0.4756, 0.2974, 0.5166, 0.4464]) \n",
      "Test Loss tensor([0.3837, 0.4742, 0.2939, 0.5204, 0.4499])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4710729122161865 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3843, 0.4764, 0.2941, 0.5239, 0.4505]) \n",
      "Test Loss tensor([0.3836, 0.4750, 0.2910, 0.5230, 0.4504])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 492 in 0.5031027793884277 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3860, 0.4726, 0.2913, 0.5171, 0.4482]) \n",
      "Test Loss tensor([0.3839, 0.4753, 0.2881, 0.5244, 0.4498])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47766661643981934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3917, 0.4744, 0.2878, 0.5230, 0.4479]) \n",
      "Test Loss tensor([0.3810, 0.4783, 0.2848, 0.5270, 0.4521])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.470731258392334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3850, 0.4772, 0.2833, 0.5233, 0.4483]) \n",
      "Test Loss tensor([0.3831, 0.4776, 0.2814, 0.5275, 0.4531])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4847903251647949 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3788, 0.4774, 0.2809, 0.5275, 0.4512]) \n",
      "Test Loss tensor([0.3827, 0.4765, 0.2787, 0.5295, 0.4518])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.46917724609375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3802, 0.4805, 0.2789, 0.5285, 0.4560]) \n",
      "Test Loss tensor([0.3808, 0.4781, 0.2751, 0.5314, 0.4532])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47179126739501953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3780, 0.4793, 0.2741, 0.5313, 0.4571]) \n",
      "Test Loss tensor([0.3821, 0.4799, 0.2722, 0.5326, 0.4536])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.46903014183044434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3787, 0.4779, 0.2732, 0.5276, 0.4518]) \n",
      "Test Loss tensor([0.3814, 0.4784, 0.2691, 0.5331, 0.4524])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.472520112991333 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3869, 0.4759, 0.2690, 0.5296, 0.4544]) \n",
      "Test Loss tensor([0.3807, 0.4794, 0.2663, 0.5342, 0.4540])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.46935176849365234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3850, 0.4789, 0.2658, 0.5363, 0.4522]) \n",
      "Test Loss tensor([0.3822, 0.4817, 0.2630, 0.5357, 0.4553])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47353577613830566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3787, 0.4830, 0.2644, 0.5338, 0.4542]) \n",
      "Test Loss tensor([0.3796, 0.4806, 0.2603, 0.5385, 0.4553])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4699983596801758 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3815, 0.4824, 0.2584, 0.5384, 0.4528]) \n",
      "Test Loss tensor([0.3807, 0.4818, 0.2573, 0.5397, 0.4544])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4702756404876709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3830, 0.4773, 0.2569, 0.5356, 0.4533]) \n",
      "Test Loss tensor([0.3796, 0.4837, 0.2546, 0.5406, 0.4576])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4675331115722656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3790, 0.4741, 0.2539, 0.5335, 0.4522]) \n",
      "Test Loss tensor([0.3812, 0.4824, 0.2509, 0.5412, 0.4561])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47003626823425293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3816, 0.4803, 0.2517, 0.5362, 0.4532]) \n",
      "Test Loss tensor([0.3788, 0.4836, 0.2483, 0.5433, 0.4579])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4696352481842041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3743, 0.4883, 0.2462, 0.5449, 0.4605]) \n",
      "Test Loss tensor([0.3803, 0.4830, 0.2456, 0.5451, 0.4572])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4718472957611084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3793, 0.4843, 0.2442, 0.5438, 0.4572]) \n",
      "Test Loss tensor([0.3817, 0.4832, 0.2427, 0.5447, 0.4573])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4708073139190674 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3770, 0.4864, 0.2433, 0.5462, 0.4605]) \n",
      "Test Loss tensor([0.3785, 0.4858, 0.2403, 0.5483, 0.4598])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.46901941299438477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3780, 0.4830, 0.2411, 0.5488, 0.4563]) \n",
      "Test Loss tensor([0.3804, 0.4826, 0.2387, 0.5452, 0.4561])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4722764492034912 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3803, 0.4849, 0.2378, 0.5414, 0.4587]) \n",
      "Test Loss tensor([0.3790, 0.4879, 0.2373, 0.5494, 0.4609])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4671003818511963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3748, 0.4861, 0.2361, 0.5496, 0.4603]) \n",
      "Test Loss tensor([0.3771, 0.4866, 0.2357, 0.5496, 0.4604])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.47264790534973145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3854, 0.4818, 0.2365, 0.5476, 0.4567]) \n",
      "Test Loss tensor([0.3781, 0.4847, 0.2342, 0.5476, 0.4583])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4677252769470215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3824, 0.4846, 0.2335, 0.5471, 0.4656]) \n",
      "Test Loss tensor([0.3810, 0.4857, 0.2327, 0.5504, 0.4612])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47153306007385254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3828, 0.4879, 0.2319, 0.5468, 0.4582]) \n",
      "Test Loss tensor([0.3808, 0.4858, 0.2310, 0.5497, 0.4604])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4686875343322754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3827, 0.4866, 0.2327, 0.5495, 0.4601]) \n",
      "Test Loss tensor([0.3799, 0.4844, 0.2310, 0.5468, 0.4593])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47282910346984863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3792, 0.4779, 0.2325, 0.5496, 0.4555]) \n",
      "Test Loss tensor([0.3800, 0.4873, 0.2305, 0.5505, 0.4618])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4701049327850342 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3748, 0.4822, 0.2301, 0.5379, 0.4600]) \n",
      "Test Loss tensor([0.3802, 0.4841, 0.2295, 0.5476, 0.4596])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4749336242675781 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3784, 0.4851, 0.2290, 0.5458, 0.4537]) \n",
      "Test Loss tensor([0.3775, 0.4860, 0.2285, 0.5503, 0.4615])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47493934631347656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3836, 0.4806, 0.2275, 0.5424, 0.4554]) \n",
      "Test Loss tensor([0.3819, 0.4842, 0.2274, 0.5492, 0.4607])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4715430736541748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3824, 0.4840, 0.2275, 0.5480, 0.4600]) \n",
      "Test Loss tensor([0.3807, 0.4850, 0.2264, 0.5478, 0.4617])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.46970057487487793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3761, 0.4859, 0.2265, 0.5504, 0.4612]) \n",
      "Test Loss tensor([0.3797, 0.4844, 0.2257, 0.5480, 0.4605])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47022104263305664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3838, 0.4839, 0.2255, 0.5453, 0.4586]) \n",
      "Test Loss tensor([0.3800, 0.4836, 0.2249, 0.5460, 0.4626])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4714488983154297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3781, 0.4872, 0.2252, 0.5511, 0.4628]) \n",
      "Test Loss tensor([0.3792, 0.4847, 0.2239, 0.5467, 0.4615])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4727461338043213 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3775, 0.4890, 0.2240, 0.5502, 0.4615]) \n",
      "Test Loss tensor([0.3800, 0.4857, 0.2232, 0.5492, 0.4641])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.47174501419067383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3841, 0.4871, 0.2230, 0.5481, 0.4621]) \n",
      "Test Loss tensor([0.3792, 0.4853, 0.2224, 0.5480, 0.4628])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47304701805114746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3852, 0.4854, 0.2226, 0.5419, 0.4607]) \n",
      "Test Loss tensor([0.3795, 0.4841, 0.2217, 0.5460, 0.4618])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.47158026695251465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3781, 0.4905, 0.2212, 0.5458, 0.4719]) \n",
      "Test Loss tensor([0.3793, 0.4839, 0.2218, 0.5460, 0.4627])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4697895050048828 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3822, 0.4770, 0.2209, 0.5412, 0.4559]) \n",
      "Test Loss tensor([0.3799, 0.4838, 0.2207, 0.5457, 0.4621])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4724886417388916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3793, 0.4776, 0.2208, 0.5454, 0.4616]) \n",
      "Test Loss tensor([0.3808, 0.4836, 0.2193, 0.5449, 0.4632])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47016477584838867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3825, 0.4837, 0.2195, 0.5422, 0.4558]) \n",
      "Test Loss tensor([0.3796, 0.4836, 0.2182, 0.5437, 0.4639])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47333216667175293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3757, 0.4810, 0.2174, 0.5395, 0.4671]) \n",
      "Test Loss tensor([0.3797, 0.4836, 0.2170, 0.5439, 0.4642])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.47417688369750977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3788, 0.4804, 0.2185, 0.5402, 0.4637]) \n",
      "Test Loss tensor([0.3798, 0.4814, 0.2150, 0.5439, 0.4628])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 656 in 0.4810779094696045 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3789, 0.4850, 0.2153, 0.5421, 0.4656]) \n",
      "Test Loss tensor([0.3809, 0.4836, 0.2127, 0.5433, 0.4644])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5279805660247803 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3874, 0.4802, 0.2133, 0.5430, 0.4606]) \n",
      "Test Loss tensor([0.3785, 0.4827, 0.2111, 0.5438, 0.4643])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4850618839263916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3856, 0.4826, 0.2107, 0.5369, 0.4636]) \n",
      "Test Loss tensor([0.3799, 0.4833, 0.2089, 0.5423, 0.4657])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4666156768798828 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3742, 0.4852, 0.2106, 0.5425, 0.4717]) \n",
      "Test Loss tensor([0.3806, 0.4834, 0.2072, 0.5434, 0.4661])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4695706367492676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3836, 0.4884, 0.2077, 0.5446, 0.4719]) \n",
      "Test Loss tensor([0.3781, 0.4834, 0.2054, 0.5423, 0.4673])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.46613168716430664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3811, 0.4773, 0.2062, 0.5373, 0.4622]) \n",
      "Test Loss tensor([0.3816, 0.4791, 0.2035, 0.5401, 0.4628])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.46425771713256836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3800, 0.4800, 0.2032, 0.5422, 0.4641]) \n",
      "Test Loss tensor([0.3807, 0.4807, 0.2014, 0.5392, 0.4656])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.46422553062438965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3870, 0.4810, 0.2021, 0.5317, 0.4597]) \n",
      "Test Loss tensor([0.3796, 0.4793, 0.1985, 0.5394, 0.4664])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4665818214416504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3837, 0.4800, 0.1982, 0.5377, 0.4617]) \n",
      "Test Loss tensor([0.3793, 0.4805, 0.1960, 0.5416, 0.4688])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4781222343444824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3804, 0.4808, 0.1958, 0.5369, 0.4649]) \n",
      "Test Loss tensor([0.3794, 0.4830, 0.1928, 0.5411, 0.4704])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.46535325050354004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3834, 0.4789, 0.1938, 0.5397, 0.4619]) \n",
      "Test Loss tensor([0.3802, 0.4823, 0.1901, 0.5401, 0.4711])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.46808552742004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3827, 0.4786, 0.1904, 0.5381, 0.4664]) \n",
      "Test Loss tensor([0.3819, 0.4797, 0.1864, 0.5396, 0.4692])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4682741165161133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3770, 0.4794, 0.1874, 0.5388, 0.4690]) \n",
      "Test Loss tensor([0.3786, 0.4818, 0.1837, 0.5407, 0.4732])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4677271842956543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3886, 0.4807, 0.1833, 0.5382, 0.4686]) \n",
      "Test Loss tensor([0.3810, 0.4800, 0.1795, 0.5392, 0.4727])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4734945297241211 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3816, 0.4807, 0.1784, 0.5425, 0.4759]) \n",
      "Test Loss tensor([0.3791, 0.4818, 0.1764, 0.5383, 0.4775])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.46671557426452637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3797, 0.4813, 0.1762, 0.5404, 0.4786]) \n",
      "Test Loss tensor([0.3802, 0.4791, 0.1727, 0.5361, 0.4750])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.46251749992370605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3827, 0.4813, 0.1728, 0.5321, 0.4744]) \n",
      "Test Loss tensor([0.3794, 0.4795, 0.1688, 0.5366, 0.4777])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4646618366241455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3845, 0.4780, 0.1681, 0.5349, 0.4755]) \n",
      "Test Loss tensor([0.3788, 0.4779, 0.1628, 0.5334, 0.4775])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4685072898864746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3759, 0.4796, 0.1650, 0.5390, 0.4805]) \n",
      "Test Loss tensor([0.3791, 0.4776, 0.1581, 0.5341, 0.4772])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47028422355651855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3746, 0.4808, 0.1587, 0.5397, 0.4863]) \n",
      "Test Loss tensor([0.3787, 0.4772, 0.1544, 0.5331, 0.4821])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.46706271171569824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3813, 0.4702, 0.1544, 0.5259, 0.4704]) \n",
      "Test Loss tensor([0.3795, 0.4762, 0.1487, 0.5300, 0.4808])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.46820807456970215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3735, 0.4795, 0.1491, 0.5338, 0.4825]) \n",
      "Test Loss tensor([0.3768, 0.4751, 0.1430, 0.5297, 0.4849])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4701502323150635 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3739, 0.4739, 0.1424, 0.5288, 0.4762]) \n",
      "Test Loss tensor([0.3775, 0.4744, 0.1368, 0.5298, 0.4881])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4686250686645508 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3764, 0.4769, 0.1362, 0.5330, 0.4903]) \n",
      "Test Loss tensor([0.3772, 0.4730, 0.1310, 0.5267, 0.4899])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47257280349731445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3728, 0.4737, 0.1314, 0.5243, 0.4911]) \n",
      "Test Loss tensor([0.3763, 0.4725, 0.1250, 0.5244, 0.4913])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.46816253662109375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3768, 0.4693, 0.1254, 0.5226, 0.4834]) \n",
      "Test Loss tensor([0.3742, 0.4693, 0.1179, 0.5214, 0.4905])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4673886299133301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3729, 0.4728, 0.1188, 0.5255, 0.4938]) \n",
      "Test Loss tensor([0.3747, 0.4696, 0.1110, 0.5203, 0.4985])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.46421122550964355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3774, 0.4645, 0.1115, 0.5169, 0.4964]) \n",
      "Test Loss tensor([0.3740, 0.4669, 0.1034, 0.5183, 0.5010])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4801814556121826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3757, 0.4643, 0.1032, 0.5176, 0.4965]) \n",
      "Test Loss tensor([0.3736, 0.4639, 0.0964, 0.5148, 0.5034])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4668428897857666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3732, 0.4649, 0.0950, 0.5169, 0.5061]) \n",
      "Test Loss tensor([0.3721, 0.4633, 0.0891, 0.5118, 0.5083])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4693901538848877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3790, 0.4615, 0.0888, 0.5091, 0.4991]) \n",
      "Test Loss tensor([0.3712, 0.4606, 0.0815, 0.5090, 0.5115])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4678232669830322 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3688, 0.4593, 0.0822, 0.5111, 0.5128]) \n",
      "Test Loss tensor([0.3672, 0.4587, 0.0746, 0.5053, 0.5165])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47127580642700195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3703, 0.4589, 0.0762, 0.5058, 0.5160]) \n",
      "Test Loss tensor([0.3678, 0.4544, 0.0677, 0.5004, 0.5194])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.46445178985595703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3598, 0.4558, 0.0675, 0.4982, 0.5337]) \n",
      "Test Loss tensor([0.3675, 0.4522, 0.0606, 0.4972, 0.5254])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4677011966705322 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3711, 0.4506, 0.0609, 0.4948, 0.5167]) \n",
      "Test Loss tensor([0.3666, 0.4492, 0.0548, 0.4929, 0.5272])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.46902942657470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3695, 0.4448, 0.0559, 0.4864, 0.5214]) \n",
      "Test Loss tensor([0.3606, 0.4463, 0.0485, 0.4883, 0.5325])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4696028232574463 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3710, 0.4435, 0.0480, 0.4855, 0.5284]) \n",
      "Test Loss tensor([0.3567, 0.4444, 0.0433, 0.4852, 0.5382])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4686925411224365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3579, 0.4421, 0.0430, 0.4828, 0.5413]) \n",
      "Test Loss tensor([0.3571, 0.4431, 0.0392, 0.4810, 0.5452])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.46614813804626465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3630, 0.4392, 0.0395, 0.4799, 0.5278]) \n",
      "Test Loss tensor([0.3521, 0.4397, 0.0351, 0.4787, 0.5449])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4932732582092285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3433, 0.4422, 0.0345, 0.4791, 0.5690]) \n",
      "Test Loss tensor([0.3486, 0.4377, 0.0312, 0.4749, 0.5546])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47471094131469727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3539, 0.4362, 0.0321, 0.4769, 0.5466]) \n",
      "Test Loss tensor([0.3458, 0.4337, 0.0287, 0.4739, 0.5526])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 820 in 0.4684174060821533 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3374, 0.4355, 0.0291, 0.4712, 0.5608]) \n",
      "Test Loss tensor([0.3394, 0.4301, 0.0268, 0.4713, 0.5598])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.46796536445617676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3378, 0.4307, 0.0263, 0.4684, 0.5566]) \n",
      "Test Loss tensor([0.3372, 0.4240, 0.0248, 0.4693, 0.5581])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.46780896186828613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3424, 0.4210, 0.0237, 0.4658, 0.5446]) \n",
      "Test Loss tensor([0.3342, 0.4174, 0.0232, 0.4669, 0.5572])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47350192070007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3275, 0.4146, 0.0244, 0.4663, 0.5581]) \n",
      "Test Loss tensor([0.3274, 0.4096, 0.0224, 0.4659, 0.5608])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4715566635131836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3316, 0.4055, 0.0219, 0.4624, 0.5475]) \n",
      "Test Loss tensor([0.3243, 0.3982, 0.0212, 0.4618, 0.5542])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.48172998428344727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3336, 0.3969, 0.0209, 0.4620, 0.5505]) \n",
      "Test Loss tensor([0.3204, 0.3877, 0.0193, 0.4597, 0.5513])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4748966693878174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3203, 0.3836, 0.0173, 0.4562, 0.5464]) \n",
      "Test Loss tensor([0.3166, 0.3774, 0.0182, 0.4566, 0.5531])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47058749198913574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3190, 0.3778, 0.0200, 0.4548, 0.5577]) \n",
      "Test Loss tensor([0.3145, 0.3674, 0.0167, 0.4521, 0.5478])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4694187641143799 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3119, 0.3662, 0.0162, 0.4531, 0.5491]) \n",
      "Test Loss tensor([0.3123, 0.3561, 0.0168, 0.4473, 0.5401])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4691298007965088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3079, 0.3575, 0.0148, 0.4497, 0.5497]) \n",
      "Test Loss tensor([0.3077, 0.3494, 0.0159, 0.4435, 0.5404])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47167420387268066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3100, 0.3506, 0.0154, 0.4425, 0.5343]) \n",
      "Test Loss tensor([0.3052, 0.3437, 0.0158, 0.4386, 0.5330])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4657716751098633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3011, 0.3391, 0.0147, 0.4373, 0.5356]) \n",
      "Test Loss tensor([0.3031, 0.3371, 0.0152, 0.4344, 0.5213])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.46898508071899414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3054, 0.3390, 0.0135, 0.4323, 0.5219]) \n",
      "Test Loss tensor([0.3002, 0.3331, 0.0149, 0.4307, 0.5063])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4651937484741211 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.3000, 0.3350, 0.0140, 0.4301, 0.5126]) \n",
      "Test Loss tensor([0.2972, 0.3287, 0.0160, 0.4265, 0.4949])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45020318031311035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2221, 0.2448, 0.0108, 0.3192, 0.3754]) \n",
      "Test Loss tensor([0.2945, 0.3237, 0.0153, 0.4224, 0.4788])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5043401718139648 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2959, 0.3251, 0.0165, 0.4189, 0.4757]) \n",
      "Test Loss tensor([0.2892, 0.3186, 0.0164, 0.4190, 0.4677])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.46886658668518066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2927, 0.3173, 0.0160, 0.4228, 0.4612]) \n",
      "Test Loss tensor([0.2869, 0.3123, 0.0160, 0.4157, 0.4530])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4658186435699463 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2899, 0.3104, 0.0165, 0.4157, 0.4510]) \n",
      "Test Loss tensor([0.2844, 0.3059, 0.0154, 0.4117, 0.4374])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4695441722869873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2803, 0.3049, 0.0153, 0.4117, 0.4440]) \n",
      "Test Loss tensor([0.2816, 0.3022, 0.0139, 0.4085, 0.4265])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.46665167808532715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2860, 0.2981, 0.0155, 0.4063, 0.4221]) \n",
      "Test Loss tensor([0.2779, 0.2954, 0.0136, 0.4038, 0.4136])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.46868133544921875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2768, 0.2942, 0.0125, 0.4033, 0.4136]) \n",
      "Test Loss tensor([0.2765, 0.2880, 0.0118, 0.3984, 0.4005])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4685044288635254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2834, 0.2897, 0.0118, 0.3980, 0.3925]) \n",
      "Test Loss tensor([0.2720, 0.2807, 0.0103, 0.3936, 0.3879])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4666142463684082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2720, 0.2775, 0.0091, 0.3944, 0.3904]) \n",
      "Test Loss tensor([0.2701, 0.2764, 0.0090, 0.3883, 0.3775])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.46608638763427734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2747, 0.2779, 0.0087, 0.3887, 0.3764]) \n",
      "Test Loss tensor([0.2675, 0.2719, 0.0088, 0.3844, 0.3614])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4679067134857178 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2755, 0.2752, 0.0102, 0.3846, 0.3662]) \n",
      "Test Loss tensor([0.2673, 0.2653, 0.0073, 0.3813, 0.3453])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.46785759925842285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2670, 0.2659, 0.0058, 0.3801, 0.3421]) \n",
      "Test Loss tensor([0.2666, 0.2599, 0.0068, 0.3783, 0.3272])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.46834301948547363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2686, 0.2714, 0.0066, 0.3820, 0.3299]) \n",
      "Test Loss tensor([0.2669, 0.2569, 0.0062, 0.3776, 0.3098])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4690132141113281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2704, 0.2524, 0.0068, 0.3785, 0.3080]) \n",
      "Test Loss tensor([0.2615, 0.2538, 0.0063, 0.3760, 0.2967])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.46593260765075684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2673, 0.2484, 0.0058, 0.3777, 0.2959]) \n",
      "Test Loss tensor([0.2639, 0.2499, 0.0055, 0.3755, 0.2797])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.492307186126709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2695, 0.2498, 0.0055, 0.3735, 0.2802]) \n",
      "Test Loss tensor([0.2624, 0.2465, 0.0055, 0.3716, 0.2700])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4681220054626465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2652, 0.2470, 0.0049, 0.3720, 0.2674]) \n",
      "Test Loss tensor([0.2629, 0.2435, 0.0051, 0.3707, 0.2586])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.47015953063964844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2689, 0.2422, 0.0059, 0.3684, 0.2584]) \n",
      "Test Loss tensor([0.2623, 0.2423, 0.0048, 0.3674, 0.2486])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4759485721588135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2662, 0.2397, 0.0048, 0.3626, 0.2426]) \n",
      "Test Loss tensor([0.2650, 0.2381, 0.0047, 0.3635, 0.2396])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4753408432006836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2725, 0.2382, 0.0050, 0.3644, 0.2361]) \n",
      "Test Loss tensor([0.2634, 0.2366, 0.0043, 0.3624, 0.2315])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4691455364227295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2650, 0.2388, 0.0043, 0.3610, 0.2349]) \n",
      "Test Loss tensor([0.2609, 0.2347, 0.0045, 0.3578, 0.2277])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4720003604888916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2705, 0.2266, 0.0046, 0.3547, 0.2178]) \n",
      "Test Loss tensor([0.2664, 0.2322, 0.0042, 0.3543, 0.2196])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5024833679199219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2506, 0.2375, 0.0042, 0.3558, 0.2239]) \n",
      "Test Loss tensor([0.2685, 0.2299, 0.0042, 0.3475, 0.2155])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4760291576385498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2616, 0.2317, 0.0039, 0.3489, 0.2161]) \n",
      "Test Loss tensor([0.2688, 0.2315, 0.0042, 0.3422, 0.2142])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.46994495391845703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2621, 0.2317, 0.0048, 0.3410, 0.2158]) \n",
      "Test Loss tensor([0.2710, 0.2307, 0.0040, 0.3368, 0.2104])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47008323669433594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2691, 0.2324, 0.0048, 0.3402, 0.2133]) \n",
      "Test Loss tensor([0.2720, 0.2301, 0.0041, 0.3319, 0.2096])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.49090099334716797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2714, 0.2279, 0.0037, 0.3293, 0.2087]) \n",
      "Test Loss tensor([0.2740, 0.2298, 0.0040, 0.3256, 0.2073])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 104 in 0.4689669609069824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2712, 0.2302, 0.0039, 0.3222, 0.2073]) \n",
      "Test Loss tensor([0.2711, 0.2303, 0.0041, 0.3200, 0.2045])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.46750926971435547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2832, 0.2313, 0.0040, 0.3209, 0.2051]) \n",
      "Test Loss tensor([0.2729, 0.2269, 0.0040, 0.3181, 0.2038])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.46875452995300293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2761, 0.2317, 0.0035, 0.3205, 0.2045]) \n",
      "Test Loss tensor([0.2692, 0.2237, 0.0043, 0.3151, 0.2024])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.46921324729919434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2848, 0.2210, 0.0043, 0.3141, 0.1987]) \n",
      "Test Loss tensor([0.2691, 0.2245, 0.0039, 0.3132, 0.1997])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.483445405960083 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2679, 0.2146, 0.0040, 0.3147, 0.1939]) \n",
      "Test Loss tensor([0.2656, 0.2219, 0.0040, 0.3126, 0.2003])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4719417095184326 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2724, 0.2233, 0.0042, 0.3166, 0.1984]) \n",
      "Test Loss tensor([0.2623, 0.2222, 0.0045, 0.3103, 0.1991])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4683260917663574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2638, 0.2217, 0.0039, 0.3083, 0.1955]) \n",
      "Test Loss tensor([0.2611, 0.2188, 0.0043, 0.3092, 0.1971])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4725916385650635 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2589, 0.2200, 0.0042, 0.3075, 0.1958]) \n",
      "Test Loss tensor([0.2614, 0.2205, 0.0041, 0.3048, 0.1962])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.46773505210876465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2612, 0.2136, 0.0039, 0.3047, 0.1912]) \n",
      "Test Loss tensor([0.2610, 0.2177, 0.0043, 0.2996, 0.1954])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4679238796234131 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2653, 0.2166, 0.0041, 0.2995, 0.1916]) \n",
      "Test Loss tensor([0.2593, 0.2159, 0.0041, 0.2967, 0.1921])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4605882167816162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2526, 0.2164, 0.0039, 0.2956, 0.1948]) \n",
      "Test Loss tensor([0.2603, 0.2152, 0.0042, 0.2918, 0.1926])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.46639108657836914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2646, 0.2156, 0.0049, 0.2888, 0.1936]) \n",
      "Test Loss tensor([0.2601, 0.2134, 0.0041, 0.2898, 0.1910])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.463822603225708 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2611, 0.2104, 0.0048, 0.2862, 0.1891]) \n",
      "Test Loss tensor([0.2595, 0.2122, 0.0042, 0.2868, 0.1888])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4664034843444824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2631, 0.2100, 0.0048, 0.2816, 0.1877]) \n",
      "Test Loss tensor([0.2566, 0.2112, 0.0046, 0.2843, 0.1911])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.46430349349975586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2548, 0.2142, 0.0042, 0.2822, 0.1936]) \n",
      "Test Loss tensor([0.2556, 0.2081, 0.0045, 0.2821, 0.1912])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4637565612792969 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2551, 0.2139, 0.0039, 0.2812, 0.1938]) \n",
      "Test Loss tensor([0.2555, 0.2071, 0.0045, 0.2806, 0.1898])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.462573766708374 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2495, 0.2068, 0.0042, 0.2769, 0.1874]) \n",
      "Test Loss tensor([0.2561, 0.2038, 0.0046, 0.2785, 0.1874])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4669525623321533 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2535, 0.2045, 0.0047, 0.2740, 0.1867]) \n",
      "Test Loss tensor([0.2543, 0.2013, 0.0046, 0.2767, 0.1846])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.46573424339294434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2566, 0.2004, 0.0053, 0.2766, 0.1877]) \n",
      "Test Loss tensor([0.2535, 0.2020, 0.0045, 0.2736, 0.1854])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4636232852935791 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2552, 0.1934, 0.0050, 0.2722, 0.1816]) \n",
      "Test Loss tensor([0.2542, 0.1979, 0.0044, 0.2712, 0.1844])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4648926258087158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2537, 0.1964, 0.0047, 0.2692, 0.1826]) \n",
      "Test Loss tensor([0.2563, 0.1942, 0.0043, 0.2672, 0.1814])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.46425318717956543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2520, 0.1923, 0.0040, 0.2684, 0.1828]) \n",
      "Test Loss tensor([0.2553, 0.1946, 0.0042, 0.2669, 0.1816])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4665257930755615 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2549, 0.1924, 0.0044, 0.2628, 0.1806]) \n",
      "Test Loss tensor([0.2531, 0.1928, 0.0043, 0.2632, 0.1806])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.46285367012023926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2581, 0.1957, 0.0043, 0.2622, 0.1830]) \n",
      "Test Loss tensor([0.2498, 0.1902, 0.0041, 0.2611, 0.1805])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4630305767059326 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2500, 0.1933, 0.0040, 0.2600, 0.1757]) \n",
      "Test Loss tensor([0.2521, 0.1873, 0.0041, 0.2588, 0.1791])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4627187252044678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2533, 0.1914, 0.0048, 0.2552, 0.1773]) \n",
      "Test Loss tensor([0.2513, 0.1843, 0.0044, 0.2575, 0.1777])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4682438373565674 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2557, 0.1838, 0.0042, 0.2564, 0.1731]) \n",
      "Test Loss tensor([0.2496, 0.1840, 0.0043, 0.2568, 0.1770])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.465975284576416 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2485, 0.1873, 0.0039, 0.2619, 0.1838]) \n",
      "Test Loss tensor([0.2467, 0.1798, 0.0042, 0.2550, 0.1750])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4683654308319092 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2498, 0.1796, 0.0041, 0.2549, 0.1774]) \n",
      "Test Loss tensor([0.2477, 0.1776, 0.0041, 0.2519, 0.1733])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4681251049041748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2437, 0.1796, 0.0041, 0.2528, 0.1758]) \n",
      "Test Loss tensor([0.2473, 0.1744, 0.0039, 0.2500, 0.1734])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47156596183776855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2467, 0.1741, 0.0037, 0.2501, 0.1727]) \n",
      "Test Loss tensor([0.2464, 0.1721, 0.0038, 0.2471, 0.1724])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.47877025604248047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2578, 0.1694, 0.0033, 0.2437, 0.1716]) \n",
      "Test Loss tensor([0.2472, 0.1711, 0.0038, 0.2431, 0.1702])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4675877094268799 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2384, 0.1707, 0.0032, 0.2401, 0.1733]) \n",
      "Test Loss tensor([0.2424, 0.1680, 0.0038, 0.2398, 0.1717])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4635016918182373 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2494, 0.1634, 0.0035, 0.2314, 0.1706]) \n",
      "Test Loss tensor([0.2432, 0.1630, 0.0038, 0.2361, 0.1674])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.464923620223999 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2388, 0.1614, 0.0042, 0.2324, 0.1708]) \n",
      "Test Loss tensor([0.2411, 0.1626, 0.0038, 0.2320, 0.1666])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.467024564743042 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2421, 0.1595, 0.0039, 0.2336, 0.1694]) \n",
      "Test Loss tensor([0.2427, 0.1584, 0.0037, 0.2314, 0.1651])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4650249481201172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2404, 0.1581, 0.0034, 0.2332, 0.1619]) \n",
      "Test Loss tensor([0.2405, 0.1541, 0.0039, 0.2274, 0.1635])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4648406505584717 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2486, 0.1561, 0.0030, 0.2312, 0.1634]) \n",
      "Test Loss tensor([0.2390, 0.1502, 0.0036, 0.2261, 0.1617])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4636189937591553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2290, 0.1545, 0.0038, 0.2255, 0.1645]) \n",
      "Test Loss tensor([0.2362, 0.1489, 0.0037, 0.2233, 0.1618])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.46573710441589355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2438, 0.1485, 0.0033, 0.2195, 0.1620]) \n",
      "Test Loss tensor([0.2362, 0.1442, 0.0035, 0.2181, 0.1581])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.46387410163879395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2351, 0.1493, 0.0039, 0.2143, 0.1604]) \n",
      "Test Loss tensor([0.2371, 0.1403, 0.0036, 0.2139, 0.1571])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 268 in 0.46722960472106934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2298, 0.1424, 0.0040, 0.2115, 0.1574]) \n",
      "Test Loss tensor([0.2366, 0.1354, 0.0035, 0.2097, 0.1560])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4648880958557129 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2435, 0.1372, 0.0033, 0.2103, 0.1521]) \n",
      "Test Loss tensor([0.2354, 0.1311, 0.0034, 0.2056, 0.1522])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4663047790527344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2367, 0.1298, 0.0033, 0.2058, 0.1494]) \n",
      "Test Loss tensor([0.2322, 0.1286, 0.0034, 0.2030, 0.1526])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4670109748840332 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2410, 0.1283, 0.0033, 0.2026, 0.1524]) \n",
      "Test Loss tensor([0.2344, 0.1219, 0.0033, 0.1977, 0.1484])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.469588041305542 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2258, 0.1226, 0.0033, 0.1926, 0.1448]) \n",
      "Test Loss tensor([0.2336, 0.1177, 0.0035, 0.1923, 0.1482])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.46433329582214355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2345, 0.1190, 0.0032, 0.1900, 0.1481]) \n",
      "Test Loss tensor([0.2333, 0.1138, 0.0033, 0.1887, 0.1464])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.46478962898254395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2235, 0.1165, 0.0033, 0.1836, 0.1447]) \n",
      "Test Loss tensor([0.2296, 0.1090, 0.0033, 0.1856, 0.1423])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.46373653411865234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2308, 0.1126, 0.0037, 0.1805, 0.1469]) \n",
      "Test Loss tensor([0.2309, 0.1028, 0.0033, 0.1788, 0.1397])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4646644592285156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2327, 0.1034, 0.0034, 0.1788, 0.1406]) \n",
      "Test Loss tensor([0.2292, 0.0992, 0.0034, 0.1736, 0.1376])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4630448818206787 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2253, 0.0963, 0.0040, 0.1755, 0.1443]) \n",
      "Test Loss tensor([0.2312, 0.0951, 0.0033, 0.1668, 0.1371])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.465348482131958 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2297, 0.0953, 0.0032, 0.1701, 0.1386]) \n",
      "Test Loss tensor([0.2308, 0.0895, 0.0032, 0.1642, 0.1333])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.46390271186828613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2290, 0.0846, 0.0037, 0.1629, 0.1343]) \n",
      "Test Loss tensor([0.2329, 0.0845, 0.0032, 0.1594, 0.1294])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.46216797828674316 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2303, 0.0849, 0.0034, 0.1616, 0.1330]) \n",
      "Test Loss tensor([0.2280, 0.0805, 0.0031, 0.1526, 0.1278])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.46709179878234863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2284, 0.0789, 0.0027, 0.1511, 0.1280]) \n",
      "Test Loss tensor([0.2288, 0.0751, 0.0032, 0.1495, 0.1235])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4628732204437256 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2299, 0.0768, 0.0029, 0.1471, 0.1244]) \n",
      "Test Loss tensor([0.2245, 0.0707, 0.0031, 0.1465, 0.1219])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.47456932067871094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2260, 0.0711, 0.0033, 0.1398, 0.1202]) \n",
      "Test Loss tensor([0.2277, 0.0649, 0.0032, 0.1401, 0.1192])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.46568775177001953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2324, 0.0635, 0.0031, 0.1438, 0.1133]) \n",
      "Test Loss tensor([0.2289, 0.0622, 0.0032, 0.1330, 0.1158])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4658796787261963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2340, 0.0588, 0.0034, 0.1327, 0.1166]) \n",
      "Test Loss tensor([0.2318, 0.0569, 0.0031, 0.1299, 0.1111])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4654238224029541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2266, 0.0579, 0.0033, 0.1285, 0.1114]) \n",
      "Test Loss tensor([0.2282, 0.0535, 0.0030, 0.1247, 0.1070])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.46546268463134766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2262, 0.0571, 0.0034, 0.1234, 0.1055]) \n",
      "Test Loss tensor([0.2350, 0.0492, 0.0030, 0.1196, 0.1044])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4667661190032959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2280, 0.0516, 0.0034, 0.1174, 0.1041]) \n",
      "Test Loss tensor([0.2320, 0.0480, 0.0029, 0.1160, 0.1017])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.46489453315734863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2333, 0.0473, 0.0033, 0.1129, 0.0996]) \n",
      "Test Loss tensor([0.2322, 0.0437, 0.0030, 0.1125, 0.0953])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4642298221588135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2334, 0.0437, 0.0028, 0.1176, 0.0919]) \n",
      "Test Loss tensor([0.2338, 0.0417, 0.0031, 0.1079, 0.0921])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.465761661529541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2370, 0.0440, 0.0036, 0.1126, 0.0898]) \n",
      "Test Loss tensor([0.2366, 0.0381, 0.0031, 0.1064, 0.0879])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4678499698638916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2408, 0.0403, 0.0029, 0.1085, 0.0857]) \n",
      "Test Loss tensor([0.2372, 0.0357, 0.0030, 0.1032, 0.0824])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.46361255645751953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2318, 0.0410, 0.0030, 0.1011, 0.0877]) \n",
      "Test Loss tensor([0.2397, 0.0348, 0.0031, 0.1016, 0.0778])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.46463441848754883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2377, 0.0364, 0.0035, 0.0963, 0.0761]) \n",
      "Test Loss tensor([0.2439, 0.0335, 0.0030, 0.0975, 0.0761])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4621427059173584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2538, 0.0388, 0.0037, 0.0992, 0.0720]) \n",
      "Test Loss tensor([0.2413, 0.0329, 0.0032, 0.0966, 0.0727])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.46707963943481445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2319, 0.0368, 0.0029, 0.0955, 0.0737]) \n",
      "Test Loss tensor([0.2400, 0.0309, 0.0032, 0.0903, 0.0678])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.46382689476013184 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2466, 0.0282, 0.0033, 0.0956, 0.0689]) \n",
      "Test Loss tensor([0.2454, 0.0302, 0.0030, 0.0907, 0.0645])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4676356315612793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2455, 0.0349, 0.0031, 0.0926, 0.0604]) \n",
      "Test Loss tensor([0.2416, 0.0305, 0.0029, 0.0899, 0.0604])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4649848937988281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2328, 0.0309, 0.0031, 0.0901, 0.0612]) \n",
      "Test Loss tensor([0.2476, 0.0282, 0.0030, 0.0869, 0.0579])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4696347713470459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2580, 0.0264, 0.0025, 0.0868, 0.0620]) \n",
      "Test Loss tensor([0.2457, 0.0291, 0.0029, 0.0874, 0.0564])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4707491397857666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2488, 0.0273, 0.0029, 0.0896, 0.0602]) \n",
      "Test Loss tensor([0.2460, 0.0278, 0.0030, 0.0863, 0.0530])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.46788763999938965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2435, 0.0267, 0.0033, 0.0906, 0.0546]) \n",
      "Test Loss tensor([0.2499, 0.0282, 0.0031, 0.0843, 0.0525])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4639415740966797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2483, 0.0280, 0.0029, 0.0845, 0.0537]) \n",
      "Test Loss tensor([0.2469, 0.0265, 0.0030, 0.0833, 0.0498])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4649078845977783 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2334, 0.0251, 0.0041, 0.0838, 0.0483]) \n",
      "Test Loss tensor([0.2501, 0.0282, 0.0031, 0.0827, 0.0487])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4655036926269531 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2484, 0.0275, 0.0029, 0.0780, 0.0447]) \n",
      "Test Loss tensor([0.2474, 0.0273, 0.0029, 0.0841, 0.0460])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.46576428413391113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2468, 0.0271, 0.0029, 0.0799, 0.0487]) \n",
      "Test Loss tensor([0.2472, 0.0271, 0.0030, 0.0838, 0.0451])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.46625471115112305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2547, 0.0264, 0.0032, 0.0836, 0.0439]) \n",
      "Test Loss tensor([0.2484, 0.0267, 0.0031, 0.0840, 0.0457])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.46622490882873535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2540, 0.0257, 0.0031, 0.0881, 0.0475]) \n",
      "Test Loss tensor([0.2459, 0.0257, 0.0035, 0.0828, 0.0433])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.4655296802520752 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2418, 0.0255, 0.0031, 0.0849, 0.0443]) \n",
      "Test Loss tensor([0.2468, 0.0263, 0.0038, 0.0821, 0.0434])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4679727554321289 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2546, 0.0243, 0.0038, 0.0773, 0.0391]) \n",
      "Test Loss tensor([0.2486, 0.0263, 0.0038, 0.0815, 0.0416])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.47137451171875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2463, 0.0239, 0.0039, 0.0878, 0.0388]) \n",
      "Test Loss tensor([0.2456, 0.0259, 0.0036, 0.0808, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.4649627208709717 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2483, 0.0273, 0.0038, 0.0801, 0.0471]) \n",
      "Test Loss tensor([0.2420, 0.0275, 0.0035, 0.0807, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4760470390319824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2533, 0.0279, 0.0036, 0.0864, 0.0436]) \n",
      "Test Loss tensor([0.2467, 0.0275, 0.0038, 0.0805, 0.0409])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.46673583984375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2319, 0.0256, 0.0041, 0.0847, 0.0431]) \n",
      "Test Loss tensor([0.2459, 0.0255, 0.0041, 0.0804, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.46828627586364746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2450, 0.0251, 0.0045, 0.0816, 0.0392]) \n",
      "Test Loss tensor([0.2436, 0.0244, 0.0041, 0.0798, 0.0405])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4648892879486084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2595, 0.0302, 0.0039, 0.0787, 0.0441]) \n",
      "Test Loss tensor([0.2439, 0.0270, 0.0036, 0.0783, 0.0412])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.46715426445007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2526, 0.0272, 0.0035, 0.0792, 0.0406]) \n",
      "Test Loss tensor([0.2449, 0.0259, 0.0032, 0.0825, 0.0428])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47026968002319336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2426, 0.0293, 0.0030, 0.0847, 0.0401]) \n",
      "Test Loss tensor([0.2452, 0.0264, 0.0031, 0.0808, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.46462345123291016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2509, 0.0322, 0.0037, 0.0804, 0.0417]) \n",
      "Test Loss tensor([0.2429, 0.0266, 0.0031, 0.0794, 0.0405])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.46672487258911133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2403, 0.0260, 0.0034, 0.0823, 0.0430]) \n",
      "Test Loss tensor([0.2418, 0.0256, 0.0034, 0.0813, 0.0398])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.46906590461730957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2439, 0.0318, 0.0035, 0.0790, 0.0422]) \n",
      "Test Loss tensor([0.2437, 0.0254, 0.0038, 0.0786, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4638221263885498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2400, 0.0248, 0.0034, 0.0796, 0.0386]) \n",
      "Test Loss tensor([0.2418, 0.0253, 0.0037, 0.0809, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.47025442123413086 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2305, 0.0302, 0.0034, 0.0753, 0.0431]) \n",
      "Test Loss tensor([0.2448, 0.0250, 0.0032, 0.0793, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.46932220458984375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2414, 0.0228, 0.0031, 0.0745, 0.0371]) \n",
      "Test Loss tensor([0.2408, 0.0256, 0.0028, 0.0781, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47609496116638184 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2384, 0.0283, 0.0029, 0.0696, 0.0412]) \n",
      "Test Loss tensor([0.2387, 0.0262, 0.0027, 0.0792, 0.0412])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4731166362762451 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2325, 0.0233, 0.0030, 0.0896, 0.0410]) \n",
      "Test Loss tensor([0.2391, 0.0277, 0.0028, 0.0786, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4625382423400879 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2425, 0.0244, 0.0026, 0.0709, 0.0374]) \n",
      "Test Loss tensor([0.2390, 0.0254, 0.0028, 0.0750, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4655613899230957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2301, 0.0284, 0.0028, 0.0770, 0.0425]) \n",
      "Test Loss tensor([0.2383, 0.0256, 0.0030, 0.0773, 0.0412])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.46216297149658203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2390, 0.0266, 0.0032, 0.0651, 0.0385]) \n",
      "Test Loss tensor([0.2378, 0.0258, 0.0035, 0.0751, 0.0416])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.46674108505249023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2371, 0.0247, 0.0031, 0.0767, 0.0451]) \n",
      "Test Loss tensor([0.2390, 0.0238, 0.0034, 0.0763, 0.0414])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4625241756439209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2411, 0.0270, 0.0033, 0.0754, 0.0455]) \n",
      "Test Loss tensor([0.2333, 0.0252, 0.0031, 0.0768, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.46613454818725586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2309, 0.0232, 0.0028, 0.0823, 0.0427]) \n",
      "Test Loss tensor([0.2288, 0.0258, 0.0026, 0.0755, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.46932220458984375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2218, 0.0261, 0.0030, 0.0715, 0.0407]) \n",
      "Test Loss tensor([0.2360, 0.0268, 0.0025, 0.0770, 0.0439])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.47123122215270996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2270, 0.0279, 0.0025, 0.0762, 0.0481]) \n",
      "Test Loss tensor([0.2339, 0.0266, 0.0026, 0.0765, 0.0425])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4736306667327881 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2283, 0.0262, 0.0026, 0.0735, 0.0432]) \n",
      "Test Loss tensor([0.2301, 0.0251, 0.0027, 0.0788, 0.0426])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4706916809082031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2373, 0.0267, 0.0028, 0.0758, 0.0470]) \n",
      "Test Loss tensor([0.2293, 0.0257, 0.0029, 0.0764, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.466505765914917 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2284, 0.0261, 0.0035, 0.0784, 0.0396]) \n",
      "Test Loss tensor([0.2294, 0.0260, 0.0035, 0.0747, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4695403575897217 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2396, 0.0241, 0.0035, 0.0742, 0.0404]) \n",
      "Test Loss tensor([0.2288, 0.0252, 0.0036, 0.0747, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.46721792221069336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2240, 0.0243, 0.0037, 0.0815, 0.0424]) \n",
      "Test Loss tensor([0.2270, 0.0246, 0.0033, 0.0756, 0.0428])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4700932502746582 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2334, 0.0213, 0.0034, 0.0768, 0.0408]) \n",
      "Test Loss tensor([0.2242, 0.0252, 0.0030, 0.0748, 0.0431])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.46663475036621094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2344, 0.0230, 0.0033, 0.0666, 0.0395]) \n",
      "Test Loss tensor([0.2248, 0.0249, 0.0028, 0.0771, 0.0445])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4676024913787842 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2162, 0.0224, 0.0030, 0.0752, 0.0416]) \n",
      "Test Loss tensor([0.2259, 0.0243, 0.0027, 0.0763, 0.0429])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.48904871940612793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2291, 0.0255, 0.0029, 0.0758, 0.0462]) \n",
      "Test Loss tensor([0.2265, 0.0254, 0.0027, 0.0751, 0.0440])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4703357219696045 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2221, 0.0225, 0.0026, 0.0658, 0.0450]) \n",
      "Test Loss tensor([0.2257, 0.0252, 0.0028, 0.0754, 0.0417])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.47594690322875977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2224, 0.0208, 0.0033, 0.0745, 0.0445]) \n",
      "Test Loss tensor([0.2272, 0.0253, 0.0029, 0.0755, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.4633815288543701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2372, 0.0241, 0.0036, 0.0786, 0.0465]) \n",
      "Test Loss tensor([0.2233, 0.0245, 0.0029, 0.0736, 0.0425])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4705996513366699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2230, 0.0267, 0.0030, 0.0758, 0.0429]) \n",
      "Test Loss tensor([0.2216, 0.0235, 0.0029, 0.0751, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.46805596351623535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2107, 0.0235, 0.0029, 0.0694, 0.0395]) \n",
      "Test Loss tensor([0.2207, 0.0240, 0.0028, 0.0747, 0.0436])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47192811965942383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2210, 0.0240, 0.0032, 0.0762, 0.0425]) \n",
      "Test Loss tensor([0.2255, 0.0238, 0.0027, 0.0715, 0.0433])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 596 in 0.4716305732727051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2272, 0.0255, 0.0027, 0.0779, 0.0432]) \n",
      "Test Loss tensor([0.2176, 0.0235, 0.0027, 0.0732, 0.0418])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4690864086151123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2166, 0.0207, 0.0025, 0.0709, 0.0422]) \n",
      "Test Loss tensor([0.2206, 0.0229, 0.0027, 0.0732, 0.0428])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4680056571960449 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2086, 0.0241, 0.0026, 0.0734, 0.0441]) \n",
      "Test Loss tensor([0.2187, 0.0233, 0.0027, 0.0739, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4703648090362549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2189, 0.0196, 0.0025, 0.0747, 0.0434]) \n",
      "Test Loss tensor([0.2209, 0.0216, 0.0029, 0.0744, 0.0414])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.46845412254333496 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2329, 0.0213, 0.0024, 0.0788, 0.0475]) \n",
      "Test Loss tensor([0.2203, 0.0223, 0.0029, 0.0746, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4641273021697998 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2208, 0.0182, 0.0032, 0.0748, 0.0423]) \n",
      "Test Loss tensor([0.2202, 0.0230, 0.0029, 0.0720, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4643251895904541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2075, 0.0224, 0.0027, 0.0740, 0.0412]) \n",
      "Test Loss tensor([0.2204, 0.0229, 0.0027, 0.0737, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4660775661468506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2255, 0.0237, 0.0024, 0.0732, 0.0400]) \n",
      "Test Loss tensor([0.2199, 0.0233, 0.0026, 0.0718, 0.0408])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4681396484375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2147, 0.0240, 0.0026, 0.0760, 0.0447]) \n",
      "Test Loss tensor([0.2202, 0.0233, 0.0027, 0.0736, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.47957515716552734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2218, 0.0220, 0.0027, 0.0715, 0.0418]) \n",
      "Test Loss tensor([0.2196, 0.0232, 0.0027, 0.0727, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.48348474502563477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2359, 0.0209, 0.0023, 0.0712, 0.0410]) \n",
      "Test Loss tensor([0.2174, 0.0228, 0.0029, 0.0714, 0.0409])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4668855667114258 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2117, 0.0229, 0.0028, 0.0633, 0.0384]) \n",
      "Test Loss tensor([0.2170, 0.0219, 0.0031, 0.0715, 0.0417])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4736919403076172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2243, 0.0230, 0.0031, 0.0660, 0.0411]) \n",
      "Test Loss tensor([0.2197, 0.0217, 0.0031, 0.0716, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.48810791969299316 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2197, 0.0216, 0.0033, 0.0687, 0.0417]) \n",
      "Test Loss tensor([0.2167, 0.0222, 0.0028, 0.0697, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.46916794776916504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2272, 0.0201, 0.0028, 0.0701, 0.0408]) \n",
      "Test Loss tensor([0.2148, 0.0219, 0.0027, 0.0725, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4666435718536377 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2076, 0.0246, 0.0033, 0.0760, 0.0440]) \n",
      "Test Loss tensor([0.2130, 0.0224, 0.0027, 0.0725, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4702737331390381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2169, 0.0230, 0.0024, 0.0764, 0.0436]) \n",
      "Test Loss tensor([0.2187, 0.0214, 0.0027, 0.0715, 0.0411])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.46718454360961914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2146, 0.0202, 0.0028, 0.0747, 0.0349]) \n",
      "Test Loss tensor([0.2142, 0.0216, 0.0030, 0.0679, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4849221706390381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2171, 0.0203, 0.0029, 0.0752, 0.0452]) \n",
      "Test Loss tensor([0.2145, 0.0211, 0.0031, 0.0718, 0.0412])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47035765647888184 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2244, 0.0210, 0.0029, 0.0763, 0.0412]) \n",
      "Test Loss tensor([0.2143, 0.0210, 0.0029, 0.0714, 0.0417])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4648935794830322 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2269, 0.0230, 0.0027, 0.0662, 0.0378]) \n",
      "Test Loss tensor([0.2159, 0.0219, 0.0028, 0.0706, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4659616947174072 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2145, 0.0228, 0.0027, 0.0672, 0.0354]) \n",
      "Test Loss tensor([0.2155, 0.0207, 0.0028, 0.0717, 0.0409])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4701118469238281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2283, 0.0215, 0.0027, 0.0678, 0.0410]) \n",
      "Test Loss tensor([0.2125, 0.0206, 0.0027, 0.0701, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.47014856338500977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2188, 0.0213, 0.0028, 0.0688, 0.0429]) \n",
      "Test Loss tensor([0.2162, 0.0202, 0.0028, 0.0683, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.46869683265686035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2172, 0.0207, 0.0026, 0.0758, 0.0447]) \n",
      "Test Loss tensor([0.2167, 0.0209, 0.0029, 0.0699, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.46785807609558105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2195, 0.0198, 0.0030, 0.0678, 0.0421]) \n",
      "Test Loss tensor([0.2143, 0.0201, 0.0029, 0.0703, 0.0400])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4696156978607178 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2203, 0.0193, 0.0026, 0.0669, 0.0410]) \n",
      "Test Loss tensor([0.2108, 0.0206, 0.0029, 0.0686, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4693446159362793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2034, 0.0188, 0.0035, 0.0733, 0.0449]) \n",
      "Test Loss tensor([0.2150, 0.0206, 0.0028, 0.0695, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.46720290184020996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2055, 0.0208, 0.0027, 0.0696, 0.0392]) \n",
      "Test Loss tensor([0.2162, 0.0212, 0.0027, 0.0693, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.46908092498779297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2098, 0.0214, 0.0032, 0.0703, 0.0387]) \n",
      "Test Loss tensor([0.2140, 0.0213, 0.0027, 0.0704, 0.0411])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.46676206588745117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2095, 0.0189, 0.0028, 0.0704, 0.0378]) \n",
      "Test Loss tensor([0.2111, 0.0203, 0.0027, 0.0689, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4719269275665283 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2021, 0.0212, 0.0025, 0.0595, 0.0405]) \n",
      "Test Loss tensor([0.2112, 0.0203, 0.0029, 0.0700, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47725605964660645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2240, 0.0199, 0.0023, 0.0723, 0.0356]) \n",
      "Test Loss tensor([0.2100, 0.0196, 0.0031, 0.0692, 0.0395])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.47650742530822754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2138, 0.0186, 0.0028, 0.0708, 0.0401]) \n",
      "Test Loss tensor([0.2108, 0.0207, 0.0032, 0.0692, 0.0383])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.46999382972717285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2075, 0.0231, 0.0033, 0.0684, 0.0367]) \n",
      "Test Loss tensor([0.2086, 0.0193, 0.0031, 0.0678, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47507667541503906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2008, 0.0188, 0.0029, 0.0685, 0.0387]) \n",
      "Test Loss tensor([0.2115, 0.0206, 0.0028, 0.0665, 0.0409])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4835946559906006 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2106, 0.0184, 0.0026, 0.0633, 0.0445]) \n",
      "Test Loss tensor([0.2067, 0.0209, 0.0026, 0.0664, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4724917411804199 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2083, 0.0203, 0.0025, 0.0677, 0.0463]) \n",
      "Test Loss tensor([0.2083, 0.0199, 0.0026, 0.0681, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.47199153900146484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2086, 0.0203, 0.0027, 0.0652, 0.0402]) \n",
      "Test Loss tensor([0.2115, 0.0199, 0.0026, 0.0676, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47269511222839355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2142, 0.0190, 0.0032, 0.0680, 0.0420]) \n",
      "Test Loss tensor([0.2115, 0.0199, 0.0027, 0.0675, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4724125862121582 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2188, 0.0185, 0.0028, 0.0704, 0.0419]) \n",
      "Test Loss tensor([0.2115, 0.0196, 0.0027, 0.0662, 0.0403])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 760 in 0.47231101989746094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2156, 0.0199, 0.0026, 0.0646, 0.0378]) \n",
      "Test Loss tensor([0.2084, 0.0194, 0.0028, 0.0677, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.4717719554901123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2167, 0.0197, 0.0029, 0.0671, 0.0385]) \n",
      "Test Loss tensor([0.2076, 0.0194, 0.0027, 0.0651, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4739844799041748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2149, 0.0196, 0.0027, 0.0689, 0.0431]) \n",
      "Test Loss tensor([0.2086, 0.0183, 0.0026, 0.0671, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4719383716583252 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2026, 0.0189, 0.0035, 0.0665, 0.0416]) \n",
      "Test Loss tensor([0.2096, 0.0204, 0.0026, 0.0663, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47127699851989746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2021, 0.0147, 0.0026, 0.0653, 0.0421]) \n",
      "Test Loss tensor([0.2088, 0.0196, 0.0025, 0.0671, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4703824520111084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2005, 0.0193, 0.0029, 0.0640, 0.0397]) \n",
      "Test Loss tensor([0.2069, 0.0194, 0.0028, 0.0661, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47134852409362793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2017, 0.0193, 0.0027, 0.0686, 0.0391]) \n",
      "Test Loss tensor([0.2081, 0.0195, 0.0029, 0.0666, 0.0397])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4735696315765381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2058, 0.0190, 0.0029, 0.0678, 0.0443]) \n",
      "Test Loss tensor([0.2095, 0.0194, 0.0028, 0.0632, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47366857528686523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2038, 0.0199, 0.0028, 0.0621, 0.0416]) \n",
      "Test Loss tensor([0.2028, 0.0187, 0.0027, 0.0654, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.476428747177124 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2014, 0.0195, 0.0027, 0.0666, 0.0403]) \n",
      "Test Loss tensor([0.2085, 0.0189, 0.0027, 0.0672, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.469149112701416 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2076, 0.0184, 0.0029, 0.0605, 0.0399]) \n",
      "Test Loss tensor([0.2132, 0.0202, 0.0028, 0.0651, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4698362350463867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2147, 0.0184, 0.0024, 0.0647, 0.0371]) \n",
      "Test Loss tensor([0.2067, 0.0191, 0.0028, 0.0631, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47057008743286133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2015, 0.0208, 0.0031, 0.0647, 0.0348]) \n",
      "Test Loss tensor([0.2042, 0.0180, 0.0029, 0.0650, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47087788581848145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2154, 0.0203, 0.0028, 0.0674, 0.0431]) \n",
      "Test Loss tensor([0.2094, 0.0191, 0.0028, 0.0655, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47003650665283203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2020, 0.0160, 0.0025, 0.0604, 0.0357]) \n",
      "Test Loss tensor([0.2063, 0.0186, 0.0027, 0.0647, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47385263442993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1913, 0.0191, 0.0033, 0.0653, 0.0410]) \n",
      "Test Loss tensor([0.2061, 0.0182, 0.0028, 0.0655, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4710121154785156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2071, 0.0187, 0.0027, 0.0647, 0.0448]) \n",
      "Test Loss tensor([0.2074, 0.0186, 0.0028, 0.0634, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47376060485839844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1948, 0.0156, 0.0027, 0.0612, 0.0393]) \n",
      "Test Loss tensor([0.2037, 0.0188, 0.0027, 0.0636, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47356200218200684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1952, 0.0164, 0.0029, 0.0656, 0.0376]) \n",
      "Test Loss tensor([0.2068, 0.0197, 0.0028, 0.0639, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4706888198852539 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1927, 0.0159, 0.0026, 0.0636, 0.0387]) \n",
      "Test Loss tensor([0.2041, 0.0192, 0.0028, 0.0653, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.47133564949035645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1982, 0.0209, 0.0027, 0.0638, 0.0343]) \n",
      "Test Loss tensor([0.2039, 0.0191, 0.0028, 0.0643, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4728689193725586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2002, 0.0223, 0.0028, 0.0709, 0.0372]) \n",
      "Test Loss tensor([0.2000, 0.0183, 0.0027, 0.0623, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47139430046081543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2023, 0.0186, 0.0028, 0.0629, 0.0430]) \n",
      "Test Loss tensor([0.2072, 0.0187, 0.0029, 0.0630, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.47281813621520996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2036, 0.0195, 0.0029, 0.0599, 0.0338]) \n",
      "Test Loss tensor([0.2037, 0.0186, 0.0026, 0.0624, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4729478359222412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2029, 0.0186, 0.0030, 0.0595, 0.0373]) \n",
      "Test Loss tensor([0.2018, 0.0192, 0.0027, 0.0632, 0.0388])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4710206985473633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1949, 0.0193, 0.0027, 0.0615, 0.0368]) \n",
      "Test Loss tensor([0.2071, 0.0189, 0.0027, 0.0638, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47083497047424316 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1958, 0.0188, 0.0023, 0.0611, 0.0394]) \n",
      "Test Loss tensor([0.2001, 0.0188, 0.0027, 0.0640, 0.0383])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4702589511871338 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2023, 0.0172, 0.0030, 0.0591, 0.0359]) \n",
      "Test Loss tensor([0.2042, 0.0188, 0.0027, 0.0627, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4704303741455078 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1996, 0.0175, 0.0026, 0.0596, 0.0361]) \n",
      "Test Loss tensor([0.2006, 0.0192, 0.0026, 0.0613, 0.0386])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45769190788269043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1542, 0.0153, 0.0022, 0.0526, 0.0282]) \n",
      "Test Loss tensor([0.2014, 0.0184, 0.0028, 0.0634, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5106654167175293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2075, 0.0182, 0.0030, 0.0665, 0.0374]) \n",
      "Test Loss tensor([0.2033, 0.0182, 0.0029, 0.0637, 0.0388])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.470566987991333 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1962, 0.0174, 0.0032, 0.0606, 0.0413]) \n",
      "Test Loss tensor([0.2011, 0.0184, 0.0029, 0.0618, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47086262702941895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2042, 0.0184, 0.0029, 0.0622, 0.0388]) \n",
      "Test Loss tensor([0.2030, 0.0180, 0.0028, 0.0637, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4713423252105713 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2043, 0.0192, 0.0027, 0.0686, 0.0411]) \n",
      "Test Loss tensor([0.2021, 0.0183, 0.0027, 0.0640, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47145867347717285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2026, 0.0161, 0.0025, 0.0627, 0.0359]) \n",
      "Test Loss tensor([0.2038, 0.0192, 0.0027, 0.0631, 0.0389])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47163844108581543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2066, 0.0177, 0.0024, 0.0624, 0.0367]) \n",
      "Test Loss tensor([0.2006, 0.0178, 0.0029, 0.0617, 0.0374])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4740641117095947 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1869, 0.0205, 0.0028, 0.0630, 0.0366]) \n",
      "Test Loss tensor([0.1997, 0.0184, 0.0029, 0.0618, 0.0388])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4789285659790039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1998, 0.0201, 0.0033, 0.0658, 0.0391]) \n",
      "Test Loss tensor([0.1964, 0.0184, 0.0027, 0.0621, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4730710983276367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1982, 0.0182, 0.0036, 0.0595, 0.0414]) \n",
      "Test Loss tensor([0.1971, 0.0183, 0.0027, 0.0614, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4706254005432129 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2034, 0.0214, 0.0027, 0.0646, 0.0350]) \n",
      "Test Loss tensor([0.1973, 0.0189, 0.0026, 0.0627, 0.0365])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4719247817993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1987, 0.0189, 0.0028, 0.0603, 0.0381]) \n",
      "Test Loss tensor([0.1976, 0.0179, 0.0027, 0.0636, 0.0368])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 44 in 0.4716215133666992 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1990, 0.0195, 0.0028, 0.0591, 0.0373]) \n",
      "Test Loss tensor([0.1984, 0.0182, 0.0028, 0.0627, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4713785648345947 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2063, 0.0196, 0.0035, 0.0605, 0.0391]) \n",
      "Test Loss tensor([0.1992, 0.0184, 0.0027, 0.0621, 0.0365])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47165703773498535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1979, 0.0172, 0.0029, 0.0615, 0.0327]) \n",
      "Test Loss tensor([0.1995, 0.0184, 0.0027, 0.0621, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.47164034843444824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1851, 0.0180, 0.0029, 0.0609, 0.0381]) \n",
      "Test Loss tensor([0.1967, 0.0180, 0.0028, 0.0617, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4736487865447998 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2088, 0.0189, 0.0028, 0.0594, 0.0400]) \n",
      "Test Loss tensor([0.2003, 0.0182, 0.0027, 0.0623, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4743058681488037 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1955, 0.0178, 0.0031, 0.0627, 0.0358]) \n",
      "Test Loss tensor([0.2013, 0.0184, 0.0027, 0.0598, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4760000705718994 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2024, 0.0167, 0.0026, 0.0602, 0.0441]) \n",
      "Test Loss tensor([0.1996, 0.0180, 0.0027, 0.0610, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5050840377807617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2037, 0.0190, 0.0026, 0.0668, 0.0378]) \n",
      "Test Loss tensor([0.1956, 0.0187, 0.0026, 0.0604, 0.0372])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.47893595695495605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1985, 0.0180, 0.0027, 0.0561, 0.0374]) \n",
      "Test Loss tensor([0.1972, 0.0190, 0.0026, 0.0608, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4869804382324219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1942, 0.0186, 0.0031, 0.0697, 0.0389]) \n",
      "Test Loss tensor([0.1970, 0.0188, 0.0026, 0.0606, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4752192497253418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1940, 0.0178, 0.0027, 0.0607, 0.0344]) \n",
      "Test Loss tensor([0.1972, 0.0175, 0.0026, 0.0599, 0.0365])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4732701778411865 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1956, 0.0195, 0.0026, 0.0591, 0.0396]) \n",
      "Test Loss tensor([0.1994, 0.0177, 0.0029, 0.0593, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4786539077758789 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1951, 0.0215, 0.0027, 0.0583, 0.0418]) \n",
      "Test Loss tensor([0.1970, 0.0181, 0.0029, 0.0605, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4783148765563965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2041, 0.0197, 0.0027, 0.0584, 0.0373]) \n",
      "Test Loss tensor([0.1955, 0.0186, 0.0027, 0.0588, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4854605197906494 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1954, 0.0168, 0.0027, 0.0566, 0.0392]) \n",
      "Test Loss tensor([0.1968, 0.0189, 0.0026, 0.0601, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4695007801055908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1918, 0.0210, 0.0033, 0.0624, 0.0390]) \n",
      "Test Loss tensor([0.1946, 0.0180, 0.0026, 0.0604, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4716300964355469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1866, 0.0171, 0.0027, 0.0636, 0.0358]) \n",
      "Test Loss tensor([0.1941, 0.0176, 0.0026, 0.0588, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4710099697113037 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2014, 0.0167, 0.0026, 0.0609, 0.0414]) \n",
      "Test Loss tensor([0.1981, 0.0182, 0.0030, 0.0598, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4727046489715576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1878, 0.0173, 0.0028, 0.0620, 0.0351]) \n",
      "Test Loss tensor([0.1976, 0.0175, 0.0032, 0.0595, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4708588123321533 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1930, 0.0157, 0.0031, 0.0644, 0.0397]) \n",
      "Test Loss tensor([0.1941, 0.0185, 0.0029, 0.0591, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.46865177154541016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1986, 0.0182, 0.0028, 0.0581, 0.0368]) \n",
      "Test Loss tensor([0.1957, 0.0188, 0.0025, 0.0596, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4721946716308594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1881, 0.0204, 0.0024, 0.0588, 0.0369]) \n",
      "Test Loss tensor([0.1930, 0.0185, 0.0026, 0.0601, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.46965885162353516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1965, 0.0156, 0.0029, 0.0565, 0.0370]) \n",
      "Test Loss tensor([0.1949, 0.0178, 0.0026, 0.0574, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4717984199523926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1869, 0.0183, 0.0023, 0.0618, 0.0366]) \n",
      "Test Loss tensor([0.1950, 0.0178, 0.0029, 0.0583, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47466135025024414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1914, 0.0184, 0.0034, 0.0642, 0.0385]) \n",
      "Test Loss tensor([0.1965, 0.0182, 0.0030, 0.0578, 0.0362])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4726133346557617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1945, 0.0167, 0.0030, 0.0553, 0.0353]) \n",
      "Test Loss tensor([0.1958, 0.0180, 0.0029, 0.0573, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.47066688537597656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2007, 0.0172, 0.0029, 0.0632, 0.0366]) \n",
      "Test Loss tensor([0.1971, 0.0172, 0.0027, 0.0563, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4734628200531006 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1901, 0.0183, 0.0032, 0.0565, 0.0352]) \n",
      "Test Loss tensor([0.1908, 0.0183, 0.0025, 0.0570, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47205352783203125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1967, 0.0167, 0.0025, 0.0554, 0.0387]) \n",
      "Test Loss tensor([0.1954, 0.0181, 0.0025, 0.0579, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4744992256164551 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1959, 0.0180, 0.0027, 0.0564, 0.0353]) \n",
      "Test Loss tensor([0.1933, 0.0185, 0.0025, 0.0564, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.46967053413391113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1920, 0.0172, 0.0028, 0.0523, 0.0372]) \n",
      "Test Loss tensor([0.1918, 0.0176, 0.0029, 0.0575, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.474168062210083 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2029, 0.0199, 0.0031, 0.0592, 0.0343]) \n",
      "Test Loss tensor([0.1948, 0.0171, 0.0031, 0.0579, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47225117683410645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1896, 0.0175, 0.0029, 0.0560, 0.0301]) \n",
      "Test Loss tensor([0.1916, 0.0178, 0.0030, 0.0565, 0.0345])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.4741852283477783 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1773, 0.0204, 0.0031, 0.0579, 0.0319]) \n",
      "Test Loss tensor([0.1923, 0.0177, 0.0028, 0.0556, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.47029805183410645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1913, 0.0157, 0.0026, 0.0486, 0.0366]) \n",
      "Test Loss tensor([0.1931, 0.0183, 0.0026, 0.0564, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4721083641052246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1892, 0.0170, 0.0025, 0.0560, 0.0354]) \n",
      "Test Loss tensor([0.1920, 0.0174, 0.0026, 0.0576, 0.0359])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4734334945678711 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1872, 0.0169, 0.0025, 0.0598, 0.0374]) \n",
      "Test Loss tensor([0.1940, 0.0173, 0.0027, 0.0565, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.47725605964660645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1997, 0.0182, 0.0027, 0.0549, 0.0332]) \n",
      "Test Loss tensor([0.1942, 0.0171, 0.0032, 0.0559, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.482712984085083 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1873, 0.0203, 0.0035, 0.0614, 0.0394]) \n",
      "Test Loss tensor([0.1921, 0.0173, 0.0035, 0.0565, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47395753860473633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1930, 0.0168, 0.0037, 0.0585, 0.0306]) \n",
      "Test Loss tensor([0.1917, 0.0173, 0.0031, 0.0571, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4733462333679199 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1898, 0.0197, 0.0029, 0.0583, 0.0393]) \n",
      "Test Loss tensor([0.1948, 0.0184, 0.0026, 0.0564, 0.0356])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 208 in 0.47530102729797363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.2022, 0.0156, 0.0026, 0.0519, 0.0378]) \n",
      "Test Loss tensor([0.1876, 0.0181, 0.0025, 0.0586, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4727184772491455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1948, 0.0197, 0.0024, 0.0524, 0.0329]) \n",
      "Test Loss tensor([0.1879, 0.0179, 0.0027, 0.0570, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.47714924812316895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1917, 0.0225, 0.0028, 0.0537, 0.0340]) \n",
      "Test Loss tensor([0.1917, 0.0182, 0.0030, 0.0563, 0.0340])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.478745698928833 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1943, 0.0159, 0.0030, 0.0494, 0.0349]) \n",
      "Test Loss tensor([0.1928, 0.0172, 0.0034, 0.0564, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.48052167892456055 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1816, 0.0185, 0.0037, 0.0568, 0.0356]) \n",
      "Test Loss tensor([0.1885, 0.0176, 0.0032, 0.0573, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.48050451278686523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1892, 0.0182, 0.0033, 0.0567, 0.0362]) \n",
      "Test Loss tensor([0.1906, 0.0178, 0.0028, 0.0544, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47412776947021484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1839, 0.0198, 0.0028, 0.0506, 0.0338]) \n",
      "Test Loss tensor([0.1893, 0.0174, 0.0025, 0.0562, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4774448871612549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1922, 0.0198, 0.0027, 0.0566, 0.0306]) \n",
      "Test Loss tensor([0.1906, 0.0169, 0.0025, 0.0562, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4736471176147461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1946, 0.0194, 0.0028, 0.0567, 0.0337]) \n",
      "Test Loss tensor([0.1862, 0.0172, 0.0027, 0.0543, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4808526039123535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1836, 0.0197, 0.0025, 0.0523, 0.0305]) \n",
      "Test Loss tensor([0.1874, 0.0183, 0.0028, 0.0539, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47584962844848633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1892, 0.0175, 0.0027, 0.0546, 0.0339]) \n",
      "Test Loss tensor([0.1911, 0.0179, 0.0028, 0.0532, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.48093175888061523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1819, 0.0178, 0.0027, 0.0539, 0.0387]) \n",
      "Test Loss tensor([0.1833, 0.0173, 0.0029, 0.0537, 0.0337])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47487902641296387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1858, 0.0185, 0.0027, 0.0522, 0.0353]) \n",
      "Test Loss tensor([0.1873, 0.0180, 0.0028, 0.0551, 0.0346])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.47464823722839355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1865, 0.0178, 0.0027, 0.0523, 0.0364]) \n",
      "Test Loss tensor([0.1868, 0.0176, 0.0028, 0.0543, 0.0337])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4775865077972412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1699, 0.0172, 0.0028, 0.0476, 0.0327]) \n",
      "Test Loss tensor([0.1868, 0.0169, 0.0028, 0.0537, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.47734904289245605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1794, 0.0200, 0.0029, 0.0523, 0.0359]) \n",
      "Test Loss tensor([0.1879, 0.0177, 0.0027, 0.0556, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4729726314544678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1788, 0.0161, 0.0025, 0.0560, 0.0368]) \n",
      "Test Loss tensor([0.1868, 0.0176, 0.0027, 0.0532, 0.0338])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.48012351989746094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1909, 0.0154, 0.0027, 0.0517, 0.0349]) \n",
      "Test Loss tensor([0.1861, 0.0170, 0.0028, 0.0531, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.47596311569213867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1838, 0.0183, 0.0024, 0.0517, 0.0351]) \n",
      "Test Loss tensor([0.1832, 0.0184, 0.0028, 0.0548, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4778861999511719 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1884, 0.0167, 0.0031, 0.0527, 0.0325]) \n",
      "Test Loss tensor([0.1830, 0.0166, 0.0028, 0.0524, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4814772605895996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1821, 0.0164, 0.0027, 0.0489, 0.0373]) \n",
      "Test Loss tensor([0.1836, 0.0179, 0.0026, 0.0516, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4751429557800293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1886, 0.0135, 0.0025, 0.0558, 0.0339]) \n",
      "Test Loss tensor([0.1839, 0.0172, 0.0028, 0.0547, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5099074840545654 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1849, 0.0176, 0.0025, 0.0517, 0.0318]) \n",
      "Test Loss tensor([0.1854, 0.0176, 0.0028, 0.0536, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47571873664855957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1895, 0.0160, 0.0028, 0.0516, 0.0384]) \n",
      "Test Loss tensor([0.1863, 0.0166, 0.0030, 0.0553, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.48005104064941406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1927, 0.0128, 0.0033, 0.0470, 0.0306]) \n",
      "Test Loss tensor([0.1843, 0.0171, 0.0030, 0.0527, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.49943017959594727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1866, 0.0168, 0.0027, 0.0578, 0.0371]) \n",
      "Test Loss tensor([0.1866, 0.0172, 0.0028, 0.0536, 0.0324])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4747459888458252 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1853, 0.0151, 0.0025, 0.0534, 0.0319]) \n",
      "Test Loss tensor([0.1852, 0.0178, 0.0026, 0.0521, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.47683000564575195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1785, 0.0160, 0.0024, 0.0498, 0.0352]) \n",
      "Test Loss tensor([0.1826, 0.0179, 0.0026, 0.0523, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4744408130645752 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1850, 0.0186, 0.0028, 0.0557, 0.0360]) \n",
      "Test Loss tensor([0.1844, 0.0172, 0.0027, 0.0520, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.47718119621276855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1953, 0.0201, 0.0029, 0.0477, 0.0302]) \n",
      "Test Loss tensor([0.1891, 0.0177, 0.0031, 0.0530, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.48151302337646484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1907, 0.0206, 0.0031, 0.0494, 0.0318]) \n",
      "Test Loss tensor([0.1829, 0.0171, 0.0032, 0.0543, 0.0329])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.47363805770874023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1863, 0.0169, 0.0033, 0.0583, 0.0342]) \n",
      "Test Loss tensor([0.1819, 0.0171, 0.0029, 0.0538, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47623109817504883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1788, 0.0151, 0.0028, 0.0568, 0.0362]) \n",
      "Test Loss tensor([0.1871, 0.0174, 0.0027, 0.0534, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.47614312171936035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1802, 0.0178, 0.0025, 0.0563, 0.0388]) \n",
      "Test Loss tensor([0.1793, 0.0175, 0.0026, 0.0523, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47738170623779297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1862, 0.0137, 0.0028, 0.0506, 0.0301]) \n",
      "Test Loss tensor([0.1825, 0.0177, 0.0028, 0.0537, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4745621681213379 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1701, 0.0166, 0.0026, 0.0513, 0.0351]) \n",
      "Test Loss tensor([0.1834, 0.0180, 0.0033, 0.0528, 0.0324])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4775421619415283 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1794, 0.0185, 0.0034, 0.0543, 0.0354]) \n",
      "Test Loss tensor([0.1825, 0.0174, 0.0031, 0.0514, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5843946933746338 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1784, 0.0174, 0.0032, 0.0490, 0.0313]) \n",
      "Test Loss tensor([0.1775, 0.0175, 0.0027, 0.0533, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5246307849884033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1754, 0.0154, 0.0031, 0.0564, 0.0291]) \n",
      "Test Loss tensor([0.1832, 0.0175, 0.0025, 0.0529, 0.0326])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4959566593170166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1812, 0.0193, 0.0026, 0.0552, 0.0288]) \n",
      "Test Loss tensor([0.1799, 0.0169, 0.0029, 0.0532, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4995841979980469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1923, 0.0167, 0.0029, 0.0526, 0.0333]) \n",
      "Test Loss tensor([0.1848, 0.0173, 0.0034, 0.0532, 0.0322])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 372 in 0.4929158687591553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1747, 0.0199, 0.0035, 0.0483, 0.0323]) \n",
      "Test Loss tensor([0.1831, 0.0183, 0.0036, 0.0535, 0.0318])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.48917365074157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1741, 0.0186, 0.0040, 0.0590, 0.0333]) \n",
      "Test Loss tensor([0.1822, 0.0175, 0.0029, 0.0514, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4909048080444336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1875, 0.0173, 0.0028, 0.0486, 0.0316]) \n",
      "Test Loss tensor([0.1805, 0.0174, 0.0025, 0.0520, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.48726916313171387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1779, 0.0194, 0.0025, 0.0477, 0.0312]) \n",
      "Test Loss tensor([0.1823, 0.0164, 0.0026, 0.0535, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4908618927001953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1840, 0.0164, 0.0028, 0.0499, 0.0323]) \n",
      "Test Loss tensor([0.1828, 0.0165, 0.0030, 0.0515, 0.0325])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.48840951919555664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1785, 0.0172, 0.0028, 0.0511, 0.0313]) \n",
      "Test Loss tensor([0.1841, 0.0180, 0.0033, 0.0526, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4856743812561035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1720, 0.0145, 0.0029, 0.0533, 0.0307]) \n",
      "Test Loss tensor([0.1786, 0.0174, 0.0032, 0.0519, 0.0324])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4874396324157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1781, 0.0187, 0.0032, 0.0528, 0.0329]) \n",
      "Test Loss tensor([0.1803, 0.0170, 0.0029, 0.0506, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.48061370849609375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1805, 0.0168, 0.0028, 0.0520, 0.0292]) \n",
      "Test Loss tensor([0.1804, 0.0184, 0.0025, 0.0527, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4837324619293213 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1777, 0.0186, 0.0024, 0.0535, 0.0305]) \n",
      "Test Loss tensor([0.1839, 0.0173, 0.0026, 0.0518, 0.0321])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.48682737350463867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1772, 0.0152, 0.0027, 0.0489, 0.0308]) \n",
      "Test Loss tensor([0.1788, 0.0174, 0.0028, 0.0504, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4836161136627197 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1764, 0.0149, 0.0028, 0.0513, 0.0332]) \n",
      "Test Loss tensor([0.1780, 0.0170, 0.0033, 0.0514, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4785280227661133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1774, 0.0160, 0.0035, 0.0470, 0.0269]) \n",
      "Test Loss tensor([0.1788, 0.0170, 0.0030, 0.0507, 0.0313])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.502798318862915 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1796, 0.0181, 0.0030, 0.0530, 0.0333]) \n",
      "Test Loss tensor([0.1771, 0.0174, 0.0029, 0.0502, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4916107654571533 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1758, 0.0192, 0.0031, 0.0514, 0.0328]) \n",
      "Test Loss tensor([0.1783, 0.0166, 0.0026, 0.0498, 0.0313])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4764244556427002 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1871, 0.0144, 0.0028, 0.0489, 0.0320]) \n",
      "Test Loss tensor([0.1776, 0.0175, 0.0027, 0.0514, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.530860185623169 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1829, 0.0154, 0.0025, 0.0512, 0.0320]) \n",
      "Test Loss tensor([0.1812, 0.0175, 0.0028, 0.0511, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5220611095428467 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1690, 0.0187, 0.0027, 0.0484, 0.0302]) \n",
      "Test Loss tensor([0.1795, 0.0172, 0.0031, 0.0507, 0.0312])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.46891260147094727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1650, 0.0173, 0.0034, 0.0454, 0.0316]) \n",
      "Test Loss tensor([0.1774, 0.0173, 0.0029, 0.0498, 0.0307])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.47137999534606934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1868, 0.0191, 0.0028, 0.0484, 0.0365]) \n",
      "Test Loss tensor([0.1751, 0.0180, 0.0026, 0.0513, 0.0318])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.46861767768859863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1724, 0.0204, 0.0027, 0.0521, 0.0317]) \n",
      "Test Loss tensor([0.1747, 0.0177, 0.0026, 0.0518, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.470552921295166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1660, 0.0167, 0.0028, 0.0541, 0.0329]) \n",
      "Test Loss tensor([0.1744, 0.0166, 0.0029, 0.0495, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.48601603507995605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1710, 0.0179, 0.0027, 0.0526, 0.0326]) \n",
      "Test Loss tensor([0.1775, 0.0179, 0.0032, 0.0518, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4725930690765381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1785, 0.0191, 0.0030, 0.0535, 0.0333]) \n",
      "Test Loss tensor([0.1741, 0.0169, 0.0032, 0.0519, 0.0310])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47043418884277344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1817, 0.0181, 0.0031, 0.0511, 0.0318]) \n",
      "Test Loss tensor([0.1783, 0.0177, 0.0029, 0.0513, 0.0313])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4708828926086426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1888, 0.0178, 0.0028, 0.0480, 0.0325]) \n",
      "Test Loss tensor([0.1747, 0.0171, 0.0026, 0.0499, 0.0318])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.46971607208251953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1719, 0.0185, 0.0026, 0.0461, 0.0354]) \n",
      "Test Loss tensor([0.1729, 0.0173, 0.0026, 0.0508, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47072649002075195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1769, 0.0164, 0.0024, 0.0489, 0.0340]) \n",
      "Test Loss tensor([0.1757, 0.0175, 0.0026, 0.0499, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.46831631660461426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1761, 0.0180, 0.0030, 0.0521, 0.0339]) \n",
      "Test Loss tensor([0.1736, 0.0176, 0.0029, 0.0489, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4705016613006592 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1691, 0.0174, 0.0027, 0.0456, 0.0309]) \n",
      "Test Loss tensor([0.1701, 0.0173, 0.0034, 0.0522, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4687180519104004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1779, 0.0187, 0.0036, 0.0547, 0.0322]) \n",
      "Test Loss tensor([0.1705, 0.0174, 0.0035, 0.0501, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.46517205238342285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1696, 0.0186, 0.0036, 0.0506, 0.0249]) \n",
      "Test Loss tensor([0.1704, 0.0185, 0.0028, 0.0491, 0.0310])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.47670722007751465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1554, 0.0175, 0.0027, 0.0443, 0.0285]) \n",
      "Test Loss tensor([0.1720, 0.0171, 0.0026, 0.0517, 0.0329])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.46867871284484863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1676, 0.0183, 0.0027, 0.0550, 0.0315]) \n",
      "Test Loss tensor([0.1684, 0.0177, 0.0027, 0.0505, 0.0317])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.471174955368042 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1651, 0.0185, 0.0027, 0.0503, 0.0352]) \n",
      "Test Loss tensor([0.1692, 0.0175, 0.0030, 0.0508, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4683084487915039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1735, 0.0181, 0.0029, 0.0529, 0.0343]) \n",
      "Test Loss tensor([0.1700, 0.0174, 0.0034, 0.0507, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4682786464691162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1672, 0.0164, 0.0040, 0.0490, 0.0329]) \n",
      "Test Loss tensor([0.1649, 0.0173, 0.0031, 0.0498, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4705018997192383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1690, 0.0160, 0.0030, 0.0496, 0.0355]) \n",
      "Test Loss tensor([0.1657, 0.0169, 0.0027, 0.0485, 0.0309])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4752509593963623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1541, 0.0171, 0.0027, 0.0485, 0.0294]) \n",
      "Test Loss tensor([0.1656, 0.0177, 0.0025, 0.0503, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4824228286743164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1639, 0.0193, 0.0027, 0.0460, 0.0290]) \n",
      "Test Loss tensor([0.1634, 0.0168, 0.0027, 0.0486, 0.0302])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4758737087249756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1720, 0.0164, 0.0027, 0.0524, 0.0292]) \n",
      "Test Loss tensor([0.1622, 0.0176, 0.0030, 0.0512, 0.0305])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 536 in 0.47560954093933105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1596, 0.0177, 0.0031, 0.0515, 0.0276]) \n",
      "Test Loss tensor([0.1626, 0.0176, 0.0031, 0.0504, 0.0310])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.47178125381469727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1615, 0.0151, 0.0032, 0.0511, 0.0327]) \n",
      "Test Loss tensor([0.1575, 0.0181, 0.0027, 0.0498, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4720933437347412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1522, 0.0173, 0.0028, 0.0563, 0.0394]) \n",
      "Test Loss tensor([0.1553, 0.0184, 0.0025, 0.0500, 0.0312])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4691615104675293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1559, 0.0187, 0.0023, 0.0514, 0.0306]) \n",
      "Test Loss tensor([0.1566, 0.0181, 0.0026, 0.0494, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.47081828117370605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1438, 0.0171, 0.0023, 0.0538, 0.0337]) \n",
      "Test Loss tensor([0.1509, 0.0182, 0.0029, 0.0521, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4712052345275879 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1499, 0.0172, 0.0027, 0.0457, 0.0300]) \n",
      "Test Loss tensor([0.1481, 0.0175, 0.0032, 0.0515, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4718961715698242 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1491, 0.0198, 0.0033, 0.0530, 0.0348]) \n",
      "Test Loss tensor([0.1487, 0.0186, 0.0027, 0.0516, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.47028350830078125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1483, 0.0184, 0.0035, 0.0507, 0.0259]) \n",
      "Test Loss tensor([0.1444, 0.0187, 0.0026, 0.0501, 0.0307])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4726879596710205 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1462, 0.0170, 0.0028, 0.0535, 0.0336]) \n",
      "Test Loss tensor([0.1423, 0.0193, 0.0026, 0.0521, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.46794724464416504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1408, 0.0176, 0.0024, 0.0549, 0.0295]) \n",
      "Test Loss tensor([0.1400, 0.0184, 0.0028, 0.0510, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4722895622253418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1400, 0.0171, 0.0025, 0.0470, 0.0329]) \n",
      "Test Loss tensor([0.1371, 0.0188, 0.0034, 0.0529, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.46942996978759766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1281, 0.0158, 0.0033, 0.0513, 0.0260]) \n",
      "Test Loss tensor([0.1340, 0.0177, 0.0032, 0.0531, 0.0309])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.47272682189941406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1292, 0.0184, 0.0030, 0.0521, 0.0288]) \n",
      "Test Loss tensor([0.1328, 0.0190, 0.0028, 0.0522, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4677700996398926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1221, 0.0176, 0.0028, 0.0530, 0.0305]) \n",
      "Test Loss tensor([0.1305, 0.0192, 0.0027, 0.0522, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47144222259521484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1345, 0.0180, 0.0027, 0.0530, 0.0278]) \n",
      "Test Loss tensor([0.1276, 0.0190, 0.0030, 0.0528, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.47006869316101074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1198, 0.0180, 0.0029, 0.0489, 0.0279]) \n",
      "Test Loss tensor([0.1252, 0.0198, 0.0036, 0.0536, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47223782539367676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1135, 0.0179, 0.0039, 0.0505, 0.0317]) \n",
      "Test Loss tensor([0.1225, 0.0195, 0.0036, 0.0538, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4727954864501953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1192, 0.0207, 0.0034, 0.0527, 0.0305]) \n",
      "Test Loss tensor([0.1205, 0.0185, 0.0031, 0.0525, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47293853759765625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1229, 0.0209, 0.0031, 0.0530, 0.0339]) \n",
      "Test Loss tensor([0.1197, 0.0184, 0.0028, 0.0547, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4701347351074219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1261, 0.0193, 0.0028, 0.0540, 0.0293]) \n",
      "Test Loss tensor([0.1166, 0.0190, 0.0030, 0.0525, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4694643020629883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1266, 0.0197, 0.0028, 0.0564, 0.0298]) \n",
      "Test Loss tensor([0.1159, 0.0197, 0.0035, 0.0527, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.47043895721435547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1145, 0.0194, 0.0033, 0.0546, 0.0350]) \n",
      "Test Loss tensor([0.1128, 0.0191, 0.0041, 0.0580, 0.0293])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.47028613090515137 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1099, 0.0196, 0.0041, 0.0525, 0.0297]) \n",
      "Test Loss tensor([0.1118, 0.0190, 0.0033, 0.0534, 0.0312])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4692714214324951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1083, 0.0167, 0.0036, 0.0537, 0.0325]) \n",
      "Test Loss tensor([0.1130, 0.0192, 0.0029, 0.0545, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4676780700683594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1079, 0.0187, 0.0037, 0.0573, 0.0343]) \n",
      "Test Loss tensor([0.1132, 0.0192, 0.0030, 0.0536, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4709298610687256 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1105, 0.0215, 0.0029, 0.0504, 0.0313]) \n",
      "Test Loss tensor([0.1087, 0.0195, 0.0037, 0.0538, 0.0297])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.46781349182128906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1171, 0.0202, 0.0040, 0.0585, 0.0364]) \n",
      "Test Loss tensor([0.1066, 0.0197, 0.0041, 0.0543, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4718780517578125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0965, 0.0191, 0.0038, 0.0548, 0.0349]) \n",
      "Test Loss tensor([0.1052, 0.0190, 0.0032, 0.0514, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4685986042022705 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1102, 0.0209, 0.0034, 0.0551, 0.0300]) \n",
      "Test Loss tensor([0.1067, 0.0191, 0.0030, 0.0525, 0.0312])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4710042476654053 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1015, 0.0204, 0.0031, 0.0515, 0.0324]) \n",
      "Test Loss tensor([0.1048, 0.0191, 0.0033, 0.0522, 0.0313])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.47107648849487305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1051, 0.0192, 0.0034, 0.0560, 0.0326]) \n",
      "Test Loss tensor([0.1042, 0.0192, 0.0038, 0.0522, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47070956230163574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1032, 0.0208, 0.0036, 0.0515, 0.0317]) \n",
      "Test Loss tensor([0.1046, 0.0199, 0.0042, 0.0526, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.46963930130004883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1003, 0.0204, 0.0042, 0.0544, 0.0304]) \n",
      "Test Loss tensor([0.1021, 0.0186, 0.0034, 0.0528, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47063422203063965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1036, 0.0186, 0.0030, 0.0468, 0.0308]) \n",
      "Test Loss tensor([0.1039, 0.0177, 0.0035, 0.0520, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.46958088874816895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1038, 0.0191, 0.0031, 0.0550, 0.0307]) \n",
      "Test Loss tensor([0.1014, 0.0179, 0.0035, 0.0522, 0.0302])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4723179340362549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0985, 0.0196, 0.0030, 0.0486, 0.0276]) \n",
      "Test Loss tensor([0.1009, 0.0182, 0.0036, 0.0522, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4702458381652832 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1018, 0.0184, 0.0036, 0.0507, 0.0258]) \n",
      "Test Loss tensor([0.1001, 0.0176, 0.0037, 0.0521, 0.0291])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.46924734115600586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0971, 0.0175, 0.0037, 0.0547, 0.0316]) \n",
      "Test Loss tensor([0.0986, 0.0181, 0.0033, 0.0520, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.46860551834106445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0966, 0.0185, 0.0031, 0.0496, 0.0329]) \n",
      "Test Loss tensor([0.1006, 0.0177, 0.0031, 0.0513, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4711341857910156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1020, 0.0189, 0.0032, 0.0514, 0.0301]) \n",
      "Test Loss tensor([0.0986, 0.0180, 0.0032, 0.0494, 0.0285])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4860241413116455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0968, 0.0196, 0.0033, 0.0586, 0.0270]) \n",
      "Test Loss tensor([0.0990, 0.0192, 0.0036, 0.0522, 0.0296])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 700 in 0.47097206115722656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0946, 0.0169, 0.0035, 0.0491, 0.0279]) \n",
      "Test Loss tensor([0.0996, 0.0180, 0.0037, 0.0496, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47150230407714844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0961, 0.0186, 0.0045, 0.0484, 0.0322]) \n",
      "Test Loss tensor([0.0985, 0.0182, 0.0033, 0.0488, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.47046422958374023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.1029, 0.0217, 0.0031, 0.0517, 0.0276]) \n",
      "Test Loss tensor([0.0974, 0.0183, 0.0030, 0.0487, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4753601551055908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0901, 0.0178, 0.0028, 0.0473, 0.0289]) \n",
      "Test Loss tensor([0.0970, 0.0176, 0.0034, 0.0505, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.46839070320129395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0990, 0.0193, 0.0037, 0.0486, 0.0291]) \n",
      "Test Loss tensor([0.0974, 0.0176, 0.0034, 0.0490, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.471024751663208 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0963, 0.0187, 0.0032, 0.0503, 0.0341]) \n",
      "Test Loss tensor([0.0926, 0.0162, 0.0036, 0.0495, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4698066711425781 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0968, 0.0184, 0.0036, 0.0442, 0.0251]) \n",
      "Test Loss tensor([0.0944, 0.0176, 0.0034, 0.0489, 0.0291])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.47104454040527344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0932, 0.0189, 0.0031, 0.0484, 0.0346]) \n",
      "Test Loss tensor([0.0949, 0.0172, 0.0032, 0.0491, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47122764587402344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0923, 0.0172, 0.0038, 0.0495, 0.0278]) \n",
      "Test Loss tensor([0.0935, 0.0157, 0.0032, 0.0489, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47049427032470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0882, 0.0167, 0.0033, 0.0465, 0.0331]) \n",
      "Test Loss tensor([0.0929, 0.0174, 0.0031, 0.0489, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.46947288513183594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0877, 0.0170, 0.0029, 0.0532, 0.0312]) \n",
      "Test Loss tensor([0.0946, 0.0176, 0.0037, 0.0481, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.47252392768859863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0909, 0.0172, 0.0046, 0.0437, 0.0238]) \n",
      "Test Loss tensor([0.0912, 0.0179, 0.0036, 0.0496, 0.0290])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4692997932434082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0855, 0.0167, 0.0037, 0.0501, 0.0267]) \n",
      "Test Loss tensor([0.0947, 0.0183, 0.0028, 0.0471, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4758315086364746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0984, 0.0162, 0.0026, 0.0455, 0.0298]) \n",
      "Test Loss tensor([0.0953, 0.0183, 0.0028, 0.0472, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.47400856018066406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0910, 0.0172, 0.0027, 0.0492, 0.0277]) \n",
      "Test Loss tensor([0.0914, 0.0172, 0.0030, 0.0466, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47225308418273926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0859, 0.0151, 0.0032, 0.0469, 0.0256]) \n",
      "Test Loss tensor([0.0918, 0.0181, 0.0037, 0.0504, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47100090980529785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0840, 0.0169, 0.0033, 0.0464, 0.0258]) \n",
      "Test Loss tensor([0.0931, 0.0182, 0.0036, 0.0477, 0.0285])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.470508337020874 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0897, 0.0170, 0.0035, 0.0431, 0.0247]) \n",
      "Test Loss tensor([0.0899, 0.0174, 0.0029, 0.0477, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.47138333320617676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0891, 0.0183, 0.0030, 0.0467, 0.0310]) \n",
      "Test Loss tensor([0.0910, 0.0169, 0.0028, 0.0483, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4689040184020996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0867, 0.0164, 0.0025, 0.0496, 0.0289]) \n",
      "Test Loss tensor([0.0891, 0.0165, 0.0031, 0.0469, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4748573303222656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0919, 0.0174, 0.0027, 0.0478, 0.0283]) \n",
      "Test Loss tensor([0.0888, 0.0176, 0.0034, 0.0469, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.470020055770874 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0871, 0.0207, 0.0040, 0.0473, 0.0298]) \n",
      "Test Loss tensor([0.0907, 0.0178, 0.0038, 0.0482, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4705810546875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0867, 0.0178, 0.0031, 0.0452, 0.0226]) \n",
      "Test Loss tensor([0.0897, 0.0175, 0.0033, 0.0476, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4694032669067383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0962, 0.0215, 0.0033, 0.0519, 0.0316]) \n",
      "Test Loss tensor([0.0898, 0.0171, 0.0030, 0.0479, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4720947742462158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0906, 0.0182, 0.0029, 0.0517, 0.0295]) \n",
      "Test Loss tensor([0.0887, 0.0169, 0.0031, 0.0462, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4718813896179199 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0913, 0.0168, 0.0032, 0.0468, 0.0278]) \n",
      "Test Loss tensor([0.0890, 0.0175, 0.0032, 0.0465, 0.0282])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.46988606452941895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0855, 0.0148, 0.0033, 0.0434, 0.0290]) \n",
      "Test Loss tensor([0.0893, 0.0171, 0.0035, 0.0474, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4698786735534668 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0885, 0.0174, 0.0036, 0.0434, 0.0243]) \n",
      "Test Loss tensor([0.0878, 0.0175, 0.0033, 0.0460, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47394490242004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0879, 0.0162, 0.0030, 0.0471, 0.0307]) \n",
      "Test Loss tensor([0.0883, 0.0172, 0.0031, 0.0474, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4713587760925293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0973, 0.0169, 0.0034, 0.0428, 0.0289]) \n",
      "Test Loss tensor([0.0864, 0.0161, 0.0033, 0.0459, 0.0277])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.470811128616333 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0861, 0.0160, 0.0033, 0.0455, 0.0274]) \n",
      "Test Loss tensor([0.0863, 0.0175, 0.0037, 0.0483, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4681880474090576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0860, 0.0172, 0.0041, 0.0460, 0.0282]) \n",
      "Test Loss tensor([0.0864, 0.0167, 0.0039, 0.0467, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4694535732269287 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0840, 0.0167, 0.0038, 0.0452, 0.0283]) \n",
      "Test Loss tensor([0.0845, 0.0175, 0.0031, 0.0460, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.49822044372558594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0876, 0.0204, 0.0034, 0.0512, 0.0261]) \n",
      "Test Loss tensor([0.0876, 0.0169, 0.0029, 0.0461, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4714319705963135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0840, 0.0179, 0.0030, 0.0432, 0.0257]) \n",
      "Test Loss tensor([0.0852, 0.0167, 0.0032, 0.0439, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4722604751586914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0832, 0.0162, 0.0030, 0.0484, 0.0272]) \n",
      "Test Loss tensor([0.0858, 0.0173, 0.0038, 0.0461, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4997227191925049 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0775, 0.0162, 0.0037, 0.0456, 0.0297]) \n",
      "Test Loss tensor([0.0860, 0.0166, 0.0036, 0.0449, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47464847564697266 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0798, 0.0144, 0.0036, 0.0392, 0.0248]) \n",
      "Test Loss tensor([0.0850, 0.0165, 0.0030, 0.0462, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4746859073638916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0844, 0.0146, 0.0033, 0.0401, 0.0230]) \n",
      "Test Loss tensor([0.0856, 0.0173, 0.0029, 0.0463, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47852063179016113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0810, 0.0179, 0.0028, 0.0429, 0.0286]) \n",
      "Test Loss tensor([0.0853, 0.0182, 0.0030, 0.0453, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4734344482421875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0836, 0.0175, 0.0027, 0.0448, 0.0311]) \n",
      "Test Loss tensor([0.0837, 0.0160, 0.0033, 0.0438, 0.0277])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.49373650550842285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0814, 0.0149, 0.0035, 0.0475, 0.0247]) \n",
      "Test Loss tensor([0.0847, 0.0165, 0.0036, 0.0454, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4903733730316162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0839, 0.0134, 0.0036, 0.0436, 0.0262]) \n",
      "Test Loss tensor([0.0838, 0.0165, 0.0030, 0.0443, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47217869758605957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0782, 0.0202, 0.0034, 0.0408, 0.0265]) \n",
      "Test Loss tensor([0.0846, 0.0171, 0.0027, 0.0447, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4523274898529053 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0602, 0.0140, 0.0022, 0.0319, 0.0195]) \n",
      "Test Loss tensor([0.0844, 0.0176, 0.0029, 0.0431, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5469341278076172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0876, 0.0150, 0.0030, 0.0406, 0.0280]) \n",
      "Test Loss tensor([0.0852, 0.0166, 0.0032, 0.0445, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.46966981887817383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0781, 0.0139, 0.0031, 0.0448, 0.0247]) \n",
      "Test Loss tensor([0.0828, 0.0166, 0.0030, 0.0453, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4787406921386719 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0830, 0.0152, 0.0030, 0.0457, 0.0278]) \n",
      "Test Loss tensor([0.0828, 0.0166, 0.0030, 0.0456, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4761357307434082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0856, 0.0171, 0.0030, 0.0420, 0.0252]) \n",
      "Test Loss tensor([0.0827, 0.0168, 0.0027, 0.0443, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47805309295654297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0882, 0.0180, 0.0026, 0.0438, 0.0265]) \n",
      "Test Loss tensor([0.0837, 0.0165, 0.0028, 0.0441, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4733271598815918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0821, 0.0184, 0.0027, 0.0409, 0.0262]) \n",
      "Test Loss tensor([0.0818, 0.0164, 0.0033, 0.0427, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47336530685424805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0811, 0.0169, 0.0033, 0.0426, 0.0285]) \n",
      "Test Loss tensor([0.0818, 0.0174, 0.0034, 0.0425, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4699702262878418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0774, 0.0174, 0.0033, 0.0501, 0.0280]) \n",
      "Test Loss tensor([0.0828, 0.0167, 0.0030, 0.0435, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.47955775260925293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0851, 0.0168, 0.0032, 0.0435, 0.0274]) \n",
      "Test Loss tensor([0.0825, 0.0165, 0.0029, 0.0443, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.47260189056396484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0812, 0.0140, 0.0029, 0.0415, 0.0292]) \n",
      "Test Loss tensor([0.0828, 0.0172, 0.0030, 0.0441, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4808042049407959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0836, 0.0161, 0.0028, 0.0462, 0.0258]) \n",
      "Test Loss tensor([0.0832, 0.0169, 0.0034, 0.0434, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.47174620628356934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0774, 0.0163, 0.0039, 0.0467, 0.0276]) \n",
      "Test Loss tensor([0.0840, 0.0168, 0.0039, 0.0440, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47490572929382324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0865, 0.0146, 0.0040, 0.0472, 0.0317]) \n",
      "Test Loss tensor([0.0810, 0.0168, 0.0031, 0.0436, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.48664402961730957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0783, 0.0166, 0.0033, 0.0445, 0.0289]) \n",
      "Test Loss tensor([0.0826, 0.0168, 0.0030, 0.0453, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.47550153732299805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0819, 0.0163, 0.0028, 0.0429, 0.0246]) \n",
      "Test Loss tensor([0.0802, 0.0164, 0.0028, 0.0432, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4737894535064697 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0771, 0.0195, 0.0032, 0.0468, 0.0306]) \n",
      "Test Loss tensor([0.0807, 0.0163, 0.0032, 0.0444, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.472898006439209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0753, 0.0166, 0.0028, 0.0394, 0.0308]) \n",
      "Test Loss tensor([0.0822, 0.0170, 0.0035, 0.0443, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4737367630004883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0800, 0.0166, 0.0030, 0.0456, 0.0251]) \n",
      "Test Loss tensor([0.0790, 0.0165, 0.0033, 0.0437, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4774792194366455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0780, 0.0159, 0.0034, 0.0413, 0.0264]) \n",
      "Test Loss tensor([0.0797, 0.0169, 0.0028, 0.0422, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4718892574310303 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0787, 0.0172, 0.0029, 0.0414, 0.0311]) \n",
      "Test Loss tensor([0.0809, 0.0163, 0.0028, 0.0435, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4747002124786377 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0731, 0.0175, 0.0028, 0.0446, 0.0267]) \n",
      "Test Loss tensor([0.0784, 0.0172, 0.0030, 0.0434, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.48301219940185547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0775, 0.0172, 0.0030, 0.0405, 0.0277]) \n",
      "Test Loss tensor([0.0792, 0.0168, 0.0034, 0.0437, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4745323657989502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0707, 0.0176, 0.0033, 0.0414, 0.0293]) \n",
      "Test Loss tensor([0.0784, 0.0163, 0.0031, 0.0421, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4762260913848877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0794, 0.0176, 0.0028, 0.0429, 0.0265]) \n",
      "Test Loss tensor([0.0815, 0.0175, 0.0027, 0.0430, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47558069229125977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0798, 0.0168, 0.0027, 0.0454, 0.0273]) \n",
      "Test Loss tensor([0.0780, 0.0175, 0.0028, 0.0420, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47702860832214355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0763, 0.0162, 0.0029, 0.0423, 0.0265]) \n",
      "Test Loss tensor([0.0771, 0.0161, 0.0033, 0.0430, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47401881217956543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0800, 0.0153, 0.0032, 0.0428, 0.0228]) \n",
      "Test Loss tensor([0.0786, 0.0161, 0.0035, 0.0426, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4752316474914551 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0821, 0.0169, 0.0034, 0.0413, 0.0299]) \n",
      "Test Loss tensor([0.0778, 0.0170, 0.0031, 0.0414, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4722929000854492 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0765, 0.0171, 0.0028, 0.0378, 0.0278]) \n",
      "Test Loss tensor([0.0784, 0.0163, 0.0029, 0.0415, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.47376346588134766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0774, 0.0170, 0.0028, 0.0401, 0.0273]) \n",
      "Test Loss tensor([0.0792, 0.0169, 0.0028, 0.0406, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4735863208770752 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0807, 0.0170, 0.0026, 0.0394, 0.0290]) \n",
      "Test Loss tensor([0.0772, 0.0172, 0.0033, 0.0425, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.47202587127685547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0757, 0.0151, 0.0033, 0.0453, 0.0258]) \n",
      "Test Loss tensor([0.0784, 0.0165, 0.0033, 0.0415, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4724245071411133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0699, 0.0155, 0.0034, 0.0392, 0.0247]) \n",
      "Test Loss tensor([0.0761, 0.0163, 0.0031, 0.0422, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4739038944244385 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0772, 0.0168, 0.0029, 0.0422, 0.0264]) \n",
      "Test Loss tensor([0.0773, 0.0165, 0.0028, 0.0404, 0.0254])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.47264599800109863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0801, 0.0175, 0.0029, 0.0437, 0.0284]) \n",
      "Test Loss tensor([0.0781, 0.0172, 0.0031, 0.0410, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47440361976623535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0717, 0.0149, 0.0032, 0.0375, 0.0260]) \n",
      "Test Loss tensor([0.0776, 0.0170, 0.0034, 0.0426, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4714791774749756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0758, 0.0162, 0.0035, 0.0424, 0.0258]) \n",
      "Test Loss tensor([0.0757, 0.0164, 0.0033, 0.0410, 0.0250])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 148 in 0.4733731746673584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0739, 0.0191, 0.0033, 0.0433, 0.0261]) \n",
      "Test Loss tensor([0.0764, 0.0162, 0.0029, 0.0409, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5223691463470459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0766, 0.0196, 0.0028, 0.0364, 0.0266]) \n",
      "Test Loss tensor([0.0757, 0.0159, 0.0029, 0.0407, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.48062801361083984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0773, 0.0167, 0.0027, 0.0467, 0.0246]) \n",
      "Test Loss tensor([0.0763, 0.0162, 0.0034, 0.0419, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4723238945007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0805, 0.0139, 0.0037, 0.0454, 0.0248]) \n",
      "Test Loss tensor([0.0757, 0.0159, 0.0033, 0.0417, 0.0254])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.47414278984069824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0747, 0.0181, 0.0030, 0.0408, 0.0261]) \n",
      "Test Loss tensor([0.0765, 0.0160, 0.0031, 0.0400, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.47542762756347656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0734, 0.0174, 0.0025, 0.0409, 0.0275]) \n",
      "Test Loss tensor([0.0760, 0.0163, 0.0029, 0.0405, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4726247787475586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0645, 0.0181, 0.0030, 0.0409, 0.0275]) \n",
      "Test Loss tensor([0.0762, 0.0165, 0.0028, 0.0408, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47228479385375977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0702, 0.0181, 0.0025, 0.0411, 0.0317]) \n",
      "Test Loss tensor([0.0778, 0.0159, 0.0031, 0.0401, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4713253974914551 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0712, 0.0163, 0.0030, 0.0415, 0.0281]) \n",
      "Test Loss tensor([0.0765, 0.0163, 0.0032, 0.0413, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.47919583320617676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0739, 0.0177, 0.0035, 0.0462, 0.0233]) \n",
      "Test Loss tensor([0.0759, 0.0159, 0.0029, 0.0396, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47423768043518066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0695, 0.0147, 0.0025, 0.0408, 0.0277]) \n",
      "Test Loss tensor([0.0758, 0.0172, 0.0027, 0.0405, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4779796600341797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0781, 0.0163, 0.0032, 0.0392, 0.0284]) \n",
      "Test Loss tensor([0.0751, 0.0158, 0.0026, 0.0396, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.48438072204589844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0704, 0.0166, 0.0030, 0.0353, 0.0232]) \n",
      "Test Loss tensor([0.0740, 0.0158, 0.0028, 0.0400, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.49692821502685547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0785, 0.0154, 0.0028, 0.0423, 0.0260]) \n",
      "Test Loss tensor([0.0758, 0.0154, 0.0030, 0.0398, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.475480318069458 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0785, 0.0171, 0.0028, 0.0381, 0.0242]) \n",
      "Test Loss tensor([0.0745, 0.0161, 0.0029, 0.0387, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4757711887359619 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0741, 0.0161, 0.0031, 0.0366, 0.0257]) \n",
      "Test Loss tensor([0.0729, 0.0164, 0.0027, 0.0402, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.48009514808654785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0753, 0.0155, 0.0026, 0.0364, 0.0248]) \n",
      "Test Loss tensor([0.0751, 0.0167, 0.0027, 0.0399, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.47691774368286133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0712, 0.0161, 0.0031, 0.0413, 0.0249]) \n",
      "Test Loss tensor([0.0748, 0.0162, 0.0029, 0.0388, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4767167568206787 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0713, 0.0148, 0.0029, 0.0373, 0.0258]) \n",
      "Test Loss tensor([0.0751, 0.0160, 0.0032, 0.0396, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4916985034942627 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0725, 0.0170, 0.0033, 0.0408, 0.0244]) \n",
      "Test Loss tensor([0.0737, 0.0162, 0.0029, 0.0387, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.47738122940063477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0768, 0.0169, 0.0030, 0.0391, 0.0259]) \n",
      "Test Loss tensor([0.0723, 0.0159, 0.0029, 0.0400, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47517967224121094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0738, 0.0172, 0.0028, 0.0407, 0.0276]) \n",
      "Test Loss tensor([0.0740, 0.0158, 0.0031, 0.0399, 0.0254])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47542452812194824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0735, 0.0158, 0.0027, 0.0404, 0.0245]) \n",
      "Test Loss tensor([0.0736, 0.0160, 0.0031, 0.0388, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4772617816925049 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0757, 0.0159, 0.0029, 0.0372, 0.0243]) \n",
      "Test Loss tensor([0.0721, 0.0161, 0.0033, 0.0383, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.47515177726745605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0810, 0.0175, 0.0034, 0.0415, 0.0301]) \n",
      "Test Loss tensor([0.0723, 0.0159, 0.0029, 0.0387, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47887206077575684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0695, 0.0167, 0.0032, 0.0397, 0.0264]) \n",
      "Test Loss tensor([0.0744, 0.0163, 0.0029, 0.0382, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4784882068634033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0750, 0.0140, 0.0028, 0.0348, 0.0264]) \n",
      "Test Loss tensor([0.0736, 0.0162, 0.0029, 0.0400, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4805028438568115 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0749, 0.0175, 0.0028, 0.0370, 0.0271]) \n",
      "Test Loss tensor([0.0713, 0.0159, 0.0033, 0.0402, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4728381633758545 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0749, 0.0174, 0.0038, 0.0386, 0.0266]) \n",
      "Test Loss tensor([0.0742, 0.0163, 0.0032, 0.0391, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4734077453613281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0694, 0.0163, 0.0032, 0.0382, 0.0210]) \n",
      "Test Loss tensor([0.0716, 0.0153, 0.0029, 0.0387, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.474454402923584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0681, 0.0161, 0.0031, 0.0394, 0.0254]) \n",
      "Test Loss tensor([0.0718, 0.0162, 0.0030, 0.0396, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.473020076751709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0688, 0.0156, 0.0026, 0.0422, 0.0217]) \n",
      "Test Loss tensor([0.0708, 0.0163, 0.0031, 0.0386, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.47453951835632324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0707, 0.0181, 0.0030, 0.0406, 0.0271]) \n",
      "Test Loss tensor([0.0732, 0.0170, 0.0033, 0.0389, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4703490734100342 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0718, 0.0157, 0.0035, 0.0365, 0.0229]) \n",
      "Test Loss tensor([0.0709, 0.0159, 0.0031, 0.0381, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4726994037628174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0716, 0.0157, 0.0032, 0.0348, 0.0254]) \n",
      "Test Loss tensor([0.0703, 0.0167, 0.0029, 0.0385, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.47334766387939453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0660, 0.0166, 0.0030, 0.0374, 0.0272]) \n",
      "Test Loss tensor([0.0701, 0.0162, 0.0028, 0.0401, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4748826026916504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0723, 0.0166, 0.0031, 0.0406, 0.0227]) \n",
      "Test Loss tensor([0.0719, 0.0167, 0.0032, 0.0402, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47170543670654297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0680, 0.0173, 0.0033, 0.0378, 0.0259]) \n",
      "Test Loss tensor([0.0724, 0.0168, 0.0031, 0.0372, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47486042976379395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0649, 0.0123, 0.0032, 0.0397, 0.0215]) \n",
      "Test Loss tensor([0.0699, 0.0160, 0.0029, 0.0373, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4720280170440674 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0678, 0.0146, 0.0027, 0.0406, 0.0280]) \n",
      "Test Loss tensor([0.0719, 0.0164, 0.0028, 0.0379, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47467827796936035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0714, 0.0152, 0.0026, 0.0428, 0.0232]) \n",
      "Test Loss tensor([0.0707, 0.0172, 0.0029, 0.0371, 0.0252])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 312 in 0.47612619400024414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0670, 0.0179, 0.0028, 0.0357, 0.0237]) \n",
      "Test Loss tensor([0.0714, 0.0157, 0.0032, 0.0384, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.48110318183898926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0766, 0.0155, 0.0030, 0.0420, 0.0237]) \n",
      "Test Loss tensor([0.0702, 0.0166, 0.0030, 0.0376, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.49169158935546875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0703, 0.0158, 0.0026, 0.0404, 0.0245]) \n",
      "Test Loss tensor([0.0704, 0.0167, 0.0030, 0.0387, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4742472171783447 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0691, 0.0171, 0.0027, 0.0410, 0.0225]) \n",
      "Test Loss tensor([0.0682, 0.0155, 0.0031, 0.0386, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.47875380516052246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0698, 0.0161, 0.0031, 0.0340, 0.0257]) \n",
      "Test Loss tensor([0.0735, 0.0160, 0.0035, 0.0382, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.47727537155151367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0763, 0.0139, 0.0035, 0.0386, 0.0246]) \n",
      "Test Loss tensor([0.0708, 0.0166, 0.0030, 0.0383, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47798871994018555 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0656, 0.0154, 0.0032, 0.0361, 0.0232]) \n",
      "Test Loss tensor([0.0706, 0.0168, 0.0030, 0.0384, 0.0247])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.47714757919311523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0703, 0.0156, 0.0031, 0.0347, 0.0244]) \n",
      "Test Loss tensor([0.0699, 0.0161, 0.0030, 0.0375, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4772307872772217 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0714, 0.0169, 0.0030, 0.0365, 0.0240]) \n",
      "Test Loss tensor([0.0709, 0.0165, 0.0032, 0.0383, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47813892364501953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0689, 0.0163, 0.0034, 0.0379, 0.0255]) \n",
      "Test Loss tensor([0.0687, 0.0158, 0.0034, 0.0384, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4769318103790283 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0698, 0.0169, 0.0035, 0.0371, 0.0239]) \n",
      "Test Loss tensor([0.0683, 0.0162, 0.0031, 0.0380, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4728877544403076 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0667, 0.0148, 0.0033, 0.0349, 0.0225]) \n",
      "Test Loss tensor([0.0705, 0.0172, 0.0031, 0.0374, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4762766361236572 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0675, 0.0204, 0.0027, 0.0386, 0.0243]) \n",
      "Test Loss tensor([0.0694, 0.0159, 0.0028, 0.0375, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.47402143478393555 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0632, 0.0188, 0.0028, 0.0366, 0.0270]) \n",
      "Test Loss tensor([0.0702, 0.0162, 0.0029, 0.0381, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.47524380683898926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0699, 0.0146, 0.0031, 0.0344, 0.0244]) \n",
      "Test Loss tensor([0.0682, 0.0156, 0.0032, 0.0369, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4736957550048828 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0697, 0.0157, 0.0038, 0.0392, 0.0207]) \n",
      "Test Loss tensor([0.0692, 0.0155, 0.0033, 0.0367, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4784581661224365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0749, 0.0213, 0.0032, 0.0397, 0.0248]) \n",
      "Test Loss tensor([0.0698, 0.0163, 0.0031, 0.0366, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4764697551727295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0682, 0.0158, 0.0028, 0.0370, 0.0244]) \n",
      "Test Loss tensor([0.0689, 0.0159, 0.0033, 0.0360, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.474043607711792 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0654, 0.0158, 0.0030, 0.0355, 0.0236]) \n",
      "Test Loss tensor([0.0687, 0.0166, 0.0031, 0.0368, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.473721981048584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0648, 0.0134, 0.0034, 0.0369, 0.0273]) \n",
      "Test Loss tensor([0.0664, 0.0154, 0.0030, 0.0366, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4725818634033203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0686, 0.0165, 0.0030, 0.0332, 0.0283]) \n",
      "Test Loss tensor([0.0680, 0.0163, 0.0031, 0.0360, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.47391223907470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0681, 0.0173, 0.0026, 0.0356, 0.0289]) \n",
      "Test Loss tensor([0.0681, 0.0170, 0.0029, 0.0361, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.47522401809692383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0700, 0.0189, 0.0030, 0.0381, 0.0241]) \n",
      "Test Loss tensor([0.0695, 0.0154, 0.0029, 0.0358, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.47555971145629883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0694, 0.0191, 0.0028, 0.0311, 0.0280]) \n",
      "Test Loss tensor([0.0669, 0.0162, 0.0029, 0.0360, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4775271415710449 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0660, 0.0183, 0.0031, 0.0350, 0.0240]) \n",
      "Test Loss tensor([0.0677, 0.0152, 0.0029, 0.0362, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47377443313598633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0741, 0.0154, 0.0029, 0.0330, 0.0229]) \n",
      "Test Loss tensor([0.0679, 0.0167, 0.0031, 0.0358, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4751091003417969 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0628, 0.0170, 0.0031, 0.0324, 0.0238]) \n",
      "Test Loss tensor([0.0672, 0.0157, 0.0030, 0.0360, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4738759994506836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0655, 0.0154, 0.0030, 0.0355, 0.0234]) \n",
      "Test Loss tensor([0.0692, 0.0163, 0.0031, 0.0362, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.47574782371520996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0608, 0.0199, 0.0032, 0.0356, 0.0247]) \n",
      "Test Loss tensor([0.0683, 0.0158, 0.0030, 0.0375, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.47330641746520996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0613, 0.0167, 0.0032, 0.0375, 0.0248]) \n",
      "Test Loss tensor([0.0679, 0.0159, 0.0031, 0.0361, 0.0237])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.47284603118896484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0589, 0.0145, 0.0029, 0.0341, 0.0221]) \n",
      "Test Loss tensor([0.0683, 0.0162, 0.0029, 0.0365, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4769749641418457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0653, 0.0160, 0.0030, 0.0349, 0.0211]) \n",
      "Test Loss tensor([0.0666, 0.0164, 0.0028, 0.0372, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4742448329925537 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0646, 0.0174, 0.0035, 0.0349, 0.0237]) \n",
      "Test Loss tensor([0.0677, 0.0161, 0.0030, 0.0371, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47567057609558105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0652, 0.0161, 0.0037, 0.0393, 0.0225]) \n",
      "Test Loss tensor([0.0650, 0.0167, 0.0031, 0.0369, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4744288921356201 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0639, 0.0149, 0.0033, 0.0318, 0.0267]) \n",
      "Test Loss tensor([0.0664, 0.0163, 0.0029, 0.0359, 0.0237])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4754674434661865 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0587, 0.0156, 0.0038, 0.0386, 0.0240]) \n",
      "Test Loss tensor([0.0656, 0.0162, 0.0029, 0.0361, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4737670421600342 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0686, 0.0136, 0.0027, 0.0347, 0.0247]) \n",
      "Test Loss tensor([0.0666, 0.0165, 0.0031, 0.0376, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4775223731994629 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0576, 0.0163, 0.0029, 0.0362, 0.0216]) \n",
      "Test Loss tensor([0.0670, 0.0163, 0.0030, 0.0361, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47416210174560547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0608, 0.0140, 0.0027, 0.0346, 0.0230]) \n",
      "Test Loss tensor([0.0658, 0.0161, 0.0028, 0.0346, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47655820846557617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0679, 0.0165, 0.0031, 0.0340, 0.0245]) \n",
      "Test Loss tensor([0.0667, 0.0163, 0.0029, 0.0355, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.474778413772583 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0676, 0.0181, 0.0028, 0.0343, 0.0250]) \n",
      "Test Loss tensor([0.0658, 0.0168, 0.0030, 0.0354, 0.0227])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 476 in 0.47687768936157227 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0627, 0.0161, 0.0030, 0.0368, 0.0256]) \n",
      "Test Loss tensor([0.0649, 0.0165, 0.0032, 0.0367, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4761672019958496 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0605, 0.0181, 0.0029, 0.0349, 0.0230]) \n",
      "Test Loss tensor([0.0677, 0.0171, 0.0033, 0.0357, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47911930084228516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0709, 0.0170, 0.0030, 0.0348, 0.0218]) \n",
      "Test Loss tensor([0.0664, 0.0161, 0.0033, 0.0354, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4857797622680664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0635, 0.0141, 0.0038, 0.0359, 0.0220]) \n",
      "Test Loss tensor([0.0642, 0.0166, 0.0029, 0.0375, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5020661354064941 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0659, 0.0150, 0.0028, 0.0358, 0.0235]) \n",
      "Test Loss tensor([0.0652, 0.0162, 0.0031, 0.0353, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47618699073791504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0654, 0.0163, 0.0029, 0.0365, 0.0210]) \n",
      "Test Loss tensor([0.0653, 0.0155, 0.0031, 0.0358, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4779341220855713 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0635, 0.0159, 0.0032, 0.0324, 0.0219]) \n",
      "Test Loss tensor([0.0648, 0.0156, 0.0032, 0.0354, 0.0237])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4955270290374756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0597, 0.0137, 0.0032, 0.0316, 0.0245]) \n",
      "Test Loss tensor([0.0672, 0.0163, 0.0029, 0.0341, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.47529077529907227 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0608, 0.0152, 0.0028, 0.0405, 0.0260]) \n",
      "Test Loss tensor([0.0674, 0.0160, 0.0026, 0.0359, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47437095642089844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0655, 0.0183, 0.0024, 0.0362, 0.0271]) \n",
      "Test Loss tensor([0.0651, 0.0155, 0.0028, 0.0336, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.47637510299682617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0590, 0.0142, 0.0030, 0.0344, 0.0256]) \n",
      "Test Loss tensor([0.0655, 0.0162, 0.0029, 0.0355, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4743831157684326 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0625, 0.0154, 0.0030, 0.0363, 0.0224]) \n",
      "Test Loss tensor([0.0645, 0.0162, 0.0031, 0.0346, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4885830879211426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0606, 0.0133, 0.0028, 0.0352, 0.0239]) \n",
      "Test Loss tensor([0.0651, 0.0148, 0.0030, 0.0349, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4771726131439209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0642, 0.0167, 0.0033, 0.0391, 0.0217]) \n",
      "Test Loss tensor([0.0646, 0.0156, 0.0029, 0.0336, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4732837677001953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0633, 0.0155, 0.0031, 0.0345, 0.0232]) \n",
      "Test Loss tensor([0.0647, 0.0163, 0.0028, 0.0364, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.47904491424560547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0637, 0.0149, 0.0024, 0.0345, 0.0213]) \n",
      "Test Loss tensor([0.0626, 0.0157, 0.0029, 0.0352, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.47571372985839844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0621, 0.0164, 0.0028, 0.0350, 0.0217]) \n",
      "Test Loss tensor([0.0652, 0.0159, 0.0031, 0.0349, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47780609130859375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0595, 0.0169, 0.0033, 0.0311, 0.0280]) \n",
      "Test Loss tensor([0.0663, 0.0159, 0.0031, 0.0355, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4723780155181885 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0614, 0.0157, 0.0029, 0.0376, 0.0227]) \n",
      "Test Loss tensor([0.0645, 0.0161, 0.0028, 0.0359, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4763960838317871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0654, 0.0158, 0.0034, 0.0343, 0.0220]) \n",
      "Test Loss tensor([0.0633, 0.0162, 0.0029, 0.0358, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4746284484863281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0591, 0.0157, 0.0026, 0.0322, 0.0240]) \n",
      "Test Loss tensor([0.0633, 0.0163, 0.0031, 0.0358, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4769861698150635 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0693, 0.0159, 0.0032, 0.0317, 0.0225]) \n",
      "Test Loss tensor([0.0626, 0.0155, 0.0029, 0.0355, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4753735065460205 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0608, 0.0159, 0.0030, 0.0335, 0.0227]) \n",
      "Test Loss tensor([0.0643, 0.0155, 0.0028, 0.0356, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4742882251739502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0667, 0.0169, 0.0028, 0.0306, 0.0222]) \n",
      "Test Loss tensor([0.0625, 0.0157, 0.0027, 0.0330, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4732327461242676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0599, 0.0147, 0.0027, 0.0356, 0.0227]) \n",
      "Test Loss tensor([0.0628, 0.0161, 0.0027, 0.0342, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.47524070739746094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0704, 0.0184, 0.0027, 0.0349, 0.0242]) \n",
      "Test Loss tensor([0.0628, 0.0155, 0.0028, 0.0365, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47406816482543945 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0606, 0.0143, 0.0030, 0.0358, 0.0233]) \n",
      "Test Loss tensor([0.0639, 0.0155, 0.0029, 0.0350, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4767768383026123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0589, 0.0147, 0.0028, 0.0320, 0.0230]) \n",
      "Test Loss tensor([0.0616, 0.0154, 0.0028, 0.0348, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47537708282470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0642, 0.0151, 0.0031, 0.0342, 0.0254]) \n",
      "Test Loss tensor([0.0635, 0.0158, 0.0027, 0.0349, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4757218360900879 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0613, 0.0164, 0.0024, 0.0352, 0.0219]) \n",
      "Test Loss tensor([0.0617, 0.0151, 0.0029, 0.0341, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4745466709136963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0611, 0.0191, 0.0029, 0.0365, 0.0249]) \n",
      "Test Loss tensor([0.0623, 0.0153, 0.0030, 0.0335, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47521400451660156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0594, 0.0177, 0.0032, 0.0318, 0.0250]) \n",
      "Test Loss tensor([0.0629, 0.0154, 0.0030, 0.0344, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4733738899230957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0591, 0.0166, 0.0027, 0.0342, 0.0222]) \n",
      "Test Loss tensor([0.0616, 0.0163, 0.0029, 0.0342, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47387003898620605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0577, 0.0150, 0.0027, 0.0337, 0.0221]) \n",
      "Test Loss tensor([0.0638, 0.0156, 0.0028, 0.0341, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47351503372192383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0598, 0.0129, 0.0033, 0.0326, 0.0207]) \n",
      "Test Loss tensor([0.0627, 0.0155, 0.0031, 0.0343, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.473358154296875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0675, 0.0149, 0.0033, 0.0349, 0.0236]) \n",
      "Test Loss tensor([0.0621, 0.0158, 0.0031, 0.0344, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.47812724113464355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0607, 0.0147, 0.0031, 0.0338, 0.0273]) \n",
      "Test Loss tensor([0.0609, 0.0153, 0.0030, 0.0345, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.47446560859680176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0631, 0.0179, 0.0030, 0.0320, 0.0234]) \n",
      "Test Loss tensor([0.0617, 0.0163, 0.0029, 0.0333, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.474271297454834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0590, 0.0173, 0.0033, 0.0387, 0.0234]) \n",
      "Test Loss tensor([0.0624, 0.0159, 0.0029, 0.0335, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4740157127380371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0631, 0.0144, 0.0033, 0.0348, 0.0228]) \n",
      "Test Loss tensor([0.0621, 0.0162, 0.0033, 0.0337, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4865708351135254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0603, 0.0153, 0.0032, 0.0342, 0.0245]) \n",
      "Test Loss tensor([0.0626, 0.0156, 0.0031, 0.0343, 0.0235])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 640 in 0.47586512565612793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0651, 0.0159, 0.0031, 0.0351, 0.0204]) \n",
      "Test Loss tensor([0.0624, 0.0166, 0.0029, 0.0342, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47631001472473145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0574, 0.0140, 0.0027, 0.0359, 0.0240]) \n",
      "Test Loss tensor([0.0614, 0.0167, 0.0028, 0.0355, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47316670417785645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0619, 0.0178, 0.0027, 0.0334, 0.0241]) \n",
      "Test Loss tensor([0.0617, 0.0160, 0.0032, 0.0331, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4795663356781006 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0549, 0.0165, 0.0030, 0.0316, 0.0252]) \n",
      "Test Loss tensor([0.0624, 0.0156, 0.0033, 0.0355, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.483264684677124 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0613, 0.0169, 0.0031, 0.0348, 0.0239]) \n",
      "Test Loss tensor([0.0608, 0.0154, 0.0030, 0.0333, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47740936279296875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0563, 0.0157, 0.0030, 0.0298, 0.0220]) \n",
      "Test Loss tensor([0.0625, 0.0163, 0.0030, 0.0357, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.47298431396484375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0601, 0.0165, 0.0031, 0.0297, 0.0275]) \n",
      "Test Loss tensor([0.0615, 0.0161, 0.0029, 0.0335, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.475691556930542 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0565, 0.0155, 0.0026, 0.0341, 0.0234]) \n",
      "Test Loss tensor([0.0621, 0.0161, 0.0031, 0.0351, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47482776641845703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0555, 0.0158, 0.0032, 0.0348, 0.0218]) \n",
      "Test Loss tensor([0.0625, 0.0160, 0.0030, 0.0341, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.47570204734802246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0617, 0.0139, 0.0030, 0.0349, 0.0240]) \n",
      "Test Loss tensor([0.0606, 0.0158, 0.0029, 0.0323, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47101402282714844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0633, 0.0175, 0.0027, 0.0348, 0.0217]) \n",
      "Test Loss tensor([0.0615, 0.0158, 0.0028, 0.0337, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4754462242126465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0601, 0.0160, 0.0027, 0.0354, 0.0265]) \n",
      "Test Loss tensor([0.0603, 0.0158, 0.0027, 0.0328, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4755544662475586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0676, 0.0180, 0.0028, 0.0355, 0.0202]) \n",
      "Test Loss tensor([0.0603, 0.0158, 0.0030, 0.0340, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4772181510925293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0598, 0.0152, 0.0028, 0.0344, 0.0238]) \n",
      "Test Loss tensor([0.0604, 0.0163, 0.0029, 0.0322, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4742753505706787 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0576, 0.0156, 0.0030, 0.0346, 0.0231]) \n",
      "Test Loss tensor([0.0609, 0.0155, 0.0031, 0.0325, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.47241997718811035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0571, 0.0146, 0.0032, 0.0313, 0.0224]) \n",
      "Test Loss tensor([0.0616, 0.0150, 0.0028, 0.0334, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47604823112487793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0593, 0.0135, 0.0026, 0.0339, 0.0238]) \n",
      "Test Loss tensor([0.0604, 0.0155, 0.0028, 0.0339, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4728400707244873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0629, 0.0147, 0.0029, 0.0346, 0.0263]) \n",
      "Test Loss tensor([0.0601, 0.0161, 0.0029, 0.0325, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.47391247749328613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0567, 0.0137, 0.0027, 0.0334, 0.0212]) \n",
      "Test Loss tensor([0.0594, 0.0160, 0.0030, 0.0333, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4732320308685303 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0568, 0.0155, 0.0027, 0.0350, 0.0240]) \n",
      "Test Loss tensor([0.0601, 0.0158, 0.0030, 0.0327, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47731590270996094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0538, 0.0133, 0.0028, 0.0348, 0.0236]) \n",
      "Test Loss tensor([0.0601, 0.0154, 0.0029, 0.0325, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4742105007171631 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0646, 0.0138, 0.0031, 0.0291, 0.0247]) \n",
      "Test Loss tensor([0.0613, 0.0155, 0.0028, 0.0329, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4752769470214844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0543, 0.0149, 0.0026, 0.0330, 0.0241]) \n",
      "Test Loss tensor([0.0600, 0.0159, 0.0028, 0.0312, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4724254608154297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0610, 0.0134, 0.0030, 0.0333, 0.0238]) \n",
      "Test Loss tensor([0.0592, 0.0161, 0.0029, 0.0312, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47564697265625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0575, 0.0149, 0.0029, 0.0378, 0.0247]) \n",
      "Test Loss tensor([0.0595, 0.0152, 0.0029, 0.0328, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.47563838958740234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0604, 0.0164, 0.0033, 0.0337, 0.0208]) \n",
      "Test Loss tensor([0.0601, 0.0151, 0.0029, 0.0329, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4764072895050049 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0570, 0.0120, 0.0034, 0.0335, 0.0245]) \n",
      "Test Loss tensor([0.0594, 0.0159, 0.0029, 0.0321, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4766223430633545 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0619, 0.0156, 0.0028, 0.0317, 0.0225]) \n",
      "Test Loss tensor([0.0577, 0.0155, 0.0030, 0.0332, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47563743591308594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0557, 0.0168, 0.0027, 0.0312, 0.0214]) \n",
      "Test Loss tensor([0.0593, 0.0153, 0.0030, 0.0312, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4757211208343506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0593, 0.0150, 0.0031, 0.0371, 0.0238]) \n",
      "Test Loss tensor([0.0600, 0.0156, 0.0030, 0.0323, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47336339950561523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0534, 0.0167, 0.0035, 0.0333, 0.0214]) \n",
      "Test Loss tensor([0.0593, 0.0164, 0.0029, 0.0322, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47673749923706055 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0528, 0.0157, 0.0028, 0.0298, 0.0256]) \n",
      "Test Loss tensor([0.0601, 0.0158, 0.0030, 0.0334, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.47523975372314453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0558, 0.0169, 0.0031, 0.0330, 0.0240]) \n",
      "Test Loss tensor([0.0593, 0.0160, 0.0032, 0.0328, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.47458982467651367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0636, 0.0160, 0.0033, 0.0335, 0.0252]) \n",
      "Test Loss tensor([0.0584, 0.0159, 0.0029, 0.0312, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47752928733825684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0594, 0.0173, 0.0029, 0.0335, 0.0208]) \n",
      "Test Loss tensor([0.0597, 0.0150, 0.0029, 0.0342, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4725379943847656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0611, 0.0180, 0.0027, 0.0339, 0.0261]) \n",
      "Test Loss tensor([0.0580, 0.0160, 0.0028, 0.0321, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4728536605834961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0635, 0.0181, 0.0030, 0.0329, 0.0226]) \n",
      "Test Loss tensor([0.0596, 0.0160, 0.0030, 0.0326, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47766709327697754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0613, 0.0141, 0.0030, 0.0367, 0.0251]) \n",
      "Test Loss tensor([0.0593, 0.0154, 0.0031, 0.0316, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47521233558654785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0608, 0.0154, 0.0032, 0.0311, 0.0236]) \n",
      "Test Loss tensor([0.0596, 0.0167, 0.0028, 0.0321, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47594666481018066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0580, 0.0157, 0.0027, 0.0334, 0.0219]) \n",
      "Test Loss tensor([0.0581, 0.0156, 0.0028, 0.0305, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4741246700286865 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0517, 0.0147, 0.0028, 0.0348, 0.0246]) \n",
      "Test Loss tensor([0.0579, 0.0158, 0.0030, 0.0323, 0.0222])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 804 in 0.4780762195587158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0607, 0.0163, 0.0032, 0.0319, 0.0190]) \n",
      "Test Loss tensor([0.0572, 0.0152, 0.0031, 0.0317, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47365283966064453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0564, 0.0155, 0.0031, 0.0312, 0.0230]) \n",
      "Test Loss tensor([0.0602, 0.0160, 0.0029, 0.0328, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4763309955596924 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0587, 0.0156, 0.0032, 0.0320, 0.0253]) \n",
      "Test Loss tensor([0.0592, 0.0152, 0.0028, 0.0317, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47524070739746094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0550, 0.0175, 0.0029, 0.0345, 0.0238]) \n",
      "Test Loss tensor([0.0589, 0.0152, 0.0028, 0.0324, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5036916732788086 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0530, 0.0135, 0.0024, 0.0299, 0.0220]) \n",
      "Test Loss tensor([0.0586, 0.0152, 0.0028, 0.0326, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4815487861633301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0570, 0.0145, 0.0028, 0.0334, 0.0224]) \n",
      "Test Loss tensor([0.0582, 0.0149, 0.0030, 0.0315, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47588229179382324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0556, 0.0174, 0.0029, 0.0349, 0.0200]) \n",
      "Test Loss tensor([0.0580, 0.0151, 0.0028, 0.0323, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47229647636413574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0555, 0.0153, 0.0029, 0.0330, 0.0220]) \n",
      "Test Loss tensor([0.0583, 0.0150, 0.0029, 0.0311, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.47631239891052246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0562, 0.0149, 0.0032, 0.0342, 0.0257]) \n",
      "Test Loss tensor([0.0577, 0.0153, 0.0028, 0.0311, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4729423522949219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0595, 0.0149, 0.0030, 0.0325, 0.0260]) \n",
      "Test Loss tensor([0.0570, 0.0155, 0.0029, 0.0310, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.47470927238464355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0624, 0.0162, 0.0026, 0.0306, 0.0242]) \n",
      "Test Loss tensor([0.0574, 0.0156, 0.0028, 0.0322, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.46964216232299805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0594, 0.0124, 0.0028, 0.0292, 0.0234]) \n",
      "Test Loss tensor([0.0590, 0.0152, 0.0030, 0.0324, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4701874256134033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0593, 0.0139, 0.0029, 0.0319, 0.0267]) \n",
      "Test Loss tensor([0.0588, 0.0157, 0.0028, 0.0316, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4710664749145508 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0566, 0.0141, 0.0026, 0.0307, 0.0213]) \n",
      "Test Loss tensor([0.0575, 0.0154, 0.0029, 0.0307, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47044897079467773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0586, 0.0145, 0.0029, 0.0299, 0.0197]) \n",
      "Test Loss tensor([0.0577, 0.0156, 0.0031, 0.0302, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47011232376098633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0536, 0.0159, 0.0030, 0.0277, 0.0209]) \n",
      "Test Loss tensor([0.0575, 0.0154, 0.0030, 0.0307, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4683830738067627 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0543, 0.0176, 0.0032, 0.0326, 0.0206]) \n",
      "Test Loss tensor([0.0584, 0.0162, 0.0030, 0.0310, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47095775604248047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0653, 0.0168, 0.0029, 0.0314, 0.0249]) \n",
      "Test Loss tensor([0.0577, 0.0150, 0.0030, 0.0317, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45218467712402344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0113, 0.0023, 0.0235, 0.0164]) \n",
      "Test Loss tensor([0.0580, 0.0155, 0.0031, 0.0306, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5101718902587891 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0607, 0.0160, 0.0027, 0.0351, 0.0179]) \n",
      "Test Loss tensor([0.0575, 0.0150, 0.0028, 0.0309, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.46785855293273926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0554, 0.0158, 0.0027, 0.0274, 0.0226]) \n",
      "Test Loss tensor([0.0589, 0.0158, 0.0028, 0.0324, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47227931022644043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0603, 0.0173, 0.0032, 0.0353, 0.0195]) \n",
      "Test Loss tensor([0.0569, 0.0152, 0.0030, 0.0305, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.46927356719970703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0520, 0.0143, 0.0030, 0.0316, 0.0222]) \n",
      "Test Loss tensor([0.0567, 0.0149, 0.0030, 0.0315, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47249674797058105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0579, 0.0154, 0.0026, 0.0341, 0.0197]) \n",
      "Test Loss tensor([0.0581, 0.0150, 0.0028, 0.0304, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4699273109436035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0568, 0.0160, 0.0032, 0.0289, 0.0234]) \n",
      "Test Loss tensor([0.0565, 0.0155, 0.0028, 0.0307, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47409749031066895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0598, 0.0143, 0.0030, 0.0307, 0.0214]) \n",
      "Test Loss tensor([0.0577, 0.0148, 0.0027, 0.0310, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4716310501098633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0553, 0.0127, 0.0024, 0.0320, 0.0214]) \n",
      "Test Loss tensor([0.0579, 0.0152, 0.0029, 0.0317, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4748103618621826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0578, 0.0138, 0.0029, 0.0365, 0.0212]) \n",
      "Test Loss tensor([0.0568, 0.0151, 0.0030, 0.0295, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4691920280456543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0552, 0.0134, 0.0030, 0.0309, 0.0241]) \n",
      "Test Loss tensor([0.0582, 0.0147, 0.0029, 0.0316, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.47313570976257324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0560, 0.0166, 0.0028, 0.0304, 0.0214]) \n",
      "Test Loss tensor([0.0563, 0.0147, 0.0030, 0.0301, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.47113752365112305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0595, 0.0169, 0.0028, 0.0314, 0.0254]) \n",
      "Test Loss tensor([0.0560, 0.0151, 0.0027, 0.0306, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4740622043609619 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0533, 0.0131, 0.0027, 0.0320, 0.0241]) \n",
      "Test Loss tensor([0.0572, 0.0157, 0.0028, 0.0314, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47059059143066406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0520, 0.0172, 0.0031, 0.0310, 0.0233]) \n",
      "Test Loss tensor([0.0581, 0.0159, 0.0027, 0.0311, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.472806453704834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0535, 0.0177, 0.0028, 0.0303, 0.0214]) \n",
      "Test Loss tensor([0.0562, 0.0156, 0.0028, 0.0296, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4736924171447754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0582, 0.0161, 0.0026, 0.0319, 0.0229]) \n",
      "Test Loss tensor([0.0573, 0.0152, 0.0027, 0.0307, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.47058916091918945 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0537, 0.0145, 0.0027, 0.0278, 0.0240]) \n",
      "Test Loss tensor([0.0563, 0.0149, 0.0028, 0.0306, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.470994234085083 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0524, 0.0118, 0.0029, 0.0299, 0.0210]) \n",
      "Test Loss tensor([0.0559, 0.0156, 0.0028, 0.0310, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.47139930725097656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0515, 0.0130, 0.0026, 0.0285, 0.0223]) \n",
      "Test Loss tensor([0.0579, 0.0148, 0.0028, 0.0294, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4701051712036133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0578, 0.0146, 0.0026, 0.0318, 0.0240]) \n",
      "Test Loss tensor([0.0571, 0.0152, 0.0030, 0.0299, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.46915531158447266 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0549, 0.0146, 0.0031, 0.0282, 0.0181]) \n",
      "Test Loss tensor([0.0569, 0.0157, 0.0028, 0.0306, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4711949825286865 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0579, 0.0138, 0.0032, 0.0288, 0.0238]) \n",
      "Test Loss tensor([0.0567, 0.0160, 0.0027, 0.0295, 0.0215])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 88 in 0.47124171257019043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0550, 0.0137, 0.0024, 0.0308, 0.0243]) \n",
      "Test Loss tensor([0.0562, 0.0151, 0.0029, 0.0305, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4717252254486084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0527, 0.0133, 0.0025, 0.0290, 0.0244]) \n",
      "Test Loss tensor([0.0568, 0.0152, 0.0030, 0.0298, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47058820724487305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0593, 0.0156, 0.0030, 0.0327, 0.0267]) \n",
      "Test Loss tensor([0.0570, 0.0157, 0.0030, 0.0302, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4705543518066406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0552, 0.0177, 0.0028, 0.0267, 0.0216]) \n",
      "Test Loss tensor([0.0549, 0.0153, 0.0028, 0.0300, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4700620174407959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0546, 0.0147, 0.0033, 0.0296, 0.0251]) \n",
      "Test Loss tensor([0.0559, 0.0156, 0.0030, 0.0297, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.47709155082702637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0535, 0.0125, 0.0029, 0.0268, 0.0198]) \n",
      "Test Loss tensor([0.0572, 0.0154, 0.0031, 0.0294, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4765024185180664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0547, 0.0148, 0.0029, 0.0309, 0.0242]) \n",
      "Test Loss tensor([0.0557, 0.0155, 0.0031, 0.0297, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4783663749694824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0514, 0.0155, 0.0035, 0.0262, 0.0232]) \n",
      "Test Loss tensor([0.0547, 0.0150, 0.0029, 0.0314, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4705994129180908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0554, 0.0163, 0.0031, 0.0278, 0.0220]) \n",
      "Test Loss tensor([0.0565, 0.0158, 0.0031, 0.0301, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.47566676139831543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0573, 0.0149, 0.0036, 0.0289, 0.0246]) \n",
      "Test Loss tensor([0.0559, 0.0150, 0.0030, 0.0304, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.47321224212646484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0520, 0.0157, 0.0036, 0.0293, 0.0237]) \n",
      "Test Loss tensor([0.0554, 0.0155, 0.0030, 0.0293, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.47264885902404785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0457, 0.0155, 0.0029, 0.0306, 0.0226]) \n",
      "Test Loss tensor([0.0554, 0.0148, 0.0031, 0.0292, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.47010302543640137 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0482, 0.0152, 0.0028, 0.0279, 0.0222]) \n",
      "Test Loss tensor([0.0546, 0.0144, 0.0031, 0.0296, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4728555679321289 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0492, 0.0124, 0.0032, 0.0279, 0.0229]) \n",
      "Test Loss tensor([0.0557, 0.0151, 0.0030, 0.0299, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.47136354446411133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0569, 0.0186, 0.0029, 0.0300, 0.0202]) \n",
      "Test Loss tensor([0.0547, 0.0148, 0.0031, 0.0298, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4868946075439453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0554, 0.0141, 0.0032, 0.0297, 0.0241]) \n",
      "Test Loss tensor([0.0571, 0.0148, 0.0030, 0.0306, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4864976406097412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0487, 0.0150, 0.0028, 0.0299, 0.0215]) \n",
      "Test Loss tensor([0.0556, 0.0158, 0.0030, 0.0296, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47011494636535645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0512, 0.0148, 0.0026, 0.0316, 0.0230]) \n",
      "Test Loss tensor([0.0555, 0.0152, 0.0029, 0.0308, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.48956871032714844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0550, 0.0149, 0.0024, 0.0237, 0.0221]) \n",
      "Test Loss tensor([0.0566, 0.0157, 0.0029, 0.0294, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.47536611557006836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0536, 0.0132, 0.0030, 0.0301, 0.0189]) \n",
      "Test Loss tensor([0.0548, 0.0150, 0.0030, 0.0302, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4766824245452881 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0509, 0.0158, 0.0032, 0.0306, 0.0217]) \n",
      "Test Loss tensor([0.0536, 0.0148, 0.0030, 0.0292, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4727354049682617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0571, 0.0159, 0.0025, 0.0295, 0.0222]) \n",
      "Test Loss tensor([0.0558, 0.0159, 0.0027, 0.0303, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.4722328186035156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0543, 0.0162, 0.0025, 0.0280, 0.0219]) \n",
      "Test Loss tensor([0.0547, 0.0145, 0.0030, 0.0293, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4712061882019043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0583, 0.0159, 0.0029, 0.0338, 0.0241]) \n",
      "Test Loss tensor([0.0550, 0.0150, 0.0030, 0.0299, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.477764368057251 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0532, 0.0144, 0.0028, 0.0321, 0.0228]) \n",
      "Test Loss tensor([0.0549, 0.0149, 0.0028, 0.0284, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47391438484191895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0510, 0.0146, 0.0027, 0.0268, 0.0203]) \n",
      "Test Loss tensor([0.0564, 0.0151, 0.0029, 0.0296, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.47225522994995117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0511, 0.0150, 0.0025, 0.0289, 0.0230]) \n",
      "Test Loss tensor([0.0558, 0.0147, 0.0028, 0.0294, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4720630645751953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0470, 0.0169, 0.0030, 0.0290, 0.0223]) \n",
      "Test Loss tensor([0.0554, 0.0145, 0.0030, 0.0293, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47330403327941895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0579, 0.0126, 0.0030, 0.0295, 0.0230]) \n",
      "Test Loss tensor([0.0548, 0.0151, 0.0028, 0.0290, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.47231459617614746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0556, 0.0140, 0.0030, 0.0306, 0.0238]) \n",
      "Test Loss tensor([0.0564, 0.0145, 0.0031, 0.0296, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4740777015686035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0524, 0.0152, 0.0027, 0.0284, 0.0217]) \n",
      "Test Loss tensor([0.0542, 0.0149, 0.0029, 0.0303, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4778602123260498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0517, 0.0124, 0.0029, 0.0311, 0.0234]) \n",
      "Test Loss tensor([0.0543, 0.0145, 0.0031, 0.0288, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.472825288772583 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0555, 0.0155, 0.0028, 0.0292, 0.0227]) \n",
      "Test Loss tensor([0.0547, 0.0146, 0.0031, 0.0295, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.47130298614501953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0491, 0.0153, 0.0033, 0.0326, 0.0198]) \n",
      "Test Loss tensor([0.0542, 0.0151, 0.0028, 0.0301, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47492146492004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0521, 0.0141, 0.0029, 0.0267, 0.0204]) \n",
      "Test Loss tensor([0.0540, 0.0152, 0.0029, 0.0299, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.472074031829834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0580, 0.0129, 0.0031, 0.0270, 0.0197]) \n",
      "Test Loss tensor([0.0550, 0.0143, 0.0029, 0.0289, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4712200164794922 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0544, 0.0134, 0.0030, 0.0333, 0.0213]) \n",
      "Test Loss tensor([0.0549, 0.0143, 0.0030, 0.0291, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47025060653686523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0479, 0.0150, 0.0030, 0.0264, 0.0180]) \n",
      "Test Loss tensor([0.0542, 0.0145, 0.0028, 0.0301, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4712636470794678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0553, 0.0167, 0.0029, 0.0292, 0.0225]) \n",
      "Test Loss tensor([0.0541, 0.0150, 0.0029, 0.0297, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4723522663116455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0484, 0.0150, 0.0033, 0.0274, 0.0199]) \n",
      "Test Loss tensor([0.0527, 0.0149, 0.0028, 0.0311, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4710683822631836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0511, 0.0151, 0.0028, 0.0338, 0.0213]) \n",
      "Test Loss tensor([0.0543, 0.0146, 0.0027, 0.0302, 0.0215])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 252 in 0.4722599983215332 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0490, 0.0145, 0.0029, 0.0318, 0.0201]) \n",
      "Test Loss tensor([0.0539, 0.0148, 0.0027, 0.0297, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47111082077026367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0522, 0.0143, 0.0026, 0.0291, 0.0198]) \n",
      "Test Loss tensor([0.0541, 0.0143, 0.0027, 0.0293, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.47237420082092285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0480, 0.0147, 0.0027, 0.0247, 0.0232]) \n",
      "Test Loss tensor([0.0540, 0.0151, 0.0029, 0.0290, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4696505069732666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0547, 0.0150, 0.0027, 0.0299, 0.0211]) \n",
      "Test Loss tensor([0.0548, 0.0150, 0.0028, 0.0285, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4727809429168701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0500, 0.0137, 0.0031, 0.0284, 0.0210]) \n",
      "Test Loss tensor([0.0527, 0.0143, 0.0028, 0.0291, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4714820384979248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0534, 0.0134, 0.0029, 0.0299, 0.0218]) \n",
      "Test Loss tensor([0.0536, 0.0152, 0.0029, 0.0294, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.47842931747436523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0530, 0.0153, 0.0026, 0.0273, 0.0201]) \n",
      "Test Loss tensor([0.0535, 0.0145, 0.0028, 0.0290, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4845874309539795 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0516, 0.0140, 0.0026, 0.0312, 0.0197]) \n",
      "Test Loss tensor([0.0519, 0.0159, 0.0028, 0.0281, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.473116397857666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0492, 0.0150, 0.0028, 0.0307, 0.0220]) \n",
      "Test Loss tensor([0.0534, 0.0146, 0.0031, 0.0295, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4741067886352539 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0534, 0.0153, 0.0030, 0.0290, 0.0202]) \n",
      "Test Loss tensor([0.0528, 0.0149, 0.0029, 0.0285, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4725780487060547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0535, 0.0134, 0.0029, 0.0296, 0.0201]) \n",
      "Test Loss tensor([0.0535, 0.0148, 0.0028, 0.0287, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47078776359558105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0543, 0.0174, 0.0026, 0.0286, 0.0200]) \n",
      "Test Loss tensor([0.0518, 0.0142, 0.0027, 0.0288, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.46971869468688965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0127, 0.0028, 0.0260, 0.0206]) \n",
      "Test Loss tensor([0.0547, 0.0145, 0.0028, 0.0285, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47161316871643066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0515, 0.0143, 0.0031, 0.0249, 0.0234]) \n",
      "Test Loss tensor([0.0528, 0.0146, 0.0028, 0.0293, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47368550300598145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0510, 0.0153, 0.0026, 0.0270, 0.0189]) \n",
      "Test Loss tensor([0.0528, 0.0144, 0.0026, 0.0296, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4724898338317871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0526, 0.0155, 0.0027, 0.0281, 0.0225]) \n",
      "Test Loss tensor([0.0537, 0.0143, 0.0027, 0.0285, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4724881649017334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0506, 0.0141, 0.0029, 0.0288, 0.0216]) \n",
      "Test Loss tensor([0.0524, 0.0149, 0.0029, 0.0286, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.472362756729126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0518, 0.0189, 0.0030, 0.0270, 0.0223]) \n",
      "Test Loss tensor([0.0519, 0.0144, 0.0029, 0.0279, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.48069286346435547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0516, 0.0123, 0.0028, 0.0300, 0.0183]) \n",
      "Test Loss tensor([0.0528, 0.0145, 0.0027, 0.0288, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.49141812324523926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0519, 0.0141, 0.0028, 0.0282, 0.0210]) \n",
      "Test Loss tensor([0.0523, 0.0151, 0.0030, 0.0292, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4717881679534912 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0521, 0.0148, 0.0029, 0.0278, 0.0210]) \n",
      "Test Loss tensor([0.0536, 0.0151, 0.0028, 0.0287, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47605371475219727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0562, 0.0127, 0.0032, 0.0303, 0.0226]) \n",
      "Test Loss tensor([0.0523, 0.0149, 0.0029, 0.0290, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.471329927444458 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0482, 0.0132, 0.0029, 0.0268, 0.0186]) \n",
      "Test Loss tensor([0.0524, 0.0148, 0.0028, 0.0294, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4732046127319336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0518, 0.0179, 0.0029, 0.0297, 0.0235]) \n",
      "Test Loss tensor([0.0515, 0.0140, 0.0027, 0.0300, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4700188636779785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0495, 0.0152, 0.0031, 0.0292, 0.0221]) \n",
      "Test Loss tensor([0.0541, 0.0149, 0.0030, 0.0282, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4829721450805664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0524, 0.0124, 0.0032, 0.0298, 0.0219]) \n",
      "Test Loss tensor([0.0521, 0.0150, 0.0030, 0.0277, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.47175168991088867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0495, 0.0128, 0.0030, 0.0261, 0.0185]) \n",
      "Test Loss tensor([0.0517, 0.0145, 0.0027, 0.0289, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4736049175262451 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0486, 0.0163, 0.0028, 0.0303, 0.0203]) \n",
      "Test Loss tensor([0.0533, 0.0145, 0.0028, 0.0285, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.47136998176574707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0505, 0.0176, 0.0026, 0.0257, 0.0205]) \n",
      "Test Loss tensor([0.0516, 0.0147, 0.0028, 0.0287, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4728066921234131 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0496, 0.0137, 0.0031, 0.0289, 0.0213]) \n",
      "Test Loss tensor([0.0519, 0.0151, 0.0030, 0.0287, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.47226691246032715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0494, 0.0134, 0.0028, 0.0272, 0.0179]) \n",
      "Test Loss tensor([0.0532, 0.0146, 0.0029, 0.0303, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4765605926513672 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0566, 0.0160, 0.0030, 0.0270, 0.0209]) \n",
      "Test Loss tensor([0.0521, 0.0153, 0.0030, 0.0276, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.47841787338256836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0503, 0.0143, 0.0024, 0.0259, 0.0184]) \n",
      "Test Loss tensor([0.0523, 0.0145, 0.0029, 0.0288, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.472562313079834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0472, 0.0152, 0.0033, 0.0274, 0.0222]) \n",
      "Test Loss tensor([0.0524, 0.0144, 0.0031, 0.0272, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4686465263366699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0490, 0.0136, 0.0035, 0.0300, 0.0209]) \n",
      "Test Loss tensor([0.0513, 0.0154, 0.0031, 0.0278, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.46883153915405273 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0488, 0.0130, 0.0031, 0.0302, 0.0242]) \n",
      "Test Loss tensor([0.0518, 0.0149, 0.0030, 0.0278, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4769899845123291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0569, 0.0126, 0.0032, 0.0275, 0.0204]) \n",
      "Test Loss tensor([0.0523, 0.0147, 0.0030, 0.0268, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4695899486541748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0509, 0.0127, 0.0034, 0.0272, 0.0212]) \n",
      "Test Loss tensor([0.0514, 0.0146, 0.0030, 0.0283, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4726083278656006 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0544, 0.0155, 0.0031, 0.0277, 0.0189]) \n",
      "Test Loss tensor([0.0519, 0.0135, 0.0030, 0.0282, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4706559181213379 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0559, 0.0151, 0.0028, 0.0253, 0.0222]) \n",
      "Test Loss tensor([0.0518, 0.0147, 0.0029, 0.0276, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47128796577453613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0471, 0.0154, 0.0028, 0.0270, 0.0204]) \n",
      "Test Loss tensor([0.0512, 0.0150, 0.0029, 0.0277, 0.0200])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 416 in 0.47083473205566406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0522, 0.0136, 0.0029, 0.0308, 0.0221]) \n",
      "Test Loss tensor([0.0507, 0.0149, 0.0029, 0.0283, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4778599739074707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0510, 0.0123, 0.0024, 0.0308, 0.0200]) \n",
      "Test Loss tensor([0.0519, 0.0148, 0.0029, 0.0276, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.47785305976867676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0461, 0.0150, 0.0031, 0.0317, 0.0213]) \n",
      "Test Loss tensor([0.0518, 0.0144, 0.0031, 0.0287, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4858970642089844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0519, 0.0144, 0.0031, 0.0260, 0.0212]) \n",
      "Test Loss tensor([0.0522, 0.0149, 0.0029, 0.0281, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4733083248138428 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0495, 0.0148, 0.0026, 0.0276, 0.0219]) \n",
      "Test Loss tensor([0.0507, 0.0148, 0.0027, 0.0285, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4728705883026123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0446, 0.0140, 0.0029, 0.0273, 0.0218]) \n",
      "Test Loss tensor([0.0514, 0.0147, 0.0027, 0.0289, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4772987365722656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0486, 0.0157, 0.0033, 0.0289, 0.0203]) \n",
      "Test Loss tensor([0.0509, 0.0140, 0.0029, 0.0283, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.48396825790405273 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0462, 0.0139, 0.0029, 0.0270, 0.0189]) \n",
      "Test Loss tensor([0.0516, 0.0148, 0.0030, 0.0275, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4853651523590088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0477, 0.0153, 0.0028, 0.0273, 0.0213]) \n",
      "Test Loss tensor([0.0517, 0.0148, 0.0029, 0.0274, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4746580123901367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0469, 0.0129, 0.0028, 0.0275, 0.0183]) \n",
      "Test Loss tensor([0.0522, 0.0139, 0.0026, 0.0292, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4754195213317871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0504, 0.0137, 0.0026, 0.0298, 0.0222]) \n",
      "Test Loss tensor([0.0512, 0.0148, 0.0029, 0.0275, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4754502773284912 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0492, 0.0150, 0.0028, 0.0302, 0.0189]) \n",
      "Test Loss tensor([0.0521, 0.0147, 0.0030, 0.0286, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4771153926849365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0465, 0.0136, 0.0028, 0.0279, 0.0173]) \n",
      "Test Loss tensor([0.0523, 0.0144, 0.0029, 0.0296, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4759821891784668 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0151, 0.0033, 0.0271, 0.0199]) \n",
      "Test Loss tensor([0.0529, 0.0148, 0.0027, 0.0286, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4724092483520508 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0525, 0.0149, 0.0027, 0.0325, 0.0209]) \n",
      "Test Loss tensor([0.0509, 0.0145, 0.0027, 0.0277, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4744553565979004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0512, 0.0142, 0.0026, 0.0272, 0.0166]) \n",
      "Test Loss tensor([0.0524, 0.0151, 0.0030, 0.0273, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4764750003814697 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0525, 0.0171, 0.0028, 0.0316, 0.0212]) \n",
      "Test Loss tensor([0.0506, 0.0141, 0.0028, 0.0284, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47130250930786133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0435, 0.0110, 0.0036, 0.0257, 0.0208]) \n",
      "Test Loss tensor([0.0509, 0.0147, 0.0027, 0.0295, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4732067584991455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0459, 0.0141, 0.0031, 0.0280, 0.0214]) \n",
      "Test Loss tensor([0.0514, 0.0145, 0.0027, 0.0279, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4745829105377197 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0507, 0.0145, 0.0026, 0.0293, 0.0207]) \n",
      "Test Loss tensor([0.0494, 0.0141, 0.0028, 0.0277, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47205281257629395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0487, 0.0129, 0.0027, 0.0307, 0.0211]) \n",
      "Test Loss tensor([0.0511, 0.0143, 0.0028, 0.0277, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4759995937347412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0470, 0.0146, 0.0024, 0.0278, 0.0191]) \n",
      "Test Loss tensor([0.0505, 0.0142, 0.0027, 0.0273, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.47480010986328125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0534, 0.0166, 0.0025, 0.0326, 0.0164]) \n",
      "Test Loss tensor([0.0521, 0.0145, 0.0027, 0.0265, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.471773624420166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0464, 0.0132, 0.0024, 0.0247, 0.0195]) \n",
      "Test Loss tensor([0.0521, 0.0145, 0.0026, 0.0271, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47137880325317383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0514, 0.0156, 0.0024, 0.0272, 0.0192]) \n",
      "Test Loss tensor([0.0498, 0.0138, 0.0026, 0.0268, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.47629857063293457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0505, 0.0119, 0.0025, 0.0263, 0.0216]) \n",
      "Test Loss tensor([0.0502, 0.0143, 0.0027, 0.0272, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.470334529876709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0477, 0.0132, 0.0028, 0.0289, 0.0215]) \n",
      "Test Loss tensor([0.0509, 0.0143, 0.0027, 0.0273, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4764857292175293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0459, 0.0162, 0.0032, 0.0253, 0.0213]) \n",
      "Test Loss tensor([0.0514, 0.0146, 0.0027, 0.0282, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47173500061035156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0484, 0.0140, 0.0027, 0.0264, 0.0199]) \n",
      "Test Loss tensor([0.0502, 0.0140, 0.0028, 0.0284, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.47249293327331543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0504, 0.0155, 0.0030, 0.0320, 0.0229]) \n",
      "Test Loss tensor([0.0516, 0.0146, 0.0029, 0.0276, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.47447776794433594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0471, 0.0149, 0.0029, 0.0264, 0.0196]) \n",
      "Test Loss tensor([0.0493, 0.0135, 0.0029, 0.0280, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4742422103881836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0508, 0.0137, 0.0028, 0.0296, 0.0207]) \n",
      "Test Loss tensor([0.0485, 0.0145, 0.0028, 0.0278, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4746391773223877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0459, 0.0141, 0.0027, 0.0253, 0.0195]) \n",
      "Test Loss tensor([0.0506, 0.0145, 0.0031, 0.0279, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4698185920715332 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0497, 0.0125, 0.0029, 0.0250, 0.0179]) \n",
      "Test Loss tensor([0.0509, 0.0143, 0.0029, 0.0274, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.47460055351257324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0489, 0.0138, 0.0028, 0.0258, 0.0190]) \n",
      "Test Loss tensor([0.0517, 0.0139, 0.0030, 0.0277, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4755373001098633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0524, 0.0163, 0.0029, 0.0292, 0.0198]) \n",
      "Test Loss tensor([0.0508, 0.0136, 0.0028, 0.0266, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4724705219268799 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0546, 0.0128, 0.0027, 0.0276, 0.0219]) \n",
      "Test Loss tensor([0.0504, 0.0142, 0.0028, 0.0280, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4712190628051758 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0470, 0.0155, 0.0035, 0.0276, 0.0174]) \n",
      "Test Loss tensor([0.0500, 0.0139, 0.0029, 0.0277, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4729635715484619 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0493, 0.0147, 0.0026, 0.0301, 0.0175]) \n",
      "Test Loss tensor([0.0497, 0.0141, 0.0028, 0.0271, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4742896556854248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0511, 0.0146, 0.0026, 0.0295, 0.0202]) \n",
      "Test Loss tensor([0.0512, 0.0142, 0.0028, 0.0272, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4735105037689209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0465, 0.0130, 0.0029, 0.0274, 0.0167]) \n",
      "Test Loss tensor([0.0496, 0.0141, 0.0029, 0.0274, 0.0193])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 580 in 0.47707033157348633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0493, 0.0128, 0.0025, 0.0264, 0.0180]) \n",
      "Test Loss tensor([0.0516, 0.0144, 0.0030, 0.0283, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.47472381591796875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0483, 0.0133, 0.0030, 0.0271, 0.0208]) \n",
      "Test Loss tensor([0.0506, 0.0143, 0.0027, 0.0266, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47454214096069336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0122, 0.0026, 0.0262, 0.0210]) \n",
      "Test Loss tensor([0.0494, 0.0144, 0.0027, 0.0297, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47453927993774414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0522, 0.0132, 0.0027, 0.0288, 0.0212]) \n",
      "Test Loss tensor([0.0506, 0.0143, 0.0028, 0.0266, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.47771739959716797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0516, 0.0148, 0.0025, 0.0259, 0.0188]) \n",
      "Test Loss tensor([0.0492, 0.0143, 0.0027, 0.0276, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47337818145751953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0482, 0.0123, 0.0028, 0.0279, 0.0222]) \n",
      "Test Loss tensor([0.0512, 0.0138, 0.0026, 0.0278, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4760923385620117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0510, 0.0152, 0.0023, 0.0257, 0.0207]) \n",
      "Test Loss tensor([0.0520, 0.0139, 0.0026, 0.0279, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4884488582611084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0484, 0.0126, 0.0026, 0.0242, 0.0210]) \n",
      "Test Loss tensor([0.0488, 0.0140, 0.0028, 0.0276, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4846372604370117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0478, 0.0151, 0.0029, 0.0265, 0.0175]) \n",
      "Test Loss tensor([0.0512, 0.0144, 0.0031, 0.0274, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4864082336425781 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0564, 0.0130, 0.0029, 0.0266, 0.0197]) \n",
      "Test Loss tensor([0.0494, 0.0138, 0.0029, 0.0255, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4766218662261963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0504, 0.0148, 0.0032, 0.0261, 0.0183]) \n",
      "Test Loss tensor([0.0500, 0.0145, 0.0028, 0.0273, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4751887321472168 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0559, 0.0170, 0.0031, 0.0266, 0.0207]) \n",
      "Test Loss tensor([0.0500, 0.0139, 0.0031, 0.0274, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47525787353515625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0536, 0.0154, 0.0031, 0.0267, 0.0188]) \n",
      "Test Loss tensor([0.0513, 0.0139, 0.0031, 0.0270, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4754054546356201 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0532, 0.0174, 0.0039, 0.0297, 0.0202]) \n",
      "Test Loss tensor([0.0492, 0.0140, 0.0029, 0.0263, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4742543697357178 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0488, 0.0152, 0.0032, 0.0250, 0.0203]) \n",
      "Test Loss tensor([0.0500, 0.0142, 0.0029, 0.0279, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4751293659210205 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0509, 0.0153, 0.0025, 0.0312, 0.0199]) \n",
      "Test Loss tensor([0.0498, 0.0143, 0.0031, 0.0266, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4749422073364258 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0511, 0.0148, 0.0031, 0.0282, 0.0208]) \n",
      "Test Loss tensor([0.0494, 0.0143, 0.0030, 0.0268, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4779684543609619 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0490, 0.0111, 0.0029, 0.0254, 0.0202]) \n",
      "Test Loss tensor([0.0497, 0.0144, 0.0028, 0.0281, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4789302349090576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0512, 0.0174, 0.0027, 0.0308, 0.0220]) \n",
      "Test Loss tensor([0.0494, 0.0141, 0.0030, 0.0268, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4763813018798828 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0467, 0.0149, 0.0033, 0.0252, 0.0165]) \n",
      "Test Loss tensor([0.0512, 0.0139, 0.0031, 0.0285, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4845881462097168 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0487, 0.0133, 0.0031, 0.0269, 0.0188]) \n",
      "Test Loss tensor([0.0500, 0.0130, 0.0028, 0.0275, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4848611354827881 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0492, 0.0153, 0.0025, 0.0244, 0.0210]) \n",
      "Test Loss tensor([0.0493, 0.0136, 0.0028, 0.0266, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47237181663513184 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0457, 0.0137, 0.0027, 0.0267, 0.0200]) \n",
      "Test Loss tensor([0.0513, 0.0135, 0.0030, 0.0288, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4818096160888672 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0514, 0.0133, 0.0032, 0.0312, 0.0169]) \n",
      "Test Loss tensor([0.0484, 0.0133, 0.0029, 0.0289, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4747128486633301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0445, 0.0125, 0.0029, 0.0244, 0.0210]) \n",
      "Test Loss tensor([0.0482, 0.0141, 0.0028, 0.0281, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4776573181152344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0139, 0.0031, 0.0272, 0.0184]) \n",
      "Test Loss tensor([0.0504, 0.0137, 0.0029, 0.0266, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4751741886138916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0502, 0.0121, 0.0030, 0.0272, 0.0198]) \n",
      "Test Loss tensor([0.0502, 0.0136, 0.0029, 0.0287, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.49802565574645996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0142, 0.0030, 0.0292, 0.0205]) \n",
      "Test Loss tensor([0.0501, 0.0141, 0.0031, 0.0275, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.48380184173583984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0497, 0.0125, 0.0026, 0.0268, 0.0184]) \n",
      "Test Loss tensor([0.0488, 0.0142, 0.0026, 0.0273, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4726436138153076 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0132, 0.0027, 0.0272, 0.0206]) \n",
      "Test Loss tensor([0.0501, 0.0136, 0.0026, 0.0304, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4938082695007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0491, 0.0152, 0.0024, 0.0286, 0.0230]) \n",
      "Test Loss tensor([0.0491, 0.0146, 0.0029, 0.0259, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4727330207824707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0489, 0.0142, 0.0033, 0.0261, 0.0191]) \n",
      "Test Loss tensor([0.0502, 0.0137, 0.0031, 0.0285, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.47036170959472656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0490, 0.0155, 0.0029, 0.0296, 0.0171]) \n",
      "Test Loss tensor([0.0490, 0.0135, 0.0028, 0.0281, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4775996208190918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0508, 0.0135, 0.0027, 0.0272, 0.0180]) \n",
      "Test Loss tensor([0.0494, 0.0138, 0.0028, 0.0276, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.47643613815307617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0485, 0.0129, 0.0029, 0.0319, 0.0202]) \n",
      "Test Loss tensor([0.0487, 0.0138, 0.0028, 0.0266, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47620725631713867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0492, 0.0137, 0.0028, 0.0244, 0.0211]) \n",
      "Test Loss tensor([0.0509, 0.0142, 0.0030, 0.0275, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4904749393463135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0139, 0.0025, 0.0257, 0.0228]) \n",
      "Test Loss tensor([0.0491, 0.0137, 0.0028, 0.0270, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4736618995666504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0476, 0.0136, 0.0025, 0.0256, 0.0185]) \n",
      "Test Loss tensor([0.0479, 0.0138, 0.0026, 0.0276, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4733426570892334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0471, 0.0128, 0.0025, 0.0269, 0.0171]) \n",
      "Test Loss tensor([0.0496, 0.0139, 0.0027, 0.0275, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4756629467010498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0499, 0.0124, 0.0031, 0.0240, 0.0197]) \n",
      "Test Loss tensor([0.0492, 0.0137, 0.0028, 0.0258, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4720275402069092 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0133, 0.0031, 0.0274, 0.0223]) \n",
      "Test Loss tensor([0.0475, 0.0140, 0.0027, 0.0278, 0.0194])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 744 in 0.470966100692749 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0459, 0.0105, 0.0026, 0.0283, 0.0184]) \n",
      "Test Loss tensor([0.0484, 0.0140, 0.0027, 0.0263, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.47438693046569824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0461, 0.0139, 0.0034, 0.0285, 0.0173]) \n",
      "Test Loss tensor([0.0492, 0.0136, 0.0029, 0.0274, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4727046489715576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0497, 0.0164, 0.0027, 0.0262, 0.0183]) \n",
      "Test Loss tensor([0.0477, 0.0139, 0.0027, 0.0269, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.47547030448913574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0460, 0.0138, 0.0033, 0.0295, 0.0167]) \n",
      "Test Loss tensor([0.0495, 0.0142, 0.0028, 0.0263, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47183728218078613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0479, 0.0112, 0.0025, 0.0236, 0.0187]) \n",
      "Test Loss tensor([0.0487, 0.0132, 0.0030, 0.0276, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47636985778808594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0522, 0.0144, 0.0029, 0.0273, 0.0211]) \n",
      "Test Loss tensor([0.0477, 0.0135, 0.0028, 0.0276, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4765610694885254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0432, 0.0118, 0.0028, 0.0253, 0.0165]) \n",
      "Test Loss tensor([0.0462, 0.0132, 0.0027, 0.0269, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.47762179374694824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0521, 0.0153, 0.0030, 0.0284, 0.0220]) \n",
      "Test Loss tensor([0.0484, 0.0130, 0.0027, 0.0267, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4714360237121582 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0482, 0.0141, 0.0024, 0.0274, 0.0205]) \n",
      "Test Loss tensor([0.0476, 0.0133, 0.0027, 0.0257, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4823935031890869 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0502, 0.0160, 0.0028, 0.0243, 0.0173]) \n",
      "Test Loss tensor([0.0487, 0.0136, 0.0029, 0.0265, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4840366840362549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0513, 0.0145, 0.0026, 0.0242, 0.0191]) \n",
      "Test Loss tensor([0.0483, 0.0133, 0.0029, 0.0261, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47440195083618164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0457, 0.0150, 0.0028, 0.0260, 0.0182]) \n",
      "Test Loss tensor([0.0483, 0.0137, 0.0030, 0.0268, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47489380836486816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0117, 0.0025, 0.0268, 0.0179]) \n",
      "Test Loss tensor([0.0481, 0.0137, 0.0031, 0.0264, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4745492935180664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0456, 0.0147, 0.0026, 0.0258, 0.0167]) \n",
      "Test Loss tensor([0.0488, 0.0139, 0.0031, 0.0260, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.47640347480773926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0519, 0.0140, 0.0032, 0.0267, 0.0212]) \n",
      "Test Loss tensor([0.0473, 0.0132, 0.0028, 0.0264, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.48166751861572266 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0498, 0.0123, 0.0028, 0.0248, 0.0216]) \n",
      "Test Loss tensor([0.0474, 0.0140, 0.0029, 0.0263, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4761343002319336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0520, 0.0117, 0.0029, 0.0293, 0.0202]) \n",
      "Test Loss tensor([0.0482, 0.0140, 0.0029, 0.0263, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47769808769226074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0503, 0.0141, 0.0026, 0.0277, 0.0174]) \n",
      "Test Loss tensor([0.0468, 0.0137, 0.0029, 0.0266, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4731590747833252 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0455, 0.0155, 0.0033, 0.0248, 0.0180]) \n",
      "Test Loss tensor([0.0471, 0.0140, 0.0029, 0.0256, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.4729025363922119 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0451, 0.0131, 0.0029, 0.0248, 0.0184]) \n",
      "Test Loss tensor([0.0484, 0.0132, 0.0029, 0.0261, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4698629379272461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0498, 0.0137, 0.0026, 0.0286, 0.0164]) \n",
      "Test Loss tensor([0.0482, 0.0135, 0.0028, 0.0258, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4694695472717285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0524, 0.0138, 0.0027, 0.0299, 0.0211]) \n",
      "Test Loss tensor([0.0497, 0.0135, 0.0026, 0.0273, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47345757484436035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0116, 0.0024, 0.0270, 0.0171]) \n",
      "Test Loss tensor([0.0477, 0.0143, 0.0027, 0.0263, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4712984561920166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0479, 0.0129, 0.0027, 0.0236, 0.0202]) \n",
      "Test Loss tensor([0.0488, 0.0141, 0.0028, 0.0263, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4743170738220215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0448, 0.0134, 0.0028, 0.0318, 0.0199]) \n",
      "Test Loss tensor([0.0483, 0.0132, 0.0027, 0.0268, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4708385467529297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0429, 0.0141, 0.0023, 0.0291, 0.0198]) \n",
      "Test Loss tensor([0.0478, 0.0141, 0.0026, 0.0267, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4742095470428467 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0502, 0.0130, 0.0024, 0.0250, 0.0208]) \n",
      "Test Loss tensor([0.0475, 0.0139, 0.0028, 0.0273, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4730715751647949 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0435, 0.0135, 0.0027, 0.0289, 0.0215]) \n",
      "Test Loss tensor([0.0496, 0.0140, 0.0029, 0.0264, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47188472747802734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0467, 0.0148, 0.0032, 0.0248, 0.0191]) \n",
      "Test Loss tensor([0.0483, 0.0138, 0.0027, 0.0254, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4711575508117676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0137, 0.0028, 0.0235, 0.0193]) \n",
      "Test Loss tensor([0.0470, 0.0133, 0.0027, 0.0283, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47360849380493164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0138, 0.0025, 0.0260, 0.0230]) \n",
      "Test Loss tensor([0.0475, 0.0137, 0.0028, 0.0259, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47037792205810547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0093, 0.0025, 0.0287, 0.0155]) \n",
      "Test Loss tensor([0.0487, 0.0130, 0.0028, 0.0270, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4741098880767822 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0119, 0.0025, 0.0268, 0.0200]) \n",
      "Test Loss tensor([0.0465, 0.0131, 0.0028, 0.0267, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4538130760192871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0087, 0.0019, 0.0187, 0.0152]) \n",
      "Test Loss tensor([0.0473, 0.0130, 0.0027, 0.0259, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5148732662200928 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0442, 0.0131, 0.0025, 0.0238, 0.0205]) \n",
      "Test Loss tensor([0.0468, 0.0131, 0.0028, 0.0250, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.47248005867004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0497, 0.0137, 0.0030, 0.0283, 0.0185]) \n",
      "Test Loss tensor([0.0468, 0.0132, 0.0027, 0.0268, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47774648666381836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0122, 0.0028, 0.0278, 0.0179]) \n",
      "Test Loss tensor([0.0464, 0.0135, 0.0029, 0.0270, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4751725196838379 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0150, 0.0029, 0.0255, 0.0183]) \n",
      "Test Loss tensor([0.0471, 0.0133, 0.0030, 0.0257, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.473618745803833 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0136, 0.0030, 0.0242, 0.0188]) \n",
      "Test Loss tensor([0.0478, 0.0138, 0.0030, 0.0264, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4712862968444824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0150, 0.0029, 0.0266, 0.0184]) \n",
      "Test Loss tensor([0.0476, 0.0132, 0.0029, 0.0265, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47107481956481934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0480, 0.0142, 0.0028, 0.0259, 0.0181]) \n",
      "Test Loss tensor([0.0476, 0.0133, 0.0029, 0.0274, 0.0183])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 28 in 0.4708118438720703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0127, 0.0030, 0.0250, 0.0212]) \n",
      "Test Loss tensor([0.0477, 0.0138, 0.0031, 0.0270, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4722723960876465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0481, 0.0126, 0.0029, 0.0265, 0.0220]) \n",
      "Test Loss tensor([0.0461, 0.0136, 0.0032, 0.0283, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.47136497497558594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0109, 0.0028, 0.0246, 0.0170]) \n",
      "Test Loss tensor([0.0480, 0.0135, 0.0028, 0.0256, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.47232675552368164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0458, 0.0116, 0.0032, 0.0284, 0.0175]) \n",
      "Test Loss tensor([0.0460, 0.0137, 0.0029, 0.0266, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4707145690917969 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0421, 0.0135, 0.0027, 0.0233, 0.0189]) \n",
      "Test Loss tensor([0.0476, 0.0129, 0.0030, 0.0265, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.469463586807251 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0489, 0.0127, 0.0032, 0.0327, 0.0188]) \n",
      "Test Loss tensor([0.0467, 0.0133, 0.0029, 0.0276, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47150683403015137 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0429, 0.0132, 0.0030, 0.0284, 0.0204]) \n",
      "Test Loss tensor([0.0484, 0.0133, 0.0027, 0.0267, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4691643714904785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0466, 0.0111, 0.0025, 0.0278, 0.0204]) \n",
      "Test Loss tensor([0.0471, 0.0134, 0.0028, 0.0258, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4734675884246826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0460, 0.0143, 0.0028, 0.0276, 0.0173]) \n",
      "Test Loss tensor([0.0481, 0.0131, 0.0029, 0.0266, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.47179388999938965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0467, 0.0120, 0.0025, 0.0264, 0.0183]) \n",
      "Test Loss tensor([0.0464, 0.0126, 0.0028, 0.0265, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4778025150299072 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0160, 0.0033, 0.0269, 0.0232]) \n",
      "Test Loss tensor([0.0463, 0.0134, 0.0027, 0.0267, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.47942352294921875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0476, 0.0146, 0.0027, 0.0259, 0.0208]) \n",
      "Test Loss tensor([0.0474, 0.0131, 0.0027, 0.0264, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.47347474098205566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0448, 0.0114, 0.0024, 0.0292, 0.0190]) \n",
      "Test Loss tensor([0.0471, 0.0132, 0.0028, 0.0255, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.47092270851135254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0488, 0.0128, 0.0030, 0.0237, 0.0181]) \n",
      "Test Loss tensor([0.0469, 0.0128, 0.0026, 0.0257, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4715113639831543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0444, 0.0104, 0.0028, 0.0265, 0.0189]) \n",
      "Test Loss tensor([0.0463, 0.0125, 0.0026, 0.0265, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4714999198913574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0451, 0.0117, 0.0029, 0.0236, 0.0170]) \n",
      "Test Loss tensor([0.0479, 0.0136, 0.0027, 0.0264, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4705057144165039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0455, 0.0122, 0.0030, 0.0302, 0.0188]) \n",
      "Test Loss tensor([0.0465, 0.0122, 0.0027, 0.0271, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47019457817077637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0461, 0.0168, 0.0025, 0.0256, 0.0177]) \n",
      "Test Loss tensor([0.0465, 0.0134, 0.0028, 0.0255, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47160792350769043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0495, 0.0135, 0.0025, 0.0215, 0.0192]) \n",
      "Test Loss tensor([0.0461, 0.0133, 0.0027, 0.0251, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47091245651245117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0510, 0.0129, 0.0028, 0.0248, 0.0182]) \n",
      "Test Loss tensor([0.0474, 0.0124, 0.0026, 0.0266, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.47119665145874023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0464, 0.0114, 0.0025, 0.0225, 0.0175]) \n",
      "Test Loss tensor([0.0471, 0.0126, 0.0027, 0.0262, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.46996378898620605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0486, 0.0134, 0.0028, 0.0301, 0.0204]) \n",
      "Test Loss tensor([0.0466, 0.0128, 0.0027, 0.0259, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4707601070404053 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0461, 0.0127, 0.0026, 0.0258, 0.0152]) \n",
      "Test Loss tensor([0.0470, 0.0129, 0.0029, 0.0264, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4743032455444336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0454, 0.0118, 0.0029, 0.0231, 0.0198]) \n",
      "Test Loss tensor([0.0467, 0.0131, 0.0028, 0.0250, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.46804285049438477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0132, 0.0027, 0.0257, 0.0187]) \n",
      "Test Loss tensor([0.0458, 0.0133, 0.0029, 0.0265, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.47200465202331543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0476, 0.0133, 0.0029, 0.0277, 0.0192]) \n",
      "Test Loss tensor([0.0466, 0.0133, 0.0028, 0.0254, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.46822214126586914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0462, 0.0130, 0.0024, 0.0266, 0.0158]) \n",
      "Test Loss tensor([0.0454, 0.0131, 0.0028, 0.0247, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4725944995880127 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0142, 0.0030, 0.0270, 0.0192]) \n",
      "Test Loss tensor([0.0455, 0.0129, 0.0029, 0.0248, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4706282615661621 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0433, 0.0131, 0.0029, 0.0223, 0.0160]) \n",
      "Test Loss tensor([0.0458, 0.0133, 0.0028, 0.0250, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4702913761138916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0137, 0.0027, 0.0252, 0.0196]) \n",
      "Test Loss tensor([0.0457, 0.0128, 0.0027, 0.0258, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4718739986419678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0458, 0.0139, 0.0024, 0.0255, 0.0199]) \n",
      "Test Loss tensor([0.0482, 0.0132, 0.0029, 0.0258, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4720926284790039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0109, 0.0025, 0.0263, 0.0181]) \n",
      "Test Loss tensor([0.0466, 0.0135, 0.0028, 0.0258, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47113823890686035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0125, 0.0027, 0.0251, 0.0183]) \n",
      "Test Loss tensor([0.0458, 0.0132, 0.0028, 0.0251, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4710063934326172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0480, 0.0120, 0.0028, 0.0236, 0.0195]) \n",
      "Test Loss tensor([0.0471, 0.0133, 0.0028, 0.0262, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4712512493133545 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0136, 0.0025, 0.0268, 0.0222]) \n",
      "Test Loss tensor([0.0462, 0.0127, 0.0029, 0.0259, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.47190284729003906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0128, 0.0029, 0.0254, 0.0176]) \n",
      "Test Loss tensor([0.0480, 0.0129, 0.0029, 0.0265, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4731011390686035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0141, 0.0035, 0.0235, 0.0190]) \n",
      "Test Loss tensor([0.0468, 0.0129, 0.0027, 0.0266, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.4713313579559326 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0422, 0.0145, 0.0023, 0.0283, 0.0193]) \n",
      "Test Loss tensor([0.0474, 0.0131, 0.0028, 0.0260, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.47105932235717773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0148, 0.0026, 0.0235, 0.0229]) \n",
      "Test Loss tensor([0.0465, 0.0136, 0.0029, 0.0252, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4699094295501709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0471, 0.0122, 0.0026, 0.0273, 0.0180]) \n",
      "Test Loss tensor([0.0468, 0.0127, 0.0028, 0.0257, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4744229316711426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0145, 0.0032, 0.0223, 0.0164]) \n",
      "Test Loss tensor([0.0453, 0.0127, 0.0028, 0.0266, 0.0180])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 192 in 0.4706110954284668 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0142, 0.0022, 0.0238, 0.0152]) \n",
      "Test Loss tensor([0.0463, 0.0132, 0.0028, 0.0264, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4730243682861328 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0409, 0.0124, 0.0027, 0.0254, 0.0197]) \n",
      "Test Loss tensor([0.0453, 0.0127, 0.0028, 0.0256, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4693629741668701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0513, 0.0112, 0.0028, 0.0277, 0.0193]) \n",
      "Test Loss tensor([0.0448, 0.0130, 0.0028, 0.0257, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.47337961196899414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0475, 0.0134, 0.0030, 0.0267, 0.0194]) \n",
      "Test Loss tensor([0.0453, 0.0133, 0.0029, 0.0261, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4805293083190918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0431, 0.0141, 0.0028, 0.0286, 0.0153]) \n",
      "Test Loss tensor([0.0465, 0.0130, 0.0028, 0.0263, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.47087955474853516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0136, 0.0024, 0.0231, 0.0181]) \n",
      "Test Loss tensor([0.0455, 0.0131, 0.0028, 0.0255, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4725172519683838 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0123, 0.0027, 0.0248, 0.0163]) \n",
      "Test Loss tensor([0.0455, 0.0130, 0.0028, 0.0245, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.47215723991394043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0143, 0.0029, 0.0255, 0.0159]) \n",
      "Test Loss tensor([0.0452, 0.0134, 0.0030, 0.0251, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47372961044311523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0426, 0.0099, 0.0024, 0.0237, 0.0179]) \n",
      "Test Loss tensor([0.0449, 0.0125, 0.0029, 0.0257, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.47295546531677246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0120, 0.0030, 0.0242, 0.0172]) \n",
      "Test Loss tensor([0.0451, 0.0127, 0.0028, 0.0260, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4711928367614746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0138, 0.0032, 0.0223, 0.0184]) \n",
      "Test Loss tensor([0.0450, 0.0128, 0.0029, 0.0250, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47719311714172363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0478, 0.0141, 0.0026, 0.0262, 0.0162]) \n",
      "Test Loss tensor([0.0458, 0.0126, 0.0031, 0.0259, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.486034631729126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0515, 0.0131, 0.0036, 0.0264, 0.0160]) \n",
      "Test Loss tensor([0.0452, 0.0133, 0.0029, 0.0250, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.47519969940185547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0446, 0.0143, 0.0030, 0.0276, 0.0175]) \n",
      "Test Loss tensor([0.0448, 0.0124, 0.0029, 0.0264, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4736757278442383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0433, 0.0138, 0.0031, 0.0233, 0.0201]) \n",
      "Test Loss tensor([0.0460, 0.0123, 0.0028, 0.0262, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4731612205505371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0486, 0.0125, 0.0025, 0.0248, 0.0220]) \n",
      "Test Loss tensor([0.0456, 0.0126, 0.0030, 0.0258, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4743325710296631 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0115, 0.0032, 0.0290, 0.0177]) \n",
      "Test Loss tensor([0.0450, 0.0125, 0.0028, 0.0254, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.47039055824279785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0431, 0.0123, 0.0032, 0.0241, 0.0167]) \n",
      "Test Loss tensor([0.0442, 0.0132, 0.0029, 0.0259, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.47196149826049805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0114, 0.0027, 0.0240, 0.0169]) \n",
      "Test Loss tensor([0.0449, 0.0132, 0.0028, 0.0256, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.47443175315856934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0123, 0.0030, 0.0253, 0.0160]) \n",
      "Test Loss tensor([0.0444, 0.0130, 0.0029, 0.0274, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.47417378425598145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0482, 0.0124, 0.0032, 0.0268, 0.0208]) \n",
      "Test Loss tensor([0.0457, 0.0127, 0.0027, 0.0257, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4716761112213135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0489, 0.0110, 0.0029, 0.0249, 0.0162]) \n",
      "Test Loss tensor([0.0455, 0.0128, 0.0027, 0.0259, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4737889766693115 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0422, 0.0123, 0.0026, 0.0231, 0.0160]) \n",
      "Test Loss tensor([0.0439, 0.0124, 0.0028, 0.0259, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.47035670280456543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0130, 0.0027, 0.0279, 0.0199]) \n",
      "Test Loss tensor([0.0461, 0.0127, 0.0028, 0.0270, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.47475290298461914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0496, 0.0140, 0.0030, 0.0271, 0.0173]) \n",
      "Test Loss tensor([0.0453, 0.0126, 0.0028, 0.0250, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4751110076904297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0117, 0.0029, 0.0284, 0.0183]) \n",
      "Test Loss tensor([0.0446, 0.0123, 0.0027, 0.0256, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47597670555114746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0133, 0.0026, 0.0253, 0.0177]) \n",
      "Test Loss tensor([0.0443, 0.0126, 0.0027, 0.0256, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4748270511627197 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0441, 0.0114, 0.0024, 0.0258, 0.0166]) \n",
      "Test Loss tensor([0.0455, 0.0124, 0.0028, 0.0253, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47417235374450684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0135, 0.0026, 0.0252, 0.0188]) \n",
      "Test Loss tensor([0.0463, 0.0134, 0.0027, 0.0244, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47165918350219727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0139, 0.0026, 0.0245, 0.0201]) \n",
      "Test Loss tensor([0.0456, 0.0136, 0.0027, 0.0258, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4723238945007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0474, 0.0138, 0.0027, 0.0243, 0.0188]) \n",
      "Test Loss tensor([0.0459, 0.0132, 0.0029, 0.0248, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.47113609313964844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0128, 0.0028, 0.0254, 0.0170]) \n",
      "Test Loss tensor([0.0456, 0.0128, 0.0027, 0.0248, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4715266227722168 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0124, 0.0029, 0.0262, 0.0155]) \n",
      "Test Loss tensor([0.0455, 0.0130, 0.0026, 0.0256, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4704864025115967 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0486, 0.0140, 0.0026, 0.0255, 0.0181]) \n",
      "Test Loss tensor([0.0451, 0.0130, 0.0028, 0.0246, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.473757266998291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0466, 0.0128, 0.0025, 0.0237, 0.0198]) \n",
      "Test Loss tensor([0.0453, 0.0131, 0.0029, 0.0267, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4720890522003174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0137, 0.0026, 0.0254, 0.0199]) \n",
      "Test Loss tensor([0.0440, 0.0134, 0.0028, 0.0250, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.46999454498291016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0136, 0.0031, 0.0226, 0.0172]) \n",
      "Test Loss tensor([0.0448, 0.0129, 0.0026, 0.0262, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.47423720359802246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0456, 0.0152, 0.0027, 0.0262, 0.0175]) \n",
      "Test Loss tensor([0.0452, 0.0134, 0.0028, 0.0260, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47161388397216797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0441, 0.0140, 0.0027, 0.0246, 0.0194]) \n",
      "Test Loss tensor([0.0466, 0.0133, 0.0030, 0.0260, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47333431243896484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0480, 0.0121, 0.0029, 0.0243, 0.0170]) \n",
      "Test Loss tensor([0.0439, 0.0135, 0.0028, 0.0244, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5050511360168457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0126, 0.0026, 0.0235, 0.0175]) \n",
      "Test Loss tensor([0.0463, 0.0132, 0.0026, 0.0260, 0.0183])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 356 in 0.4734022617340088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0481, 0.0118, 0.0025, 0.0251, 0.0196]) \n",
      "Test Loss tensor([0.0443, 0.0130, 0.0029, 0.0256, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5003206729888916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0134, 0.0029, 0.0249, 0.0183]) \n",
      "Test Loss tensor([0.0450, 0.0127, 0.0030, 0.0265, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.478848934173584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0463, 0.0111, 0.0030, 0.0259, 0.0185]) \n",
      "Test Loss tensor([0.0442, 0.0126, 0.0028, 0.0254, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.47051525115966797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0370, 0.0127, 0.0027, 0.0229, 0.0158]) \n",
      "Test Loss tensor([0.0456, 0.0133, 0.0028, 0.0261, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.47449636459350586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0484, 0.0132, 0.0026, 0.0272, 0.0163]) \n",
      "Test Loss tensor([0.0450, 0.0126, 0.0028, 0.0243, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4722285270690918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0463, 0.0135, 0.0028, 0.0262, 0.0161]) \n",
      "Test Loss tensor([0.0447, 0.0127, 0.0029, 0.0251, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4740586280822754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0118, 0.0025, 0.0259, 0.0147]) \n",
      "Test Loss tensor([0.0455, 0.0127, 0.0029, 0.0252, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4809558391571045 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0133, 0.0026, 0.0264, 0.0172]) \n",
      "Test Loss tensor([0.0440, 0.0130, 0.0028, 0.0252, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.47684288024902344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0413, 0.0111, 0.0027, 0.0226, 0.0177]) \n",
      "Test Loss tensor([0.0447, 0.0128, 0.0029, 0.0253, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.47159242630004883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0446, 0.0138, 0.0030, 0.0262, 0.0154]) \n",
      "Test Loss tensor([0.0443, 0.0121, 0.0029, 0.0251, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4906303882598877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0121, 0.0025, 0.0241, 0.0187]) \n",
      "Test Loss tensor([0.0448, 0.0124, 0.0029, 0.0246, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4711318016052246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0113, 0.0027, 0.0264, 0.0162]) \n",
      "Test Loss tensor([0.0438, 0.0127, 0.0027, 0.0257, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4782226085662842 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0127, 0.0028, 0.0245, 0.0174]) \n",
      "Test Loss tensor([0.0450, 0.0131, 0.0029, 0.0255, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.48403024673461914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0431, 0.0126, 0.0026, 0.0238, 0.0176]) \n",
      "Test Loss tensor([0.0454, 0.0124, 0.0027, 0.0256, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4741854667663574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0439, 0.0118, 0.0026, 0.0241, 0.0172]) \n",
      "Test Loss tensor([0.0469, 0.0131, 0.0026, 0.0255, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.47153782844543457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0406, 0.0107, 0.0027, 0.0249, 0.0188]) \n",
      "Test Loss tensor([0.0441, 0.0130, 0.0027, 0.0245, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4703497886657715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0456, 0.0125, 0.0025, 0.0279, 0.0162]) \n",
      "Test Loss tensor([0.0477, 0.0126, 0.0031, 0.0279, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4707200527191162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0485, 0.0112, 0.0025, 0.0266, 0.0204]) \n",
      "Test Loss tensor([0.0444, 0.0125, 0.0028, 0.0250, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4700336456298828 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0115, 0.0028, 0.0234, 0.0176]) \n",
      "Test Loss tensor([0.0483, 0.0134, 0.0026, 0.0286, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4728355407714844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0489, 0.0132, 0.0027, 0.0267, 0.0183]) \n",
      "Test Loss tensor([0.0428, 0.0129, 0.0026, 0.0247, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4703841209411621 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0458, 0.0108, 0.0025, 0.0286, 0.0176]) \n",
      "Test Loss tensor([0.0510, 0.0128, 0.0033, 0.0305, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4723799228668213 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0101, 0.0033, 0.0231, 0.0151]) \n",
      "Test Loss tensor([0.0465, 0.0131, 0.0029, 0.0260, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47089338302612305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0479, 0.0127, 0.0030, 0.0270, 0.0158]) \n",
      "Test Loss tensor([0.0474, 0.0134, 0.0027, 0.0262, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.47561001777648926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0142, 0.0024, 0.0281, 0.0182]) \n",
      "Test Loss tensor([0.0451, 0.0130, 0.0027, 0.0255, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4706456661224365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0463, 0.0137, 0.0026, 0.0237, 0.0213]) \n",
      "Test Loss tensor([0.0458, 0.0121, 0.0028, 0.0263, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5060558319091797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0400, 0.0121, 0.0033, 0.0233, 0.0171]) \n",
      "Test Loss tensor([0.0461, 0.0129, 0.0030, 0.0262, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.47429370880126953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0465, 0.0125, 0.0027, 0.0266, 0.0166]) \n",
      "Test Loss tensor([0.0451, 0.0121, 0.0029, 0.0248, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47655296325683594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0456, 0.0109, 0.0026, 0.0253, 0.0185]) \n",
      "Test Loss tensor([0.0487, 0.0137, 0.0026, 0.0274, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4727811813354492 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0468, 0.0122, 0.0025, 0.0257, 0.0188]) \n",
      "Test Loss tensor([0.0457, 0.0121, 0.0028, 0.0255, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.47715234756469727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0133, 0.0025, 0.0254, 0.0149]) \n",
      "Test Loss tensor([0.0459, 0.0134, 0.0031, 0.0270, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4755995273590088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0122, 0.0035, 0.0263, 0.0172]) \n",
      "Test Loss tensor([0.0445, 0.0127, 0.0027, 0.0250, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47343969345092773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0411, 0.0117, 0.0027, 0.0248, 0.0156]) \n",
      "Test Loss tensor([0.0453, 0.0139, 0.0027, 0.0259, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4838590621948242 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0126, 0.0028, 0.0253, 0.0164]) \n",
      "Test Loss tensor([0.0444, 0.0135, 0.0025, 0.0249, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.47345399856567383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0117, 0.0026, 0.0273, 0.0169]) \n",
      "Test Loss tensor([0.0462, 0.0135, 0.0031, 0.0250, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4708559513092041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0121, 0.0033, 0.0233, 0.0170]) \n",
      "Test Loss tensor([0.0458, 0.0126, 0.0028, 0.0252, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47258758544921875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0131, 0.0025, 0.0255, 0.0170]) \n",
      "Test Loss tensor([0.0436, 0.0126, 0.0027, 0.0238, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4717841148376465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0121, 0.0030, 0.0224, 0.0196]) \n",
      "Test Loss tensor([0.0460, 0.0131, 0.0026, 0.0252, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4727475643157959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0108, 0.0023, 0.0264, 0.0183]) \n",
      "Test Loss tensor([0.0450, 0.0125, 0.0026, 0.0247, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.47276973724365234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0108, 0.0025, 0.0257, 0.0173]) \n",
      "Test Loss tensor([0.0455, 0.0126, 0.0028, 0.0265, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.46936559677124023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0447, 0.0128, 0.0029, 0.0262, 0.0160]) \n",
      "Test Loss tensor([0.0447, 0.0125, 0.0027, 0.0257, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.470994234085083 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0107, 0.0030, 0.0260, 0.0198]) \n",
      "Test Loss tensor([0.0437, 0.0121, 0.0026, 0.0261, 0.0173])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 520 in 0.4696171283721924 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0428, 0.0109, 0.0028, 0.0253, 0.0165]) \n",
      "Test Loss tensor([0.0458, 0.0134, 0.0025, 0.0252, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4748194217681885 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0485, 0.0110, 0.0024, 0.0268, 0.0188]) \n",
      "Test Loss tensor([0.0451, 0.0119, 0.0027, 0.0245, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4692232608795166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0464, 0.0110, 0.0027, 0.0237, 0.0149]) \n",
      "Test Loss tensor([0.0471, 0.0126, 0.0031, 0.0257, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4714632034301758 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0467, 0.0131, 0.0028, 0.0255, 0.0179]) \n",
      "Test Loss tensor([0.0453, 0.0125, 0.0027, 0.0251, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.47077012062072754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0120, 0.0028, 0.0257, 0.0174]) \n",
      "Test Loss tensor([0.0453, 0.0127, 0.0025, 0.0256, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.47246265411376953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0431, 0.0137, 0.0026, 0.0273, 0.0211]) \n",
      "Test Loss tensor([0.0450, 0.0130, 0.0028, 0.0245, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47147083282470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0110, 0.0025, 0.0227, 0.0166]) \n",
      "Test Loss tensor([0.0451, 0.0123, 0.0031, 0.0258, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.47222375869750977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0119, 0.0026, 0.0254, 0.0188]) \n",
      "Test Loss tensor([0.0449, 0.0121, 0.0029, 0.0250, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.47235679626464844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0433, 0.0122, 0.0025, 0.0269, 0.0188]) \n",
      "Test Loss tensor([0.0450, 0.0122, 0.0027, 0.0249, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47190046310424805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0109, 0.0028, 0.0257, 0.0184]) \n",
      "Test Loss tensor([0.0442, 0.0123, 0.0027, 0.0252, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.47066378593444824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0111, 0.0030, 0.0232, 0.0164]) \n",
      "Test Loss tensor([0.0447, 0.0123, 0.0029, 0.0235, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4707612991333008 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0106, 0.0023, 0.0241, 0.0188]) \n",
      "Test Loss tensor([0.0442, 0.0124, 0.0028, 0.0256, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.47103214263916016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0477, 0.0123, 0.0025, 0.0250, 0.0171]) \n",
      "Test Loss tensor([0.0425, 0.0120, 0.0028, 0.0238, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4697592258453369 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0114, 0.0025, 0.0237, 0.0170]) \n",
      "Test Loss tensor([0.0469, 0.0129, 0.0027, 0.0259, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4835948944091797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0121, 0.0024, 0.0236, 0.0171]) \n",
      "Test Loss tensor([0.0439, 0.0130, 0.0027, 0.0240, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47255635261535645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0403, 0.0118, 0.0029, 0.0264, 0.0146]) \n",
      "Test Loss tensor([0.0441, 0.0129, 0.0027, 0.0253, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4735407829284668 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0434, 0.0125, 0.0026, 0.0227, 0.0185]) \n",
      "Test Loss tensor([0.0438, 0.0125, 0.0028, 0.0250, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47024083137512207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0144, 0.0026, 0.0247, 0.0151]) \n",
      "Test Loss tensor([0.0447, 0.0123, 0.0026, 0.0247, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47200775146484375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0123, 0.0028, 0.0263, 0.0151]) \n",
      "Test Loss tensor([0.0449, 0.0125, 0.0025, 0.0254, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.46826672554016113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0113, 0.0025, 0.0244, 0.0163]) \n",
      "Test Loss tensor([0.0429, 0.0125, 0.0026, 0.0245, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4751729965209961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0428, 0.0121, 0.0026, 0.0247, 0.0146]) \n",
      "Test Loss tensor([0.0429, 0.0121, 0.0027, 0.0244, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.47136449813842773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0107, 0.0025, 0.0268, 0.0176]) \n",
      "Test Loss tensor([0.0438, 0.0129, 0.0027, 0.0243, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47154688835144043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0424, 0.0113, 0.0027, 0.0228, 0.0186]) \n",
      "Test Loss tensor([0.0429, 0.0123, 0.0026, 0.0239, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47111964225769043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0124, 0.0025, 0.0224, 0.0169]) \n",
      "Test Loss tensor([0.0437, 0.0126, 0.0026, 0.0247, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4737260341644287 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0112, 0.0024, 0.0245, 0.0140]) \n",
      "Test Loss tensor([0.0435, 0.0122, 0.0027, 0.0241, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4712958335876465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0442, 0.0102, 0.0027, 0.0222, 0.0181]) \n",
      "Test Loss tensor([0.0445, 0.0117, 0.0029, 0.0247, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.471480131149292 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0438, 0.0118, 0.0026, 0.0256, 0.0161]) \n",
      "Test Loss tensor([0.0426, 0.0121, 0.0026, 0.0235, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4716053009033203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0121, 0.0025, 0.0235, 0.0180]) \n",
      "Test Loss tensor([0.0444, 0.0121, 0.0026, 0.0244, 0.0170])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4724729061126709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0127, 0.0030, 0.0268, 0.0168]) \n",
      "Test Loss tensor([0.0458, 0.0119, 0.0026, 0.0242, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.47029566764831543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0428, 0.0134, 0.0030, 0.0264, 0.0166]) \n",
      "Test Loss tensor([0.0447, 0.0120, 0.0026, 0.0243, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4734327793121338 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0436, 0.0113, 0.0028, 0.0217, 0.0164]) \n",
      "Test Loss tensor([0.0465, 0.0134, 0.0028, 0.0256, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47257304191589355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0409, 0.0113, 0.0027, 0.0244, 0.0170]) \n",
      "Test Loss tensor([0.0427, 0.0119, 0.0027, 0.0236, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4766230583190918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0127, 0.0028, 0.0246, 0.0168]) \n",
      "Test Loss tensor([0.0469, 0.0129, 0.0026, 0.0271, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.47382116317749023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0467, 0.0132, 0.0031, 0.0238, 0.0181]) \n",
      "Test Loss tensor([0.0426, 0.0117, 0.0026, 0.0248, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.47466111183166504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0412, 0.0105, 0.0023, 0.0220, 0.0199]) \n",
      "Test Loss tensor([0.0471, 0.0129, 0.0029, 0.0264, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47953152656555176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0410, 0.0120, 0.0031, 0.0280, 0.0162]) \n",
      "Test Loss tensor([0.0438, 0.0120, 0.0027, 0.0246, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.474947452545166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0121, 0.0026, 0.0233, 0.0173]) \n",
      "Test Loss tensor([0.0448, 0.0122, 0.0026, 0.0246, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4759678840637207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0446, 0.0126, 0.0026, 0.0242, 0.0150]) \n",
      "Test Loss tensor([0.0451, 0.0125, 0.0025, 0.0252, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4691915512084961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0422, 0.0131, 0.0027, 0.0245, 0.0143]) \n",
      "Test Loss tensor([0.0440, 0.0120, 0.0027, 0.0259, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4824826717376709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0476, 0.0150, 0.0024, 0.0238, 0.0159]) \n",
      "Test Loss tensor([0.0445, 0.0119, 0.0028, 0.0254, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47051358222961426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0124, 0.0024, 0.0223, 0.0158]) \n",
      "Test Loss tensor([0.0440, 0.0122, 0.0026, 0.0255, 0.0169])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 684 in 0.4751746654510498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0444, 0.0131, 0.0025, 0.0228, 0.0176]) \n",
      "Test Loss tensor([0.0430, 0.0127, 0.0026, 0.0247, 0.0172])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4754664897918701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0121, 0.0023, 0.0231, 0.0188]) \n",
      "Test Loss tensor([0.0418, 0.0122, 0.0025, 0.0237, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.47417616844177246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0457, 0.0110, 0.0029, 0.0211, 0.0194]) \n",
      "Test Loss tensor([0.0440, 0.0121, 0.0026, 0.0252, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4664433002471924 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0118, 0.0026, 0.0242, 0.0162]) \n",
      "Test Loss tensor([0.0441, 0.0122, 0.0026, 0.0243, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4703991413116455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0120, 0.0027, 0.0248, 0.0168]) \n",
      "Test Loss tensor([0.0445, 0.0123, 0.0026, 0.0249, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.469165563583374 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0115, 0.0028, 0.0242, 0.0182]) \n",
      "Test Loss tensor([0.0426, 0.0125, 0.0027, 0.0247, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.47114014625549316 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0142, 0.0026, 0.0224, 0.0184]) \n",
      "Test Loss tensor([0.0436, 0.0122, 0.0028, 0.0243, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4703068733215332 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0126, 0.0026, 0.0216, 0.0175]) \n",
      "Test Loss tensor([0.0425, 0.0122, 0.0028, 0.0235, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.46987009048461914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0130, 0.0028, 0.0262, 0.0174]) \n",
      "Test Loss tensor([0.0429, 0.0126, 0.0027, 0.0239, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47008752822875977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0122, 0.0027, 0.0245, 0.0179]) \n",
      "Test Loss tensor([0.0438, 0.0117, 0.0027, 0.0233, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47139549255371094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0125, 0.0025, 0.0214, 0.0163]) \n",
      "Test Loss tensor([0.0432, 0.0120, 0.0026, 0.0246, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.46978020668029785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0113, 0.0028, 0.0227, 0.0177]) \n",
      "Test Loss tensor([0.0447, 0.0121, 0.0027, 0.0259, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4711802005767822 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0431, 0.0142, 0.0027, 0.0227, 0.0189]) \n",
      "Test Loss tensor([0.0431, 0.0117, 0.0026, 0.0247, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4748210906982422 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0101, 0.0028, 0.0255, 0.0175]) \n",
      "Test Loss tensor([0.0446, 0.0120, 0.0025, 0.0247, 0.0169])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4702906608581543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0112, 0.0025, 0.0230, 0.0173]) \n",
      "Test Loss tensor([0.0430, 0.0116, 0.0026, 0.0241, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4898242950439453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0106, 0.0027, 0.0261, 0.0161]) \n",
      "Test Loss tensor([0.0427, 0.0122, 0.0025, 0.0239, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.47295594215393066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0107, 0.0027, 0.0242, 0.0196]) \n",
      "Test Loss tensor([0.0429, 0.0122, 0.0026, 0.0238, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4767909049987793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0111, 0.0027, 0.0240, 0.0168]) \n",
      "Test Loss tensor([0.0433, 0.0121, 0.0027, 0.0250, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.47169017791748047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0117, 0.0027, 0.0253, 0.0180]) \n",
      "Test Loss tensor([0.0423, 0.0116, 0.0027, 0.0246, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47353577613830566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0436, 0.0112, 0.0026, 0.0232, 0.0158]) \n",
      "Test Loss tensor([0.0430, 0.0123, 0.0026, 0.0249, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47052907943725586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0126, 0.0029, 0.0273, 0.0180]) \n",
      "Test Loss tensor([0.0427, 0.0117, 0.0026, 0.0247, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4749794006347656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0413, 0.0131, 0.0028, 0.0236, 0.0182]) \n",
      "Test Loss tensor([0.0435, 0.0119, 0.0029, 0.0241, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4730527400970459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0428, 0.0113, 0.0026, 0.0213, 0.0166]) \n",
      "Test Loss tensor([0.0422, 0.0122, 0.0027, 0.0247, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47287535667419434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0118, 0.0028, 0.0239, 0.0166]) \n",
      "Test Loss tensor([0.0427, 0.0121, 0.0026, 0.0244, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47169065475463867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0134, 0.0027, 0.0251, 0.0178]) \n",
      "Test Loss tensor([0.0420, 0.0117, 0.0026, 0.0237, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4731731414794922 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0115, 0.0024, 0.0263, 0.0156]) \n",
      "Test Loss tensor([0.0429, 0.0118, 0.0027, 0.0250, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.46970415115356445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0109, 0.0026, 0.0242, 0.0173]) \n",
      "Test Loss tensor([0.0431, 0.0113, 0.0028, 0.0250, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4812581539154053 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0421, 0.0109, 0.0024, 0.0229, 0.0135]) \n",
      "Test Loss tensor([0.0425, 0.0118, 0.0026, 0.0252, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47946619987487793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0406, 0.0121, 0.0025, 0.0262, 0.0163]) \n",
      "Test Loss tensor([0.0437, 0.0117, 0.0026, 0.0248, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.477114200592041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0406, 0.0120, 0.0029, 0.0273, 0.0171]) \n",
      "Test Loss tensor([0.0416, 0.0114, 0.0026, 0.0245, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.474773645401001 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0440, 0.0132, 0.0025, 0.0238, 0.0161]) \n",
      "Test Loss tensor([0.0419, 0.0122, 0.0028, 0.0238, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4712531566619873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0461, 0.0114, 0.0027, 0.0245, 0.0182]) \n",
      "Test Loss tensor([0.0431, 0.0119, 0.0028, 0.0249, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47164487838745117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0123, 0.0027, 0.0249, 0.0163]) \n",
      "Test Loss tensor([0.0411, 0.0115, 0.0026, 0.0249, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4715602397918701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0417, 0.0119, 0.0027, 0.0258, 0.0179]) \n",
      "Test Loss tensor([0.0425, 0.0127, 0.0026, 0.0255, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47376561164855957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0117, 0.0028, 0.0244, 0.0156]) \n",
      "Test Loss tensor([0.0420, 0.0119, 0.0028, 0.0242, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4690070152282715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0419, 0.0109, 0.0031, 0.0226, 0.0181]) \n",
      "Test Loss tensor([0.0438, 0.0122, 0.0028, 0.0238, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47518062591552734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0133, 0.0026, 0.0240, 0.0169]) \n",
      "Test Loss tensor([0.0426, 0.0123, 0.0027, 0.0245, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47319531440734863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0103, 0.0036, 0.0284, 0.0165]) \n",
      "Test Loss tensor([0.0427, 0.0118, 0.0026, 0.0253, 0.0171])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.46985864639282227 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0100, 0.0029, 0.0221, 0.0169]) \n",
      "Test Loss tensor([0.0424, 0.0117, 0.0026, 0.0243, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4759652614593506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0421, 0.0097, 0.0026, 0.0236, 0.0169]) \n",
      "Test Loss tensor([0.0429, 0.0119, 0.0026, 0.0255, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4768397808074951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0115, 0.0026, 0.0257, 0.0174]) \n",
      "Test Loss tensor([0.0422, 0.0119, 0.0027, 0.0231, 0.0165])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 848 in 0.4784388542175293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0376, 0.0118, 0.0026, 0.0214, 0.0165]) \n",
      "Test Loss tensor([0.0421, 0.0123, 0.0026, 0.0251, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4698343276977539 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0453, 0.0122, 0.0030, 0.0244, 0.0175]) \n",
      "Test Loss tensor([0.0417, 0.0124, 0.0026, 0.0231, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4771420955657959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0429, 0.0111, 0.0026, 0.0232, 0.0169]) \n",
      "Test Loss tensor([0.0429, 0.0121, 0.0026, 0.0235, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47751927375793457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0413, 0.0129, 0.0027, 0.0257, 0.0157]) \n",
      "Test Loss tensor([0.0414, 0.0117, 0.0026, 0.0230, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47301673889160156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0475, 0.0097, 0.0026, 0.0248, 0.0133]) \n",
      "Test Loss tensor([0.0413, 0.0114, 0.0026, 0.0244, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4896259307861328 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0436, 0.0116, 0.0027, 0.0249, 0.0177]) \n",
      "Test Loss tensor([0.0427, 0.0116, 0.0026, 0.0248, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4761779308319092 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0433, 0.0114, 0.0029, 0.0220, 0.0177]) \n",
      "Test Loss tensor([0.0421, 0.0122, 0.0026, 0.0237, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45933103561401367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0317, 0.0087, 0.0019, 0.0171, 0.0124]) \n",
      "Test Loss tensor([0.0414, 0.0126, 0.0026, 0.0235, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5125529766082764 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0370, 0.0102, 0.0028, 0.0236, 0.0169]) \n",
      "Test Loss tensor([0.0422, 0.0116, 0.0026, 0.0243, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.47832798957824707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0439, 0.0117, 0.0027, 0.0237, 0.0186]) \n",
      "Test Loss tensor([0.0416, 0.0125, 0.0027, 0.0229, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47556233406066895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0454, 0.0111, 0.0025, 0.0221, 0.0149]) \n",
      "Test Loss tensor([0.0434, 0.0125, 0.0026, 0.0241, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5120306015014648 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0105, 0.0024, 0.0237, 0.0153]) \n",
      "Test Loss tensor([0.0412, 0.0118, 0.0026, 0.0237, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4782569408416748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0108, 0.0026, 0.0245, 0.0126]) \n",
      "Test Loss tensor([0.0438, 0.0124, 0.0026, 0.0260, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.496171236038208 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0410, 0.0131, 0.0033, 0.0234, 0.0138]) \n",
      "Test Loss tensor([0.0425, 0.0125, 0.0027, 0.0248, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47760581970214844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0460, 0.0131, 0.0030, 0.0248, 0.0158]) \n",
      "Test Loss tensor([0.0419, 0.0122, 0.0025, 0.0241, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4805126190185547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0105, 0.0026, 0.0218, 0.0182]) \n",
      "Test Loss tensor([0.0418, 0.0118, 0.0026, 0.0251, 0.0167])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.48860979080200195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0104, 0.0027, 0.0239, 0.0178]) \n",
      "Test Loss tensor([0.0417, 0.0118, 0.0028, 0.0237, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4734640121459961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0110, 0.0024, 0.0243, 0.0152]) \n",
      "Test Loss tensor([0.0439, 0.0122, 0.0028, 0.0250, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4740262031555176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0432, 0.0119, 0.0025, 0.0275, 0.0172]) \n",
      "Test Loss tensor([0.0421, 0.0120, 0.0026, 0.0240, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.47440171241760254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0109, 0.0027, 0.0223, 0.0162]) \n",
      "Test Loss tensor([0.0444, 0.0124, 0.0025, 0.0254, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4772770404815674 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0465, 0.0126, 0.0024, 0.0250, 0.0177]) \n",
      "Test Loss tensor([0.0417, 0.0122, 0.0026, 0.0236, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.469893217086792 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0140, 0.0025, 0.0267, 0.0173]) \n",
      "Test Loss tensor([0.0433, 0.0120, 0.0027, 0.0248, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.47777223587036133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0448, 0.0123, 0.0027, 0.0250, 0.0181]) \n",
      "Test Loss tensor([0.0431, 0.0115, 0.0027, 0.0235, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.47144436836242676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0430, 0.0108, 0.0026, 0.0259, 0.0171]) \n",
      "Test Loss tensor([0.0432, 0.0126, 0.0025, 0.0243, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4776115417480469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0128, 0.0025, 0.0267, 0.0148]) \n",
      "Test Loss tensor([0.0438, 0.0126, 0.0025, 0.0235, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4730947017669678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0100, 0.0027, 0.0243, 0.0131]) \n",
      "Test Loss tensor([0.0424, 0.0121, 0.0025, 0.0244, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4752185344696045 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0406, 0.0106, 0.0027, 0.0215, 0.0154]) \n",
      "Test Loss tensor([0.0435, 0.0123, 0.0027, 0.0246, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.47235703468322754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0411, 0.0136, 0.0028, 0.0258, 0.0174]) \n",
      "Test Loss tensor([0.0420, 0.0114, 0.0026, 0.0232, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4732985496520996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0113, 0.0028, 0.0191, 0.0170]) \n",
      "Test Loss tensor([0.0436, 0.0115, 0.0025, 0.0248, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.47382640838623047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0118, 0.0025, 0.0272, 0.0159]) \n",
      "Test Loss tensor([0.0422, 0.0116, 0.0026, 0.0236, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.47342419624328613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0434, 0.0115, 0.0026, 0.0239, 0.0181]) \n",
      "Test Loss tensor([0.0423, 0.0119, 0.0026, 0.0241, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4706993103027344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0118, 0.0025, 0.0238, 0.0165]) \n",
      "Test Loss tensor([0.0423, 0.0115, 0.0028, 0.0225, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4778013229370117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0108, 0.0032, 0.0241, 0.0179]) \n",
      "Test Loss tensor([0.0412, 0.0121, 0.0027, 0.0228, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4718329906463623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0129, 0.0025, 0.0219, 0.0165]) \n",
      "Test Loss tensor([0.0426, 0.0125, 0.0026, 0.0232, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4744257926940918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0106, 0.0027, 0.0232, 0.0181]) \n",
      "Test Loss tensor([0.0413, 0.0109, 0.0027, 0.0242, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4805285930633545 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0111, 0.0024, 0.0207, 0.0156]) \n",
      "Test Loss tensor([0.0409, 0.0119, 0.0028, 0.0240, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4725825786590576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0446, 0.0147, 0.0033, 0.0255, 0.0180]) \n",
      "Test Loss tensor([0.0424, 0.0116, 0.0028, 0.0241, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.47202253341674805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0426, 0.0107, 0.0030, 0.0219, 0.0128]) \n",
      "Test Loss tensor([0.0420, 0.0121, 0.0027, 0.0238, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4705991744995117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0129, 0.0028, 0.0257, 0.0160]) \n",
      "Test Loss tensor([0.0425, 0.0119, 0.0025, 0.0252, 0.0166])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4731631278991699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0098, 0.0026, 0.0246, 0.0177]) \n",
      "Test Loss tensor([0.0410, 0.0118, 0.0026, 0.0236, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4721367359161377 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0113, 0.0025, 0.0280, 0.0168]) \n",
      "Test Loss tensor([0.0426, 0.0119, 0.0029, 0.0240, 0.0162])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 132 in 0.4740598201751709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0127, 0.0026, 0.0220, 0.0142]) \n",
      "Test Loss tensor([0.0415, 0.0121, 0.0027, 0.0235, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4869663715362549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0117, 0.0027, 0.0237, 0.0174]) \n",
      "Test Loss tensor([0.0423, 0.0122, 0.0026, 0.0254, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4741935729980469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0115, 0.0025, 0.0265, 0.0157]) \n",
      "Test Loss tensor([0.0422, 0.0123, 0.0026, 0.0243, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.474963903427124 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0112, 0.0028, 0.0237, 0.0164]) \n",
      "Test Loss tensor([0.0425, 0.0118, 0.0028, 0.0232, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4733126163482666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0115, 0.0028, 0.0241, 0.0184]) \n",
      "Test Loss tensor([0.0421, 0.0117, 0.0028, 0.0238, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4750862121582031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0098, 0.0030, 0.0256, 0.0146]) \n",
      "Test Loss tensor([0.0421, 0.0117, 0.0027, 0.0234, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47658252716064453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0130, 0.0023, 0.0243, 0.0166]) \n",
      "Test Loss tensor([0.0422, 0.0115, 0.0026, 0.0246, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.47621893882751465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0452, 0.0100, 0.0025, 0.0256, 0.0154]) \n",
      "Test Loss tensor([0.0405, 0.0117, 0.0026, 0.0238, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4769144058227539 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0104, 0.0027, 0.0215, 0.0148]) \n",
      "Test Loss tensor([0.0422, 0.0126, 0.0027, 0.0241, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4718029499053955 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0124, 0.0024, 0.0239, 0.0160]) \n",
      "Test Loss tensor([0.0416, 0.0116, 0.0027, 0.0239, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47214722633361816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0421, 0.0126, 0.0028, 0.0240, 0.0140]) \n",
      "Test Loss tensor([0.0403, 0.0112, 0.0025, 0.0233, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47321057319641113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0105, 0.0024, 0.0226, 0.0159]) \n",
      "Test Loss tensor([0.0406, 0.0123, 0.0026, 0.0244, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.47580957412719727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0100, 0.0027, 0.0247, 0.0169]) \n",
      "Test Loss tensor([0.0407, 0.0119, 0.0026, 0.0238, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4775052070617676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0124, 0.0022, 0.0225, 0.0151]) \n",
      "Test Loss tensor([0.0426, 0.0114, 0.0027, 0.0232, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47637033462524414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0101, 0.0027, 0.0221, 0.0158]) \n",
      "Test Loss tensor([0.0422, 0.0119, 0.0027, 0.0237, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.47608184814453125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0118, 0.0024, 0.0239, 0.0147]) \n",
      "Test Loss tensor([0.0415, 0.0116, 0.0026, 0.0242, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4751608371734619 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0118, 0.0024, 0.0249, 0.0172]) \n",
      "Test Loss tensor([0.0421, 0.0118, 0.0026, 0.0241, 0.0164])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.48454809188842773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0422, 0.0102, 0.0026, 0.0238, 0.0148]) \n",
      "Test Loss tensor([0.0432, 0.0119, 0.0027, 0.0242, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.47557973861694336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0096, 0.0026, 0.0256, 0.0151]) \n",
      "Test Loss tensor([0.0414, 0.0118, 0.0027, 0.0241, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4753451347351074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0107, 0.0024, 0.0228, 0.0159]) \n",
      "Test Loss tensor([0.0411, 0.0117, 0.0026, 0.0229, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4724304676055908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0442, 0.0106, 0.0025, 0.0243, 0.0170]) \n",
      "Test Loss tensor([0.0425, 0.0123, 0.0025, 0.0236, 0.0163])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4729342460632324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0118, 0.0021, 0.0213, 0.0177]) \n",
      "Test Loss tensor([0.0415, 0.0111, 0.0026, 0.0238, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.47278499603271484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0135, 0.0023, 0.0208, 0.0149]) \n",
      "Test Loss tensor([0.0420, 0.0114, 0.0028, 0.0248, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.478926420211792 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0141, 0.0025, 0.0265, 0.0153]) \n",
      "Test Loss tensor([0.0414, 0.0118, 0.0027, 0.0234, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.478987455368042 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0437, 0.0124, 0.0026, 0.0236, 0.0154]) \n",
      "Test Loss tensor([0.0422, 0.0119, 0.0026, 0.0234, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4795346260070801 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0114, 0.0026, 0.0219, 0.0160]) \n",
      "Test Loss tensor([0.0414, 0.0124, 0.0027, 0.0233, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4774463176727295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0412, 0.0111, 0.0028, 0.0239, 0.0152]) \n",
      "Test Loss tensor([0.0417, 0.0118, 0.0027, 0.0231, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.47574806213378906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0122, 0.0026, 0.0246, 0.0157]) \n",
      "Test Loss tensor([0.0406, 0.0116, 0.0027, 0.0223, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.47174906730651855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0122, 0.0027, 0.0226, 0.0150]) \n",
      "Test Loss tensor([0.0412, 0.0118, 0.0026, 0.0233, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47468042373657227 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0132, 0.0026, 0.0244, 0.0145]) \n",
      "Test Loss tensor([0.0414, 0.0117, 0.0026, 0.0234, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4727799892425537 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0410, 0.0134, 0.0031, 0.0217, 0.0172]) \n",
      "Test Loss tensor([0.0403, 0.0114, 0.0026, 0.0238, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.480072021484375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0112, 0.0025, 0.0235, 0.0145]) \n",
      "Test Loss tensor([0.0417, 0.0119, 0.0028, 0.0227, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4754951000213623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0110, 0.0027, 0.0236, 0.0158]) \n",
      "Test Loss tensor([0.0424, 0.0119, 0.0028, 0.0244, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4750211238861084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0412, 0.0105, 0.0025, 0.0221, 0.0147]) \n",
      "Test Loss tensor([0.0414, 0.0116, 0.0026, 0.0227, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4744687080383301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0109, 0.0027, 0.0229, 0.0140]) \n",
      "Test Loss tensor([0.0416, 0.0114, 0.0025, 0.0236, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4787609577178955 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0118, 0.0028, 0.0232, 0.0186]) \n",
      "Test Loss tensor([0.0406, 0.0119, 0.0026, 0.0225, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4769165515899658 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0400, 0.0126, 0.0027, 0.0216, 0.0194]) \n",
      "Test Loss tensor([0.0415, 0.0110, 0.0027, 0.0247, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4745826721191406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0120, 0.0026, 0.0204, 0.0159]) \n",
      "Test Loss tensor([0.0415, 0.0111, 0.0026, 0.0230, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.475679874420166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0409, 0.0133, 0.0024, 0.0224, 0.0145]) \n",
      "Test Loss tensor([0.0422, 0.0115, 0.0025, 0.0243, 0.0161])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4756045341491699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0107, 0.0023, 0.0235, 0.0167]) \n",
      "Test Loss tensor([0.0401, 0.0113, 0.0025, 0.0245, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4770009517669678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0130, 0.0024, 0.0231, 0.0161]) \n",
      "Test Loss tensor([0.0407, 0.0107, 0.0026, 0.0240, 0.0156])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 296 in 0.4750239849090576 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0100, 0.0026, 0.0238, 0.0177]) \n",
      "Test Loss tensor([0.0417, 0.0114, 0.0027, 0.0231, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47422361373901367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0129, 0.0025, 0.0240, 0.0176]) \n",
      "Test Loss tensor([0.0415, 0.0122, 0.0026, 0.0233, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4697127342224121 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0134, 0.0028, 0.0225, 0.0182]) \n",
      "Test Loss tensor([0.0415, 0.0110, 0.0026, 0.0233, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4764573574066162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0134, 0.0025, 0.0236, 0.0171]) \n",
      "Test Loss tensor([0.0411, 0.0114, 0.0028, 0.0237, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4709289073944092 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0108, 0.0026, 0.0285, 0.0160]) \n",
      "Test Loss tensor([0.0415, 0.0112, 0.0028, 0.0238, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4773752689361572 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0090, 0.0029, 0.0223, 0.0148]) \n",
      "Test Loss tensor([0.0400, 0.0112, 0.0027, 0.0235, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4737355709075928 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0122, 0.0024, 0.0232, 0.0153]) \n",
      "Test Loss tensor([0.0405, 0.0120, 0.0026, 0.0233, 0.0160])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4715249538421631 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0390, 0.0111, 0.0024, 0.0239, 0.0171]) \n",
      "Test Loss tensor([0.0413, 0.0124, 0.0027, 0.0224, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4714498519897461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0103, 0.0028, 0.0204, 0.0175]) \n",
      "Test Loss tensor([0.0410, 0.0111, 0.0028, 0.0228, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4726994037628174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0436, 0.0105, 0.0025, 0.0258, 0.0165]) \n",
      "Test Loss tensor([0.0409, 0.0117, 0.0029, 0.0224, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4729909896850586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0400, 0.0121, 0.0028, 0.0182, 0.0159]) \n",
      "Test Loss tensor([0.0410, 0.0118, 0.0025, 0.0236, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4717984199523926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0130, 0.0027, 0.0257, 0.0150]) \n",
      "Test Loss tensor([0.0406, 0.0112, 0.0027, 0.0239, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47147607803344727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0109, 0.0028, 0.0210, 0.0150]) \n",
      "Test Loss tensor([0.0416, 0.0119, 0.0028, 0.0242, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4752328395843506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0117, 0.0026, 0.0230, 0.0143]) \n",
      "Test Loss tensor([0.0399, 0.0110, 0.0028, 0.0233, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.47083234786987305 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0134, 0.0029, 0.0218, 0.0163]) \n",
      "Test Loss tensor([0.0397, 0.0114, 0.0028, 0.0228, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4732048511505127 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0390, 0.0110, 0.0026, 0.0266, 0.0158]) \n",
      "Test Loss tensor([0.0420, 0.0113, 0.0028, 0.0228, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4719109535217285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0113, 0.0026, 0.0219, 0.0152]) \n",
      "Test Loss tensor([0.0408, 0.0113, 0.0026, 0.0232, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4719560146331787 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0129, 0.0027, 0.0248, 0.0162]) \n",
      "Test Loss tensor([0.0411, 0.0113, 0.0028, 0.0234, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.48773193359375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0098, 0.0027, 0.0234, 0.0166]) \n",
      "Test Loss tensor([0.0416, 0.0123, 0.0026, 0.0231, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4725484848022461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0410, 0.0122, 0.0025, 0.0203, 0.0169]) \n",
      "Test Loss tensor([0.0406, 0.0119, 0.0026, 0.0236, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4724695682525635 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0104, 0.0025, 0.0281, 0.0145]) \n",
      "Test Loss tensor([0.0397, 0.0116, 0.0027, 0.0241, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.47110724449157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0117, 0.0023, 0.0232, 0.0157]) \n",
      "Test Loss tensor([0.0390, 0.0111, 0.0027, 0.0230, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.47443318367004395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0102, 0.0023, 0.0222, 0.0162]) \n",
      "Test Loss tensor([0.0409, 0.0119, 0.0026, 0.0239, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.46961355209350586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0439, 0.0112, 0.0029, 0.0227, 0.0170]) \n",
      "Test Loss tensor([0.0404, 0.0116, 0.0026, 0.0233, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.47263360023498535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0386, 0.0115, 0.0028, 0.0232, 0.0148]) \n",
      "Test Loss tensor([0.0412, 0.0113, 0.0027, 0.0237, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4730865955352783 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0114, 0.0029, 0.0220, 0.0132]) \n",
      "Test Loss tensor([0.0403, 0.0115, 0.0027, 0.0230, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.47519373893737793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0117, 0.0026, 0.0202, 0.0178]) \n",
      "Test Loss tensor([0.0409, 0.0120, 0.0026, 0.0235, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4707012176513672 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0125, 0.0030, 0.0238, 0.0151]) \n",
      "Test Loss tensor([0.0412, 0.0116, 0.0026, 0.0237, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4716343879699707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0454, 0.0105, 0.0024, 0.0234, 0.0182]) \n",
      "Test Loss tensor([0.0399, 0.0115, 0.0027, 0.0228, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47116708755493164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0102, 0.0026, 0.0232, 0.0152]) \n",
      "Test Loss tensor([0.0410, 0.0117, 0.0027, 0.0227, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4737684726715088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0113, 0.0024, 0.0267, 0.0156]) \n",
      "Test Loss tensor([0.0396, 0.0115, 0.0027, 0.0226, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4725780487060547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0116, 0.0027, 0.0241, 0.0156]) \n",
      "Test Loss tensor([0.0405, 0.0113, 0.0026, 0.0237, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4753119945526123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0425, 0.0115, 0.0024, 0.0237, 0.0157]) \n",
      "Test Loss tensor([0.0407, 0.0119, 0.0025, 0.0233, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4716763496398926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0403, 0.0115, 0.0027, 0.0190, 0.0155]) \n",
      "Test Loss tensor([0.0424, 0.0116, 0.0028, 0.0250, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4730501174926758 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0408, 0.0112, 0.0029, 0.0272, 0.0174]) \n",
      "Test Loss tensor([0.0397, 0.0117, 0.0027, 0.0226, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4700295925140381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0104, 0.0023, 0.0227, 0.0166]) \n",
      "Test Loss tensor([0.0433, 0.0115, 0.0025, 0.0240, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.47159862518310547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0472, 0.0136, 0.0024, 0.0233, 0.0165]) \n",
      "Test Loss tensor([0.0406, 0.0108, 0.0025, 0.0228, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47306275367736816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0423, 0.0116, 0.0027, 0.0216, 0.0174]) \n",
      "Test Loss tensor([0.0416, 0.0118, 0.0027, 0.0237, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4726595878601074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0102, 0.0029, 0.0240, 0.0174]) \n",
      "Test Loss tensor([0.0405, 0.0115, 0.0026, 0.0242, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.47670841217041016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0119, 0.0025, 0.0205, 0.0151]) \n",
      "Test Loss tensor([0.0397, 0.0118, 0.0025, 0.0237, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.470001220703125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0093, 0.0023, 0.0224, 0.0141]) \n",
      "Test Loss tensor([0.0413, 0.0118, 0.0025, 0.0235, 0.0158])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 460 in 0.4732630252838135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0138, 0.0026, 0.0219, 0.0165]) \n",
      "Test Loss tensor([0.0399, 0.0116, 0.0026, 0.0230, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.46901679039001465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0393, 0.0120, 0.0026, 0.0196, 0.0160]) \n",
      "Test Loss tensor([0.0425, 0.0115, 0.0028, 0.0227, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47475767135620117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0119, 0.0026, 0.0236, 0.0174]) \n",
      "Test Loss tensor([0.0407, 0.0117, 0.0028, 0.0228, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.47414493560791016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0403, 0.0115, 0.0027, 0.0251, 0.0146]) \n",
      "Test Loss tensor([0.0416, 0.0117, 0.0026, 0.0237, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.47151613235473633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0443, 0.0126, 0.0026, 0.0225, 0.0160]) \n",
      "Test Loss tensor([0.0411, 0.0111, 0.0025, 0.0232, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4712212085723877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0106, 0.0026, 0.0233, 0.0171]) \n",
      "Test Loss tensor([0.0411, 0.0121, 0.0027, 0.0243, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4722166061401367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0388, 0.0117, 0.0024, 0.0242, 0.0164]) \n",
      "Test Loss tensor([0.0416, 0.0113, 0.0028, 0.0248, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.47217655181884766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0112, 0.0024, 0.0270, 0.0151]) \n",
      "Test Loss tensor([0.0409, 0.0117, 0.0025, 0.0237, 0.0159])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4738802909851074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0418, 0.0098, 0.0025, 0.0216, 0.0128]) \n",
      "Test Loss tensor([0.0435, 0.0115, 0.0025, 0.0249, 0.0162])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.4716305732727051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0449, 0.0114, 0.0026, 0.0244, 0.0167]) \n",
      "Test Loss tensor([0.0407, 0.0118, 0.0026, 0.0227, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4738903045654297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0434, 0.0099, 0.0024, 0.0213, 0.0149]) \n",
      "Test Loss tensor([0.0407, 0.0110, 0.0027, 0.0244, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.47270870208740234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0108, 0.0029, 0.0247, 0.0162]) \n",
      "Test Loss tensor([0.0421, 0.0116, 0.0027, 0.0236, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4739058017730713 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0388, 0.0110, 0.0025, 0.0239, 0.0133]) \n",
      "Test Loss tensor([0.0417, 0.0115, 0.0026, 0.0238, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47305750846862793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0109, 0.0025, 0.0236, 0.0165]) \n",
      "Test Loss tensor([0.0403, 0.0117, 0.0025, 0.0228, 0.0158])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.47196197509765625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0102, 0.0030, 0.0210, 0.0156]) \n",
      "Test Loss tensor([0.0397, 0.0110, 0.0027, 0.0233, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4816920757293701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0411, 0.0108, 0.0028, 0.0229, 0.0162]) \n",
      "Test Loss tensor([0.0404, 0.0119, 0.0025, 0.0228, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.47219395637512207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0097, 0.0022, 0.0210, 0.0172]) \n",
      "Test Loss tensor([0.0404, 0.0115, 0.0025, 0.0239, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47269368171691895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0412, 0.0132, 0.0025, 0.0205, 0.0168]) \n",
      "Test Loss tensor([0.0402, 0.0118, 0.0024, 0.0237, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.46938300132751465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0104, 0.0022, 0.0217, 0.0147]) \n",
      "Test Loss tensor([0.0385, 0.0106, 0.0026, 0.0220, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4904325008392334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0110, 0.0024, 0.0245, 0.0169]) \n",
      "Test Loss tensor([0.0395, 0.0114, 0.0026, 0.0240, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4707155227661133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0103, 0.0027, 0.0249, 0.0142]) \n",
      "Test Loss tensor([0.0413, 0.0114, 0.0026, 0.0230, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4767343997955322 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0114, 0.0026, 0.0205, 0.0152]) \n",
      "Test Loss tensor([0.0397, 0.0116, 0.0024, 0.0229, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4740114212036133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0413, 0.0097, 0.0025, 0.0269, 0.0148]) \n",
      "Test Loss tensor([0.0389, 0.0111, 0.0026, 0.0238, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5077521800994873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0107, 0.0023, 0.0222, 0.0160]) \n",
      "Test Loss tensor([0.0410, 0.0113, 0.0027, 0.0234, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47494959831237793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0426, 0.0119, 0.0024, 0.0260, 0.0158]) \n",
      "Test Loss tensor([0.0399, 0.0123, 0.0025, 0.0226, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4994676113128662 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0417, 0.0134, 0.0026, 0.0214, 0.0151]) \n",
      "Test Loss tensor([0.0401, 0.0112, 0.0026, 0.0237, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4732944965362549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0105, 0.0024, 0.0212, 0.0163]) \n",
      "Test Loss tensor([0.0399, 0.0113, 0.0027, 0.0224, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.47487688064575195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0127, 0.0030, 0.0217, 0.0151]) \n",
      "Test Loss tensor([0.0394, 0.0117, 0.0026, 0.0219, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.47257208824157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0119, 0.0027, 0.0255, 0.0176]) \n",
      "Test Loss tensor([0.0398, 0.0113, 0.0026, 0.0232, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4732086658477783 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0125, 0.0027, 0.0233, 0.0167]) \n",
      "Test Loss tensor([0.0406, 0.0112, 0.0027, 0.0224, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47088170051574707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0112, 0.0023, 0.0251, 0.0135]) \n",
      "Test Loss tensor([0.0404, 0.0119, 0.0026, 0.0226, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4862701892852783 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0117, 0.0033, 0.0230, 0.0150]) \n",
      "Test Loss tensor([0.0400, 0.0114, 0.0026, 0.0232, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5032980442047119 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0112, 0.0023, 0.0210, 0.0175]) \n",
      "Test Loss tensor([0.0394, 0.0114, 0.0027, 0.0227, 0.0157])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47306251525878906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0080, 0.0026, 0.0200, 0.0158]) \n",
      "Test Loss tensor([0.0396, 0.0116, 0.0026, 0.0227, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.477036714553833 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0106, 0.0023, 0.0195, 0.0139]) \n",
      "Test Loss tensor([0.0398, 0.0113, 0.0027, 0.0219, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47530651092529297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0402, 0.0100, 0.0027, 0.0237, 0.0134]) \n",
      "Test Loss tensor([0.0410, 0.0111, 0.0025, 0.0231, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.47219181060791016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0111, 0.0026, 0.0233, 0.0159]) \n",
      "Test Loss tensor([0.0400, 0.0108, 0.0026, 0.0233, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47571873664855957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0102, 0.0029, 0.0222, 0.0146]) \n",
      "Test Loss tensor([0.0398, 0.0113, 0.0026, 0.0238, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4829232692718506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0454, 0.0117, 0.0023, 0.0247, 0.0174]) \n",
      "Test Loss tensor([0.0391, 0.0107, 0.0025, 0.0230, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4731557369232178 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0355, 0.0095, 0.0025, 0.0227, 0.0155]) \n",
      "Test Loss tensor([0.0411, 0.0113, 0.0026, 0.0232, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.474820613861084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0111, 0.0026, 0.0203, 0.0168]) \n",
      "Test Loss tensor([0.0405, 0.0114, 0.0026, 0.0221, 0.0149])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 624 in 0.4735109806060791 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0116, 0.0026, 0.0212, 0.0153]) \n",
      "Test Loss tensor([0.0399, 0.0114, 0.0025, 0.0227, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4730393886566162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0108, 0.0029, 0.0201, 0.0155]) \n",
      "Test Loss tensor([0.0397, 0.0114, 0.0026, 0.0228, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4704906940460205 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0402, 0.0105, 0.0024, 0.0223, 0.0156]) \n",
      "Test Loss tensor([0.0396, 0.0113, 0.0027, 0.0231, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4748847484588623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0110, 0.0025, 0.0213, 0.0144]) \n",
      "Test Loss tensor([0.0406, 0.0116, 0.0027, 0.0228, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47138118743896484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0108, 0.0024, 0.0264, 0.0164]) \n",
      "Test Loss tensor([0.0403, 0.0114, 0.0025, 0.0233, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47293615341186523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0106, 0.0022, 0.0239, 0.0123]) \n",
      "Test Loss tensor([0.0407, 0.0116, 0.0025, 0.0235, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47350597381591797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0109, 0.0025, 0.0215, 0.0153]) \n",
      "Test Loss tensor([0.0380, 0.0105, 0.0025, 0.0230, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.474196195602417 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0106, 0.0030, 0.0238, 0.0155]) \n",
      "Test Loss tensor([0.0403, 0.0115, 0.0026, 0.0232, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4726729393005371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0089, 0.0023, 0.0251, 0.0149]) \n",
      "Test Loss tensor([0.0396, 0.0112, 0.0025, 0.0217, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47188615798950195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0109, 0.0023, 0.0209, 0.0153]) \n",
      "Test Loss tensor([0.0398, 0.0120, 0.0026, 0.0228, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4697422981262207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0415, 0.0110, 0.0029, 0.0241, 0.0159]) \n",
      "Test Loss tensor([0.0388, 0.0115, 0.0026, 0.0220, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47263503074645996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0116, 0.0024, 0.0238, 0.0153]) \n",
      "Test Loss tensor([0.0406, 0.0114, 0.0027, 0.0236, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4720768928527832 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0105, 0.0029, 0.0239, 0.0149]) \n",
      "Test Loss tensor([0.0393, 0.0117, 0.0026, 0.0234, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4739093780517578 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0108, 0.0023, 0.0241, 0.0128]) \n",
      "Test Loss tensor([0.0396, 0.0118, 0.0025, 0.0236, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47211480140686035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0108, 0.0026, 0.0222, 0.0180]) \n",
      "Test Loss tensor([0.0401, 0.0115, 0.0026, 0.0224, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4713912010192871 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0112, 0.0027, 0.0234, 0.0141]) \n",
      "Test Loss tensor([0.0400, 0.0110, 0.0025, 0.0237, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.47210192680358887 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0386, 0.0107, 0.0027, 0.0228, 0.0156]) \n",
      "Test Loss tensor([0.0398, 0.0110, 0.0024, 0.0224, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.47435522079467773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0115, 0.0022, 0.0212, 0.0169]) \n",
      "Test Loss tensor([0.0392, 0.0110, 0.0025, 0.0235, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4744861125946045 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0113, 0.0025, 0.0230, 0.0152]) \n",
      "Test Loss tensor([0.0396, 0.0111, 0.0025, 0.0234, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4729290008544922 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0116, 0.0027, 0.0222, 0.0147]) \n",
      "Test Loss tensor([0.0397, 0.0115, 0.0026, 0.0225, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5040838718414307 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0432, 0.0095, 0.0025, 0.0206, 0.0138]) \n",
      "Test Loss tensor([0.0399, 0.0112, 0.0025, 0.0218, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4720311164855957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0355, 0.0117, 0.0025, 0.0241, 0.0134]) \n",
      "Test Loss tensor([0.0402, 0.0112, 0.0025, 0.0223, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.47498607635498047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0097, 0.0022, 0.0219, 0.0145]) \n",
      "Test Loss tensor([0.0397, 0.0104, 0.0024, 0.0228, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.47188329696655273 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0124, 0.0029, 0.0212, 0.0154]) \n",
      "Test Loss tensor([0.0395, 0.0107, 0.0026, 0.0229, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4765961170196533 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0090, 0.0024, 0.0230, 0.0146]) \n",
      "Test Loss tensor([0.0397, 0.0107, 0.0026, 0.0226, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4705815315246582 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0411, 0.0107, 0.0024, 0.0248, 0.0145]) \n",
      "Test Loss tensor([0.0397, 0.0110, 0.0025, 0.0223, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.47774386405944824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0107, 0.0024, 0.0234, 0.0146]) \n",
      "Test Loss tensor([0.0405, 0.0119, 0.0024, 0.0236, 0.0154])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4723360538482666 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0110, 0.0024, 0.0233, 0.0145]) \n",
      "Test Loss tensor([0.0395, 0.0113, 0.0025, 0.0232, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47490715980529785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0113, 0.0023, 0.0206, 0.0157]) \n",
      "Test Loss tensor([0.0399, 0.0119, 0.0027, 0.0227, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.47200584411621094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0427, 0.0141, 0.0024, 0.0213, 0.0157]) \n",
      "Test Loss tensor([0.0397, 0.0109, 0.0026, 0.0225, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.473555326461792 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0104, 0.0028, 0.0248, 0.0130]) \n",
      "Test Loss tensor([0.0401, 0.0112, 0.0025, 0.0222, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4797494411468506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0108, 0.0027, 0.0273, 0.0185]) \n",
      "Test Loss tensor([0.0397, 0.0115, 0.0025, 0.0238, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47580456733703613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0424, 0.0104, 0.0025, 0.0221, 0.0160]) \n",
      "Test Loss tensor([0.0385, 0.0109, 0.0025, 0.0216, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4740734100341797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0107, 0.0026, 0.0227, 0.0143]) \n",
      "Test Loss tensor([0.0392, 0.0107, 0.0025, 0.0236, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47359132766723633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0119, 0.0026, 0.0211, 0.0135]) \n",
      "Test Loss tensor([0.0398, 0.0108, 0.0024, 0.0221, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.4734992980957031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0097, 0.0024, 0.0226, 0.0155]) \n",
      "Test Loss tensor([0.0392, 0.0117, 0.0024, 0.0229, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4744839668273926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0098, 0.0026, 0.0191, 0.0122]) \n",
      "Test Loss tensor([0.0391, 0.0109, 0.0025, 0.0225, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4719405174255371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0432, 0.0125, 0.0030, 0.0221, 0.0166]) \n",
      "Test Loss tensor([0.0392, 0.0110, 0.0025, 0.0230, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.471677303314209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0403, 0.0128, 0.0026, 0.0232, 0.0173]) \n",
      "Test Loss tensor([0.0402, 0.0111, 0.0026, 0.0222, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47287988662719727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0118, 0.0027, 0.0240, 0.0155]) \n",
      "Test Loss tensor([0.0383, 0.0113, 0.0024, 0.0219, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47092556953430176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0113, 0.0024, 0.0199, 0.0151]) \n",
      "Test Loss tensor([0.0391, 0.0108, 0.0026, 0.0225, 0.0148])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 788 in 0.471297025680542 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0402, 0.0085, 0.0029, 0.0229, 0.0151]) \n",
      "Test Loss tensor([0.0395, 0.0107, 0.0025, 0.0222, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47008681297302246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0113, 0.0025, 0.0226, 0.0156]) \n",
      "Test Loss tensor([0.0387, 0.0110, 0.0024, 0.0226, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47508978843688965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0111, 0.0023, 0.0216, 0.0146]) \n",
      "Test Loss tensor([0.0391, 0.0116, 0.0025, 0.0226, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4709665775299072 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0117, 0.0024, 0.0203, 0.0147]) \n",
      "Test Loss tensor([0.0390, 0.0107, 0.0026, 0.0223, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4726247787475586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0105, 0.0028, 0.0241, 0.0160]) \n",
      "Test Loss tensor([0.0388, 0.0112, 0.0026, 0.0218, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47147440910339355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0100, 0.0023, 0.0224, 0.0140]) \n",
      "Test Loss tensor([0.0387, 0.0113, 0.0025, 0.0229, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47255778312683105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0105, 0.0026, 0.0231, 0.0155]) \n",
      "Test Loss tensor([0.0390, 0.0109, 0.0026, 0.0220, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4713003635406494 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0390, 0.0090, 0.0024, 0.0211, 0.0145]) \n",
      "Test Loss tensor([0.0391, 0.0113, 0.0025, 0.0227, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.4769282341003418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0106, 0.0026, 0.0233, 0.0166]) \n",
      "Test Loss tensor([0.0390, 0.0108, 0.0024, 0.0224, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.47289323806762695 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0093, 0.0022, 0.0199, 0.0136]) \n",
      "Test Loss tensor([0.0392, 0.0114, 0.0024, 0.0229, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4730949401855469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0103, 0.0025, 0.0253, 0.0155]) \n",
      "Test Loss tensor([0.0394, 0.0107, 0.0025, 0.0220, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4717702865600586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0097, 0.0030, 0.0239, 0.0147]) \n",
      "Test Loss tensor([0.0405, 0.0112, 0.0026, 0.0233, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4709012508392334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0108, 0.0023, 0.0197, 0.0173]) \n",
      "Test Loss tensor([0.0404, 0.0105, 0.0025, 0.0225, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4719703197479248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0106, 0.0023, 0.0267, 0.0162]) \n",
      "Test Loss tensor([0.0395, 0.0110, 0.0024, 0.0227, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.47262120246887207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0096, 0.0024, 0.0229, 0.0147]) \n",
      "Test Loss tensor([0.0402, 0.0111, 0.0024, 0.0237, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47359681129455566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0385, 0.0103, 0.0023, 0.0223, 0.0152]) \n",
      "Test Loss tensor([0.0393, 0.0106, 0.0026, 0.0221, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4757671356201172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0100, 0.0030, 0.0219, 0.0146]) \n",
      "Test Loss tensor([0.0394, 0.0111, 0.0026, 0.0236, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47124695777893066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0100, 0.0023, 0.0223, 0.0169]) \n",
      "Test Loss tensor([0.0393, 0.0113, 0.0026, 0.0221, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4706282615661621 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0118, 0.0026, 0.0212, 0.0140]) \n",
      "Test Loss tensor([0.0407, 0.0116, 0.0025, 0.0246, 0.0156])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4743533134460449 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0122, 0.0021, 0.0263, 0.0138]) \n",
      "Test Loss tensor([0.0388, 0.0106, 0.0024, 0.0222, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4710259437561035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0318, 0.0104, 0.0026, 0.0194, 0.0145]) \n",
      "Test Loss tensor([0.0408, 0.0115, 0.0026, 0.0231, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4886624813079834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0439, 0.0123, 0.0028, 0.0243, 0.0155]) \n",
      "Test Loss tensor([0.0378, 0.0112, 0.0025, 0.0237, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4534568786621094 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0295, 0.0071, 0.0017, 0.0168, 0.0115]) \n",
      "Test Loss tensor([0.0399, 0.0108, 0.0025, 0.0234, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5119554996490479 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0101, 0.0023, 0.0262, 0.0151]) \n",
      "Test Loss tensor([0.0389, 0.0113, 0.0025, 0.0211, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.47347187995910645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0088, 0.0024, 0.0235, 0.0132]) \n",
      "Test Loss tensor([0.0382, 0.0106, 0.0026, 0.0229, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4734811782836914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0098, 0.0024, 0.0203, 0.0161]) \n",
      "Test Loss tensor([0.0387, 0.0111, 0.0025, 0.0237, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47161245346069336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0100, 0.0027, 0.0211, 0.0133]) \n",
      "Test Loss tensor([0.0386, 0.0106, 0.0024, 0.0224, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47680187225341797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0100, 0.0026, 0.0225, 0.0159]) \n",
      "Test Loss tensor([0.0392, 0.0115, 0.0025, 0.0218, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47328972816467285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0112, 0.0026, 0.0234, 0.0163]) \n",
      "Test Loss tensor([0.0392, 0.0110, 0.0026, 0.0226, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.473696231842041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0121, 0.0024, 0.0235, 0.0164]) \n",
      "Test Loss tensor([0.0388, 0.0109, 0.0026, 0.0225, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4733860492706299 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0106, 0.0023, 0.0197, 0.0158]) \n",
      "Test Loss tensor([0.0391, 0.0111, 0.0027, 0.0222, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4754362106323242 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0096, 0.0026, 0.0220, 0.0146]) \n",
      "Test Loss tensor([0.0376, 0.0110, 0.0025, 0.0226, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4759683609008789 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0421, 0.0109, 0.0030, 0.0214, 0.0150]) \n",
      "Test Loss tensor([0.0376, 0.0113, 0.0025, 0.0224, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.47556138038635254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0090, 0.0024, 0.0200, 0.0137]) \n",
      "Test Loss tensor([0.0382, 0.0110, 0.0026, 0.0228, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4750094413757324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0117, 0.0025, 0.0218, 0.0147]) \n",
      "Test Loss tensor([0.0383, 0.0111, 0.0026, 0.0227, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4829268455505371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0106, 0.0030, 0.0205, 0.0170]) \n",
      "Test Loss tensor([0.0393, 0.0111, 0.0025, 0.0228, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.48931431770324707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0088, 0.0025, 0.0202, 0.0153]) \n",
      "Test Loss tensor([0.0384, 0.0112, 0.0026, 0.0226, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4722268581390381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0094, 0.0029, 0.0226, 0.0170]) \n",
      "Test Loss tensor([0.0389, 0.0111, 0.0026, 0.0227, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4774196147918701 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0376, 0.0108, 0.0028, 0.0239, 0.0136]) \n",
      "Test Loss tensor([0.0392, 0.0109, 0.0026, 0.0223, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4722418785095215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0109, 0.0026, 0.0223, 0.0154]) \n",
      "Test Loss tensor([0.0385, 0.0114, 0.0025, 0.0217, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4754030704498291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0095, 0.0027, 0.0221, 0.0166]) \n",
      "Test Loss tensor([0.0385, 0.0109, 0.0025, 0.0222, 0.0148])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 72 in 0.4771304130554199 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0095, 0.0024, 0.0223, 0.0159]) \n",
      "Test Loss tensor([0.0380, 0.0112, 0.0025, 0.0214, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4763326644897461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0127, 0.0029, 0.0216, 0.0155]) \n",
      "Test Loss tensor([0.0386, 0.0108, 0.0025, 0.0222, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.47255492210388184 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0108, 0.0028, 0.0220, 0.0160]) \n",
      "Test Loss tensor([0.0386, 0.0109, 0.0025, 0.0219, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.48087620735168457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0093, 0.0024, 0.0213, 0.0150]) \n",
      "Test Loss tensor([0.0383, 0.0108, 0.0025, 0.0220, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.47226786613464355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0394, 0.0112, 0.0023, 0.0213, 0.0157]) \n",
      "Test Loss tensor([0.0398, 0.0112, 0.0025, 0.0218, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4822094440460205 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0112, 0.0025, 0.0217, 0.0159]) \n",
      "Test Loss tensor([0.0390, 0.0110, 0.0025, 0.0231, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47482943534851074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0118, 0.0023, 0.0234, 0.0147]) \n",
      "Test Loss tensor([0.0378, 0.0111, 0.0024, 0.0226, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47650694847106934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0115, 0.0025, 0.0231, 0.0145]) \n",
      "Test Loss tensor([0.0395, 0.0112, 0.0024, 0.0223, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47618722915649414 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0405, 0.0101, 0.0026, 0.0203, 0.0155]) \n",
      "Test Loss tensor([0.0389, 0.0104, 0.0024, 0.0223, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.48046207427978516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0110, 0.0023, 0.0224, 0.0131]) \n",
      "Test Loss tensor([0.0392, 0.0111, 0.0025, 0.0224, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4742872714996338 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0094, 0.0023, 0.0217, 0.0136]) \n",
      "Test Loss tensor([0.0382, 0.0106, 0.0025, 0.0223, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4755074977874756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0413, 0.0104, 0.0027, 0.0195, 0.0167]) \n",
      "Test Loss tensor([0.0382, 0.0108, 0.0024, 0.0230, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.47270750999450684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0100, 0.0025, 0.0230, 0.0153]) \n",
      "Test Loss tensor([0.0380, 0.0107, 0.0026, 0.0220, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.476823091506958 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0107, 0.0026, 0.0250, 0.0148]) \n",
      "Test Loss tensor([0.0384, 0.0109, 0.0026, 0.0221, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4755403995513916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0115, 0.0024, 0.0216, 0.0141]) \n",
      "Test Loss tensor([0.0381, 0.0111, 0.0026, 0.0227, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.47710514068603516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0099, 0.0024, 0.0200, 0.0137]) \n",
      "Test Loss tensor([0.0394, 0.0110, 0.0025, 0.0240, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4744892120361328 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0130, 0.0021, 0.0265, 0.0168]) \n",
      "Test Loss tensor([0.0392, 0.0116, 0.0026, 0.0220, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47539258003234863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0112, 0.0027, 0.0224, 0.0163]) \n",
      "Test Loss tensor([0.0394, 0.0107, 0.0027, 0.0226, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4729957580566406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0343, 0.0098, 0.0024, 0.0238, 0.0144]) \n",
      "Test Loss tensor([0.0383, 0.0113, 0.0025, 0.0228, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.47893357276916504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0100, 0.0028, 0.0202, 0.0162]) \n",
      "Test Loss tensor([0.0382, 0.0108, 0.0025, 0.0222, 0.0155])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4717679023742676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0125, 0.0025, 0.0199, 0.0130]) \n",
      "Test Loss tensor([0.0380, 0.0106, 0.0024, 0.0222, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4787890911102295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0099, 0.0023, 0.0205, 0.0157]) \n",
      "Test Loss tensor([0.0387, 0.0108, 0.0025, 0.0229, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4921586513519287 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0385, 0.0100, 0.0027, 0.0213, 0.0153]) \n",
      "Test Loss tensor([0.0389, 0.0108, 0.0025, 0.0227, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.47371935844421387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0103, 0.0024, 0.0234, 0.0134]) \n",
      "Test Loss tensor([0.0379, 0.0106, 0.0024, 0.0220, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4791710376739502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0101, 0.0021, 0.0206, 0.0153]) \n",
      "Test Loss tensor([0.0387, 0.0108, 0.0024, 0.0221, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47664690017700195 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0108, 0.0026, 0.0240, 0.0150]) \n",
      "Test Loss tensor([0.0383, 0.0110, 0.0024, 0.0225, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.4767177104949951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0106, 0.0024, 0.0235, 0.0146]) \n",
      "Test Loss tensor([0.0366, 0.0108, 0.0024, 0.0221, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4763922691345215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0412, 0.0103, 0.0026, 0.0195, 0.0135]) \n",
      "Test Loss tensor([0.0378, 0.0107, 0.0025, 0.0220, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4737370014190674 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0107, 0.0025, 0.0252, 0.0133]) \n",
      "Test Loss tensor([0.0381, 0.0106, 0.0024, 0.0216, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47601938247680664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0124, 0.0023, 0.0229, 0.0143]) \n",
      "Test Loss tensor([0.0376, 0.0103, 0.0025, 0.0227, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4776003360748291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0102, 0.0024, 0.0217, 0.0159]) \n",
      "Test Loss tensor([0.0391, 0.0110, 0.0024, 0.0222, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4709913730621338 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0117, 0.0024, 0.0212, 0.0135]) \n",
      "Test Loss tensor([0.0386, 0.0111, 0.0024, 0.0217, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47244930267333984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0112, 0.0023, 0.0210, 0.0143]) \n",
      "Test Loss tensor([0.0377, 0.0107, 0.0025, 0.0213, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.47398853302001953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0090, 0.0028, 0.0218, 0.0155]) \n",
      "Test Loss tensor([0.0375, 0.0110, 0.0025, 0.0226, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4837925434112549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0099, 0.0025, 0.0212, 0.0157]) \n",
      "Test Loss tensor([0.0390, 0.0110, 0.0026, 0.0215, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.49468398094177246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0376, 0.0097, 0.0026, 0.0229, 0.0154]) \n",
      "Test Loss tensor([0.0398, 0.0112, 0.0025, 0.0221, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4729764461517334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0096, 0.0021, 0.0218, 0.0155]) \n",
      "Test Loss tensor([0.0381, 0.0110, 0.0025, 0.0221, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4950845241546631 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0137, 0.0028, 0.0232, 0.0157]) \n",
      "Test Loss tensor([0.0384, 0.0106, 0.0026, 0.0229, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47583532333374023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0106, 0.0034, 0.0225, 0.0159]) \n",
      "Test Loss tensor([0.0380, 0.0111, 0.0025, 0.0221, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4716508388519287 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0111, 0.0022, 0.0225, 0.0142]) \n",
      "Test Loss tensor([0.0390, 0.0107, 0.0024, 0.0232, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47168445587158203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0114, 0.0027, 0.0243, 0.0139]) \n",
      "Test Loss tensor([0.0374, 0.0109, 0.0025, 0.0234, 0.0143])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 236 in 0.4715268611907959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0091, 0.0023, 0.0269, 0.0141]) \n",
      "Test Loss tensor([0.0382, 0.0114, 0.0025, 0.0223, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.476184606552124 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0101, 0.0025, 0.0216, 0.0157]) \n",
      "Test Loss tensor([0.0373, 0.0106, 0.0025, 0.0220, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.49182868003845215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0099, 0.0025, 0.0224, 0.0150]) \n",
      "Test Loss tensor([0.0386, 0.0115, 0.0026, 0.0211, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4720602035522461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0106, 0.0022, 0.0242, 0.0139]) \n",
      "Test Loss tensor([0.0376, 0.0110, 0.0024, 0.0222, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.47757482528686523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0398, 0.0090, 0.0023, 0.0245, 0.0163]) \n",
      "Test Loss tensor([0.0380, 0.0103, 0.0025, 0.0209, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47141194343566895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0109, 0.0028, 0.0222, 0.0147]) \n",
      "Test Loss tensor([0.0388, 0.0104, 0.0025, 0.0230, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4989197254180908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0100, 0.0023, 0.0202, 0.0158]) \n",
      "Test Loss tensor([0.0388, 0.0112, 0.0026, 0.0223, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4716312885284424 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0105, 0.0025, 0.0230, 0.0157]) \n",
      "Test Loss tensor([0.0376, 0.0109, 0.0024, 0.0217, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4729955196380615 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0103, 0.0026, 0.0198, 0.0162]) \n",
      "Test Loss tensor([0.0395, 0.0115, 0.0024, 0.0229, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4709482192993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0107, 0.0027, 0.0222, 0.0137]) \n",
      "Test Loss tensor([0.0375, 0.0104, 0.0024, 0.0224, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4770832061767578 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0105, 0.0028, 0.0237, 0.0155]) \n",
      "Test Loss tensor([0.0404, 0.0113, 0.0026, 0.0237, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4741485118865967 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0097, 0.0025, 0.0241, 0.0159]) \n",
      "Test Loss tensor([0.0380, 0.0103, 0.0025, 0.0210, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4744565486907959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0098, 0.0027, 0.0210, 0.0144]) \n",
      "Test Loss tensor([0.0380, 0.0111, 0.0024, 0.0220, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4706766605377197 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0385, 0.0128, 0.0021, 0.0220, 0.0140]) \n",
      "Test Loss tensor([0.0375, 0.0110, 0.0024, 0.0232, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.473827600479126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0120, 0.0020, 0.0234, 0.0150]) \n",
      "Test Loss tensor([0.0371, 0.0105, 0.0025, 0.0211, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4732956886291504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0108, 0.0023, 0.0199, 0.0140]) \n",
      "Test Loss tensor([0.0385, 0.0107, 0.0026, 0.0227, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47322988510131836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0136, 0.0028, 0.0176, 0.0142]) \n",
      "Test Loss tensor([0.0374, 0.0111, 0.0025, 0.0221, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47267746925354004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0118, 0.0025, 0.0227, 0.0156]) \n",
      "Test Loss tensor([0.0384, 0.0113, 0.0025, 0.0226, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47331976890563965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0109, 0.0024, 0.0195, 0.0144]) \n",
      "Test Loss tensor([0.0379, 0.0110, 0.0026, 0.0219, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.48125481605529785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0081, 0.0024, 0.0209, 0.0138]) \n",
      "Test Loss tensor([0.0377, 0.0112, 0.0026, 0.0224, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4724869728088379 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0097, 0.0025, 0.0218, 0.0145]) \n",
      "Test Loss tensor([0.0372, 0.0107, 0.0025, 0.0212, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.47429561614990234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0092, 0.0023, 0.0229, 0.0144]) \n",
      "Test Loss tensor([0.0385, 0.0112, 0.0025, 0.0225, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4788484573364258 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0106, 0.0021, 0.0207, 0.0136]) \n",
      "Test Loss tensor([0.0379, 0.0106, 0.0026, 0.0215, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4885098934173584 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0130, 0.0024, 0.0198, 0.0154]) \n",
      "Test Loss tensor([0.0377, 0.0105, 0.0027, 0.0212, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.47643041610717773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0106, 0.0023, 0.0239, 0.0142]) \n",
      "Test Loss tensor([0.0380, 0.0107, 0.0025, 0.0213, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4768674373626709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0105, 0.0024, 0.0225, 0.0143]) \n",
      "Test Loss tensor([0.0376, 0.0105, 0.0025, 0.0216, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.47706151008605957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0098, 0.0023, 0.0207, 0.0138]) \n",
      "Test Loss tensor([0.0378, 0.0110, 0.0024, 0.0223, 0.0148])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47376179695129395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0114, 0.0027, 0.0220, 0.0151]) \n",
      "Test Loss tensor([0.0373, 0.0109, 0.0025, 0.0209, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47289180755615234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0119, 0.0025, 0.0222, 0.0142]) \n",
      "Test Loss tensor([0.0377, 0.0110, 0.0025, 0.0216, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.47341251373291016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0087, 0.0026, 0.0228, 0.0149]) \n",
      "Test Loss tensor([0.0378, 0.0104, 0.0025, 0.0218, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4709138870239258 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0094, 0.0025, 0.0234, 0.0133]) \n",
      "Test Loss tensor([0.0375, 0.0105, 0.0025, 0.0216, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.476426362991333 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0089, 0.0022, 0.0205, 0.0140]) \n",
      "Test Loss tensor([0.0378, 0.0110, 0.0024, 0.0227, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4696364402770996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0107, 0.0023, 0.0219, 0.0144]) \n",
      "Test Loss tensor([0.0387, 0.0110, 0.0024, 0.0222, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4732367992401123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0107, 0.0025, 0.0193, 0.0146]) \n",
      "Test Loss tensor([0.0375, 0.0108, 0.0025, 0.0209, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.47188401222229004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0123, 0.0026, 0.0193, 0.0154]) \n",
      "Test Loss tensor([0.0371, 0.0104, 0.0024, 0.0216, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.47214579582214355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0106, 0.0031, 0.0190, 0.0140]) \n",
      "Test Loss tensor([0.0372, 0.0111, 0.0025, 0.0214, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.47329020500183105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0104, 0.0026, 0.0217, 0.0144]) \n",
      "Test Loss tensor([0.0391, 0.0108, 0.0024, 0.0228, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4770939350128174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0098, 0.0024, 0.0248, 0.0128]) \n",
      "Test Loss tensor([0.0376, 0.0106, 0.0025, 0.0220, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4711275100708008 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0363, 0.0106, 0.0026, 0.0200, 0.0154]) \n",
      "Test Loss tensor([0.0386, 0.0109, 0.0026, 0.0216, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.472151517868042 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0104, 0.0025, 0.0216, 0.0137]) \n",
      "Test Loss tensor([0.0385, 0.0105, 0.0026, 0.0224, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.47246360778808594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0407, 0.0105, 0.0025, 0.0242, 0.0146]) \n",
      "Test Loss tensor([0.0381, 0.0112, 0.0025, 0.0226, 0.0143])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.4722168445587158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0113, 0.0023, 0.0192, 0.0130]) \n",
      "Test Loss tensor([0.0385, 0.0112, 0.0025, 0.0222, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.47148799896240234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0114, 0.0025, 0.0245, 0.0139]) \n",
      "Test Loss tensor([0.0384, 0.0110, 0.0027, 0.0217, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4729640483856201 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0420, 0.0111, 0.0025, 0.0230, 0.0151]) \n",
      "Test Loss tensor([0.0402, 0.0109, 0.0029, 0.0231, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47324514389038086 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0120, 0.0029, 0.0219, 0.0155]) \n",
      "Test Loss tensor([0.0377, 0.0110, 0.0025, 0.0221, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.47178006172180176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0089, 0.0026, 0.0229, 0.0168]) \n",
      "Test Loss tensor([0.0402, 0.0108, 0.0024, 0.0244, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.47331881523132324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0113, 0.0026, 0.0225, 0.0175]) \n",
      "Test Loss tensor([0.0376, 0.0107, 0.0024, 0.0218, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4706716537475586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0096, 0.0027, 0.0218, 0.0128]) \n",
      "Test Loss tensor([0.0385, 0.0108, 0.0027, 0.0228, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.472017765045166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0113, 0.0030, 0.0222, 0.0139]) \n",
      "Test Loss tensor([0.0370, 0.0101, 0.0025, 0.0219, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4702627658843994 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0094, 0.0024, 0.0218, 0.0125]) \n",
      "Test Loss tensor([0.0395, 0.0105, 0.0023, 0.0229, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4745473861694336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0114, 0.0021, 0.0203, 0.0141]) \n",
      "Test Loss tensor([0.0405, 0.0109, 0.0024, 0.0225, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4701259136199951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0099, 0.0024, 0.0237, 0.0154]) \n",
      "Test Loss tensor([0.0381, 0.0108, 0.0025, 0.0220, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47319626808166504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0106, 0.0025, 0.0243, 0.0141]) \n",
      "Test Loss tensor([0.0404, 0.0102, 0.0025, 0.0229, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4711439609527588 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0401, 0.0093, 0.0023, 0.0273, 0.0154]) \n",
      "Test Loss tensor([0.0385, 0.0110, 0.0024, 0.0214, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.47334909439086914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0113, 0.0023, 0.0219, 0.0137]) \n",
      "Test Loss tensor([0.0389, 0.0108, 0.0024, 0.0232, 0.0147])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.469409704208374 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0113, 0.0025, 0.0254, 0.0139]) \n",
      "Test Loss tensor([0.0374, 0.0103, 0.0024, 0.0219, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.47166895866394043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0341, 0.0121, 0.0025, 0.0194, 0.0157]) \n",
      "Test Loss tensor([0.0391, 0.0105, 0.0025, 0.0225, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4709510803222656 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0381, 0.0098, 0.0022, 0.0232, 0.0150]) \n",
      "Test Loss tensor([0.0368, 0.0108, 0.0024, 0.0229, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47296738624572754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0395, 0.0115, 0.0022, 0.0205, 0.0157]) \n",
      "Test Loss tensor([0.0370, 0.0109, 0.0024, 0.0230, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.47248172760009766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0388, 0.0100, 0.0023, 0.0249, 0.0142]) \n",
      "Test Loss tensor([0.0367, 0.0104, 0.0024, 0.0212, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4735262393951416 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0129, 0.0021, 0.0228, 0.0145]) \n",
      "Test Loss tensor([0.0375, 0.0111, 0.0025, 0.0220, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47159790992736816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0308, 0.0089, 0.0025, 0.0240, 0.0138]) \n",
      "Test Loss tensor([0.0373, 0.0112, 0.0026, 0.0225, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47138261795043945 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0092, 0.0027, 0.0230, 0.0157]) \n",
      "Test Loss tensor([0.0366, 0.0103, 0.0024, 0.0212, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4713428020477295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0100, 0.0025, 0.0212, 0.0157]) \n",
      "Test Loss tensor([0.0384, 0.0113, 0.0024, 0.0221, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4701507091522217 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0307, 0.0109, 0.0023, 0.0263, 0.0130]) \n",
      "Test Loss tensor([0.0369, 0.0110, 0.0025, 0.0211, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.494814395904541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0109, 0.0026, 0.0226, 0.0132]) \n",
      "Test Loss tensor([0.0373, 0.0104, 0.0026, 0.0220, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.47264742851257324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0385, 0.0084, 0.0028, 0.0224, 0.0131]) \n",
      "Test Loss tensor([0.0379, 0.0106, 0.0025, 0.0207, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.47219085693359375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0111, 0.0026, 0.0218, 0.0155]) \n",
      "Test Loss tensor([0.0379, 0.0108, 0.0025, 0.0214, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4707825183868408 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0082, 0.0023, 0.0233, 0.0126]) \n",
      "Test Loss tensor([0.0367, 0.0106, 0.0025, 0.0223, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47716689109802246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0363, 0.0087, 0.0025, 0.0227, 0.0136]) \n",
      "Test Loss tensor([0.0377, 0.0108, 0.0026, 0.0212, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4698295593261719 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0376, 0.0113, 0.0023, 0.0215, 0.0180]) \n",
      "Test Loss tensor([0.0374, 0.0110, 0.0025, 0.0217, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4738137722015381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0124, 0.0030, 0.0226, 0.0141]) \n",
      "Test Loss tensor([0.0369, 0.0105, 0.0025, 0.0228, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4709503650665283 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0355, 0.0096, 0.0021, 0.0226, 0.0122]) \n",
      "Test Loss tensor([0.0381, 0.0101, 0.0025, 0.0237, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47532081604003906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0106, 0.0023, 0.0221, 0.0137]) \n",
      "Test Loss tensor([0.0374, 0.0103, 0.0024, 0.0221, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4699716567993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0106, 0.0027, 0.0222, 0.0110]) \n",
      "Test Loss tensor([0.0382, 0.0109, 0.0024, 0.0221, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4734165668487549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0110, 0.0025, 0.0194, 0.0118]) \n",
      "Test Loss tensor([0.0374, 0.0108, 0.0024, 0.0231, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4720032215118408 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0110, 0.0027, 0.0204, 0.0139]) \n",
      "Test Loss tensor([0.0382, 0.0110, 0.0024, 0.0224, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4751405715942383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0092, 0.0026, 0.0207, 0.0150]) \n",
      "Test Loss tensor([0.0390, 0.0108, 0.0024, 0.0234, 0.0153])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4707489013671875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0411, 0.0097, 0.0022, 0.0229, 0.0150]) \n",
      "Test Loss tensor([0.0373, 0.0107, 0.0023, 0.0212, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4728832244873047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0089, 0.0023, 0.0224, 0.0163]) \n",
      "Test Loss tensor([0.0392, 0.0108, 0.0025, 0.0233, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47133851051330566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0099, 0.0023, 0.0237, 0.0149]) \n",
      "Test Loss tensor([0.0370, 0.0105, 0.0025, 0.0214, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.47287774085998535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0118, 0.0024, 0.0219, 0.0141]) \n",
      "Test Loss tensor([0.0373, 0.0106, 0.0024, 0.0217, 0.0140])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 564 in 0.47388148307800293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0414, 0.0104, 0.0021, 0.0226, 0.0141]) \n",
      "Test Loss tensor([0.0363, 0.0102, 0.0025, 0.0222, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.47267651557922363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0089, 0.0022, 0.0217, 0.0154]) \n",
      "Test Loss tensor([0.0363, 0.0101, 0.0024, 0.0213, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.480576753616333 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0090, 0.0023, 0.0194, 0.0131]) \n",
      "Test Loss tensor([0.0374, 0.0105, 0.0025, 0.0215, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.48139476776123047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0098, 0.0025, 0.0213, 0.0156]) \n",
      "Test Loss tensor([0.0369, 0.0107, 0.0025, 0.0218, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47991108894348145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0112, 0.0025, 0.0201, 0.0137]) \n",
      "Test Loss tensor([0.0364, 0.0106, 0.0024, 0.0223, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.48075127601623535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0116, 0.0025, 0.0210, 0.0129]) \n",
      "Test Loss tensor([0.0359, 0.0103, 0.0025, 0.0210, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4823441505432129 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0104, 0.0028, 0.0194, 0.0131]) \n",
      "Test Loss tensor([0.0379, 0.0108, 0.0025, 0.0217, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4781355857849121 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0107, 0.0021, 0.0184, 0.0136]) \n",
      "Test Loss tensor([0.0365, 0.0103, 0.0024, 0.0215, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.48172664642333984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0386, 0.0114, 0.0022, 0.0193, 0.0142]) \n",
      "Test Loss tensor([0.0376, 0.0106, 0.0025, 0.0214, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4771437644958496 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0089, 0.0025, 0.0198, 0.0128]) \n",
      "Test Loss tensor([0.0367, 0.0097, 0.0025, 0.0220, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4789435863494873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0090, 0.0024, 0.0202, 0.0145]) \n",
      "Test Loss tensor([0.0368, 0.0099, 0.0024, 0.0223, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47989892959594727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0124, 0.0024, 0.0198, 0.0152]) \n",
      "Test Loss tensor([0.0374, 0.0104, 0.0023, 0.0219, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4838075637817383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0090, 0.0022, 0.0231, 0.0130]) \n",
      "Test Loss tensor([0.0375, 0.0101, 0.0024, 0.0210, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.47519731521606445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0091, 0.0027, 0.0207, 0.0130]) \n",
      "Test Loss tensor([0.0377, 0.0102, 0.0023, 0.0209, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4808800220489502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0109, 0.0024, 0.0217, 0.0140]) \n",
      "Test Loss tensor([0.0363, 0.0107, 0.0023, 0.0223, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4765586853027344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0102, 0.0023, 0.0216, 0.0144]) \n",
      "Test Loss tensor([0.0370, 0.0106, 0.0024, 0.0216, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.48554301261901855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0100, 0.0026, 0.0215, 0.0135]) \n",
      "Test Loss tensor([0.0361, 0.0104, 0.0023, 0.0220, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4754180908203125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0404, 0.0088, 0.0024, 0.0212, 0.0124]) \n",
      "Test Loss tensor([0.0372, 0.0105, 0.0023, 0.0220, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.47751593589782715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0094, 0.0022, 0.0213, 0.0159]) \n",
      "Test Loss tensor([0.0374, 0.0107, 0.0023, 0.0221, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47624897956848145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0388, 0.0105, 0.0023, 0.0213, 0.0139]) \n",
      "Test Loss tensor([0.0368, 0.0102, 0.0024, 0.0228, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47919440269470215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0112, 0.0022, 0.0224, 0.0133]) \n",
      "Test Loss tensor([0.0362, 0.0101, 0.0024, 0.0230, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.477245569229126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0113, 0.0025, 0.0204, 0.0126]) \n",
      "Test Loss tensor([0.0370, 0.0109, 0.0023, 0.0209, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.477405309677124 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0116, 0.0024, 0.0213, 0.0151]) \n",
      "Test Loss tensor([0.0367, 0.0104, 0.0024, 0.0218, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4776337146759033 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0086, 0.0023, 0.0204, 0.0156]) \n",
      "Test Loss tensor([0.0362, 0.0100, 0.0024, 0.0221, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47867655754089355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0317, 0.0088, 0.0021, 0.0213, 0.0153]) \n",
      "Test Loss tensor([0.0374, 0.0109, 0.0025, 0.0204, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.48950958251953125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0103, 0.0026, 0.0177, 0.0119]) \n",
      "Test Loss tensor([0.0378, 0.0104, 0.0023, 0.0218, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47629356384277344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0099, 0.0021, 0.0219, 0.0132]) \n",
      "Test Loss tensor([0.0363, 0.0106, 0.0023, 0.0221, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4801790714263916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0085, 0.0025, 0.0204, 0.0153]) \n",
      "Test Loss tensor([0.0374, 0.0104, 0.0023, 0.0213, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4755399227142334 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0113, 0.0024, 0.0222, 0.0149]) \n",
      "Test Loss tensor([0.0367, 0.0104, 0.0024, 0.0213, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4780149459838867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0101, 0.0021, 0.0190, 0.0141]) \n",
      "Test Loss tensor([0.0369, 0.0101, 0.0024, 0.0214, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4740879535675049 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0105, 0.0026, 0.0234, 0.0135]) \n",
      "Test Loss tensor([0.0377, 0.0107, 0.0024, 0.0220, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.47798871994018555 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0106, 0.0029, 0.0255, 0.0149]) \n",
      "Test Loss tensor([0.0378, 0.0104, 0.0024, 0.0213, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4756596088409424 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0098, 0.0022, 0.0220, 0.0131]) \n",
      "Test Loss tensor([0.0378, 0.0104, 0.0023, 0.0223, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4804084300994873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0406, 0.0113, 0.0027, 0.0244, 0.0148]) \n",
      "Test Loss tensor([0.0365, 0.0110, 0.0024, 0.0214, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4749913215637207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0280, 0.0102, 0.0023, 0.0216, 0.0117]) \n",
      "Test Loss tensor([0.0377, 0.0102, 0.0025, 0.0214, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4777841567993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0114, 0.0026, 0.0207, 0.0128]) \n",
      "Test Loss tensor([0.0368, 0.0111, 0.0023, 0.0221, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4771296977996826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0104, 0.0022, 0.0225, 0.0131]) \n",
      "Test Loss tensor([0.0370, 0.0106, 0.0024, 0.0216, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.48780155181884766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0097, 0.0025, 0.0211, 0.0132]) \n",
      "Test Loss tensor([0.0370, 0.0104, 0.0024, 0.0225, 0.0145])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.49967002868652344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0122, 0.0021, 0.0214, 0.0155]) \n",
      "Test Loss tensor([0.0374, 0.0099, 0.0024, 0.0214, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4857950210571289 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0094, 0.0023, 0.0200, 0.0141]) \n",
      "Test Loss tensor([0.0380, 0.0107, 0.0024, 0.0205, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.49444127082824707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0113, 0.0023, 0.0209, 0.0143]) \n",
      "Test Loss tensor([0.0373, 0.0103, 0.0024, 0.0208, 0.0135])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 728 in 0.4801907539367676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0118, 0.0023, 0.0227, 0.0147]) \n",
      "Test Loss tensor([0.0370, 0.0104, 0.0023, 0.0211, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47577857971191406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0088, 0.0021, 0.0218, 0.0145]) \n",
      "Test Loss tensor([0.0376, 0.0103, 0.0024, 0.0215, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4817345142364502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0416, 0.0106, 0.0025, 0.0222, 0.0143]) \n",
      "Test Loss tensor([0.0351, 0.0106, 0.0025, 0.0211, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4958841800689697 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0089, 0.0024, 0.0190, 0.0130]) \n",
      "Test Loss tensor([0.0366, 0.0107, 0.0027, 0.0213, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.47924017906188965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0105, 0.0024, 0.0204, 0.0151]) \n",
      "Test Loss tensor([0.0359, 0.0104, 0.0025, 0.0222, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5200481414794922 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0099, 0.0023, 0.0239, 0.0122]) \n",
      "Test Loss tensor([0.0374, 0.0105, 0.0025, 0.0218, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47896504402160645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0399, 0.0106, 0.0026, 0.0214, 0.0132]) \n",
      "Test Loss tensor([0.0366, 0.0105, 0.0025, 0.0213, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5004022121429443 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0109, 0.0029, 0.0188, 0.0146]) \n",
      "Test Loss tensor([0.0364, 0.0103, 0.0024, 0.0218, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4807600975036621 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0098, 0.0022, 0.0223, 0.0139]) \n",
      "Test Loss tensor([0.0362, 0.0100, 0.0024, 0.0218, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47765111923217773 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0109, 0.0023, 0.0234, 0.0137]) \n",
      "Test Loss tensor([0.0369, 0.0110, 0.0024, 0.0216, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4764106273651123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0114, 0.0027, 0.0198, 0.0153]) \n",
      "Test Loss tensor([0.0365, 0.0107, 0.0024, 0.0205, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.47818613052368164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0099, 0.0023, 0.0212, 0.0148]) \n",
      "Test Loss tensor([0.0373, 0.0104, 0.0025, 0.0217, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4782261848449707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0093, 0.0022, 0.0221, 0.0143]) \n",
      "Test Loss tensor([0.0364, 0.0099, 0.0024, 0.0224, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4757673740386963 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0108, 0.0021, 0.0214, 0.0128]) \n",
      "Test Loss tensor([0.0364, 0.0105, 0.0024, 0.0215, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.49277210235595703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0095, 0.0023, 0.0219, 0.0146]) \n",
      "Test Loss tensor([0.0351, 0.0100, 0.0024, 0.0218, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47507429122924805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0093, 0.0023, 0.0213, 0.0133]) \n",
      "Test Loss tensor([0.0366, 0.0107, 0.0023, 0.0213, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47852325439453125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0104, 0.0023, 0.0185, 0.0151]) \n",
      "Test Loss tensor([0.0375, 0.0105, 0.0026, 0.0226, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.48150134086608887 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0380, 0.0116, 0.0025, 0.0202, 0.0136]) \n",
      "Test Loss tensor([0.0357, 0.0106, 0.0024, 0.0224, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4743015766143799 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0088, 0.0021, 0.0221, 0.0130]) \n",
      "Test Loss tensor([0.0365, 0.0104, 0.0023, 0.0227, 0.0146])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4784877300262451 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0103, 0.0024, 0.0219, 0.0141]) \n",
      "Test Loss tensor([0.0366, 0.0100, 0.0024, 0.0198, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4773268699645996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0096, 0.0023, 0.0223, 0.0126]) \n",
      "Test Loss tensor([0.0384, 0.0107, 0.0024, 0.0220, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4786348342895508 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0096, 0.0025, 0.0220, 0.0135]) \n",
      "Test Loss tensor([0.0359, 0.0105, 0.0024, 0.0212, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47673988342285156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0096, 0.0022, 0.0199, 0.0140]) \n",
      "Test Loss tensor([0.0376, 0.0106, 0.0023, 0.0209, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.4817159175872803 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0088, 0.0022, 0.0216, 0.0112]) \n",
      "Test Loss tensor([0.0364, 0.0100, 0.0024, 0.0216, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.47676825523376465 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0383, 0.0107, 0.0026, 0.0208, 0.0130]) \n",
      "Test Loss tensor([0.0379, 0.0110, 0.0024, 0.0237, 0.0143])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.49414610862731934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0121, 0.0022, 0.0221, 0.0141]) \n",
      "Test Loss tensor([0.0361, 0.0100, 0.0025, 0.0219, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.48036646842956543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0113, 0.0029, 0.0231, 0.0147]) \n",
      "Test Loss tensor([0.0386, 0.0104, 0.0024, 0.0222, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.48014330863952637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0392, 0.0119, 0.0022, 0.0217, 0.0135]) \n",
      "Test Loss tensor([0.0362, 0.0103, 0.0024, 0.0217, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4790804386138916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0098, 0.0026, 0.0213, 0.0142]) \n",
      "Test Loss tensor([0.0366, 0.0106, 0.0025, 0.0220, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4802711009979248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0109, 0.0025, 0.0226, 0.0123]) \n",
      "Test Loss tensor([0.0366, 0.0108, 0.0024, 0.0214, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47560596466064453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0095, 0.0023, 0.0231, 0.0136]) \n",
      "Test Loss tensor([0.0373, 0.0109, 0.0024, 0.0222, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.477217435836792 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0109, 0.0022, 0.0239, 0.0116]) \n",
      "Test Loss tensor([0.0388, 0.0105, 0.0023, 0.0221, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47698259353637695 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0132, 0.0021, 0.0213, 0.0146]) \n",
      "Test Loss tensor([0.0369, 0.0104, 0.0025, 0.0213, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47754740715026855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0107, 0.0024, 0.0204, 0.0140]) \n",
      "Test Loss tensor([0.0368, 0.0107, 0.0025, 0.0223, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4773073196411133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0102, 0.0022, 0.0207, 0.0125]) \n",
      "Test Loss tensor([0.0360, 0.0104, 0.0023, 0.0213, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4768223762512207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0085, 0.0025, 0.0229, 0.0142]) \n",
      "Test Loss tensor([0.0376, 0.0101, 0.0023, 0.0214, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47641515731811523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0086, 0.0031, 0.0207, 0.0153]) \n",
      "Test Loss tensor([0.0363, 0.0109, 0.0023, 0.0208, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4622993469238281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0264, 0.0080, 0.0019, 0.0157, 0.0099]) \n",
      "Test Loss tensor([0.0362, 0.0107, 0.0023, 0.0216, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5222601890563965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0095, 0.0023, 0.0218, 0.0136]) \n",
      "Test Loss tensor([0.0366, 0.0103, 0.0024, 0.0211, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4608039855957031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0396, 0.0109, 0.0022, 0.0213, 0.0122]) \n",
      "Test Loss tensor([0.0376, 0.0102, 0.0024, 0.0205, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.46135520935058594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0106, 0.0023, 0.0242, 0.0133]) \n",
      "Test Loss tensor([0.0369, 0.0106, 0.0023, 0.0218, 0.0139])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 12 in 0.4591822624206543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0111, 0.0021, 0.0192, 0.0135]) \n",
      "Test Loss tensor([0.0371, 0.0107, 0.0024, 0.0218, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4622933864593506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0095, 0.0030, 0.0211, 0.0139]) \n",
      "Test Loss tensor([0.0360, 0.0101, 0.0024, 0.0212, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4636809825897217 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0101, 0.0022, 0.0230, 0.0147]) \n",
      "Test Loss tensor([0.0360, 0.0099, 0.0024, 0.0216, 0.0142])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.46343016624450684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0097, 0.0026, 0.0210, 0.0134]) \n",
      "Test Loss tensor([0.0362, 0.0104, 0.0024, 0.0233, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4615967273712158 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0110, 0.0027, 0.0195, 0.0142]) \n",
      "Test Loss tensor([0.0370, 0.0101, 0.0024, 0.0213, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4625515937805176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0116, 0.0022, 0.0226, 0.0158]) \n",
      "Test Loss tensor([0.0357, 0.0102, 0.0024, 0.0210, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.463329553604126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0370, 0.0097, 0.0028, 0.0179, 0.0128]) \n",
      "Test Loss tensor([0.0364, 0.0104, 0.0024, 0.0204, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.46397948265075684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0089, 0.0021, 0.0237, 0.0200]) \n",
      "Test Loss tensor([0.0370, 0.0101, 0.0024, 0.0209, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4610128402709961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0372, 0.0103, 0.0022, 0.0203, 0.0136]) \n",
      "Test Loss tensor([0.0355, 0.0102, 0.0023, 0.0217, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47066187858581543 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0098, 0.0023, 0.0226, 0.0129]) \n",
      "Test Loss tensor([0.0358, 0.0100, 0.0023, 0.0211, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4666755199432373 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0093, 0.0027, 0.0182, 0.0123]) \n",
      "Test Loss tensor([0.0368, 0.0105, 0.0023, 0.0214, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.46473073959350586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0101, 0.0022, 0.0185, 0.0131]) \n",
      "Test Loss tensor([0.0361, 0.0103, 0.0024, 0.0208, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4675178527832031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0102, 0.0025, 0.0194, 0.0146]) \n",
      "Test Loss tensor([0.0359, 0.0108, 0.0024, 0.0215, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.46744704246520996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0391, 0.0108, 0.0027, 0.0220, 0.0124]) \n",
      "Test Loss tensor([0.0363, 0.0109, 0.0024, 0.0220, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4671289920806885 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0110, 0.0025, 0.0214, 0.0140]) \n",
      "Test Loss tensor([0.0354, 0.0107, 0.0023, 0.0221, 0.0141])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4656643867492676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0110, 0.0023, 0.0204, 0.0126]) \n",
      "Test Loss tensor([0.0365, 0.0107, 0.0023, 0.0212, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4672396183013916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0119, 0.0024, 0.0220, 0.0128]) \n",
      "Test Loss tensor([0.0353, 0.0107, 0.0023, 0.0217, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4662449359893799 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0102, 0.0022, 0.0225, 0.0111]) \n",
      "Test Loss tensor([0.0355, 0.0102, 0.0023, 0.0208, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4699132442474365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0103, 0.0024, 0.0194, 0.0097]) \n",
      "Test Loss tensor([0.0358, 0.0100, 0.0024, 0.0216, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.46472811698913574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0081, 0.0023, 0.0232, 0.0131]) \n",
      "Test Loss tensor([0.0363, 0.0102, 0.0024, 0.0208, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.47072553634643555 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0090, 0.0019, 0.0208, 0.0127]) \n",
      "Test Loss tensor([0.0359, 0.0098, 0.0024, 0.0212, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.46994590759277344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0119, 0.0026, 0.0212, 0.0169]) \n",
      "Test Loss tensor([0.0357, 0.0102, 0.0024, 0.0209, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47254300117492676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0089, 0.0022, 0.0213, 0.0132]) \n",
      "Test Loss tensor([0.0362, 0.0107, 0.0024, 0.0205, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4707357883453369 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0113, 0.0022, 0.0199, 0.0145]) \n",
      "Test Loss tensor([0.0354, 0.0103, 0.0024, 0.0217, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4716520309448242 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0101, 0.0025, 0.0208, 0.0138]) \n",
      "Test Loss tensor([0.0351, 0.0100, 0.0023, 0.0211, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.47084522247314453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0096, 0.0023, 0.0242, 0.0136]) \n",
      "Test Loss tensor([0.0344, 0.0106, 0.0024, 0.0211, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.47661709785461426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0315, 0.0095, 0.0023, 0.0203, 0.0122]) \n",
      "Test Loss tensor([0.0351, 0.0106, 0.0024, 0.0210, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.47357606887817383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0099, 0.0025, 0.0258, 0.0139]) \n",
      "Test Loss tensor([0.0360, 0.0098, 0.0023, 0.0215, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.47226953506469727 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0094, 0.0023, 0.0205, 0.0139]) \n",
      "Test Loss tensor([0.0357, 0.0104, 0.0024, 0.0205, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4690113067626953 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0104, 0.0027, 0.0213, 0.0135]) \n",
      "Test Loss tensor([0.0352, 0.0105, 0.0023, 0.0217, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4679560661315918 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0100, 0.0027, 0.0196, 0.0136]) \n",
      "Test Loss tensor([0.0363, 0.0107, 0.0023, 0.0207, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4691023826599121 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0343, 0.0097, 0.0023, 0.0220, 0.0131]) \n",
      "Test Loss tensor([0.0355, 0.0104, 0.0023, 0.0210, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4703066349029541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0089, 0.0027, 0.0210, 0.0134]) \n",
      "Test Loss tensor([0.0360, 0.0105, 0.0023, 0.0200, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4686405658721924 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0301, 0.0096, 0.0023, 0.0188, 0.0143]) \n",
      "Test Loss tensor([0.0368, 0.0102, 0.0024, 0.0217, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4674220085144043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0127, 0.0023, 0.0211, 0.0135]) \n",
      "Test Loss tensor([0.0351, 0.0103, 0.0024, 0.0205, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4695875644683838 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0095, 0.0021, 0.0210, 0.0116]) \n",
      "Test Loss tensor([0.0364, 0.0105, 0.0023, 0.0212, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4675710201263428 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0083, 0.0023, 0.0190, 0.0147]) \n",
      "Test Loss tensor([0.0363, 0.0101, 0.0023, 0.0209, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.47303104400634766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0093, 0.0023, 0.0212, 0.0147]) \n",
      "Test Loss tensor([0.0357, 0.0103, 0.0023, 0.0208, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.46897196769714355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0387, 0.0105, 0.0024, 0.0238, 0.0133]) \n",
      "Test Loss tensor([0.0346, 0.0102, 0.0022, 0.0208, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.47203993797302246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0113, 0.0024, 0.0219, 0.0137]) \n",
      "Test Loss tensor([0.0366, 0.0103, 0.0024, 0.0213, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4688265323638916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0087, 0.0027, 0.0203, 0.0120]) \n",
      "Test Loss tensor([0.0346, 0.0103, 0.0024, 0.0212, 0.0139])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 176 in 0.4708399772644043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0093, 0.0020, 0.0209, 0.0170]) \n",
      "Test Loss tensor([0.0364, 0.0098, 0.0023, 0.0216, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.46872377395629883 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0089, 0.0022, 0.0224, 0.0127]) \n",
      "Test Loss tensor([0.0357, 0.0105, 0.0022, 0.0219, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.47045111656188965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0088, 0.0023, 0.0200, 0.0128]) \n",
      "Test Loss tensor([0.0363, 0.0104, 0.0023, 0.0204, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4698817729949951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0100, 0.0023, 0.0206, 0.0126]) \n",
      "Test Loss tensor([0.0370, 0.0099, 0.0024, 0.0206, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4701571464538574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0111, 0.0022, 0.0199, 0.0155]) \n",
      "Test Loss tensor([0.0351, 0.0104, 0.0024, 0.0213, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4693596363067627 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0121, 0.0023, 0.0199, 0.0145]) \n",
      "Test Loss tensor([0.0358, 0.0100, 0.0022, 0.0211, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47003698348999023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0100, 0.0026, 0.0203, 0.0121]) \n",
      "Test Loss tensor([0.0349, 0.0103, 0.0023, 0.0210, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.469921350479126 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0107, 0.0023, 0.0235, 0.0154]) \n",
      "Test Loss tensor([0.0348, 0.0103, 0.0024, 0.0213, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4681587219238281 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0376, 0.0095, 0.0024, 0.0223, 0.0134]) \n",
      "Test Loss tensor([0.0357, 0.0104, 0.0023, 0.0211, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4709467887878418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0109, 0.0024, 0.0213, 0.0141]) \n",
      "Test Loss tensor([0.0360, 0.0102, 0.0023, 0.0211, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.471437931060791 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0101, 0.0025, 0.0239, 0.0138]) \n",
      "Test Loss tensor([0.0356, 0.0106, 0.0023, 0.0212, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4722099304199219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0086, 0.0021, 0.0209, 0.0135]) \n",
      "Test Loss tensor([0.0360, 0.0103, 0.0023, 0.0221, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.47753167152404785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0096, 0.0026, 0.0202, 0.0136]) \n",
      "Test Loss tensor([0.0362, 0.0098, 0.0023, 0.0209, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.47297215461730957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0101, 0.0022, 0.0207, 0.0128]) \n",
      "Test Loss tensor([0.0366, 0.0104, 0.0023, 0.0209, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47144412994384766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0109, 0.0023, 0.0187, 0.0127]) \n",
      "Test Loss tensor([0.0365, 0.0105, 0.0024, 0.0209, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4694826602935791 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0107, 0.0023, 0.0188, 0.0131]) \n",
      "Test Loss tensor([0.0372, 0.0104, 0.0024, 0.0220, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.46897220611572266 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0096, 0.0025, 0.0220, 0.0146]) \n",
      "Test Loss tensor([0.0350, 0.0099, 0.0023, 0.0209, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.47303104400634766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0101, 0.0022, 0.0227, 0.0117]) \n",
      "Test Loss tensor([0.0358, 0.0101, 0.0023, 0.0224, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47191834449768066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0370, 0.0112, 0.0023, 0.0214, 0.0154]) \n",
      "Test Loss tensor([0.0358, 0.0102, 0.0024, 0.0210, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.47324633598327637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0092, 0.0025, 0.0197, 0.0145]) \n",
      "Test Loss tensor([0.0363, 0.0101, 0.0024, 0.0211, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.46820926666259766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0103, 0.0023, 0.0206, 0.0148]) \n",
      "Test Loss tensor([0.0361, 0.0101, 0.0023, 0.0213, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.47013282775878906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0378, 0.0106, 0.0024, 0.0217, 0.0116]) \n",
      "Test Loss tensor([0.0364, 0.0101, 0.0024, 0.0215, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4704909324645996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0113, 0.0023, 0.0195, 0.0104]) \n",
      "Test Loss tensor([0.0359, 0.0099, 0.0023, 0.0210, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.46838808059692383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0088, 0.0023, 0.0204, 0.0141]) \n",
      "Test Loss tensor([0.0345, 0.0099, 0.0023, 0.0207, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.46769118309020996 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0313, 0.0105, 0.0022, 0.0213, 0.0127]) \n",
      "Test Loss tensor([0.0348, 0.0100, 0.0024, 0.0199, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.46838998794555664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0389, 0.0111, 0.0019, 0.0199, 0.0153]) \n",
      "Test Loss tensor([0.0353, 0.0103, 0.0023, 0.0204, 0.0139])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4685811996459961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0109, 0.0023, 0.0203, 0.0129]) \n",
      "Test Loss tensor([0.0366, 0.0105, 0.0023, 0.0206, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.47086644172668457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0382, 0.0092, 0.0027, 0.0184, 0.0133]) \n",
      "Test Loss tensor([0.0367, 0.0105, 0.0024, 0.0215, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4807615280151367 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0103, 0.0021, 0.0221, 0.0137]) \n",
      "Test Loss tensor([0.0354, 0.0105, 0.0024, 0.0206, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4678468704223633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0307, 0.0092, 0.0021, 0.0214, 0.0119]) \n",
      "Test Loss tensor([0.0344, 0.0101, 0.0023, 0.0209, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4698162078857422 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0113, 0.0026, 0.0203, 0.0145]) \n",
      "Test Loss tensor([0.0334, 0.0095, 0.0024, 0.0206, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4681873321533203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0105, 0.0023, 0.0219, 0.0146]) \n",
      "Test Loss tensor([0.0353, 0.0104, 0.0023, 0.0208, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4721221923828125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0314, 0.0099, 0.0024, 0.0181, 0.0129]) \n",
      "Test Loss tensor([0.0356, 0.0104, 0.0025, 0.0213, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.46431493759155273 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0090, 0.0022, 0.0211, 0.0134]) \n",
      "Test Loss tensor([0.0371, 0.0104, 0.0023, 0.0213, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4687507152557373 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0121, 0.0023, 0.0203, 0.0123]) \n",
      "Test Loss tensor([0.0350, 0.0103, 0.0022, 0.0208, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4680297374725342 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0093, 0.0026, 0.0179, 0.0152]) \n",
      "Test Loss tensor([0.0361, 0.0105, 0.0024, 0.0216, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4704549312591553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0092, 0.0026, 0.0214, 0.0149]) \n",
      "Test Loss tensor([0.0356, 0.0108, 0.0025, 0.0205, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4698984622955322 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0089, 0.0023, 0.0239, 0.0112]) \n",
      "Test Loss tensor([0.0373, 0.0096, 0.0023, 0.0210, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.47316813468933105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0397, 0.0097, 0.0023, 0.0223, 0.0153]) \n",
      "Test Loss tensor([0.0354, 0.0099, 0.0023, 0.0207, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4709479808807373 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0098, 0.0023, 0.0213, 0.0147]) \n",
      "Test Loss tensor([0.0350, 0.0097, 0.0024, 0.0210, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47562718391418457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0084, 0.0023, 0.0197, 0.0142]) \n",
      "Test Loss tensor([0.0348, 0.0110, 0.0025, 0.0209, 0.0139])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 340 in 0.47439074516296387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0083, 0.0022, 0.0187, 0.0134]) \n",
      "Test Loss tensor([0.0346, 0.0103, 0.0024, 0.0204, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.46677350997924805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0083, 0.0024, 0.0186, 0.0129]) \n",
      "Test Loss tensor([0.0348, 0.0104, 0.0023, 0.0208, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.46860551834106445 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0343, 0.0096, 0.0023, 0.0181, 0.0136]) \n",
      "Test Loss tensor([0.0354, 0.0102, 0.0024, 0.0208, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4696218967437744 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0098, 0.0024, 0.0216, 0.0145]) \n",
      "Test Loss tensor([0.0344, 0.0104, 0.0024, 0.0211, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.46857523918151855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0355, 0.0121, 0.0026, 0.0186, 0.0134]) \n",
      "Test Loss tensor([0.0348, 0.0103, 0.0024, 0.0212, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4649472236633301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0104, 0.0024, 0.0192, 0.0140]) \n",
      "Test Loss tensor([0.0350, 0.0095, 0.0023, 0.0214, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4683651924133301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0355, 0.0120, 0.0023, 0.0207, 0.0139]) \n",
      "Test Loss tensor([0.0354, 0.0102, 0.0024, 0.0209, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.46674442291259766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0104, 0.0024, 0.0205, 0.0125]) \n",
      "Test Loss tensor([0.0348, 0.0100, 0.0024, 0.0207, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4705991744995117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0107, 0.0024, 0.0227, 0.0142]) \n",
      "Test Loss tensor([0.0347, 0.0099, 0.0024, 0.0206, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4673588275909424 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0123, 0.0025, 0.0199, 0.0116]) \n",
      "Test Loss tensor([0.0351, 0.0103, 0.0022, 0.0207, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.46781229972839355 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0098, 0.0021, 0.0217, 0.0133]) \n",
      "Test Loss tensor([0.0347, 0.0097, 0.0023, 0.0202, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.46932482719421387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0102, 0.0023, 0.0216, 0.0141]) \n",
      "Test Loss tensor([0.0341, 0.0101, 0.0023, 0.0219, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4709603786468506 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0348, 0.0086, 0.0023, 0.0190, 0.0147]) \n",
      "Test Loss tensor([0.0346, 0.0100, 0.0023, 0.0216, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4682590961456299 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0105, 0.0022, 0.0191, 0.0150]) \n",
      "Test Loss tensor([0.0351, 0.0095, 0.0024, 0.0212, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.46898794174194336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0112, 0.0021, 0.0229, 0.0157]) \n",
      "Test Loss tensor([0.0353, 0.0101, 0.0023, 0.0199, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4680640697479248 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0096, 0.0025, 0.0183, 0.0126]) \n",
      "Test Loss tensor([0.0351, 0.0102, 0.0023, 0.0209, 0.0140])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.47059178352355957 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0367, 0.0096, 0.0022, 0.0238, 0.0129]) \n",
      "Test Loss tensor([0.0348, 0.0100, 0.0023, 0.0202, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4689826965332031 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0117, 0.0022, 0.0224, 0.0130]) \n",
      "Test Loss tensor([0.0356, 0.0101, 0.0023, 0.0210, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.49642419815063477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0083, 0.0026, 0.0220, 0.0139]) \n",
      "Test Loss tensor([0.0353, 0.0107, 0.0023, 0.0215, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4701693058013916 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0119, 0.0021, 0.0211, 0.0115]) \n",
      "Test Loss tensor([0.0346, 0.0097, 0.0024, 0.0214, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4849233627319336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0106, 0.0023, 0.0212, 0.0161]) \n",
      "Test Loss tensor([0.0353, 0.0102, 0.0024, 0.0208, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4728517532348633 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0096, 0.0024, 0.0211, 0.0135]) \n",
      "Test Loss tensor([0.0345, 0.0098, 0.0023, 0.0208, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4669158458709717 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0092, 0.0022, 0.0208, 0.0126]) \n",
      "Test Loss tensor([0.0351, 0.0103, 0.0023, 0.0210, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.46998119354248047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0092, 0.0023, 0.0226, 0.0143]) \n",
      "Test Loss tensor([0.0354, 0.0096, 0.0023, 0.0215, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4678184986114502 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0088, 0.0028, 0.0194, 0.0122]) \n",
      "Test Loss tensor([0.0351, 0.0104, 0.0023, 0.0206, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.46915411949157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0106, 0.0023, 0.0226, 0.0144]) \n",
      "Test Loss tensor([0.0360, 0.0102, 0.0023, 0.0207, 0.0137])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.4677762985229492 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0101, 0.0022, 0.0217, 0.0141]) \n",
      "Test Loss tensor([0.0343, 0.0101, 0.0023, 0.0196, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.47668933868408203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0115, 0.0021, 0.0233, 0.0141]) \n",
      "Test Loss tensor([0.0354, 0.0102, 0.0022, 0.0207, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4712083339691162 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0306, 0.0101, 0.0020, 0.0216, 0.0145]) \n",
      "Test Loss tensor([0.0344, 0.0097, 0.0022, 0.0205, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.48310017585754395 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0343, 0.0097, 0.0023, 0.0207, 0.0130]) \n",
      "Test Loss tensor([0.0363, 0.0105, 0.0023, 0.0212, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.47130608558654785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0098, 0.0024, 0.0215, 0.0130]) \n",
      "Test Loss tensor([0.0344, 0.0097, 0.0023, 0.0206, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47101378440856934 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0112, 0.0022, 0.0210, 0.0125]) \n",
      "Test Loss tensor([0.0338, 0.0103, 0.0023, 0.0214, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4703841209411621 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0097, 0.0024, 0.0216, 0.0138]) \n",
      "Test Loss tensor([0.0344, 0.0098, 0.0023, 0.0199, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4699990749359131 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0356, 0.0110, 0.0030, 0.0241, 0.0138]) \n",
      "Test Loss tensor([0.0352, 0.0098, 0.0023, 0.0203, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.47092390060424805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0296, 0.0081, 0.0022, 0.0188, 0.0129]) \n",
      "Test Loss tensor([0.0334, 0.0102, 0.0023, 0.0206, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47060298919677734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0111, 0.0021, 0.0210, 0.0147]) \n",
      "Test Loss tensor([0.0351, 0.0105, 0.0023, 0.0207, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47019171714782715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0090, 0.0027, 0.0186, 0.0128]) \n",
      "Test Loss tensor([0.0353, 0.0101, 0.0023, 0.0194, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4697608947753906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0094, 0.0024, 0.0222, 0.0145]) \n",
      "Test Loss tensor([0.0348, 0.0102, 0.0022, 0.0212, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4709019660949707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0080, 0.0022, 0.0182, 0.0144]) \n",
      "Test Loss tensor([0.0355, 0.0100, 0.0023, 0.0206, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.46744370460510254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0105, 0.0022, 0.0239, 0.0130]) \n",
      "Test Loss tensor([0.0346, 0.0099, 0.0022, 0.0214, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.47207212448120117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0098, 0.0021, 0.0223, 0.0146]) \n",
      "Test Loss tensor([0.0344, 0.0103, 0.0023, 0.0217, 0.0130])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 504 in 0.4684305191040039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0337, 0.0097, 0.0027, 0.0202, 0.0126]) \n",
      "Test Loss tensor([0.0345, 0.0101, 0.0023, 0.0201, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.47151684761047363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0073, 0.0025, 0.0199, 0.0124]) \n",
      "Test Loss tensor([0.0344, 0.0104, 0.0023, 0.0201, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.46726489067077637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0107, 0.0021, 0.0179, 0.0141]) \n",
      "Test Loss tensor([0.0345, 0.0102, 0.0023, 0.0201, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4715077877044678 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0089, 0.0024, 0.0198, 0.0124]) \n",
      "Test Loss tensor([0.0339, 0.0099, 0.0023, 0.0208, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4660012722015381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0088, 0.0020, 0.0228, 0.0132]) \n",
      "Test Loss tensor([0.0342, 0.0103, 0.0023, 0.0214, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.470958948135376 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0130, 0.0022, 0.0247, 0.0128]) \n",
      "Test Loss tensor([0.0343, 0.0101, 0.0024, 0.0204, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4698300361633301 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0289, 0.0099, 0.0021, 0.0187, 0.0123]) \n",
      "Test Loss tensor([0.0335, 0.0105, 0.0023, 0.0209, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.46903061866760254 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0095, 0.0024, 0.0190, 0.0141]) \n",
      "Test Loss tensor([0.0352, 0.0098, 0.0023, 0.0202, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.47020792961120605 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0106, 0.0022, 0.0220, 0.0119]) \n",
      "Test Loss tensor([0.0340, 0.0100, 0.0022, 0.0198, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4712393283843994 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0374, 0.0100, 0.0021, 0.0188, 0.0135]) \n",
      "Test Loss tensor([0.0345, 0.0101, 0.0023, 0.0204, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47130465507507324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0363, 0.0096, 0.0023, 0.0197, 0.0159]) \n",
      "Test Loss tensor([0.0346, 0.0102, 0.0023, 0.0203, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.47084832191467285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0319, 0.0100, 0.0020, 0.0237, 0.0161]) \n",
      "Test Loss tensor([0.0347, 0.0102, 0.0023, 0.0205, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4688894748687744 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0106, 0.0020, 0.0229, 0.0145]) \n",
      "Test Loss tensor([0.0352, 0.0102, 0.0024, 0.0209, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47036075592041016 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0100, 0.0021, 0.0196, 0.0119]) \n",
      "Test Loss tensor([0.0336, 0.0096, 0.0024, 0.0204, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.46973252296447754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0087, 0.0024, 0.0189, 0.0146]) \n",
      "Test Loss tensor([0.0354, 0.0096, 0.0024, 0.0210, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.46491265296936035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0107, 0.0021, 0.0221, 0.0125]) \n",
      "Test Loss tensor([0.0336, 0.0100, 0.0022, 0.0197, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.47031688690185547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0083, 0.0023, 0.0209, 0.0128]) \n",
      "Test Loss tensor([0.0349, 0.0098, 0.0022, 0.0208, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4711802005767822 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0302, 0.0094, 0.0021, 0.0194, 0.0143]) \n",
      "Test Loss tensor([0.0346, 0.0102, 0.0024, 0.0209, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4746372699737549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0312, 0.0102, 0.0022, 0.0197, 0.0126]) \n",
      "Test Loss tensor([0.0349, 0.0102, 0.0023, 0.0205, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.4699568748474121 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0097, 0.0025, 0.0202, 0.0121]) \n",
      "Test Loss tensor([0.0343, 0.0096, 0.0021, 0.0212, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4742703437805176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0094, 0.0023, 0.0208, 0.0125]) \n",
      "Test Loss tensor([0.0338, 0.0096, 0.0023, 0.0214, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47142529487609863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0103, 0.0025, 0.0188, 0.0123]) \n",
      "Test Loss tensor([0.0345, 0.0099, 0.0023, 0.0209, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4740734100341797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0103, 0.0027, 0.0222, 0.0138]) \n",
      "Test Loss tensor([0.0343, 0.0103, 0.0023, 0.0218, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4736630916595459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0308, 0.0083, 0.0024, 0.0214, 0.0132]) \n",
      "Test Loss tensor([0.0349, 0.0101, 0.0023, 0.0206, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4784858226776123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0358, 0.0090, 0.0022, 0.0201, 0.0141]) \n",
      "Test Loss tensor([0.0339, 0.0103, 0.0022, 0.0200, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4734973907470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0087, 0.0022, 0.0193, 0.0142]) \n",
      "Test Loss tensor([0.0342, 0.0098, 0.0023, 0.0205, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47460103034973145 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0086, 0.0022, 0.0199, 0.0137]) \n",
      "Test Loss tensor([0.0343, 0.0103, 0.0023, 0.0209, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47422003746032715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0096, 0.0021, 0.0216, 0.0131]) \n",
      "Test Loss tensor([0.0349, 0.0104, 0.0023, 0.0211, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4725222587585449 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0122, 0.0025, 0.0217, 0.0136]) \n",
      "Test Loss tensor([0.0353, 0.0099, 0.0023, 0.0209, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.47377514839172363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0384, 0.0097, 0.0022, 0.0206, 0.0125]) \n",
      "Test Loss tensor([0.0347, 0.0099, 0.0022, 0.0214, 0.0138])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4788179397583008 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0315, 0.0089, 0.0024, 0.0198, 0.0133]) \n",
      "Test Loss tensor([0.0356, 0.0097, 0.0023, 0.0197, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.48270297050476074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0107, 0.0025, 0.0186, 0.0137]) \n",
      "Test Loss tensor([0.0345, 0.0099, 0.0023, 0.0203, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4751760959625244 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0099, 0.0022, 0.0207, 0.0136]) \n",
      "Test Loss tensor([0.0350, 0.0101, 0.0022, 0.0201, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4733119010925293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0318, 0.0100, 0.0026, 0.0201, 0.0130]) \n",
      "Test Loss tensor([0.0340, 0.0101, 0.0023, 0.0194, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4725799560546875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0100, 0.0022, 0.0207, 0.0121]) \n",
      "Test Loss tensor([0.0346, 0.0104, 0.0022, 0.0207, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4731631278991699 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0369, 0.0084, 0.0020, 0.0179, 0.0136]) \n",
      "Test Loss tensor([0.0347, 0.0101, 0.0023, 0.0198, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47390270233154297 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0081, 0.0020, 0.0196, 0.0117]) \n",
      "Test Loss tensor([0.0350, 0.0101, 0.0022, 0.0202, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4752621650695801 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0080, 0.0021, 0.0184, 0.0132]) \n",
      "Test Loss tensor([0.0336, 0.0099, 0.0023, 0.0194, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4747273921966553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0106, 0.0024, 0.0195, 0.0111]) \n",
      "Test Loss tensor([0.0347, 0.0103, 0.0023, 0.0203, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4777340888977051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0097, 0.0023, 0.0204, 0.0130]) \n",
      "Test Loss tensor([0.0345, 0.0097, 0.0023, 0.0205, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4700143337249756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0361, 0.0084, 0.0023, 0.0208, 0.0129]) \n",
      "Test Loss tensor([0.0339, 0.0091, 0.0022, 0.0195, 0.0128])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 668 in 0.4766714572906494 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0086, 0.0020, 0.0225, 0.0138]) \n",
      "Test Loss tensor([0.0345, 0.0096, 0.0023, 0.0201, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47336769104003906 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0314, 0.0099, 0.0022, 0.0205, 0.0111]) \n",
      "Test Loss tensor([0.0340, 0.0099, 0.0023, 0.0210, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4730837345123291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0088, 0.0025, 0.0178, 0.0124]) \n",
      "Test Loss tensor([0.0344, 0.0096, 0.0023, 0.0205, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4715235233306885 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0096, 0.0025, 0.0177, 0.0132]) \n",
      "Test Loss tensor([0.0345, 0.0099, 0.0023, 0.0206, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4790463447570801 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0079, 0.0022, 0.0209, 0.0137]) \n",
      "Test Loss tensor([0.0342, 0.0099, 0.0023, 0.0198, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.47156262397766113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0083, 0.0022, 0.0219, 0.0122]) \n",
      "Test Loss tensor([0.0355, 0.0096, 0.0023, 0.0205, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4723193645477295 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0319, 0.0086, 0.0027, 0.0179, 0.0102]) \n",
      "Test Loss tensor([0.0331, 0.0096, 0.0022, 0.0201, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.47307753562927246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0083, 0.0023, 0.0213, 0.0123]) \n",
      "Test Loss tensor([0.0347, 0.0101, 0.0023, 0.0208, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.47384214401245117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0364, 0.0081, 0.0025, 0.0217, 0.0142]) \n",
      "Test Loss tensor([0.0346, 0.0101, 0.0023, 0.0197, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47255420684814453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0308, 0.0100, 0.0024, 0.0228, 0.0129]) \n",
      "Test Loss tensor([0.0351, 0.0100, 0.0023, 0.0207, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4712977409362793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0089, 0.0022, 0.0196, 0.0117]) \n",
      "Test Loss tensor([0.0335, 0.0099, 0.0024, 0.0204, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.47289538383483887 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0080, 0.0024, 0.0202, 0.0143]) \n",
      "Test Loss tensor([0.0347, 0.0100, 0.0023, 0.0203, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.472292423248291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0078, 0.0023, 0.0189, 0.0122]) \n",
      "Test Loss tensor([0.0344, 0.0098, 0.0023, 0.0199, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47333526611328125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0103, 0.0025, 0.0191, 0.0120]) \n",
      "Test Loss tensor([0.0344, 0.0099, 0.0024, 0.0212, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47116827964782715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0371, 0.0090, 0.0022, 0.0186, 0.0141]) \n",
      "Test Loss tensor([0.0346, 0.0101, 0.0023, 0.0211, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4725339412689209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0319, 0.0086, 0.0024, 0.0185, 0.0136]) \n",
      "Test Loss tensor([0.0346, 0.0101, 0.0023, 0.0208, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4701504707336426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0100, 0.0025, 0.0206, 0.0105]) \n",
      "Test Loss tensor([0.0330, 0.0098, 0.0022, 0.0205, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4737403392791748 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0096, 0.0024, 0.0207, 0.0123]) \n",
      "Test Loss tensor([0.0338, 0.0101, 0.0023, 0.0201, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.47292327880859375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0297, 0.0083, 0.0020, 0.0207, 0.0122]) \n",
      "Test Loss tensor([0.0342, 0.0099, 0.0023, 0.0200, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4736344814300537 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0118, 0.0025, 0.0220, 0.0138]) \n",
      "Test Loss tensor([0.0334, 0.0097, 0.0022, 0.0208, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.47034430503845215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0081, 0.0024, 0.0182, 0.0138]) \n",
      "Test Loss tensor([0.0338, 0.0100, 0.0023, 0.0200, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4731013774871826 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0306, 0.0107, 0.0022, 0.0196, 0.0139]) \n",
      "Test Loss tensor([0.0344, 0.0098, 0.0023, 0.0213, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.47174072265625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0103, 0.0023, 0.0193, 0.0127]) \n",
      "Test Loss tensor([0.0348, 0.0101, 0.0022, 0.0208, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4702169895172119 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0104, 0.0024, 0.0207, 0.0106]) \n",
      "Test Loss tensor([0.0336, 0.0095, 0.0023, 0.0211, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47122859954833984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0095, 0.0022, 0.0176, 0.0148]) \n",
      "Test Loss tensor([0.0337, 0.0096, 0.0022, 0.0200, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.47232747077941895 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0320, 0.0102, 0.0023, 0.0235, 0.0123]) \n",
      "Test Loss tensor([0.0335, 0.0099, 0.0022, 0.0211, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4713919162750244 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0365, 0.0106, 0.0023, 0.0241, 0.0120]) \n",
      "Test Loss tensor([0.0336, 0.0097, 0.0022, 0.0207, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4717893600463867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0090, 0.0022, 0.0227, 0.0136]) \n",
      "Test Loss tensor([0.0343, 0.0096, 0.0022, 0.0211, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4728665351867676 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0375, 0.0102, 0.0022, 0.0196, 0.0135]) \n",
      "Test Loss tensor([0.0345, 0.0098, 0.0022, 0.0205, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47267770767211914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0099, 0.0026, 0.0242, 0.0148]) \n",
      "Test Loss tensor([0.0338, 0.0100, 0.0022, 0.0200, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4725339412689209 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0368, 0.0080, 0.0022, 0.0231, 0.0131]) \n",
      "Test Loss tensor([0.0340, 0.0096, 0.0022, 0.0197, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47014641761779785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0094, 0.0023, 0.0186, 0.0117]) \n",
      "Test Loss tensor([0.0340, 0.0097, 0.0023, 0.0191, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5016388893127441 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0090, 0.0022, 0.0204, 0.0149]) \n",
      "Test Loss tensor([0.0333, 0.0099, 0.0022, 0.0210, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4831273555755615 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0080, 0.0024, 0.0177, 0.0135]) \n",
      "Test Loss tensor([0.0338, 0.0102, 0.0023, 0.0203, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.47435975074768066 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0289, 0.0103, 0.0027, 0.0200, 0.0134]) \n",
      "Test Loss tensor([0.0329, 0.0097, 0.0023, 0.0203, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47091245651245117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0341, 0.0094, 0.0019, 0.0177, 0.0143]) \n",
      "Test Loss tensor([0.0340, 0.0102, 0.0023, 0.0205, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4728837013244629 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0307, 0.0101, 0.0023, 0.0196, 0.0126]) \n",
      "Test Loss tensor([0.0337, 0.0099, 0.0023, 0.0211, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.46902942657470703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0115, 0.0022, 0.0212, 0.0158]) \n",
      "Test Loss tensor([0.0337, 0.0100, 0.0023, 0.0200, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47209811210632324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0085, 0.0019, 0.0222, 0.0110]) \n",
      "Test Loss tensor([0.0349, 0.0104, 0.0023, 0.0198, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4760165214538574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0091, 0.0024, 0.0214, 0.0155]) \n",
      "Test Loss tensor([0.0347, 0.0102, 0.0023, 0.0211, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4716167449951172 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0099, 0.0023, 0.0191, 0.0140]) \n",
      "Test Loss tensor([0.0332, 0.0101, 0.0022, 0.0209, 0.0126])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 832 in 0.4711887836456299 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0099, 0.0022, 0.0194, 0.0132]) \n",
      "Test Loss tensor([0.0324, 0.0096, 0.0023, 0.0195, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.47434139251708984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0098, 0.0023, 0.0219, 0.0133]) \n",
      "Test Loss tensor([0.0335, 0.0097, 0.0022, 0.0193, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.47545623779296875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0109, 0.0024, 0.0190, 0.0129]) \n",
      "Test Loss tensor([0.0335, 0.0104, 0.0023, 0.0195, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5457651615142822 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0095, 0.0022, 0.0202, 0.0166]) \n",
      "Test Loss tensor([0.0341, 0.0097, 0.0022, 0.0202, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5441300868988037 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0108, 0.0026, 0.0209, 0.0143]) \n",
      "Test Loss tensor([0.0336, 0.0101, 0.0023, 0.0212, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.48655200004577637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0097, 0.0023, 0.0217, 0.0137]) \n",
      "Test Loss tensor([0.0330, 0.0103, 0.0022, 0.0195, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47498321533203125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0314, 0.0107, 0.0021, 0.0201, 0.0148]) \n",
      "Test Loss tensor([0.0341, 0.0101, 0.0022, 0.0207, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47507739067077637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0306, 0.0090, 0.0021, 0.0186, 0.0142]) \n",
      "Test Loss tensor([0.0334, 0.0098, 0.0023, 0.0196, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47112178802490234 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0105, 0.0022, 0.0174, 0.0143]) \n",
      "Test Loss tensor([0.0335, 0.0097, 0.0023, 0.0206, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47275853157043457 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0118, 0.0021, 0.0183, 0.0129]) \n",
      "Test Loss tensor([0.0336, 0.0096, 0.0023, 0.0200, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4719536304473877 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0294, 0.0096, 0.0024, 0.0218, 0.0115]) \n",
      "Test Loss tensor([0.0343, 0.0100, 0.0023, 0.0200, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4727742671966553 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0239, 0.0073, 0.0022, 0.0154, 0.0110]) \n",
      "Test Loss tensor([0.0361, 0.0095, 0.0022, 0.0206, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5109353065490723 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0357, 0.0076, 0.0026, 0.0194, 0.0128]) \n",
      "Test Loss tensor([0.0338, 0.0098, 0.0022, 0.0203, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4745481014251709 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0085, 0.0022, 0.0208, 0.0112]) \n",
      "Test Loss tensor([0.0346, 0.0096, 0.0024, 0.0190, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47244930267333984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0093, 0.0025, 0.0215, 0.0116]) \n",
      "Test Loss tensor([0.0339, 0.0092, 0.0022, 0.0198, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47170162200927734 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0083, 0.0023, 0.0194, 0.0115]) \n",
      "Test Loss tensor([0.0345, 0.0097, 0.0022, 0.0203, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47175025939941406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0103, 0.0021, 0.0184, 0.0106]) \n",
      "Test Loss tensor([0.0336, 0.0099, 0.0022, 0.0201, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4729957580566406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0113, 0.0024, 0.0190, 0.0131]) \n",
      "Test Loss tensor([0.0345, 0.0096, 0.0022, 0.0198, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4725043773651123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0344, 0.0093, 0.0020, 0.0225, 0.0136]) \n",
      "Test Loss tensor([0.0346, 0.0099, 0.0023, 0.0199, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4729447364807129 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0097, 0.0024, 0.0203, 0.0128]) \n",
      "Test Loss tensor([0.0340, 0.0098, 0.0023, 0.0212, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.471881628036499 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0089, 0.0024, 0.0219, 0.0133]) \n",
      "Test Loss tensor([0.0331, 0.0100, 0.0023, 0.0190, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4785614013671875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0287, 0.0106, 0.0025, 0.0212, 0.0124]) \n",
      "Test Loss tensor([0.0348, 0.0101, 0.0023, 0.0193, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.47952795028686523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0101, 0.0021, 0.0191, 0.0129]) \n",
      "Test Loss tensor([0.0349, 0.0099, 0.0023, 0.0195, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.470062255859375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0307, 0.0090, 0.0023, 0.0195, 0.0129]) \n",
      "Test Loss tensor([0.0346, 0.0096, 0.0022, 0.0202, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47313380241394043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0352, 0.0109, 0.0022, 0.0193, 0.0137]) \n",
      "Test Loss tensor([0.0346, 0.0095, 0.0021, 0.0197, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4702143669128418 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0373, 0.0097, 0.0022, 0.0202, 0.0111]) \n",
      "Test Loss tensor([0.0346, 0.0103, 0.0023, 0.0203, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4731757640838623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0101, 0.0023, 0.0202, 0.0153]) \n",
      "Test Loss tensor([0.0342, 0.0103, 0.0023, 0.0208, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4705185890197754 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0083, 0.0024, 0.0165, 0.0134]) \n",
      "Test Loss tensor([0.0341, 0.0098, 0.0022, 0.0218, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.47185850143432617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0341, 0.0083, 0.0023, 0.0212, 0.0114]) \n",
      "Test Loss tensor([0.0333, 0.0096, 0.0022, 0.0200, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.47287607192993164 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0093, 0.0023, 0.0174, 0.0133]) \n",
      "Test Loss tensor([0.0362, 0.0103, 0.0025, 0.0207, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5056805610656738 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0098, 0.0022, 0.0221, 0.0140]) \n",
      "Test Loss tensor([0.0338, 0.0094, 0.0023, 0.0198, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4742302894592285 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0313, 0.0110, 0.0023, 0.0196, 0.0135]) \n",
      "Test Loss tensor([0.0351, 0.0101, 0.0022, 0.0218, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5092983245849609 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0337, 0.0093, 0.0025, 0.0221, 0.0118]) \n",
      "Test Loss tensor([0.0346, 0.0097, 0.0022, 0.0196, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4764370918273926 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0094, 0.0022, 0.0191, 0.0143]) \n",
      "Test Loss tensor([0.0337, 0.0099, 0.0024, 0.0206, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.47530221939086914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0103, 0.0027, 0.0217, 0.0134]) \n",
      "Test Loss tensor([0.0337, 0.0096, 0.0022, 0.0204, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4730651378631592 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0094, 0.0023, 0.0198, 0.0138]) \n",
      "Test Loss tensor([0.0353, 0.0098, 0.0021, 0.0214, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47335290908813477 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0103, 0.0020, 0.0193, 0.0128]) \n",
      "Test Loss tensor([0.0340, 0.0098, 0.0022, 0.0211, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47310590744018555 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0102, 0.0022, 0.0195, 0.0136]) \n",
      "Test Loss tensor([0.0327, 0.0094, 0.0023, 0.0217, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47278809547424316 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0282, 0.0105, 0.0022, 0.0174, 0.0121]) \n",
      "Test Loss tensor([0.0338, 0.0103, 0.0022, 0.0201, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.47930169105529785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0299, 0.0086, 0.0021, 0.0198, 0.0135]) \n",
      "Test Loss tensor([0.0354, 0.0100, 0.0022, 0.0190, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.47639966011047363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0101, 0.0026, 0.0184, 0.0132]) \n",
      "Test Loss tensor([0.0322, 0.0102, 0.0022, 0.0199, 0.0131])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 116 in 0.4725644588470459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0305, 0.0089, 0.0023, 0.0213, 0.0112]) \n",
      "Test Loss tensor([0.0346, 0.0097, 0.0022, 0.0196, 0.0134])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.47194528579711914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0092, 0.0022, 0.0200, 0.0129]) \n",
      "Test Loss tensor([0.0340, 0.0102, 0.0022, 0.0199, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4734354019165039 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0314, 0.0100, 0.0021, 0.0199, 0.0144]) \n",
      "Test Loss tensor([0.0323, 0.0100, 0.0023, 0.0212, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4730663299560547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0104, 0.0023, 0.0186, 0.0114]) \n",
      "Test Loss tensor([0.0340, 0.0101, 0.0023, 0.0207, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.47482776641845703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0094, 0.0020, 0.0203, 0.0134]) \n",
      "Test Loss tensor([0.0336, 0.0097, 0.0023, 0.0203, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4690394401550293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0088, 0.0025, 0.0176, 0.0118]) \n",
      "Test Loss tensor([0.0335, 0.0103, 0.0022, 0.0203, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47240757942199707 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0098, 0.0028, 0.0187, 0.0135]) \n",
      "Test Loss tensor([0.0340, 0.0097, 0.0022, 0.0202, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.46983790397644043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0107, 0.0024, 0.0204, 0.0121]) \n",
      "Test Loss tensor([0.0338, 0.0098, 0.0022, 0.0206, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.47460198402404785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0084, 0.0022, 0.0211, 0.0135]) \n",
      "Test Loss tensor([0.0330, 0.0095, 0.0022, 0.0208, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4745969772338867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0104, 0.0023, 0.0205, 0.0131]) \n",
      "Test Loss tensor([0.0329, 0.0097, 0.0022, 0.0200, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4719853401184082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0327, 0.0100, 0.0021, 0.0190, 0.0106]) \n",
      "Test Loss tensor([0.0334, 0.0099, 0.0021, 0.0197, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4718146324157715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0113, 0.0021, 0.0180, 0.0133]) \n",
      "Test Loss tensor([0.0337, 0.0101, 0.0023, 0.0195, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4728879928588867 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0084, 0.0019, 0.0229, 0.0144]) \n",
      "Test Loss tensor([0.0348, 0.0103, 0.0023, 0.0204, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4717273712158203 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0295, 0.0094, 0.0025, 0.0183, 0.0137]) \n",
      "Test Loss tensor([0.0344, 0.0102, 0.0023, 0.0211, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4712529182434082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0317, 0.0096, 0.0021, 0.0184, 0.0132]) \n",
      "Test Loss tensor([0.0344, 0.0096, 0.0022, 0.0197, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47213149070739746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0101, 0.0021, 0.0220, 0.0130]) \n",
      "Test Loss tensor([0.0345, 0.0091, 0.0022, 0.0206, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4736974239349365 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0301, 0.0088, 0.0024, 0.0197, 0.0123]) \n",
      "Test Loss tensor([0.0331, 0.0100, 0.0022, 0.0199, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.47153258323669434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0100, 0.0021, 0.0219, 0.0121]) \n",
      "Test Loss tensor([0.0346, 0.0096, 0.0022, 0.0203, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47168540954589844 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0362, 0.0091, 0.0026, 0.0191, 0.0115]) \n",
      "Test Loss tensor([0.0331, 0.0099, 0.0022, 0.0198, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4695577621459961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0091, 0.0021, 0.0209, 0.0145]) \n",
      "Test Loss tensor([0.0336, 0.0092, 0.0022, 0.0206, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.472705602645874 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0102, 0.0022, 0.0175, 0.0127]) \n",
      "Test Loss tensor([0.0325, 0.0098, 0.0022, 0.0198, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.47324085235595703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0093, 0.0020, 0.0218, 0.0139]) \n",
      "Test Loss tensor([0.0334, 0.0096, 0.0022, 0.0207, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4730532169342041 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0093, 0.0023, 0.0188, 0.0114]) \n",
      "Test Loss tensor([0.0323, 0.0101, 0.0023, 0.0199, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4730384349822998 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0096, 0.0021, 0.0181, 0.0130]) \n",
      "Test Loss tensor([0.0342, 0.0097, 0.0022, 0.0207, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.47116661071777344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0105, 0.0023, 0.0224, 0.0136]) \n",
      "Test Loss tensor([0.0327, 0.0096, 0.0022, 0.0211, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4738340377807617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0294, 0.0106, 0.0022, 0.0181, 0.0133]) \n",
      "Test Loss tensor([0.0332, 0.0099, 0.0022, 0.0195, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.46991825103759766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0094, 0.0023, 0.0198, 0.0115]) \n",
      "Test Loss tensor([0.0338, 0.0100, 0.0023, 0.0203, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4728071689605713 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0092, 0.0022, 0.0194, 0.0112]) \n",
      "Test Loss tensor([0.0325, 0.0099, 0.0023, 0.0201, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4717416763305664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0310, 0.0102, 0.0022, 0.0234, 0.0145]) \n",
      "Test Loss tensor([0.0333, 0.0105, 0.0022, 0.0202, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4739499092102051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0080, 0.0024, 0.0185, 0.0126]) \n",
      "Test Loss tensor([0.0339, 0.0100, 0.0023, 0.0201, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47221946716308594 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0312, 0.0093, 0.0020, 0.0206, 0.0124]) \n",
      "Test Loss tensor([0.0343, 0.0100, 0.0023, 0.0202, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.47256040573120117 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0112, 0.0024, 0.0221, 0.0130]) \n",
      "Test Loss tensor([0.0349, 0.0102, 0.0022, 0.0211, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4715995788574219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0090, 0.0019, 0.0194, 0.0120]) \n",
      "Test Loss tensor([0.0347, 0.0100, 0.0022, 0.0199, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47868847846984863 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0088, 0.0021, 0.0197, 0.0139]) \n",
      "Test Loss tensor([0.0348, 0.0099, 0.0023, 0.0210, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4824693202972412 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0315, 0.0082, 0.0021, 0.0229, 0.0150]) \n",
      "Test Loss tensor([0.0353, 0.0100, 0.0022, 0.0213, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47269654273986816 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0096, 0.0022, 0.0230, 0.0125]) \n",
      "Test Loss tensor([0.0342, 0.0105, 0.0022, 0.0204, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4710423946380615 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0317, 0.0086, 0.0022, 0.0213, 0.0142]) \n",
      "Test Loss tensor([0.0343, 0.0104, 0.0022, 0.0202, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.47133803367614746 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0291, 0.0097, 0.0023, 0.0188, 0.0139]) \n",
      "Test Loss tensor([0.0340, 0.0107, 0.0021, 0.0207, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.47234630584716797 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0089, 0.0022, 0.0206, 0.0114]) \n",
      "Test Loss tensor([0.0346, 0.0098, 0.0023, 0.0207, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.47219014167785645 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0092, 0.0023, 0.0219, 0.0140]) \n",
      "Test Loss tensor([0.0338, 0.0095, 0.0022, 0.0205, 0.0133])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.47222161293029785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0313, 0.0094, 0.0019, 0.0198, 0.0124]) \n",
      "Test Loss tensor([0.0341, 0.0098, 0.0022, 0.0204, 0.0131])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 280 in 0.4694631099700928 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0084, 0.0023, 0.0186, 0.0129]) \n",
      "Test Loss tensor([0.0355, 0.0100, 0.0022, 0.0219, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4748971462249756 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0094, 0.0025, 0.0227, 0.0139]) \n",
      "Test Loss tensor([0.0342, 0.0100, 0.0022, 0.0206, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4704132080078125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0091, 0.0021, 0.0209, 0.0118]) \n",
      "Test Loss tensor([0.0348, 0.0094, 0.0022, 0.0207, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.47446203231811523 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0110, 0.0025, 0.0204, 0.0126]) \n",
      "Test Loss tensor([0.0340, 0.0101, 0.0021, 0.0193, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4684004783630371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0103, 0.0021, 0.0220, 0.0133]) \n",
      "Test Loss tensor([0.0340, 0.0093, 0.0023, 0.0209, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4730842113494873 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0094, 0.0021, 0.0188, 0.0138]) \n",
      "Test Loss tensor([0.0333, 0.0100, 0.0022, 0.0197, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47269320487976074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0092, 0.0021, 0.0201, 0.0147]) \n",
      "Test Loss tensor([0.0343, 0.0106, 0.0022, 0.0210, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4760406017303467 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0091, 0.0022, 0.0177, 0.0126]) \n",
      "Test Loss tensor([0.0332, 0.0099, 0.0023, 0.0195, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4711751937866211 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0300, 0.0089, 0.0021, 0.0189, 0.0140]) \n",
      "Test Loss tensor([0.0341, 0.0096, 0.0022, 0.0203, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4713013172149658 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0353, 0.0118, 0.0022, 0.0186, 0.0122]) \n",
      "Test Loss tensor([0.0328, 0.0101, 0.0023, 0.0199, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.47231125831604004 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0294, 0.0088, 0.0024, 0.0191, 0.0135]) \n",
      "Test Loss tensor([0.0346, 0.0105, 0.0022, 0.0211, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.47252488136291504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0095, 0.0022, 0.0213, 0.0140]) \n",
      "Test Loss tensor([0.0336, 0.0097, 0.0022, 0.0203, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.47210097312927246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0097, 0.0020, 0.0198, 0.0113]) \n",
      "Test Loss tensor([0.0339, 0.0097, 0.0022, 0.0211, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4738953113555908 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0305, 0.0112, 0.0022, 0.0216, 0.0132]) \n",
      "Test Loss tensor([0.0331, 0.0099, 0.0022, 0.0197, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47092556953430176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0088, 0.0023, 0.0195, 0.0117]) \n",
      "Test Loss tensor([0.0330, 0.0105, 0.0022, 0.0206, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4719107151031494 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0098, 0.0024, 0.0186, 0.0123]) \n",
      "Test Loss tensor([0.0334, 0.0099, 0.0022, 0.0200, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.471604585647583 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0092, 0.0020, 0.0192, 0.0118]) \n",
      "Test Loss tensor([0.0316, 0.0095, 0.0022, 0.0199, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47110557556152344 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0101, 0.0022, 0.0193, 0.0126]) \n",
      "Test Loss tensor([0.0337, 0.0102, 0.0022, 0.0205, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4725008010864258 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0089, 0.0024, 0.0184, 0.0130]) \n",
      "Test Loss tensor([0.0329, 0.0100, 0.0022, 0.0203, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4720137119293213 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0084, 0.0021, 0.0191, 0.0135]) \n",
      "Test Loss tensor([0.0331, 0.0099, 0.0022, 0.0202, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4710860252380371 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0290, 0.0080, 0.0020, 0.0200, 0.0142]) \n",
      "Test Loss tensor([0.0327, 0.0098, 0.0022, 0.0199, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.4713773727416992 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0319, 0.0105, 0.0021, 0.0175, 0.0129]) \n",
      "Test Loss tensor([0.0333, 0.0099, 0.0021, 0.0202, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4739193916320801 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0285, 0.0111, 0.0026, 0.0206, 0.0116]) \n",
      "Test Loss tensor([0.0333, 0.0101, 0.0023, 0.0199, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4682950973510742 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0315, 0.0101, 0.0023, 0.0210, 0.0123]) \n",
      "Test Loss tensor([0.0340, 0.0095, 0.0022, 0.0189, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.47273755073547363 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0093, 0.0021, 0.0169, 0.0124]) \n",
      "Test Loss tensor([0.0340, 0.0099, 0.0021, 0.0190, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4709599018096924 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0318, 0.0103, 0.0028, 0.0180, 0.0126]) \n",
      "Test Loss tensor([0.0337, 0.0100, 0.0022, 0.0203, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.47290706634521484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0094, 0.0020, 0.0203, 0.0126]) \n",
      "Test Loss tensor([0.0331, 0.0102, 0.0022, 0.0199, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.47064661979675293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0109, 0.0026, 0.0169, 0.0140]) \n",
      "Test Loss tensor([0.0323, 0.0093, 0.0022, 0.0198, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.47252535820007324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0108, 0.0022, 0.0193, 0.0129]) \n",
      "Test Loss tensor([0.0337, 0.0095, 0.0022, 0.0196, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.471860408782959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0305, 0.0094, 0.0021, 0.0187, 0.0143]) \n",
      "Test Loss tensor([0.0328, 0.0096, 0.0022, 0.0186, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.47110843658447266 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0363, 0.0099, 0.0024, 0.0198, 0.0121]) \n",
      "Test Loss tensor([0.0323, 0.0094, 0.0022, 0.0200, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.48105645179748535 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0293, 0.0094, 0.0021, 0.0183, 0.0112]) \n",
      "Test Loss tensor([0.0335, 0.0104, 0.0021, 0.0193, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4730367660522461 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0094, 0.0021, 0.0208, 0.0127]) \n",
      "Test Loss tensor([0.0336, 0.0097, 0.0022, 0.0192, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47307562828063965 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0090, 0.0023, 0.0185, 0.0136]) \n",
      "Test Loss tensor([0.0318, 0.0099, 0.0023, 0.0196, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.47324490547180176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0116, 0.0020, 0.0163, 0.0116]) \n",
      "Test Loss tensor([0.0325, 0.0099, 0.0022, 0.0199, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.48761844635009766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0100, 0.0023, 0.0209, 0.0138]) \n",
      "Test Loss tensor([0.0330, 0.0095, 0.0021, 0.0192, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4694805145263672 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0349, 0.0100, 0.0022, 0.0198, 0.0127]) \n",
      "Test Loss tensor([0.0332, 0.0097, 0.0023, 0.0192, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4730720520019531 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0315, 0.0103, 0.0020, 0.0209, 0.0141]) \n",
      "Test Loss tensor([0.0336, 0.0104, 0.0022, 0.0196, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4715003967285156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0302, 0.0110, 0.0020, 0.0177, 0.0110]) \n",
      "Test Loss tensor([0.0342, 0.0097, 0.0022, 0.0194, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4715108871459961 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0089, 0.0024, 0.0201, 0.0131]) \n",
      "Test Loss tensor([0.0318, 0.0099, 0.0022, 0.0202, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.470379114151001 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0354, 0.0102, 0.0024, 0.0198, 0.0119]) \n",
      "Test Loss tensor([0.0331, 0.0100, 0.0022, 0.0199, 0.0128])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 444 in 0.47332024574279785 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0312, 0.0103, 0.0026, 0.0202, 0.0137]) \n",
      "Test Loss tensor([0.0317, 0.0101, 0.0022, 0.0189, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4713554382324219 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0105, 0.0021, 0.0212, 0.0128]) \n",
      "Test Loss tensor([0.0329, 0.0096, 0.0022, 0.0197, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4740149974822998 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0086, 0.0018, 0.0191, 0.0131]) \n",
      "Test Loss tensor([0.0334, 0.0105, 0.0022, 0.0211, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4715383052825928 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0290, 0.0088, 0.0021, 0.0206, 0.0119]) \n",
      "Test Loss tensor([0.0320, 0.0093, 0.0022, 0.0197, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4725644588470459 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0105, 0.0022, 0.0197, 0.0114]) \n",
      "Test Loss tensor([0.0333, 0.0094, 0.0022, 0.0197, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47449684143066406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0079, 0.0022, 0.0223, 0.0140]) \n",
      "Test Loss tensor([0.0324, 0.0092, 0.0022, 0.0197, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47451281547546387 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0097, 0.0022, 0.0205, 0.0125]) \n",
      "Test Loss tensor([0.0331, 0.0099, 0.0022, 0.0197, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4693567752838135 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0082, 0.0025, 0.0191, 0.0142]) \n",
      "Test Loss tensor([0.0326, 0.0101, 0.0021, 0.0201, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4733011722564697 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0313, 0.0094, 0.0022, 0.0219, 0.0120]) \n",
      "Test Loss tensor([0.0334, 0.0100, 0.0022, 0.0196, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4747140407562256 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0096, 0.0025, 0.0195, 0.0134]) \n",
      "Test Loss tensor([0.0323, 0.0095, 0.0022, 0.0202, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4734938144683838 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0324, 0.0098, 0.0022, 0.0196, 0.0137]) \n",
      "Test Loss tensor([0.0326, 0.0098, 0.0021, 0.0207, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4713749885559082 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0096, 0.0023, 0.0203, 0.0130]) \n",
      "Test Loss tensor([0.0323, 0.0102, 0.0023, 0.0203, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4717857837677002 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0127, 0.0024, 0.0177, 0.0117]) \n",
      "Test Loss tensor([0.0333, 0.0101, 0.0021, 0.0191, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.4711439609527588 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0320, 0.0080, 0.0022, 0.0200, 0.0119]) \n",
      "Test Loss tensor([0.0333, 0.0103, 0.0022, 0.0209, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4705209732055664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0112, 0.0023, 0.0196, 0.0118]) \n",
      "Test Loss tensor([0.0332, 0.0094, 0.0022, 0.0194, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4727139472961426 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0092, 0.0026, 0.0187, 0.0143]) \n",
      "Test Loss tensor([0.0346, 0.0105, 0.0023, 0.0196, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.47008657455444336 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0085, 0.0021, 0.0186, 0.0135]) \n",
      "Test Loss tensor([0.0332, 0.0096, 0.0023, 0.0198, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4715278148651123 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0347, 0.0094, 0.0023, 0.0225, 0.0131]) \n",
      "Test Loss tensor([0.0329, 0.0101, 0.0023, 0.0209, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.46996188163757324 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0338, 0.0091, 0.0022, 0.0237, 0.0120]) \n",
      "Test Loss tensor([0.0321, 0.0097, 0.0022, 0.0186, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.47293806076049805 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0314, 0.0089, 0.0022, 0.0192, 0.0120]) \n",
      "Test Loss tensor([0.0345, 0.0098, 0.0024, 0.0202, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4817194938659668 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0108, 0.0027, 0.0210, 0.0134]) \n",
      "Test Loss tensor([0.0345, 0.0097, 0.0022, 0.0194, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4720730781555176 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0302, 0.0095, 0.0020, 0.0185, 0.0134]) \n",
      "Test Loss tensor([0.0333, 0.0101, 0.0021, 0.0194, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4710853099822998 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0099, 0.0023, 0.0224, 0.0136]) \n",
      "Test Loss tensor([0.0331, 0.0096, 0.0022, 0.0207, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.472348690032959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0305, 0.0114, 0.0023, 0.0178, 0.0131]) \n",
      "Test Loss tensor([0.0329, 0.0100, 0.0022, 0.0193, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4699099063873291 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0320, 0.0094, 0.0024, 0.0199, 0.0137]) \n",
      "Test Loss tensor([0.0319, 0.0096, 0.0022, 0.0196, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4709451198577881 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0345, 0.0076, 0.0022, 0.0188, 0.0139]) \n",
      "Test Loss tensor([0.0333, 0.0095, 0.0022, 0.0210, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4716305732727051 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0299, 0.0104, 0.0024, 0.0235, 0.0123]) \n",
      "Test Loss tensor([0.0329, 0.0096, 0.0022, 0.0201, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4709322452545166 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0319, 0.0083, 0.0025, 0.0177, 0.0141]) \n",
      "Test Loss tensor([0.0348, 0.0093, 0.0023, 0.0219, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4731311798095703 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0379, 0.0094, 0.0022, 0.0195, 0.0124]) \n",
      "Test Loss tensor([0.0333, 0.0099, 0.0022, 0.0204, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.47252321243286133 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0076, 0.0022, 0.0209, 0.0113]) \n",
      "Test Loss tensor([0.0363, 0.0098, 0.0022, 0.0202, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.473388671875 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0099, 0.0019, 0.0196, 0.0149]) \n",
      "Test Loss tensor([0.0343, 0.0101, 0.0022, 0.0194, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4745941162109375 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0278, 0.0082, 0.0020, 0.0230, 0.0106]) \n",
      "Test Loss tensor([0.0344, 0.0097, 0.0022, 0.0209, 0.0129])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.47020506858825684 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0339, 0.0081, 0.0022, 0.0190, 0.0117]) \n",
      "Test Loss tensor([0.0320, 0.0101, 0.0021, 0.0203, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.47144174575805664 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0290, 0.0073, 0.0022, 0.0206, 0.0134]) \n",
      "Test Loss tensor([0.0349, 0.0101, 0.0022, 0.0208, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47564196586608887 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0359, 0.0086, 0.0021, 0.0201, 0.0138]) \n",
      "Test Loss tensor([0.0323, 0.0100, 0.0022, 0.0196, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.47931814193725586 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0303, 0.0080, 0.0020, 0.0210, 0.0126]) \n",
      "Test Loss tensor([0.0353, 0.0104, 0.0023, 0.0211, 0.0136])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4887199401855469 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0103, 0.0023, 0.0196, 0.0129]) \n",
      "Test Loss tensor([0.0322, 0.0096, 0.0021, 0.0195, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47070741653442383 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0108, 0.0022, 0.0171, 0.0126]) \n",
      "Test Loss tensor([0.0350, 0.0099, 0.0022, 0.0209, 0.0131])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4747936725616455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0329, 0.0096, 0.0021, 0.0206, 0.0122]) \n",
      "Test Loss tensor([0.0327, 0.0100, 0.0022, 0.0192, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47116756439208984 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0073, 0.0022, 0.0213, 0.0111]) \n",
      "Test Loss tensor([0.0346, 0.0097, 0.0023, 0.0213, 0.0132])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4739995002746582 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0312, 0.0089, 0.0023, 0.0238, 0.0153]) \n",
      "Test Loss tensor([0.0322, 0.0094, 0.0022, 0.0197, 0.0128])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 608 in 0.472430944442749 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0072, 0.0024, 0.0193, 0.0122]) \n",
      "Test Loss tensor([0.0368, 0.0103, 0.0021, 0.0212, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.48085999488830566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0377, 0.0107, 0.0023, 0.0209, 0.0140]) \n",
      "Test Loss tensor([0.0332, 0.0100, 0.0021, 0.0199, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4956045150756836 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0346, 0.0090, 0.0022, 0.0206, 0.0134]) \n",
      "Test Loss tensor([0.0361, 0.0099, 0.0023, 0.0203, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.49576258659362793 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0094, 0.0023, 0.0198, 0.0133]) \n",
      "Test Loss tensor([0.0331, 0.0100, 0.0022, 0.0198, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4694488048553467 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0307, 0.0095, 0.0020, 0.0219, 0.0121]) \n",
      "Test Loss tensor([0.0347, 0.0096, 0.0022, 0.0208, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.4708902835845947 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0097, 0.0023, 0.0206, 0.0139]) \n",
      "Test Loss tensor([0.0320, 0.0098, 0.0022, 0.0193, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4684886932373047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0333, 0.0099, 0.0021, 0.0224, 0.0143]) \n",
      "Test Loss tensor([0.0336, 0.0099, 0.0022, 0.0192, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.470883846282959 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0340, 0.0106, 0.0021, 0.0219, 0.0114]) \n",
      "Test Loss tensor([0.0324, 0.0102, 0.0021, 0.0198, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47185611724853516 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0082, 0.0021, 0.0206, 0.0130]) \n",
      "Test Loss tensor([0.0323, 0.0097, 0.0021, 0.0215, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4716014862060547 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0287, 0.0091, 0.0022, 0.0217, 0.0117]) \n",
      "Test Loss tensor([0.0328, 0.0100, 0.0023, 0.0188, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.48481059074401855 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0342, 0.0081, 0.0023, 0.0213, 0.0137]) \n",
      "Test Loss tensor([0.0337, 0.0093, 0.0022, 0.0189, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4738438129425049 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0095, 0.0021, 0.0182, 0.0120]) \n",
      "Test Loss tensor([0.0319, 0.0095, 0.0022, 0.0196, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.47589635848999023 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0310, 0.0097, 0.0023, 0.0207, 0.0132]) \n",
      "Test Loss tensor([0.0323, 0.0096, 0.0021, 0.0197, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4724133014678955 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0336, 0.0097, 0.0023, 0.0200, 0.0123]) \n",
      "Test Loss tensor([0.0323, 0.0096, 0.0022, 0.0187, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.47332167625427246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0106, 0.0023, 0.0203, 0.0131]) \n",
      "Test Loss tensor([0.0320, 0.0099, 0.0022, 0.0203, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47106361389160156 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0089, 0.0021, 0.0165, 0.0157]) \n",
      "Test Loss tensor([0.0323, 0.0099, 0.0022, 0.0190, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4720025062561035 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0298, 0.0099, 0.0021, 0.0205, 0.0141]) \n",
      "Test Loss tensor([0.0323, 0.0093, 0.0022, 0.0200, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4718959331512451 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0317, 0.0105, 0.0019, 0.0191, 0.0120]) \n",
      "Test Loss tensor([0.0322, 0.0098, 0.0021, 0.0196, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47282862663269043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0087, 0.0021, 0.0208, 0.0108]) \n",
      "Test Loss tensor([0.0326, 0.0100, 0.0022, 0.0187, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4709312915802002 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0366, 0.0097, 0.0027, 0.0188, 0.0136]) \n",
      "Test Loss tensor([0.0321, 0.0096, 0.0022, 0.0191, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4730346202850342 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0302, 0.0105, 0.0022, 0.0217, 0.0135]) \n",
      "Test Loss tensor([0.0312, 0.0097, 0.0022, 0.0191, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.47133517265319824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0311, 0.0084, 0.0022, 0.0185, 0.0142]) \n",
      "Test Loss tensor([0.0325, 0.0097, 0.0021, 0.0197, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.47033262252807617 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0330, 0.0089, 0.0021, 0.0192, 0.0108]) \n",
      "Test Loss tensor([0.0308, 0.0097, 0.0022, 0.0201, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.47141242027282715 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0332, 0.0096, 0.0022, 0.0194, 0.0130]) \n",
      "Test Loss tensor([0.0335, 0.0097, 0.0022, 0.0196, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4741642475128174 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0320, 0.0103, 0.0019, 0.0188, 0.0118]) \n",
      "Test Loss tensor([0.0320, 0.0094, 0.0022, 0.0202, 0.0130])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4703352451324463 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0103, 0.0022, 0.0210, 0.0135]) \n",
      "Test Loss tensor([0.0320, 0.0099, 0.0022, 0.0186, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.47040843963623047 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0291, 0.0104, 0.0025, 0.0183, 0.0119]) \n",
      "Test Loss tensor([0.0324, 0.0097, 0.0021, 0.0195, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.47066211700439453 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0328, 0.0108, 0.0022, 0.0207, 0.0119]) \n",
      "Test Loss tensor([0.0330, 0.0100, 0.0023, 0.0190, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47029948234558105 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0269, 0.0087, 0.0023, 0.0209, 0.0133]) \n",
      "Test Loss tensor([0.0316, 0.0100, 0.0022, 0.0197, 0.0125])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4758169651031494 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0318, 0.0097, 0.0023, 0.0201, 0.0113]) \n",
      "Test Loss tensor([0.0327, 0.0101, 0.0022, 0.0200, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4719269275665283 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0350, 0.0094, 0.0020, 0.0197, 0.0124]) \n",
      "Test Loss tensor([0.0318, 0.0095, 0.0022, 0.0193, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.472135066986084 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0295, 0.0100, 0.0020, 0.0179, 0.0118]) \n",
      "Test Loss tensor([0.0318, 0.0097, 0.0022, 0.0195, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4724256992340088 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0280, 0.0082, 0.0022, 0.0194, 0.0121]) \n",
      "Test Loss tensor([0.0327, 0.0094, 0.0021, 0.0208, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4731178283691406 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0316, 0.0101, 0.0024, 0.0211, 0.0129]) \n",
      "Test Loss tensor([0.0328, 0.0092, 0.0023, 0.0194, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4691784381866455 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0321, 0.0100, 0.0024, 0.0166, 0.0137]) \n",
      "Test Loss tensor([0.0330, 0.0098, 0.0023, 0.0193, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.47046637535095215 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0281, 0.0078, 0.0021, 0.0176, 0.0134]) \n",
      "Test Loss tensor([0.0331, 0.0096, 0.0023, 0.0200, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.46877145767211914 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0334, 0.0101, 0.0024, 0.0207, 0.0124]) \n",
      "Test Loss tensor([0.0321, 0.0095, 0.0023, 0.0189, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4920382499694824 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0299, 0.0077, 0.0025, 0.0182, 0.0140]) \n",
      "Test Loss tensor([0.0332, 0.0097, 0.0022, 0.0202, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4711771011352539 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0360, 0.0102, 0.0023, 0.0189, 0.0134]) \n",
      "Test Loss tensor([0.0323, 0.0095, 0.0022, 0.0193, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47045373916625977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0313, 0.0082, 0.0020, 0.0200, 0.0132]) \n",
      "Test Loss tensor([0.0328, 0.0099, 0.0022, 0.0199, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.47000622749328613 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0341, 0.0098, 0.0020, 0.0211, 0.0115]) \n",
      "Test Loss tensor([0.0324, 0.0097, 0.0021, 0.0194, 0.0124])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 772 in 0.4748506546020508 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0297, 0.0105, 0.0023, 0.0190, 0.0122]) \n",
      "Test Loss tensor([0.0331, 0.0106, 0.0023, 0.0199, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47418212890625 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0106, 0.0022, 0.0185, 0.0115]) \n",
      "Test Loss tensor([0.0316, 0.0099, 0.0021, 0.0198, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47426915168762207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0282, 0.0087, 0.0026, 0.0197, 0.0130]) \n",
      "Test Loss tensor([0.0322, 0.0094, 0.0021, 0.0201, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4723818302154541 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0299, 0.0106, 0.0021, 0.0203, 0.0140]) \n",
      "Test Loss tensor([0.0310, 0.0099, 0.0021, 0.0191, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47418713569641113 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0299, 0.0093, 0.0023, 0.0188, 0.0142]) \n",
      "Test Loss tensor([0.0326, 0.0099, 0.0021, 0.0198, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47214770317077637 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0309, 0.0098, 0.0022, 0.0184, 0.0136]) \n",
      "Test Loss tensor([0.0326, 0.0098, 0.0021, 0.0193, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4704623222351074 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0296, 0.0090, 0.0022, 0.0184, 0.0144]) \n",
      "Test Loss tensor([0.0314, 0.0092, 0.0022, 0.0197, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4718296527862549 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0351, 0.0100, 0.0025, 0.0194, 0.0124]) \n",
      "Test Loss tensor([0.0316, 0.0097, 0.0022, 0.0186, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.47149133682250977 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0335, 0.0105, 0.0022, 0.0178, 0.0130]) \n",
      "Test Loss tensor([0.0322, 0.0092, 0.0022, 0.0195, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4735419750213623 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0322, 0.0094, 0.0020, 0.0212, 0.0124]) \n",
      "Test Loss tensor([0.0313, 0.0095, 0.0022, 0.0181, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4735751152038574 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0278, 0.0091, 0.0024, 0.0218, 0.0123]) \n",
      "Test Loss tensor([0.0321, 0.0092, 0.0021, 0.0189, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4743201732635498 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0286, 0.0100, 0.0020, 0.0176, 0.0115]) \n",
      "Test Loss tensor([0.0329, 0.0097, 0.0022, 0.0193, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.4719729423522949 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0288, 0.0093, 0.0021, 0.0195, 0.0120]) \n",
      "Test Loss tensor([0.0324, 0.0097, 0.0022, 0.0193, 0.0119])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.47136521339416504 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0326, 0.0089, 0.0023, 0.0173, 0.0134]) \n",
      "Test Loss tensor([0.0320, 0.0093, 0.0021, 0.0194, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47162723541259766 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0304, 0.0097, 0.0020, 0.0209, 0.0117]) \n",
      "Test Loss tensor([0.0326, 0.0097, 0.0022, 0.0188, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4746682643890381 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0294, 0.0108, 0.0020, 0.0176, 0.0119]) \n",
      "Test Loss tensor([0.0314, 0.0097, 0.0022, 0.0194, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.47127747535705566 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0280, 0.0095, 0.0023, 0.0192, 0.0123]) \n",
      "Test Loss tensor([0.0325, 0.0098, 0.0022, 0.0194, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4720609188079834 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0308, 0.0095, 0.0020, 0.0184, 0.0123]) \n",
      "Test Loss tensor([0.0329, 0.0099, 0.0022, 0.0187, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4701380729675293 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0296, 0.0099, 0.0023, 0.0201, 0.0108]) \n",
      "Test Loss tensor([0.0327, 0.0095, 0.0022, 0.0189, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4731776714324951 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0331, 0.0120, 0.0023, 0.0217, 0.0144]) \n",
      "Test Loss tensor([0.0337, 0.0099, 0.0022, 0.0195, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.47254443168640137 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0269, 0.0081, 0.0026, 0.0203, 0.0123]) \n",
      "Test Loss tensor([0.0312, 0.0097, 0.0022, 0.0194, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47271132469177246 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0325, 0.0108, 0.0020, 0.0220, 0.0135]) \n",
      "Test Loss tensor([0.0328, 0.0099, 0.0022, 0.0205, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47492218017578125 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0269, 0.0088, 0.0020, 0.0206, 0.0125]) \n",
      "Test Loss tensor([0.0320, 0.0100, 0.0022, 0.0204, 0.0122])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.47664952278137207 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0288, 0.0096, 0.0023, 0.0182, 0.0127]) \n",
      "Test Loss tensor([0.0318, 0.0094, 0.0023, 0.0188, 0.0123])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47331690788269043 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0306, 0.0085, 0.0021, 0.0144, 0.0142]) \n",
      "Test Loss tensor([0.0328, 0.0095, 0.0022, 0.0194, 0.0124])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47275328636169434 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0323, 0.0097, 0.0023, 0.0190, 0.0130]) \n",
      "Test Loss tensor([0.0316, 0.0097, 0.0021, 0.0193, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45520687103271484 **************\n",
      "\n",
      "Training Idx 2 \n",
      "Train Loss tensor([0.0245, 0.0060, 0.0018, 0.0146, 0.0097]) \n",
      "Test Loss tensor([0.0327, 0.0093, 0.0022, 0.0191, 0.0124])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.5096986293792725 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4388, 0.4375, 0.4350, 0.4407, 0.3431]) \n",
      "Test Loss tensor([0.4384, 0.4364, 0.4323, 0.4388, 0.3423])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.473818302154541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4389, 0.4382, 0.4331, 0.4396, 0.3394]) \n",
      "Test Loss tensor([0.4368, 0.4354, 0.4308, 0.4388, 0.3406])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4753556251525879 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4371, 0.4353, 0.4333, 0.4391, 0.3422]) \n",
      "Test Loss tensor([0.4359, 0.4340, 0.4301, 0.4385, 0.3402])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47074198722839355 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4354, 0.4327, 0.4308, 0.4374, 0.3418]) \n",
      "Test Loss tensor([0.4346, 0.4326, 0.4287, 0.4372, 0.3397])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4863569736480713 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4345, 0.4350, 0.4295, 0.4383, 0.3347]) \n",
      "Test Loss tensor([0.4331, 0.4314, 0.4270, 0.4371, 0.3384])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4747505187988281 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4350, 0.4318, 0.4287, 0.4369, 0.3368]) \n",
      "Test Loss tensor([0.4316, 0.4297, 0.4269, 0.4374, 0.3383])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4783005714416504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4324, 0.4292, 0.4253, 0.4375, 0.3402]) \n",
      "Test Loss tensor([0.4305, 0.4286, 0.4251, 0.4364, 0.3380])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4708740711212158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4296, 0.4292, 0.4242, 0.4345, 0.3371]) \n",
      "Test Loss tensor([0.4293, 0.4273, 0.4235, 0.4354, 0.3364])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.47266268730163574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4280, 0.4275, 0.4252, 0.4385, 0.3388]) \n",
      "Test Loss tensor([0.4278, 0.4256, 0.4230, 0.4348, 0.3371])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.47247767448425293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4270, 0.4257, 0.4225, 0.4350, 0.3368]) \n",
      "Test Loss tensor([0.4261, 0.4246, 0.4224, 0.4347, 0.3364])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4769573211669922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4268, 0.4239, 0.4210, 0.4345, 0.3336]) \n",
      "Test Loss tensor([0.4248, 0.4231, 0.4203, 0.4337, 0.3345])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.47951602935791016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4256, 0.4237, 0.4173, 0.4332, 0.3365]) \n",
      "Test Loss tensor([0.4239, 0.4217, 0.4194, 0.4333, 0.3354])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4718363285064697 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4250, 0.4216, 0.4191, 0.4342, 0.3385]) \n",
      "Test Loss tensor([0.4224, 0.4202, 0.4188, 0.4326, 0.3341])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4727649688720703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4221, 0.4202, 0.4183, 0.4333, 0.3362]) \n",
      "Test Loss tensor([0.4210, 0.4188, 0.4174, 0.4320, 0.3337])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.473966121673584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4222, 0.4179, 0.4159, 0.4336, 0.3347]) \n",
      "Test Loss tensor([0.4194, 0.4180, 0.4160, 0.4320, 0.3336])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4727907180786133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4203, 0.4181, 0.4157, 0.4332, 0.3348]) \n",
      "Test Loss tensor([0.4187, 0.4164, 0.4149, 0.4317, 0.3328])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.46953248977661133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4182, 0.4162, 0.4155, 0.4306, 0.3355]) \n",
      "Test Loss tensor([0.4173, 0.4147, 0.4134, 0.4315, 0.3331])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4723014831542969 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4183, 0.4155, 0.4118, 0.4297, 0.3326]) \n",
      "Test Loss tensor([0.4158, 0.4136, 0.4129, 0.4311, 0.3319])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4707648754119873 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4162, 0.4122, 0.4148, 0.4294, 0.3331]) \n",
      "Test Loss tensor([0.4144, 0.4126, 0.4113, 0.4304, 0.3302])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4770689010620117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4158, 0.4125, 0.4133, 0.4310, 0.3293]) \n",
      "Test Loss tensor([0.4128, 0.4107, 0.4104, 0.4294, 0.3299])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.469897985458374 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4141, 0.4106, 0.4107, 0.4306, 0.3320]) \n",
      "Test Loss tensor([0.4113, 0.4099, 0.4089, 0.4297, 0.3300])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4711754322052002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4114, 0.4091, 0.4074, 0.4313, 0.3243]) \n",
      "Test Loss tensor([0.4105, 0.4075, 0.4072, 0.4286, 0.3301])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4707512855529785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4107, 0.4074, 0.4074, 0.4288, 0.3320]) \n",
      "Test Loss tensor([0.4087, 0.4066, 0.4061, 0.4280, 0.3292])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.47164201736450195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4076, 0.4053, 0.4072, 0.4296, 0.3296]) \n",
      "Test Loss tensor([0.4074, 0.4049, 0.4053, 0.4270, 0.3268])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5035450458526611 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4061, 0.4047, 0.4046, 0.4266, 0.3262]) \n",
      "Test Loss tensor([0.4059, 0.4040, 0.4035, 0.4266, 0.3285])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4784679412841797 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4071, 0.4041, 0.4054, 0.4300, 0.3255]) \n",
      "Test Loss tensor([0.4042, 0.4025, 0.4017, 0.4253, 0.3253])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47803378105163574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4041, 0.4019, 0.4033, 0.4259, 0.3288]) \n",
      "Test Loss tensor([0.4034, 0.4005, 0.4013, 0.4262, 0.3261])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.47603869438171387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4023, 0.4015, 0.3994, 0.4254, 0.3282]) \n",
      "Test Loss tensor([0.4021, 0.3990, 0.3999, 0.4256, 0.3261])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.47449636459350586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.4017, 0.3985, 0.4005, 0.4281, 0.3242]) \n",
      "Test Loss tensor([0.4000, 0.3977, 0.3990, 0.4250, 0.3256])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.47057318687438965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3983, 0.3990, 0.4014, 0.4255, 0.3234]) \n",
      "Test Loss tensor([0.3988, 0.3961, 0.3976, 0.4245, 0.3243])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4689302444458008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3992, 0.3963, 0.3986, 0.4263, 0.3254]) \n",
      "Test Loss tensor([0.3974, 0.3950, 0.3964, 0.4234, 0.3234])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.48684096336364746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3984, 0.3948, 0.3976, 0.4259, 0.3248]) \n",
      "Test Loss tensor([0.3956, 0.3931, 0.3954, 0.4230, 0.3242])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.46876072883605957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3960, 0.3934, 0.3956, 0.4237, 0.3216]) \n",
      "Test Loss tensor([0.3945, 0.3915, 0.3934, 0.4229, 0.3217])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.472491979598999 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3946, 0.3914, 0.3942, 0.4209, 0.3222]) \n",
      "Test Loss tensor([0.3928, 0.3903, 0.3929, 0.4222, 0.3220])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.46853160858154297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3933, 0.3894, 0.3925, 0.4225, 0.3189]) \n",
      "Test Loss tensor([0.3914, 0.3887, 0.3917, 0.4218, 0.3210])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47083115577697754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3918, 0.3898, 0.3892, 0.4206, 0.3217]) \n",
      "Test Loss tensor([0.3898, 0.3869, 0.3902, 0.4209, 0.3207])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.48635005950927734 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3906, 0.3869, 0.3902, 0.4197, 0.3199]) \n",
      "Test Loss tensor([0.3881, 0.3851, 0.3884, 0.4208, 0.3200])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.46968913078308105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3873, 0.3863, 0.3901, 0.4198, 0.3200]) \n",
      "Test Loss tensor([0.3869, 0.3840, 0.3869, 0.4197, 0.3186])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4753589630126953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3870, 0.3831, 0.3869, 0.4204, 0.3196]) \n",
      "Test Loss tensor([0.3852, 0.3823, 0.3858, 0.4192, 0.3189])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4695167541503906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3846, 0.3830, 0.3870, 0.4219, 0.3168]) \n",
      "Test Loss tensor([0.3838, 0.3806, 0.3845, 0.4191, 0.3183])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.47157812118530273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3841, 0.3809, 0.3835, 0.4235, 0.3178]) \n",
      "Test Loss tensor([0.3821, 0.3790, 0.3832, 0.4183, 0.3179])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 164 in 0.47069573402404785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3819, 0.3797, 0.3819, 0.4192, 0.3179]) \n",
      "Test Loss tensor([0.3804, 0.3777, 0.3820, 0.4176, 0.3175])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.47260403633117676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3808, 0.3779, 0.3817, 0.4150, 0.3193]) \n",
      "Test Loss tensor([0.3791, 0.3758, 0.3799, 0.4178, 0.3151])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.469954252243042 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3798, 0.3756, 0.3815, 0.4155, 0.3140]) \n",
      "Test Loss tensor([0.3776, 0.3739, 0.3787, 0.4161, 0.3161])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47221922874450684 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3791, 0.3737, 0.3792, 0.4177, 0.3136]) \n",
      "Test Loss tensor([0.3753, 0.3725, 0.3779, 0.4161, 0.3152])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4704263210296631 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3753, 0.3708, 0.3768, 0.4147, 0.3157]) \n",
      "Test Loss tensor([0.3738, 0.3703, 0.3762, 0.4159, 0.3153])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.46996545791625977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3742, 0.3701, 0.3747, 0.4165, 0.3158]) \n",
      "Test Loss tensor([0.3724, 0.3688, 0.3745, 0.4152, 0.3118])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4699995517730713 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3725, 0.3700, 0.3746, 0.4159, 0.3119]) \n",
      "Test Loss tensor([0.3706, 0.3672, 0.3727, 0.4134, 0.3134])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.47120070457458496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3705, 0.3673, 0.3733, 0.4162, 0.3130]) \n",
      "Test Loss tensor([0.3683, 0.3653, 0.3712, 0.4138, 0.3118])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.47097063064575195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3694, 0.3634, 0.3726, 0.4162, 0.3095]) \n",
      "Test Loss tensor([0.3669, 0.3634, 0.3698, 0.4132, 0.3126])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4729013442993164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3681, 0.3629, 0.3703, 0.4117, 0.3127]) \n",
      "Test Loss tensor([0.3653, 0.3615, 0.3678, 0.4129, 0.3099])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4730672836303711 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3657, 0.3605, 0.3689, 0.4132, 0.3095]) \n",
      "Test Loss tensor([0.3631, 0.3596, 0.3666, 0.4118, 0.3109])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4774940013885498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3633, 0.3593, 0.3663, 0.4107, 0.3120]) \n",
      "Test Loss tensor([0.3610, 0.3578, 0.3651, 0.4111, 0.3089])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.48502683639526367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3609, 0.3568, 0.3667, 0.4134, 0.3067]) \n",
      "Test Loss tensor([0.3596, 0.3558, 0.3630, 0.4111, 0.3082])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4710719585418701 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3587, 0.3579, 0.3646, 0.4109, 0.3079]) \n",
      "Test Loss tensor([0.3576, 0.3540, 0.3616, 0.4088, 0.3083])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4728085994720459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3571, 0.3533, 0.3621, 0.4104, 0.3056]) \n",
      "Test Loss tensor([0.3556, 0.3521, 0.3603, 0.4098, 0.3090])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.46940135955810547 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3549, 0.3507, 0.3597, 0.4098, 0.3054]) \n",
      "Test Loss tensor([0.3530, 0.3501, 0.3591, 0.4087, 0.3068])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.473743200302124 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3550, 0.3493, 0.3575, 0.4105, 0.3072]) \n",
      "Test Loss tensor([0.3517, 0.3478, 0.3571, 0.4093, 0.3069])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47037529945373535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3517, 0.3488, 0.3553, 0.4094, 0.3092]) \n",
      "Test Loss tensor([0.3496, 0.3462, 0.3556, 0.4084, 0.3058])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.47205686569213867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3501, 0.3444, 0.3549, 0.4138, 0.3048]) \n",
      "Test Loss tensor([0.3479, 0.3440, 0.3534, 0.4069, 0.3042])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.46845197677612305 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3475, 0.3446, 0.3530, 0.4088, 0.3019]) \n",
      "Test Loss tensor([0.3462, 0.3418, 0.3518, 0.4063, 0.3051])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4714655876159668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3437, 0.3420, 0.3518, 0.4066, 0.3034]) \n",
      "Test Loss tensor([0.3438, 0.3397, 0.3501, 0.4054, 0.3029])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.47186994552612305 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3438, 0.3393, 0.3489, 0.4048, 0.3080]) \n",
      "Test Loss tensor([0.3416, 0.3375, 0.3478, 0.4056, 0.3023])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4705321788787842 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3408, 0.3378, 0.3458, 0.4058, 0.2949]) \n",
      "Test Loss tensor([0.3394, 0.3353, 0.3459, 0.4044, 0.3011])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47119140625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3403, 0.3355, 0.3490, 0.4096, 0.3015]) \n",
      "Test Loss tensor([0.3372, 0.3329, 0.3445, 0.4036, 0.3011])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.47110986709594727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3366, 0.3343, 0.3436, 0.4029, 0.3020]) \n",
      "Test Loss tensor([0.3352, 0.3313, 0.3427, 0.4028, 0.2997])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.47331857681274414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3361, 0.3298, 0.3418, 0.4031, 0.2940]) \n",
      "Test Loss tensor([0.3325, 0.3288, 0.3403, 0.4024, 0.2968])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.4722871780395508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3337, 0.3283, 0.3410, 0.4052, 0.2948]) \n",
      "Test Loss tensor([0.3310, 0.3261, 0.3379, 0.4019, 0.2986])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.48975467681884766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3309, 0.3260, 0.3382, 0.4007, 0.2952]) \n",
      "Test Loss tensor([0.3279, 0.3242, 0.3364, 0.4002, 0.2975])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4853672981262207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3297, 0.3243, 0.3364, 0.4004, 0.2997]) \n",
      "Test Loss tensor([0.3260, 0.3212, 0.3348, 0.3997, 0.2959])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4910740852355957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3265, 0.3219, 0.3357, 0.3967, 0.2956]) \n",
      "Test Loss tensor([0.3236, 0.3194, 0.3325, 0.3988, 0.2953])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4736161231994629 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3253, 0.3190, 0.3331, 0.4034, 0.2946]) \n",
      "Test Loss tensor([0.3217, 0.3167, 0.3310, 0.3997, 0.2952])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4731466770172119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3214, 0.3165, 0.3312, 0.4018, 0.2951]) \n",
      "Test Loss tensor([0.3194, 0.3143, 0.3292, 0.3988, 0.2940])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4722096920013428 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3206, 0.3146, 0.3304, 0.3993, 0.2924]) \n",
      "Test Loss tensor([0.3168, 0.3124, 0.3265, 0.3971, 0.2927])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4711124897003174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3166, 0.3120, 0.3249, 0.3996, 0.2898]) \n",
      "Test Loss tensor([0.3142, 0.3099, 0.3249, 0.3976, 0.2922])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.4706096649169922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3149, 0.3107, 0.3245, 0.3968, 0.2921]) \n",
      "Test Loss tensor([0.3121, 0.3074, 0.3228, 0.3964, 0.2918])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4707458019256592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3133, 0.3071, 0.3221, 0.3955, 0.2879]) \n",
      "Test Loss tensor([0.3095, 0.3051, 0.3206, 0.3959, 0.2901])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.4884495735168457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3087, 0.3037, 0.3184, 0.3962, 0.2864]) \n",
      "Test Loss tensor([0.3074, 0.3023, 0.3186, 0.3950, 0.2892])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.47577953338623047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3068, 0.3021, 0.3172, 0.3986, 0.2925]) \n",
      "Test Loss tensor([0.3041, 0.2994, 0.3157, 0.3941, 0.2880])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4693644046783447 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3040, 0.2993, 0.3122, 0.3943, 0.2871]) \n",
      "Test Loss tensor([0.3024, 0.2968, 0.3128, 0.3921, 0.2883])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4740598201751709 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.3015, 0.2954, 0.3127, 0.3909, 0.2877]) \n",
      "Test Loss tensor([0.2994, 0.2944, 0.3119, 0.3924, 0.2874])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.46989893913269043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2968, 0.2943, 0.3092, 0.3928, 0.2897]) \n",
      "Test Loss tensor([0.2974, 0.2910, 0.3093, 0.3902, 0.2859])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 328 in 0.47438573837280273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2968, 0.2918, 0.3111, 0.3932, 0.2843]) \n",
      "Test Loss tensor([0.2930, 0.2881, 0.3070, 0.3902, 0.2858])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4716312885284424 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2933, 0.2881, 0.3108, 0.3885, 0.2853]) \n",
      "Test Loss tensor([0.2904, 0.2851, 0.3046, 0.3900, 0.2860])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.46985316276550293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2901, 0.2859, 0.3049, 0.3880, 0.2819]) \n",
      "Test Loss tensor([0.2878, 0.2822, 0.3016, 0.3877, 0.2844])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4735560417175293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2861, 0.2814, 0.3019, 0.3838, 0.2822]) \n",
      "Test Loss tensor([0.2841, 0.2786, 0.2993, 0.3874, 0.2816])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47424960136413574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2832, 0.2799, 0.3010, 0.3951, 0.2805]) \n",
      "Test Loss tensor([0.2818, 0.2758, 0.2970, 0.3878, 0.2826])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47278261184692383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2827, 0.2758, 0.2995, 0.3887, 0.2790]) \n",
      "Test Loss tensor([0.2785, 0.2719, 0.2942, 0.3849, 0.2802])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4706301689147949 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2791, 0.2719, 0.2948, 0.3856, 0.2832]) \n",
      "Test Loss tensor([0.2754, 0.2690, 0.2915, 0.3856, 0.2803])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4736630916595459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2754, 0.2694, 0.2921, 0.3933, 0.2797]) \n",
      "Test Loss tensor([0.2722, 0.2661, 0.2883, 0.3850, 0.2781])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.47368931770324707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2724, 0.2657, 0.2912, 0.3889, 0.2775]) \n",
      "Test Loss tensor([0.2683, 0.2625, 0.2855, 0.3839, 0.2777])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.47133636474609375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2680, 0.2637, 0.2834, 0.3826, 0.2797]) \n",
      "Test Loss tensor([0.2652, 0.2588, 0.2833, 0.3820, 0.2778])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.47556543350219727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2663, 0.2587, 0.2832, 0.3829, 0.2759]) \n",
      "Test Loss tensor([0.2613, 0.2548, 0.2798, 0.3823, 0.2767])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4722442626953125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2615, 0.2557, 0.2820, 0.3849, 0.2790]) \n",
      "Test Loss tensor([0.2583, 0.2511, 0.2761, 0.3815, 0.2749])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.47925901412963867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2593, 0.2516, 0.2774, 0.3848, 0.2784]) \n",
      "Test Loss tensor([0.2546, 0.2476, 0.2724, 0.3805, 0.2736])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4975893497467041 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2547, 0.2471, 0.2751, 0.3776, 0.2718]) \n",
      "Test Loss tensor([0.2501, 0.2430, 0.2703, 0.3794, 0.2737])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4739253520965576 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2498, 0.2425, 0.2728, 0.3805, 0.2700]) \n",
      "Test Loss tensor([0.2465, 0.2388, 0.2663, 0.3784, 0.2703])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.47229599952697754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2446, 0.2379, 0.2612, 0.3766, 0.2693]) \n",
      "Test Loss tensor([0.2421, 0.2345, 0.2620, 0.3763, 0.2693])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4701671600341797 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2416, 0.2338, 0.2622, 0.3812, 0.2695]) \n",
      "Test Loss tensor([0.2379, 0.2308, 0.2590, 0.3751, 0.2695])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.474529504776001 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2373, 0.2303, 0.2585, 0.3733, 0.2689]) \n",
      "Test Loss tensor([0.2347, 0.2257, 0.2549, 0.3759, 0.2668])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4714181423187256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2331, 0.2255, 0.2561, 0.3718, 0.2702]) \n",
      "Test Loss tensor([0.2288, 0.2205, 0.2506, 0.3724, 0.2673])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4746251106262207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2276, 0.2209, 0.2510, 0.3771, 0.2642]) \n",
      "Test Loss tensor([0.2243, 0.2157, 0.2472, 0.3694, 0.2661])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4729175567626953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2258, 0.2153, 0.2492, 0.3774, 0.2653]) \n",
      "Test Loss tensor([0.2184, 0.2106, 0.2434, 0.3714, 0.2653])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4727518558502197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2179, 0.2097, 0.2423, 0.3759, 0.2659]) \n",
      "Test Loss tensor([0.2143, 0.2051, 0.2393, 0.3698, 0.2646])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4724278450012207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2118, 0.2041, 0.2339, 0.3734, 0.2610]) \n",
      "Test Loss tensor([0.2078, 0.1990, 0.2349, 0.3719, 0.2632])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.47092723846435547 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2087, 0.1987, 0.2350, 0.3685, 0.2647]) \n",
      "Test Loss tensor([0.2028, 0.1934, 0.2297, 0.3677, 0.2620])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.47124743461608887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.2038, 0.1938, 0.2262, 0.3673, 0.2619]) \n",
      "Test Loss tensor([0.1965, 0.1875, 0.2242, 0.3661, 0.2625])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.4722864627838135 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1981, 0.1874, 0.2302, 0.3745, 0.2577]) \n",
      "Test Loss tensor([0.1896, 0.1807, 0.2179, 0.3644, 0.2590])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4724404811859131 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1893, 0.1792, 0.2133, 0.3689, 0.2542]) \n",
      "Test Loss tensor([0.1838, 0.1739, 0.2151, 0.3662, 0.2596])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4748208522796631 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1815, 0.1739, 0.2141, 0.3699, 0.2585]) \n",
      "Test Loss tensor([0.1768, 0.1668, 0.2074, 0.3630, 0.2556])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4715256690979004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1781, 0.1671, 0.2143, 0.3699, 0.2493]) \n",
      "Test Loss tensor([0.1697, 0.1597, 0.2033, 0.3649, 0.2577])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.472217321395874 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1705, 0.1576, 0.2016, 0.3624, 0.2562]) \n",
      "Test Loss tensor([0.1625, 0.1522, 0.1966, 0.3630, 0.2563])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4721050262451172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1607, 0.1513, 0.1936, 0.3572, 0.2511]) \n",
      "Test Loss tensor([0.1541, 0.1441, 0.1899, 0.3629, 0.2534])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4729797840118408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1549, 0.1432, 0.1877, 0.3625, 0.2570]) \n",
      "Test Loss tensor([0.1469, 0.1361, 0.1835, 0.3618, 0.2548])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4716629981994629 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1485, 0.1353, 0.1888, 0.3600, 0.2593]) \n",
      "Test Loss tensor([0.1375, 0.1274, 0.1761, 0.3577, 0.2541])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4707815647125244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1367, 0.1277, 0.1761, 0.3693, 0.2507]) \n",
      "Test Loss tensor([0.1299, 0.1184, 0.1713, 0.3620, 0.2552])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4796571731567383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1295, 0.1177, 0.1668, 0.3636, 0.2479]) \n",
      "Test Loss tensor([0.1208, 0.1100, 0.1628, 0.3591, 0.2558])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4734053611755371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1248, 0.1095, 0.1610, 0.3722, 0.2570]) \n",
      "Test Loss tensor([0.1119, 0.1006, 0.1565, 0.3621, 0.2558])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4747753143310547 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1108, 0.1016, 0.1621, 0.3670, 0.2575]) \n",
      "Test Loss tensor([0.1028, 0.0910, 0.1481, 0.3649, 0.2554])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.47063660621643066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.1022, 0.0920, 0.1464, 0.3654, 0.2535]) \n",
      "Test Loss tensor([0.0945, 0.0814, 0.1433, 0.3605, 0.2607])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.47238922119140625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0960, 0.0829, 0.1424, 0.3668, 0.2579]) \n",
      "Test Loss tensor([0.0863, 0.0740, 0.1371, 0.3664, 0.2654])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47053050994873047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0882, 0.0728, 0.1365, 0.3625, 0.2635]) \n",
      "Test Loss tensor([0.0780, 0.0649, 0.1311, 0.3679, 0.2668])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4737553596496582 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0803, 0.0661, 0.1312, 0.3656, 0.2627]) \n",
      "Test Loss tensor([0.0707, 0.0560, 0.1248, 0.3654, 0.2694])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 492 in 0.4724094867706299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0724, 0.0583, 0.1245, 0.3871, 0.2717]) \n",
      "Test Loss tensor([0.0637, 0.0500, 0.1181, 0.3702, 0.2745])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47247791290283203 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0611, 0.0514, 0.1205, 0.3690, 0.2804]) \n",
      "Test Loss tensor([0.0562, 0.0431, 0.1149, 0.3742, 0.2765])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4706456661224365 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0538, 0.0466, 0.1161, 0.3774, 0.2729]) \n",
      "Test Loss tensor([0.0516, 0.0379, 0.1137, 0.3795, 0.2825])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.47054028511047363 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0509, 0.0398, 0.1092, 0.3842, 0.2915]) \n",
      "Test Loss tensor([0.0463, 0.0331, 0.1103, 0.3798, 0.2865])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4723224639892578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0505, 0.0315, 0.1210, 0.3874, 0.2862]) \n",
      "Test Loss tensor([0.0437, 0.0288, 0.1070, 0.3861, 0.2934])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47295069694519043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0407, 0.0267, 0.1160, 0.3910, 0.2802]) \n",
      "Test Loss tensor([0.0410, 0.0262, 0.1084, 0.3926, 0.2977])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4728569984436035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0374, 0.0249, 0.1038, 0.4013, 0.2830]) \n",
      "Test Loss tensor([0.0382, 0.0246, 0.1073, 0.4012, 0.3010])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.47084975242614746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0398, 0.0212, 0.1094, 0.4164, 0.2838]) \n",
      "Test Loss tensor([0.0367, 0.0227, 0.1064, 0.4005, 0.3019])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.47144198417663574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0362, 0.0206, 0.1063, 0.4039, 0.3038]) \n",
      "Test Loss tensor([0.0364, 0.0217, 0.1069, 0.3997, 0.3101])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47136473655700684 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0357, 0.0212, 0.1078, 0.3922, 0.3081]) \n",
      "Test Loss tensor([0.0350, 0.0213, 0.1039, 0.4001, 0.3071])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.47022271156311035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0361, 0.0213, 0.1135, 0.4221, 0.2985]) \n",
      "Test Loss tensor([0.0352, 0.0202, 0.1046, 0.4009, 0.3096])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4721262454986572 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0400, 0.0192, 0.1117, 0.4132, 0.3063]) \n",
      "Test Loss tensor([0.0351, 0.0191, 0.1057, 0.4081, 0.3110])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4725217819213867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0299, 0.0184, 0.1064, 0.4176, 0.3019]) \n",
      "Test Loss tensor([0.0337, 0.0198, 0.1050, 0.4062, 0.3113])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.46924924850463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0364, 0.0165, 0.1079, 0.4051, 0.3200]) \n",
      "Test Loss tensor([0.0338, 0.0199, 0.1033, 0.4056, 0.3097])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4878525733947754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0346, 0.0163, 0.1076, 0.3977, 0.3119]) \n",
      "Test Loss tensor([0.0359, 0.0202, 0.1060, 0.4065, 0.3129])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4723975658416748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0333, 0.0187, 0.1075, 0.4055, 0.3152]) \n",
      "Test Loss tensor([0.0353, 0.0201, 0.1039, 0.4040, 0.3095])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4745597839355469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0361, 0.0226, 0.1029, 0.4120, 0.2998]) \n",
      "Test Loss tensor([0.0350, 0.0201, 0.1056, 0.4033, 0.3116])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4705085754394531 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0355, 0.0153, 0.1031, 0.4053, 0.3041]) \n",
      "Test Loss tensor([0.0353, 0.0199, 0.1037, 0.4012, 0.3104])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.47104907035827637 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0375, 0.0224, 0.1092, 0.4099, 0.2923]) \n",
      "Test Loss tensor([0.0355, 0.0220, 0.1053, 0.3980, 0.3058])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4698023796081543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0313, 0.0190, 0.1006, 0.4043, 0.3030]) \n",
      "Test Loss tensor([0.0377, 0.0222, 0.1090, 0.4035, 0.3057])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.472576379776001 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0341, 0.0204, 0.1036, 0.3902, 0.3222]) \n",
      "Test Loss tensor([0.0374, 0.0218, 0.1055, 0.4021, 0.2998])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.47153687477111816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0396, 0.0208, 0.1017, 0.4118, 0.2996]) \n",
      "Test Loss tensor([0.0375, 0.0237, 0.1065, 0.3971, 0.3013])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47292590141296387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0374, 0.0227, 0.1016, 0.4038, 0.3011]) \n",
      "Test Loss tensor([0.0397, 0.0244, 0.1067, 0.3964, 0.2994])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4734187126159668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0373, 0.0210, 0.1016, 0.3965, 0.2947]) \n",
      "Test Loss tensor([0.0397, 0.0267, 0.1071, 0.3926, 0.2995])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4753546714782715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0423, 0.0272, 0.1052, 0.3919, 0.2939]) \n",
      "Test Loss tensor([0.0399, 0.0268, 0.1069, 0.3881, 0.2977])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47399091720581055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0427, 0.0259, 0.1153, 0.3939, 0.2884]) \n",
      "Test Loss tensor([0.0417, 0.0276, 0.1075, 0.3893, 0.2928])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4722256660461426 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0409, 0.0265, 0.1087, 0.3804, 0.2849]) \n",
      "Test Loss tensor([0.0436, 0.0301, 0.1073, 0.3857, 0.2900])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47203874588012695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0445, 0.0296, 0.1126, 0.3972, 0.2840]) \n",
      "Test Loss tensor([0.0445, 0.0305, 0.1079, 0.3901, 0.2913])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4740118980407715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0423, 0.0277, 0.1045, 0.3946, 0.2738]) \n",
      "Test Loss tensor([0.0448, 0.0311, 0.1074, 0.3870, 0.2857])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47293519973754883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0430, 0.0304, 0.1066, 0.3895, 0.2915]) \n",
      "Test Loss tensor([0.0448, 0.0324, 0.1088, 0.3886, 0.2845])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47537994384765625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0478, 0.0326, 0.1101, 0.3985, 0.2848]) \n",
      "Test Loss tensor([0.0469, 0.0335, 0.1111, 0.3865, 0.2847])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.47212767601013184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0512, 0.0313, 0.1096, 0.3831, 0.2769]) \n",
      "Test Loss tensor([0.0483, 0.0343, 0.1113, 0.3838, 0.2841])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.46953248977661133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0490, 0.0320, 0.1062, 0.3951, 0.2780]) \n",
      "Test Loss tensor([0.0482, 0.0351, 0.1110, 0.3835, 0.2807])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4738340377807617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0488, 0.0332, 0.1088, 0.3932, 0.2817]) \n",
      "Test Loss tensor([0.0473, 0.0341, 0.1121, 0.3822, 0.2835])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47098207473754883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0491, 0.0342, 0.1113, 0.3835, 0.2857]) \n",
      "Test Loss tensor([0.0486, 0.0353, 0.1094, 0.3835, 0.2793])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.47320055961608887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0490, 0.0361, 0.1233, 0.3822, 0.2885]) \n",
      "Test Loss tensor([0.0489, 0.0349, 0.1112, 0.3838, 0.2818])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.47286391258239746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0437, 0.0347, 0.0982, 0.3966, 0.2759]) \n",
      "Test Loss tensor([0.0492, 0.0347, 0.1115, 0.3812, 0.2845])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47347187995910645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0451, 0.0338, 0.1013, 0.3877, 0.2770]) \n",
      "Test Loss tensor([0.0486, 0.0352, 0.1120, 0.3844, 0.2834])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4760270118713379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0488, 0.0358, 0.1119, 0.3803, 0.2845]) \n",
      "Test Loss tensor([0.0480, 0.0350, 0.1120, 0.3826, 0.2865])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4725346565246582 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0460, 0.0325, 0.1073, 0.3740, 0.2845]) \n",
      "Test Loss tensor([0.0482, 0.0343, 0.1107, 0.3814, 0.2831])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4720590114593506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0531, 0.0329, 0.1139, 0.3950, 0.2750]) \n",
      "Test Loss tensor([0.0462, 0.0328, 0.1096, 0.3827, 0.2827])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 656 in 0.4700019359588623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0448, 0.0342, 0.1095, 0.3798, 0.2838]) \n",
      "Test Loss tensor([0.0452, 0.0326, 0.1072, 0.3820, 0.2854])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4771273136138916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0504, 0.0355, 0.1141, 0.3899, 0.2852]) \n",
      "Test Loss tensor([0.0450, 0.0318, 0.1088, 0.3862, 0.2855])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4759328365325928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0456, 0.0323, 0.1165, 0.3977, 0.2818]) \n",
      "Test Loss tensor([0.0454, 0.0318, 0.1093, 0.3854, 0.2868])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47281956672668457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0465, 0.0344, 0.1149, 0.4067, 0.2700]) \n",
      "Test Loss tensor([0.0452, 0.0318, 0.1095, 0.3877, 0.2839])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47060275077819824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0449, 0.0299, 0.1083, 0.3778, 0.2842]) \n",
      "Test Loss tensor([0.0434, 0.0321, 0.1085, 0.3848, 0.2874])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4705822467803955 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0384, 0.0278, 0.1068, 0.3803, 0.2820]) \n",
      "Test Loss tensor([0.0430, 0.0311, 0.1104, 0.3857, 0.2864])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47377967834472656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0468, 0.0280, 0.1098, 0.3946, 0.2867]) \n",
      "Test Loss tensor([0.0446, 0.0309, 0.1095, 0.3862, 0.2907])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4743480682373047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0464, 0.0315, 0.1157, 0.3895, 0.2803]) \n",
      "Test Loss tensor([0.0418, 0.0294, 0.1070, 0.3863, 0.2881])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4719736576080322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0418, 0.0278, 0.1078, 0.3784, 0.2800]) \n",
      "Test Loss tensor([0.0419, 0.0292, 0.1083, 0.3872, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.47156286239624023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0432, 0.0314, 0.1089, 0.3862, 0.2879]) \n",
      "Test Loss tensor([0.0433, 0.0293, 0.1058, 0.3887, 0.2891])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.47228455543518066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0421, 0.0296, 0.1096, 0.3804, 0.2878]) \n",
      "Test Loss tensor([0.0415, 0.0293, 0.1051, 0.3880, 0.2903])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4740333557128906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0453, 0.0295, 0.1042, 0.3903, 0.2939]) \n",
      "Test Loss tensor([0.0418, 0.0289, 0.1057, 0.3877, 0.2927])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47243690490722656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0384, 0.0312, 0.1101, 0.3980, 0.2896]) \n",
      "Test Loss tensor([0.0416, 0.0299, 0.1058, 0.3940, 0.2881])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.47286081314086914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0410, 0.0281, 0.0957, 0.3680, 0.2841]) \n",
      "Test Loss tensor([0.0418, 0.0291, 0.1085, 0.3896, 0.2886])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.46927952766418457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0391, 0.0275, 0.1047, 0.3860, 0.2827]) \n",
      "Test Loss tensor([0.0419, 0.0294, 0.1066, 0.3877, 0.2912])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4879453182220459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0464, 0.0321, 0.1094, 0.3956, 0.2773]) \n",
      "Test Loss tensor([0.0414, 0.0296, 0.1045, 0.3840, 0.2945])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47231173515319824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0400, 0.0290, 0.1093, 0.3788, 0.2933]) \n",
      "Test Loss tensor([0.0424, 0.0286, 0.1085, 0.3866, 0.2894])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.475372314453125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0394, 0.0265, 0.1084, 0.3882, 0.2897]) \n",
      "Test Loss tensor([0.0427, 0.0299, 0.1086, 0.3886, 0.2898])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4710109233856201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0453, 0.0296, 0.1083, 0.3883, 0.2792]) \n",
      "Test Loss tensor([0.0416, 0.0293, 0.1061, 0.3841, 0.2899])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47262001037597656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0420, 0.0280, 0.1082, 0.3854, 0.2921]) \n",
      "Test Loss tensor([0.0420, 0.0296, 0.1062, 0.3843, 0.2912])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4707489013671875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0445, 0.0310, 0.1058, 0.3827, 0.2962]) \n",
      "Test Loss tensor([0.0430, 0.0296, 0.1078, 0.3919, 0.2870])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.47298526763916016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0393, 0.0292, 0.1098, 0.4045, 0.2777]) \n",
      "Test Loss tensor([0.0426, 0.0298, 0.1051, 0.3873, 0.2885])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4727811813354492 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0395, 0.0277, 0.1070, 0.3982, 0.2946]) \n",
      "Test Loss tensor([0.0434, 0.0303, 0.1076, 0.3889, 0.2877])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4726414680480957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0449, 0.0306, 0.1108, 0.3818, 0.2938]) \n",
      "Test Loss tensor([0.0433, 0.0298, 0.1091, 0.3862, 0.2898])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4729042053222656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0435, 0.0304, 0.1046, 0.3963, 0.2671]) \n",
      "Test Loss tensor([0.0449, 0.0309, 0.1081, 0.3868, 0.2875])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4728424549102783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0453, 0.0312, 0.1134, 0.3770, 0.2922]) \n",
      "Test Loss tensor([0.0420, 0.0297, 0.1062, 0.3811, 0.2863])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.47245264053344727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0392, 0.0286, 0.0997, 0.3829, 0.2818]) \n",
      "Test Loss tensor([0.0424, 0.0298, 0.1109, 0.3885, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47228169441223145 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0450, 0.0314, 0.1140, 0.3936, 0.2931]) \n",
      "Test Loss tensor([0.0432, 0.0299, 0.1077, 0.3827, 0.2877])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4741530418395996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0388, 0.0298, 0.0996, 0.3949, 0.2749]) \n",
      "Test Loss tensor([0.0447, 0.0317, 0.1079, 0.3846, 0.2896])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4722867012023926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0486, 0.0301, 0.1137, 0.3894, 0.2886]) \n",
      "Test Loss tensor([0.0437, 0.0308, 0.1113, 0.3905, 0.2850])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47399449348449707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0392, 0.0303, 0.1071, 0.3831, 0.2671]) \n",
      "Test Loss tensor([0.0443, 0.0313, 0.1069, 0.3847, 0.2856])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47177553176879883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0434, 0.0281, 0.1031, 0.4041, 0.2764]) \n",
      "Test Loss tensor([0.0441, 0.0316, 0.1089, 0.3844, 0.2866])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47329092025756836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0428, 0.0324, 0.1179, 0.4022, 0.2721]) \n",
      "Test Loss tensor([0.0438, 0.0308, 0.1068, 0.3773, 0.2907])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4715125560760498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0433, 0.0306, 0.1102, 0.3856, 0.2907]) \n",
      "Test Loss tensor([0.0427, 0.0307, 0.1076, 0.3865, 0.2879])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.47417211532592773 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0398, 0.0300, 0.1067, 0.3817, 0.2776]) \n",
      "Test Loss tensor([0.0422, 0.0297, 0.1061, 0.3841, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4729635715484619 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0396, 0.0323, 0.1069, 0.3794, 0.2822]) \n",
      "Test Loss tensor([0.0439, 0.0306, 0.1087, 0.3824, 0.2858])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.47267580032348633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0437, 0.0317, 0.1084, 0.3987, 0.2833]) \n",
      "Test Loss tensor([0.0430, 0.0306, 0.1083, 0.3861, 0.2862])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.47297167778015137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0422, 0.0313, 0.1130, 0.3887, 0.2811]) \n",
      "Test Loss tensor([0.0424, 0.0304, 0.1073, 0.3827, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47507214546203613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0426, 0.0298, 0.1083, 0.3796, 0.2814]) \n",
      "Test Loss tensor([0.0421, 0.0297, 0.1088, 0.3815, 0.2814])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4733750820159912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0404, 0.0289, 0.1057, 0.4035, 0.2770]) \n",
      "Test Loss tensor([0.0420, 0.0299, 0.1071, 0.3856, 0.2833])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5111982822418213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0425, 0.0324, 0.1062, 0.3921, 0.2719]) \n",
      "Test Loss tensor([0.0437, 0.0302, 0.1068, 0.3824, 0.2886])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 820 in 0.5048315525054932 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0412, 0.0304, 0.1088, 0.3971, 0.2729]) \n",
      "Test Loss tensor([0.0412, 0.0303, 0.1065, 0.3830, 0.2880])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4759833812713623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0404, 0.0296, 0.1028, 0.3901, 0.2747]) \n",
      "Test Loss tensor([0.0425, 0.0305, 0.1080, 0.3860, 0.2871])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47649240493774414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0418, 0.0290, 0.1060, 0.3857, 0.2797]) \n",
      "Test Loss tensor([0.0423, 0.0294, 0.1072, 0.3838, 0.2856])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47588419914245605 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0475, 0.0292, 0.1182, 0.3967, 0.2834]) \n",
      "Test Loss tensor([0.0408, 0.0297, 0.1042, 0.3843, 0.2891])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4737739562988281 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0420, 0.0319, 0.1074, 0.3912, 0.2670]) \n",
      "Test Loss tensor([0.0416, 0.0293, 0.1072, 0.3836, 0.2857])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.47597599029541016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0431, 0.0303, 0.1110, 0.3913, 0.2796]) \n",
      "Test Loss tensor([0.0419, 0.0288, 0.1080, 0.3879, 0.2861])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.47373151779174805 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0414, 0.0298, 0.1062, 0.3863, 0.2803]) \n",
      "Test Loss tensor([0.0423, 0.0300, 0.1060, 0.3806, 0.2913])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4744727611541748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0446, 0.0273, 0.1101, 0.3880, 0.2880]) \n",
      "Test Loss tensor([0.0413, 0.0299, 0.1066, 0.3832, 0.2908])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4900381565093994 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0452, 0.0311, 0.1063, 0.3766, 0.2842]) \n",
      "Test Loss tensor([0.0402, 0.0284, 0.1063, 0.3815, 0.2859])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4764525890350342 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0428, 0.0301, 0.1069, 0.3963, 0.2839]) \n",
      "Test Loss tensor([0.0413, 0.0291, 0.1074, 0.3859, 0.2837])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4773719310760498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0359, 0.0290, 0.0957, 0.3989, 0.2830]) \n",
      "Test Loss tensor([0.0417, 0.0309, 0.1062, 0.3858, 0.2837])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.476454496383667 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0394, 0.0279, 0.1027, 0.3717, 0.2804]) \n",
      "Test Loss tensor([0.0423, 0.0293, 0.1070, 0.3836, 0.2856])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47498393058776855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0409, 0.0304, 0.1140, 0.3963, 0.2905]) \n",
      "Test Loss tensor([0.0426, 0.0291, 0.1087, 0.3815, 0.2831])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47452569007873535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0371, 0.0318, 0.1050, 0.3891, 0.2864]) \n",
      "Test Loss tensor([0.0419, 0.0298, 0.1078, 0.3841, 0.2842])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4581780433654785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0334, 0.0217, 0.0839, 0.2958, 0.2112]) \n",
      "Test Loss tensor([0.0426, 0.0299, 0.1078, 0.3849, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5134470462799072 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0387, 0.0289, 0.1064, 0.3992, 0.2761]) \n",
      "Test Loss tensor([0.0420, 0.0307, 0.1072, 0.3833, 0.2880])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4924159049987793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0462, 0.0286, 0.1045, 0.3906, 0.2874]) \n",
      "Test Loss tensor([0.0427, 0.0299, 0.1069, 0.3846, 0.2832])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47264790534973145 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0397, 0.0290, 0.1018, 0.3856, 0.2810]) \n",
      "Test Loss tensor([0.0421, 0.0296, 0.1065, 0.3793, 0.2832])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47717952728271484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0442, 0.0303, 0.1114, 0.3728, 0.2800]) \n",
      "Test Loss tensor([0.0430, 0.0299, 0.1064, 0.3825, 0.2825])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.475419282913208 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0404, 0.0293, 0.1086, 0.3790, 0.2779]) \n",
      "Test Loss tensor([0.0421, 0.0303, 0.1085, 0.3852, 0.2858])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4774925708770752 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0416, 0.0304, 0.1089, 0.3837, 0.2803]) \n",
      "Test Loss tensor([0.0408, 0.0294, 0.1068, 0.3818, 0.2826])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47926807403564453 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0387, 0.0314, 0.1050, 0.3775, 0.2785]) \n",
      "Test Loss tensor([0.0420, 0.0311, 0.1066, 0.3844, 0.2839])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4764418601989746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0365, 0.0284, 0.1050, 0.3707, 0.2769]) \n",
      "Test Loss tensor([0.0421, 0.0301, 0.1060, 0.3843, 0.2847])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.47505903244018555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0420, 0.0290, 0.1091, 0.3891, 0.2717]) \n",
      "Test Loss tensor([0.0414, 0.0298, 0.1063, 0.3807, 0.2824])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4779355525970459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0442, 0.0296, 0.1117, 0.3902, 0.2806]) \n",
      "Test Loss tensor([0.0410, 0.0293, 0.1046, 0.3780, 0.2877])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4755280017852783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0405, 0.0284, 0.1085, 0.3819, 0.2761]) \n",
      "Test Loss tensor([0.0408, 0.0288, 0.1068, 0.3836, 0.2826])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4752061367034912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0380, 0.0319, 0.1051, 0.3840, 0.2777]) \n",
      "Test Loss tensor([0.0412, 0.0294, 0.1066, 0.3771, 0.2858])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47467780113220215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0420, 0.0282, 0.1018, 0.3798, 0.2860]) \n",
      "Test Loss tensor([0.0408, 0.0292, 0.1052, 0.3811, 0.2882])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47569870948791504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0428, 0.0272, 0.1087, 0.3904, 0.2712]) \n",
      "Test Loss tensor([0.0409, 0.0289, 0.1039, 0.3781, 0.2857])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4769868850708008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0435, 0.0291, 0.1086, 0.3786, 0.2786]) \n",
      "Test Loss tensor([0.0412, 0.0299, 0.1066, 0.3805, 0.2891])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4638645648956299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0443, 0.0289, 0.1095, 0.3869, 0.2658]) \n",
      "Test Loss tensor([0.0402, 0.0291, 0.1082, 0.3806, 0.2813])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4594848155975342 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0414, 0.0275, 0.1042, 0.3854, 0.2779]) \n",
      "Test Loss tensor([0.0403, 0.0296, 0.1079, 0.3773, 0.2864])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.46318793296813965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0362, 0.0295, 0.1083, 0.3752, 0.2861]) \n",
      "Test Loss tensor([0.0400, 0.0294, 0.1027, 0.3790, 0.2876])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4620528221130371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0387, 0.0286, 0.1115, 0.3825, 0.2729]) \n",
      "Test Loss tensor([0.0405, 0.0291, 0.1057, 0.3781, 0.2816])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4630775451660156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0416, 0.0268, 0.1083, 0.3894, 0.2852]) \n",
      "Test Loss tensor([0.0402, 0.0292, 0.1085, 0.3838, 0.2811])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4635646343231201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0343, 0.0248, 0.0954, 0.3931, 0.2831]) \n",
      "Test Loss tensor([0.0396, 0.0294, 0.1049, 0.3787, 0.2828])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.45981812477111816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0438, 0.0304, 0.1050, 0.3758, 0.2766]) \n",
      "Test Loss tensor([0.0412, 0.0287, 0.1064, 0.3799, 0.2809])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4656643867492676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0442, 0.0276, 0.1052, 0.3881, 0.2927]) \n",
      "Test Loss tensor([0.0405, 0.0291, 0.1067, 0.3750, 0.2801])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4615359306335449 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0411, 0.0284, 0.1100, 0.3935, 0.2699]) \n",
      "Test Loss tensor([0.0410, 0.0294, 0.1087, 0.3805, 0.2795])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.46290159225463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0431, 0.0293, 0.1085, 0.3780, 0.2669]) \n",
      "Test Loss tensor([0.0409, 0.0288, 0.1084, 0.3768, 0.2816])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.46314525604248047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0349, 0.0278, 0.1015, 0.3737, 0.2758]) \n",
      "Test Loss tensor([0.0412, 0.0294, 0.1078, 0.3757, 0.2794])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 104 in 0.4631514549255371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0356, 0.0286, 0.0980, 0.3773, 0.2684]) \n",
      "Test Loss tensor([0.0403, 0.0291, 0.1064, 0.3800, 0.2774])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.46649169921875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0438, 0.0300, 0.1093, 0.3764, 0.2796]) \n",
      "Test Loss tensor([0.0403, 0.0298, 0.1042, 0.3747, 0.2809])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.46802186965942383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0408, 0.0271, 0.1003, 0.3669, 0.2778]) \n",
      "Test Loss tensor([0.0408, 0.0278, 0.1049, 0.3774, 0.2807])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4713258743286133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0455, 0.0271, 0.1117, 0.3807, 0.2759]) \n",
      "Test Loss tensor([0.0391, 0.0289, 0.1067, 0.3788, 0.2806])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4695265293121338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0363, 0.0237, 0.1049, 0.3849, 0.2658]) \n",
      "Test Loss tensor([0.0387, 0.0281, 0.1060, 0.3742, 0.2820])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4700815677642822 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0361, 0.0285, 0.1113, 0.3883, 0.2797]) \n",
      "Test Loss tensor([0.0398, 0.0278, 0.1064, 0.3725, 0.2784])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4667682647705078 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0361, 0.0257, 0.0995, 0.3899, 0.2802]) \n",
      "Test Loss tensor([0.0383, 0.0268, 0.1030, 0.3753, 0.2748])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.46809983253479004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0354, 0.0256, 0.1095, 0.3820, 0.2875]) \n",
      "Test Loss tensor([0.0399, 0.0270, 0.1032, 0.3730, 0.2805])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.46770143508911133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0397, 0.0273, 0.1036, 0.3748, 0.2811]) \n",
      "Test Loss tensor([0.0384, 0.0282, 0.1063, 0.3746, 0.2781])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4696991443634033 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0373, 0.0290, 0.1094, 0.3894, 0.2774]) \n",
      "Test Loss tensor([0.0386, 0.0283, 0.1028, 0.3742, 0.2790])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.46671295166015625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0397, 0.0252, 0.1106, 0.3723, 0.2771]) \n",
      "Test Loss tensor([0.0396, 0.0266, 0.1034, 0.3723, 0.2768])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4686589241027832 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0376, 0.0255, 0.1028, 0.3928, 0.2702]) \n",
      "Test Loss tensor([0.0391, 0.0270, 0.1062, 0.3755, 0.2767])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4667234420776367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0414, 0.0305, 0.1076, 0.3879, 0.2737]) \n",
      "Test Loss tensor([0.0389, 0.0272, 0.1058, 0.3693, 0.2772])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4676237106323242 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0421, 0.0262, 0.1022, 0.3836, 0.2741]) \n",
      "Test Loss tensor([0.0382, 0.0277, 0.1038, 0.3685, 0.2799])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4681968688964844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0363, 0.0245, 0.1004, 0.3833, 0.2653]) \n",
      "Test Loss tensor([0.0385, 0.0269, 0.1035, 0.3687, 0.2796])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.46851658821105957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0379, 0.0280, 0.1065, 0.3720, 0.2755]) \n",
      "Test Loss tensor([0.0381, 0.0261, 0.1031, 0.3692, 0.2768])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4664268493652344 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0366, 0.0268, 0.1028, 0.3876, 0.2656]) \n",
      "Test Loss tensor([0.0376, 0.0263, 0.1061, 0.3708, 0.2739])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4714658260345459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0385, 0.0285, 0.1067, 0.3733, 0.2728]) \n",
      "Test Loss tensor([0.0381, 0.0258, 0.1048, 0.3697, 0.2705])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.46924424171447754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0373, 0.0258, 0.1080, 0.3665, 0.2760]) \n",
      "Test Loss tensor([0.0362, 0.0246, 0.1018, 0.3663, 0.2746])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4662294387817383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0343, 0.0235, 0.1044, 0.3734, 0.2658]) \n",
      "Test Loss tensor([0.0375, 0.0251, 0.1037, 0.3674, 0.2733])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.46819615364074707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0359, 0.0239, 0.1038, 0.3655, 0.2624]) \n",
      "Test Loss tensor([0.0373, 0.0260, 0.1050, 0.3660, 0.2725])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.46840667724609375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0331, 0.0250, 0.1000, 0.3530, 0.2696]) \n",
      "Test Loss tensor([0.0371, 0.0252, 0.1022, 0.3635, 0.2742])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4682598114013672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0340, 0.0234, 0.0970, 0.3612, 0.2677]) \n",
      "Test Loss tensor([0.0375, 0.0254, 0.1033, 0.3680, 0.2714])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.46712255477905273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0335, 0.0222, 0.1004, 0.3612, 0.2583]) \n",
      "Test Loss tensor([0.0366, 0.0245, 0.1003, 0.3639, 0.2686])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.465928316116333 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0357, 0.0249, 0.0979, 0.3599, 0.2675]) \n",
      "Test Loss tensor([0.0358, 0.0244, 0.1040, 0.3617, 0.2701])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4663066864013672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0371, 0.0230, 0.0977, 0.3590, 0.2637]) \n",
      "Test Loss tensor([0.0364, 0.0245, 0.1034, 0.3555, 0.2691])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4698493480682373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0336, 0.0261, 0.1053, 0.3772, 0.2697]) \n",
      "Test Loss tensor([0.0351, 0.0249, 0.1023, 0.3532, 0.2713])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.4668595790863037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0329, 0.0233, 0.1013, 0.3552, 0.2695]) \n",
      "Test Loss tensor([0.0353, 0.0244, 0.1019, 0.3583, 0.2651])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.46824049949645996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0329, 0.0235, 0.0958, 0.3628, 0.2558]) \n",
      "Test Loss tensor([0.0358, 0.0233, 0.1030, 0.3564, 0.2611])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.46709728240966797 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0374, 0.0243, 0.1059, 0.3559, 0.2620]) \n",
      "Test Loss tensor([0.0351, 0.0240, 0.1001, 0.3545, 0.2648])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4690275192260742 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0327, 0.0270, 0.1021, 0.3566, 0.2623]) \n",
      "Test Loss tensor([0.0333, 0.0233, 0.0996, 0.3511, 0.2607])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4817225933074951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0333, 0.0232, 0.1008, 0.3319, 0.2674]) \n",
      "Test Loss tensor([0.0343, 0.0234, 0.1024, 0.3482, 0.2599])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.48277854919433594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0352, 0.0261, 0.1015, 0.3538, 0.2481]) \n",
      "Test Loss tensor([0.0343, 0.0236, 0.1012, 0.3498, 0.2605])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4687337875366211 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0319, 0.0219, 0.1011, 0.3500, 0.2557]) \n",
      "Test Loss tensor([0.0323, 0.0232, 0.0982, 0.3437, 0.2571])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4701046943664551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0334, 0.0228, 0.0964, 0.3465, 0.2475]) \n",
      "Test Loss tensor([0.0331, 0.0225, 0.1015, 0.3451, 0.2524])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.46938300132751465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0328, 0.0215, 0.0971, 0.3361, 0.2559]) \n",
      "Test Loss tensor([0.0323, 0.0219, 0.0984, 0.3381, 0.2511])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4691901206970215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0321, 0.0203, 0.1054, 0.3478, 0.2320]) \n",
      "Test Loss tensor([0.0322, 0.0219, 0.0982, 0.3334, 0.2508])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.46706604957580566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0330, 0.0220, 0.1083, 0.3310, 0.2499]) \n",
      "Test Loss tensor([0.0316, 0.0215, 0.0972, 0.3346, 0.2472])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47871923446655273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0325, 0.0239, 0.0974, 0.3362, 0.2509]) \n",
      "Test Loss tensor([0.0306, 0.0213, 0.0976, 0.3258, 0.2453])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4663102626800537 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0340, 0.0214, 0.1031, 0.3293, 0.2415]) \n",
      "Test Loss tensor([0.0305, 0.0214, 0.0973, 0.3235, 0.2400])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.469921350479126 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0297, 0.0232, 0.0974, 0.3244, 0.2370]) \n",
      "Test Loss tensor([0.0297, 0.0199, 0.0948, 0.3219, 0.2345])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 268 in 0.4736173152923584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0252, 0.0182, 0.0927, 0.3260, 0.2186]) \n",
      "Test Loss tensor([0.0288, 0.0205, 0.0940, 0.3150, 0.2302])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.468111515045166 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0270, 0.0203, 0.0981, 0.3046, 0.2218]) \n",
      "Test Loss tensor([0.0281, 0.0196, 0.0940, 0.3048, 0.2240])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.46949052810668945 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0284, 0.0189, 0.0907, 0.3023, 0.2208]) \n",
      "Test Loss tensor([0.0273, 0.0188, 0.0927, 0.3052, 0.2186])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.46802210807800293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0267, 0.0205, 0.0955, 0.2999, 0.2158]) \n",
      "Test Loss tensor([0.0261, 0.0186, 0.0923, 0.2965, 0.2114])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.47199010848999023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0288, 0.0165, 0.0910, 0.3002, 0.2059]) \n",
      "Test Loss tensor([0.0252, 0.0184, 0.0923, 0.2921, 0.2043])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4678316116333008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0263, 0.0170, 0.0870, 0.2928, 0.2056]) \n",
      "Test Loss tensor([0.0238, 0.0173, 0.0879, 0.2835, 0.1962])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.4690666198730469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0243, 0.0163, 0.0875, 0.2860, 0.1910]) \n",
      "Test Loss tensor([0.0235, 0.0170, 0.0874, 0.2711, 0.1890])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4668874740600586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0267, 0.0192, 0.0856, 0.2759, 0.1854]) \n",
      "Test Loss tensor([0.0230, 0.0167, 0.0860, 0.2628, 0.1824])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47120189666748047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0218, 0.0178, 0.0898, 0.2703, 0.1829]) \n",
      "Test Loss tensor([0.0231, 0.0162, 0.0857, 0.2530, 0.1750])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.46665525436401367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0233, 0.0177, 0.0832, 0.2491, 0.1753]) \n",
      "Test Loss tensor([0.0214, 0.0165, 0.0819, 0.2412, 0.1693])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.46976804733276367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0194, 0.0158, 0.0794, 0.2454, 0.1641]) \n",
      "Test Loss tensor([0.0207, 0.0161, 0.0824, 0.2301, 0.1631])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4718778133392334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0228, 0.0159, 0.0816, 0.2412, 0.1609]) \n",
      "Test Loss tensor([0.0203, 0.0163, 0.0796, 0.2178, 0.1572])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4682276248931885 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0187, 0.0147, 0.0766, 0.2224, 0.1591]) \n",
      "Test Loss tensor([0.0192, 0.0161, 0.0764, 0.2126, 0.1533])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4681518077850342 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0177, 0.0136, 0.0788, 0.2137, 0.1514]) \n",
      "Test Loss tensor([0.0182, 0.0161, 0.0762, 0.2028, 0.1516])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4711759090423584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0179, 0.0164, 0.0791, 0.2044, 0.1508]) \n",
      "Test Loss tensor([0.0185, 0.0162, 0.0774, 0.1983, 0.1476])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.46747279167175293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0194, 0.0186, 0.0790, 0.2053, 0.1494]) \n",
      "Test Loss tensor([0.0175, 0.0161, 0.0759, 0.1914, 0.1464])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.46996140480041504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0176, 0.0175, 0.0777, 0.1909, 0.1450]) \n",
      "Test Loss tensor([0.0177, 0.0163, 0.0755, 0.1889, 0.1453])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.46779751777648926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0169, 0.0160, 0.0752, 0.1927, 0.1433]) \n",
      "Test Loss tensor([0.0174, 0.0168, 0.0731, 0.1845, 0.1445])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4702484607696533 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0180, 0.0169, 0.0721, 0.1850, 0.1368]) \n",
      "Test Loss tensor([0.0166, 0.0162, 0.0747, 0.1812, 0.1421])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4866149425506592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0186, 0.0169, 0.0780, 0.1837, 0.1395]) \n",
      "Test Loss tensor([0.0171, 0.0168, 0.0743, 0.1777, 0.1428])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.4714090824127197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0177, 0.0165, 0.0751, 0.1741, 0.1387]) \n",
      "Test Loss tensor([0.0170, 0.0162, 0.0750, 0.1786, 0.1385])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.47281980514526367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0184, 0.0170, 0.0787, 0.1806, 0.1415]) \n",
      "Test Loss tensor([0.0169, 0.0161, 0.0731, 0.1747, 0.1367])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.46862292289733887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0180, 0.0165, 0.0763, 0.1787, 0.1378]) \n",
      "Test Loss tensor([0.0170, 0.0159, 0.0722, 0.1725, 0.1359])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4740145206451416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0166, 0.0162, 0.0759, 0.1772, 0.1327]) \n",
      "Test Loss tensor([0.0164, 0.0159, 0.0733, 0.1704, 0.1347])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.46979355812072754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0173, 0.0144, 0.0750, 0.1746, 0.1353]) \n",
      "Test Loss tensor([0.0166, 0.0158, 0.0740, 0.1684, 0.1326])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4718472957611084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0157, 0.0156, 0.0748, 0.1734, 0.1301]) \n",
      "Test Loss tensor([0.0166, 0.0151, 0.0703, 0.1666, 0.1295])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.46900153160095215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0163, 0.0145, 0.0754, 0.1667, 0.1327]) \n",
      "Test Loss tensor([0.0164, 0.0152, 0.0716, 0.1654, 0.1284])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.47213077545166016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0168, 0.0171, 0.0733, 0.1632, 0.1281]) \n",
      "Test Loss tensor([0.0164, 0.0154, 0.0716, 0.1645, 0.1261])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.47011780738830566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0164, 0.0157, 0.0758, 0.1655, 0.1240]) \n",
      "Test Loss tensor([0.0159, 0.0153, 0.0719, 0.1608, 0.1249])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4694375991821289 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0134, 0.0148, 0.0699, 0.1610, 0.1233]) \n",
      "Test Loss tensor([0.0160, 0.0146, 0.0704, 0.1594, 0.1231])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4687964916229248 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0158, 0.0153, 0.0680, 0.1685, 0.1191]) \n",
      "Test Loss tensor([0.0160, 0.0144, 0.0708, 0.1567, 0.1217])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4719350337982178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0166, 0.0161, 0.0794, 0.1672, 0.1224]) \n",
      "Test Loss tensor([0.0156, 0.0152, 0.0717, 0.1568, 0.1208])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.46990370750427246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0149, 0.0134, 0.0732, 0.1631, 0.1196]) \n",
      "Test Loss tensor([0.0155, 0.0144, 0.0709, 0.1540, 0.1195])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4702441692352295 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0164, 0.0158, 0.0734, 0.1608, 0.1126]) \n",
      "Test Loss tensor([0.0159, 0.0137, 0.0719, 0.1532, 0.1171])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.469710111618042 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0174, 0.0144, 0.0729, 0.1575, 0.1154]) \n",
      "Test Loss tensor([0.0154, 0.0135, 0.0704, 0.1525, 0.1157])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.46777939796447754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0146, 0.0146, 0.0713, 0.1552, 0.1115]) \n",
      "Test Loss tensor([0.0158, 0.0140, 0.0707, 0.1506, 0.1144])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47052764892578125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0157, 0.0147, 0.0688, 0.1526, 0.1159]) \n",
      "Test Loss tensor([0.0154, 0.0139, 0.0686, 0.1469, 0.1121])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4689493179321289 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0146, 0.0133, 0.0691, 0.1467, 0.1117]) \n",
      "Test Loss tensor([0.0156, 0.0140, 0.0677, 0.1461, 0.1124])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4717895984649658 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0176, 0.0151, 0.0685, 0.1531, 0.1092]) \n",
      "Test Loss tensor([0.0151, 0.0139, 0.0690, 0.1426, 0.1118])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4665238857269287 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0134, 0.0150, 0.0663, 0.1473, 0.1120]) \n",
      "Test Loss tensor([0.0149, 0.0145, 0.0675, 0.1417, 0.1107])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.46982312202453613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0139, 0.0136, 0.0702, 0.1434, 0.1100]) \n",
      "Test Loss tensor([0.0149, 0.0137, 0.0668, 0.1410, 0.1076])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.4689610004425049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0167, 0.0158, 0.0731, 0.1421, 0.1072]) \n",
      "Test Loss tensor([0.0151, 0.0133, 0.0666, 0.1387, 0.1053])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4720151424407959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0158, 0.0129, 0.0687, 0.1405, 0.1033]) \n",
      "Test Loss tensor([0.0150, 0.0143, 0.0666, 0.1373, 0.1044])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.47539782524108887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0147, 0.0130, 0.0677, 0.1360, 0.1019]) \n",
      "Test Loss tensor([0.0144, 0.0135, 0.0678, 0.1339, 0.1013])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.4775412082672119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0144, 0.0139, 0.0716, 0.1419, 0.1038]) \n",
      "Test Loss tensor([0.0145, 0.0133, 0.0673, 0.1330, 0.1004])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4785733222961426 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0131, 0.0150, 0.0679, 0.1348, 0.0994]) \n",
      "Test Loss tensor([0.0144, 0.0132, 0.0660, 0.1307, 0.0988])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4737880229949951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0151, 0.0119, 0.0712, 0.1354, 0.0988]) \n",
      "Test Loss tensor([0.0143, 0.0136, 0.0677, 0.1273, 0.0976])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4731607437133789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0142, 0.0116, 0.0643, 0.1299, 0.0936]) \n",
      "Test Loss tensor([0.0142, 0.0134, 0.0654, 0.1254, 0.0950])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.47292089462280273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0141, 0.0134, 0.0650, 0.1241, 0.0977]) \n",
      "Test Loss tensor([0.0141, 0.0128, 0.0660, 0.1231, 0.0928])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47519731521606445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0146, 0.0131, 0.0734, 0.1287, 0.0923]) \n",
      "Test Loss tensor([0.0142, 0.0127, 0.0667, 0.1204, 0.0901])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4743773937225342 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0146, 0.0130, 0.0658, 0.1232, 0.0889]) \n",
      "Test Loss tensor([0.0142, 0.0131, 0.0676, 0.1185, 0.0882])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4760925769805908 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0166, 0.0158, 0.0708, 0.1216, 0.0905]) \n",
      "Test Loss tensor([0.0142, 0.0128, 0.0643, 0.1147, 0.0863])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.47565388679504395 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0139, 0.0143, 0.0707, 0.1174, 0.0848]) \n",
      "Test Loss tensor([0.0144, 0.0130, 0.0655, 0.1118, 0.0829])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5094096660614014 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0153, 0.0128, 0.0609, 0.1109, 0.0854]) \n",
      "Test Loss tensor([0.0139, 0.0130, 0.0664, 0.1099, 0.0794])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4869053363800049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0128, 0.0120, 0.0619, 0.1100, 0.0815]) \n",
      "Test Loss tensor([0.0141, 0.0131, 0.0665, 0.1060, 0.0774])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.47162604331970215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0126, 0.0125, 0.0711, 0.1056, 0.0773]) \n",
      "Test Loss tensor([0.0134, 0.0127, 0.0660, 0.1029, 0.0759])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4731414318084717 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0122, 0.0130, 0.0640, 0.1025, 0.0754]) \n",
      "Test Loss tensor([0.0139, 0.0130, 0.0670, 0.1001, 0.0740])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.47254514694213867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0144, 0.0137, 0.0668, 0.1017, 0.0774]) \n",
      "Test Loss tensor([0.0130, 0.0131, 0.0646, 0.0954, 0.0720])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.47008275985717773 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0123, 0.0152, 0.0651, 0.0967, 0.0742]) \n",
      "Test Loss tensor([0.0127, 0.0131, 0.0655, 0.0929, 0.0686])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.47233152389526367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0129, 0.0114, 0.0605, 0.0906, 0.0698]) \n",
      "Test Loss tensor([0.0130, 0.0127, 0.0639, 0.0879, 0.0682])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4700164794921875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0144, 0.0136, 0.0669, 0.0872, 0.0682]) \n",
      "Test Loss tensor([0.0130, 0.0136, 0.0631, 0.0829, 0.0648])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4891469478607178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0143, 0.0139, 0.0680, 0.0881, 0.0686]) \n",
      "Test Loss tensor([0.0130, 0.0135, 0.0645, 0.0795, 0.0633])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4861283302307129 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0131, 0.0125, 0.0665, 0.0876, 0.0609]) \n",
      "Test Loss tensor([0.0126, 0.0141, 0.0642, 0.0763, 0.0612])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.46991515159606934 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0124, 0.0135, 0.0660, 0.0739, 0.0651]) \n",
      "Test Loss tensor([0.0123, 0.0128, 0.0644, 0.0734, 0.0599])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4732167720794678 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0141, 0.0145, 0.0694, 0.0755, 0.0585]) \n",
      "Test Loss tensor([0.0126, 0.0135, 0.0630, 0.0680, 0.0578])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4718034267425537 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0124, 0.0126, 0.0601, 0.0654, 0.0578]) \n",
      "Test Loss tensor([0.0122, 0.0132, 0.0636, 0.0655, 0.0566])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.47178173065185547 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0094, 0.0135, 0.0658, 0.0639, 0.0536]) \n",
      "Test Loss tensor([0.0119, 0.0134, 0.0631, 0.0615, 0.0549])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.47458481788635254 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0118, 0.0138, 0.0709, 0.0619, 0.0552]) \n",
      "Test Loss tensor([0.0116, 0.0130, 0.0646, 0.0592, 0.0538])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4720578193664551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0140, 0.0133, 0.0638, 0.0607, 0.0554]) \n",
      "Test Loss tensor([0.0120, 0.0143, 0.0623, 0.0556, 0.0524])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47216200828552246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0119, 0.0155, 0.0704, 0.0571, 0.0514]) \n",
      "Test Loss tensor([0.0119, 0.0130, 0.0632, 0.0520, 0.0513])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.47290468215942383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0135, 0.0167, 0.0659, 0.0553, 0.0548]) \n",
      "Test Loss tensor([0.0114, 0.0134, 0.0626, 0.0493, 0.0508])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4710273742675781 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0111, 0.0157, 0.0623, 0.0499, 0.0519]) \n",
      "Test Loss tensor([0.0115, 0.0136, 0.0639, 0.0469, 0.0506])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.46969151496887207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0119, 0.0145, 0.0573, 0.0467, 0.0461]) \n",
      "Test Loss tensor([0.0116, 0.0143, 0.0616, 0.0438, 0.0507])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4706597328186035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0096, 0.0133, 0.0614, 0.0408, 0.0487]) \n",
      "Test Loss tensor([0.0121, 0.0133, 0.0601, 0.0412, 0.0502])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.4742603302001953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0137, 0.0125, 0.0618, 0.0399, 0.0465]) \n",
      "Test Loss tensor([0.0111, 0.0141, 0.0605, 0.0405, 0.0504])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4741783142089844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0130, 0.0164, 0.0629, 0.0414, 0.0540]) \n",
      "Test Loss tensor([0.0109, 0.0140, 0.0631, 0.0381, 0.0506])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4735884666442871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0137, 0.0108, 0.0618, 0.0385, 0.0505]) \n",
      "Test Loss tensor([0.0114, 0.0144, 0.0614, 0.0369, 0.0506])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.47026515007019043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0113, 0.0134, 0.0627, 0.0382, 0.0519]) \n",
      "Test Loss tensor([0.0106, 0.0150, 0.0624, 0.0359, 0.0506])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.47365546226501465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0129, 0.0155, 0.0635, 0.0370, 0.0466]) \n",
      "Test Loss tensor([0.0115, 0.0152, 0.0609, 0.0334, 0.0494])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.47026872634887695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0108, 0.0145, 0.0595, 0.0340, 0.0501]) \n",
      "Test Loss tensor([0.0109, 0.0146, 0.0617, 0.0344, 0.0503])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47470641136169434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0103, 0.0173, 0.0631, 0.0336, 0.0503]) \n",
      "Test Loss tensor([0.0114, 0.0148, 0.0604, 0.0318, 0.0514])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.47153782844543457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0123, 0.0155, 0.0681, 0.0339, 0.0511]) \n",
      "Test Loss tensor([0.0114, 0.0146, 0.0605, 0.0315, 0.0517])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 596 in 0.47241878509521484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0106, 0.0175, 0.0584, 0.0322, 0.0525]) \n",
      "Test Loss tensor([0.0108, 0.0134, 0.0626, 0.0311, 0.0519])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.47109007835388184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0110, 0.0162, 0.0583, 0.0319, 0.0528]) \n",
      "Test Loss tensor([0.0112, 0.0145, 0.0606, 0.0308, 0.0526])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.475632905960083 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0127, 0.0133, 0.0658, 0.0299, 0.0496]) \n",
      "Test Loss tensor([0.0110, 0.0143, 0.0599, 0.0301, 0.0522])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47339534759521484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0112, 0.0166, 0.0603, 0.0295, 0.0533]) \n",
      "Test Loss tensor([0.0110, 0.0144, 0.0606, 0.0292, 0.0537])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4723362922668457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0132, 0.0188, 0.0654, 0.0312, 0.0532]) \n",
      "Test Loss tensor([0.0113, 0.0147, 0.0610, 0.0291, 0.0536])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4722292423248291 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0119, 0.0152, 0.0538, 0.0304, 0.0517]) \n",
      "Test Loss tensor([0.0105, 0.0146, 0.0598, 0.0288, 0.0528])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4735252857208252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0099, 0.0143, 0.0615, 0.0255, 0.0524]) \n",
      "Test Loss tensor([0.0111, 0.0153, 0.0582, 0.0287, 0.0526])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.47348523139953613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0101, 0.0160, 0.0623, 0.0286, 0.0504]) \n",
      "Test Loss tensor([0.0105, 0.0152, 0.0571, 0.0285, 0.0530])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47151851654052734 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0120, 0.0156, 0.0598, 0.0269, 0.0534]) \n",
      "Test Loss tensor([0.0103, 0.0155, 0.0596, 0.0288, 0.0527])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.47042036056518555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0092, 0.0190, 0.0596, 0.0276, 0.0559]) \n",
      "Test Loss tensor([0.0105, 0.0158, 0.0602, 0.0284, 0.0525])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4700953960418701 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0102, 0.0106, 0.0527, 0.0295, 0.0525]) \n",
      "Test Loss tensor([0.0114, 0.0143, 0.0592, 0.0292, 0.0532])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.47191834449768066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0076, 0.0146, 0.0602, 0.0331, 0.0532]) \n",
      "Test Loss tensor([0.0101, 0.0139, 0.0578, 0.0288, 0.0523])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.47278690338134766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0119, 0.0157, 0.0610, 0.0284, 0.0520]) \n",
      "Test Loss tensor([0.0112, 0.0141, 0.0571, 0.0279, 0.0530])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47314953804016113 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0109, 0.0172, 0.0550, 0.0297, 0.0520]) \n",
      "Test Loss tensor([0.0110, 0.0143, 0.0586, 0.0280, 0.0527])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4700629711151123 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0108, 0.0142, 0.0554, 0.0306, 0.0517]) \n",
      "Test Loss tensor([0.0106, 0.0133, 0.0601, 0.0267, 0.0514])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4725487232208252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0139, 0.0162, 0.0637, 0.0296, 0.0553]) \n",
      "Test Loss tensor([0.0108, 0.0153, 0.0585, 0.0268, 0.0525])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.46936893463134766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0131, 0.0147, 0.0603, 0.0260, 0.0511]) \n",
      "Test Loss tensor([0.0110, 0.0145, 0.0563, 0.0272, 0.0516])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.47247743606567383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0099, 0.0105, 0.0586, 0.0316, 0.0547]) \n",
      "Test Loss tensor([0.0110, 0.0143, 0.0569, 0.0274, 0.0519])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47169947624206543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0131, 0.0139, 0.0572, 0.0265, 0.0516]) \n",
      "Test Loss tensor([0.0105, 0.0134, 0.0560, 0.0281, 0.0509])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.47116780281066895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0106, 0.0149, 0.0600, 0.0309, 0.0515]) \n",
      "Test Loss tensor([0.0104, 0.0143, 0.0568, 0.0279, 0.0516])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4715750217437744 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0100, 0.0164, 0.0588, 0.0308, 0.0533]) \n",
      "Test Loss tensor([0.0106, 0.0143, 0.0566, 0.0291, 0.0505])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47969722747802734 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0103, 0.0137, 0.0576, 0.0281, 0.0503]) \n",
      "Test Loss tensor([0.0107, 0.0141, 0.0596, 0.0289, 0.0513])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.4753420352935791 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0126, 0.0160, 0.0562, 0.0303, 0.0523]) \n",
      "Test Loss tensor([0.0104, 0.0132, 0.0569, 0.0276, 0.0504])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4725053310394287 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0125, 0.0131, 0.0546, 0.0305, 0.0493]) \n",
      "Test Loss tensor([0.0108, 0.0130, 0.0554, 0.0275, 0.0496])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4720954895019531 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0125, 0.0139, 0.0528, 0.0306, 0.0481]) \n",
      "Test Loss tensor([0.0107, 0.0138, 0.0556, 0.0284, 0.0502])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4712662696838379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0100, 0.0152, 0.0615, 0.0301, 0.0512]) \n",
      "Test Loss tensor([0.0102, 0.0142, 0.0562, 0.0283, 0.0500])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4715290069580078 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0093, 0.0135, 0.0529, 0.0290, 0.0497]) \n",
      "Test Loss tensor([0.0106, 0.0142, 0.0567, 0.0287, 0.0499])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.47035694122314453 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0111, 0.0157, 0.0606, 0.0302, 0.0501]) \n",
      "Test Loss tensor([0.0100, 0.0129, 0.0550, 0.0286, 0.0495])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4704113006591797 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0111, 0.0138, 0.0503, 0.0284, 0.0509]) \n",
      "Test Loss tensor([0.0103, 0.0137, 0.0532, 0.0284, 0.0494])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.4730672836303711 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0102, 0.0136, 0.0530, 0.0279, 0.0451]) \n",
      "Test Loss tensor([0.0104, 0.0134, 0.0556, 0.0286, 0.0500])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.476604700088501 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0100, 0.0128, 0.0497, 0.0287, 0.0469]) \n",
      "Test Loss tensor([0.0102, 0.0125, 0.0547, 0.0284, 0.0485])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.47012782096862793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0102, 0.0158, 0.0516, 0.0287, 0.0501]) \n",
      "Test Loss tensor([0.0101, 0.0135, 0.0561, 0.0288, 0.0490])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47215723991394043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0088, 0.0138, 0.0573, 0.0304, 0.0477]) \n",
      "Test Loss tensor([0.0107, 0.0133, 0.0535, 0.0286, 0.0477])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.46855926513671875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0098, 0.0121, 0.0516, 0.0279, 0.0469]) \n",
      "Test Loss tensor([0.0105, 0.0128, 0.0547, 0.0274, 0.0493])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4740746021270752 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0132, 0.0118, 0.0559, 0.0299, 0.0505]) \n",
      "Test Loss tensor([0.0104, 0.0125, 0.0530, 0.0278, 0.0486])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4706242084503174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0126, 0.0124, 0.0528, 0.0271, 0.0492]) \n",
      "Test Loss tensor([0.0107, 0.0125, 0.0548, 0.0286, 0.0484])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4703369140625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0095, 0.0138, 0.0504, 0.0295, 0.0481]) \n",
      "Test Loss tensor([0.0100, 0.0125, 0.0535, 0.0282, 0.0477])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.47079968452453613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0101, 0.0129, 0.0545, 0.0264, 0.0470]) \n",
      "Test Loss tensor([0.0098, 0.0123, 0.0533, 0.0275, 0.0485])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4714927673339844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0100, 0.0142, 0.0521, 0.0277, 0.0493]) \n",
      "Test Loss tensor([0.0098, 0.0126, 0.0534, 0.0277, 0.0484])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.47284889221191406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0120, 0.0128, 0.0572, 0.0302, 0.0472]) \n",
      "Test Loss tensor([0.0105, 0.0132, 0.0541, 0.0285, 0.0483])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4725198745727539 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0100, 0.0116, 0.0517, 0.0276, 0.0498]) \n",
      "Test Loss tensor([0.0102, 0.0128, 0.0520, 0.0283, 0.0479])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 760 in 0.46939945220947266 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0093, 0.0116, 0.0567, 0.0278, 0.0452]) \n",
      "Test Loss tensor([0.0096, 0.0127, 0.0535, 0.0275, 0.0476])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.47106432914733887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0093, 0.0121, 0.0550, 0.0291, 0.0489]) \n",
      "Test Loss tensor([0.0095, 0.0126, 0.0534, 0.0262, 0.0481])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4688243865966797 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0115, 0.0133, 0.0545, 0.0277, 0.0474]) \n",
      "Test Loss tensor([0.0098, 0.0122, 0.0524, 0.0274, 0.0478])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4704890251159668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0109, 0.0148, 0.0530, 0.0254, 0.0484]) \n",
      "Test Loss tensor([0.0100, 0.0128, 0.0534, 0.0274, 0.0472])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47129273414611816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0082, 0.0130, 0.0566, 0.0275, 0.0493]) \n",
      "Test Loss tensor([0.0096, 0.0119, 0.0523, 0.0275, 0.0479])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.468860387802124 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0087, 0.0124, 0.0522, 0.0289, 0.0491]) \n",
      "Test Loss tensor([0.0100, 0.0124, 0.0527, 0.0270, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4709467887878418 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0110, 0.0138, 0.0522, 0.0267, 0.0480]) \n",
      "Test Loss tensor([0.0097, 0.0121, 0.0544, 0.0275, 0.0474])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47176218032836914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0122, 0.0101, 0.0548, 0.0277, 0.0449]) \n",
      "Test Loss tensor([0.0094, 0.0121, 0.0532, 0.0274, 0.0474])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.4729917049407959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0086, 0.0127, 0.0482, 0.0247, 0.0459]) \n",
      "Test Loss tensor([0.0095, 0.0123, 0.0527, 0.0262, 0.0475])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.4698936939239502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0092, 0.0122, 0.0490, 0.0251, 0.0466]) \n",
      "Test Loss tensor([0.0092, 0.0121, 0.0525, 0.0264, 0.0475])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.47423791885375977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0108, 0.0153, 0.0510, 0.0220, 0.0464]) \n",
      "Test Loss tensor([0.0092, 0.0120, 0.0539, 0.0257, 0.0472])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4763944149017334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0099, 0.0120, 0.0525, 0.0232, 0.0456]) \n",
      "Test Loss tensor([0.0094, 0.0127, 0.0531, 0.0249, 0.0475])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.47107386589050293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0088, 0.0131, 0.0506, 0.0246, 0.0477]) \n",
      "Test Loss tensor([0.0099, 0.0115, 0.0531, 0.0255, 0.0473])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47194910049438477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0113, 0.0107, 0.0520, 0.0271, 0.0494]) \n",
      "Test Loss tensor([0.0097, 0.0114, 0.0515, 0.0262, 0.0471])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47333288192749023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0096, 0.0137, 0.0557, 0.0233, 0.0484]) \n",
      "Test Loss tensor([0.0092, 0.0119, 0.0537, 0.0252, 0.0476])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47215771675109863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0086, 0.0124, 0.0521, 0.0217, 0.0453]) \n",
      "Test Loss tensor([0.0093, 0.0120, 0.0544, 0.0254, 0.0476])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4714367389678955 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0105, 0.0105, 0.0485, 0.0250, 0.0476]) \n",
      "Test Loss tensor([0.0089, 0.0125, 0.0535, 0.0261, 0.0472])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47419166564941406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0111, 0.0118, 0.0558, 0.0247, 0.0488]) \n",
      "Test Loss tensor([0.0086, 0.0115, 0.0510, 0.0257, 0.0471])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4725968837738037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0095, 0.0109, 0.0507, 0.0244, 0.0485]) \n",
      "Test Loss tensor([0.0085, 0.0128, 0.0532, 0.0263, 0.0481])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.46971559524536133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0075, 0.0112, 0.0601, 0.0279, 0.0464]) \n",
      "Test Loss tensor([0.0084, 0.0118, 0.0529, 0.0248, 0.0478])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.47337913513183594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0096, 0.0122, 0.0506, 0.0240, 0.0472]) \n",
      "Test Loss tensor([0.0086, 0.0113, 0.0510, 0.0246, 0.0477])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.470379114151001 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0076, 0.0091, 0.0527, 0.0223, 0.0485]) \n",
      "Test Loss tensor([0.0086, 0.0116, 0.0513, 0.0245, 0.0478])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.478198766708374 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0084, 0.0143, 0.0536, 0.0248, 0.0467]) \n",
      "Test Loss tensor([0.0084, 0.0112, 0.0521, 0.0252, 0.0473])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.47946929931640625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0079, 0.0129, 0.0497, 0.0243, 0.0469]) \n",
      "Test Loss tensor([0.0084, 0.0121, 0.0508, 0.0246, 0.0472])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47260284423828125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0083, 0.0125, 0.0481, 0.0235, 0.0476]) \n",
      "Test Loss tensor([0.0078, 0.0107, 0.0523, 0.0244, 0.0473])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47369885444641113 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0093, 0.0112, 0.0483, 0.0270, 0.0488]) \n",
      "Test Loss tensor([0.0081, 0.0116, 0.0507, 0.0241, 0.0471])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4688894748687744 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0081, 0.0126, 0.0547, 0.0227, 0.0428]) \n",
      "Test Loss tensor([0.0076, 0.0113, 0.0510, 0.0232, 0.0471])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.47487592697143555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0064, 0.0109, 0.0523, 0.0245, 0.0497]) \n",
      "Test Loss tensor([0.0072, 0.0122, 0.0509, 0.0234, 0.0473])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.472304105758667 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0135, 0.0476, 0.0227, 0.0484]) \n",
      "Test Loss tensor([0.0073, 0.0111, 0.0502, 0.0237, 0.0464])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4552762508392334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0066, 0.0393, 0.0177, 0.0344]) \n",
      "Test Loss tensor([0.0070, 0.0113, 0.0512, 0.0229, 0.0468])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.506981372833252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0074, 0.0127, 0.0467, 0.0198, 0.0498]) \n",
      "Test Loss tensor([0.0074, 0.0115, 0.0507, 0.0245, 0.0471])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4714033603668213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0082, 0.0123, 0.0544, 0.0245, 0.0503]) \n",
      "Test Loss tensor([0.0069, 0.0104, 0.0509, 0.0236, 0.0474])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4685971736907959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0101, 0.0482, 0.0245, 0.0461]) \n",
      "Test Loss tensor([0.0073, 0.0109, 0.0507, 0.0230, 0.0466])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.47300124168395996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0079, 0.0106, 0.0501, 0.0234, 0.0470]) \n",
      "Test Loss tensor([0.0074, 0.0110, 0.0517, 0.0240, 0.0468])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4684743881225586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0075, 0.0146, 0.0480, 0.0239, 0.0468]) \n",
      "Test Loss tensor([0.0068, 0.0104, 0.0515, 0.0237, 0.0470])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47307705879211426 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0072, 0.0119, 0.0587, 0.0241, 0.0430]) \n",
      "Test Loss tensor([0.0071, 0.0115, 0.0520, 0.0237, 0.0464])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4705991744995117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0103, 0.0514, 0.0250, 0.0454]) \n",
      "Test Loss tensor([0.0073, 0.0104, 0.0504, 0.0247, 0.0470])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.47223591804504395 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0077, 0.0486, 0.0239, 0.0480]) \n",
      "Test Loss tensor([0.0068, 0.0114, 0.0510, 0.0236, 0.0462])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4697556495666504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0078, 0.0084, 0.0469, 0.0203, 0.0437]) \n",
      "Test Loss tensor([0.0069, 0.0107, 0.0505, 0.0233, 0.0474])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4707014560699463 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0111, 0.0515, 0.0205, 0.0491]) \n",
      "Test Loss tensor([0.0070, 0.0098, 0.0495, 0.0230, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.46999406814575195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0128, 0.0464, 0.0200, 0.0465]) \n",
      "Test Loss tensor([0.0071, 0.0106, 0.0505, 0.0233, 0.0463])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 44 in 0.4716928005218506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0095, 0.0511, 0.0227, 0.0457]) \n",
      "Test Loss tensor([0.0072, 0.0116, 0.0501, 0.0233, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47220849990844727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0077, 0.0107, 0.0570, 0.0245, 0.0486]) \n",
      "Test Loss tensor([0.0068, 0.0106, 0.0477, 0.0230, 0.0462])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47149062156677246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0081, 0.0081, 0.0474, 0.0255, 0.0477]) \n",
      "Test Loss tensor([0.0066, 0.0107, 0.0528, 0.0237, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.46984100341796875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0130, 0.0467, 0.0240, 0.0484]) \n",
      "Test Loss tensor([0.0067, 0.0108, 0.0513, 0.0231, 0.0458])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.47228431701660156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0102, 0.0494, 0.0228, 0.0472]) \n",
      "Test Loss tensor([0.0068, 0.0109, 0.0492, 0.0226, 0.0467])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.47081637382507324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0091, 0.0505, 0.0274, 0.0458]) \n",
      "Test Loss tensor([0.0070, 0.0114, 0.0489, 0.0227, 0.0459])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.47038698196411133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0074, 0.0107, 0.0494, 0.0268, 0.0468]) \n",
      "Test Loss tensor([0.0067, 0.0102, 0.0502, 0.0228, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4697601795196533 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0114, 0.0480, 0.0245, 0.0448]) \n",
      "Test Loss tensor([0.0067, 0.0098, 0.0492, 0.0219, 0.0459])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4700288772583008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0104, 0.0518, 0.0227, 0.0472]) \n",
      "Test Loss tensor([0.0066, 0.0112, 0.0498, 0.0220, 0.0469])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4709312915802002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0078, 0.0141, 0.0524, 0.0240, 0.0479]) \n",
      "Test Loss tensor([0.0063, 0.0102, 0.0481, 0.0221, 0.0468])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4698643684387207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0075, 0.0122, 0.0482, 0.0207, 0.0482]) \n",
      "Test Loss tensor([0.0066, 0.0108, 0.0503, 0.0224, 0.0463])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.47178101539611816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0074, 0.0103, 0.0489, 0.0220, 0.0476]) \n",
      "Test Loss tensor([0.0068, 0.0100, 0.0495, 0.0226, 0.0465])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4694638252258301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0121, 0.0507, 0.0221, 0.0470]) \n",
      "Test Loss tensor([0.0065, 0.0107, 0.0472, 0.0222, 0.0451])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4696986675262451 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0078, 0.0131, 0.0453, 0.0243, 0.0436]) \n",
      "Test Loss tensor([0.0067, 0.0097, 0.0471, 0.0219, 0.0457])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4703643321990967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0073, 0.0125, 0.0503, 0.0254, 0.0464]) \n",
      "Test Loss tensor([0.0064, 0.0107, 0.0488, 0.0217, 0.0458])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.46996617317199707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0087, 0.0116, 0.0496, 0.0208, 0.0437]) \n",
      "Test Loss tensor([0.0064, 0.0107, 0.0485, 0.0220, 0.0457])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4697129726409912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0071, 0.0126, 0.0500, 0.0188, 0.0434]) \n",
      "Test Loss tensor([0.0063, 0.0099, 0.0476, 0.0227, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4687676429748535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0112, 0.0502, 0.0272, 0.0467]) \n",
      "Test Loss tensor([0.0066, 0.0108, 0.0491, 0.0220, 0.0455])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.47090601921081543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0083, 0.0101, 0.0500, 0.0220, 0.0460]) \n",
      "Test Loss tensor([0.0066, 0.0112, 0.0498, 0.0220, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.47448229789733887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0108, 0.0497, 0.0216, 0.0471]) \n",
      "Test Loss tensor([0.0070, 0.0107, 0.0488, 0.0231, 0.0460])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.47006702423095703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0117, 0.0473, 0.0222, 0.0421]) \n",
      "Test Loss tensor([0.0068, 0.0102, 0.0494, 0.0229, 0.0447])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.4701223373413086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0084, 0.0096, 0.0502, 0.0242, 0.0444]) \n",
      "Test Loss tensor([0.0062, 0.0097, 0.0493, 0.0232, 0.0439])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4719276428222656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0103, 0.0521, 0.0231, 0.0442]) \n",
      "Test Loss tensor([0.0065, 0.0100, 0.0481, 0.0238, 0.0450])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.47342467308044434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0079, 0.0112, 0.0567, 0.0221, 0.0450]) \n",
      "Test Loss tensor([0.0064, 0.0106, 0.0496, 0.0229, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4866771697998047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0079, 0.0091, 0.0486, 0.0210, 0.0457]) \n",
      "Test Loss tensor([0.0066, 0.0098, 0.0483, 0.0221, 0.0450])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5155255794525146 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0073, 0.0124, 0.0510, 0.0222, 0.0459]) \n",
      "Test Loss tensor([0.0067, 0.0101, 0.0483, 0.0231, 0.0444])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4707169532775879 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0076, 0.0456, 0.0220, 0.0449]) \n",
      "Test Loss tensor([0.0059, 0.0102, 0.0483, 0.0223, 0.0449])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4695467948913574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0091, 0.0449, 0.0238, 0.0446]) \n",
      "Test Loss tensor([0.0064, 0.0105, 0.0470, 0.0225, 0.0450])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4717411994934082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0112, 0.0428, 0.0213, 0.0437]) \n",
      "Test Loss tensor([0.0065, 0.0094, 0.0478, 0.0232, 0.0445])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4680311679840088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0081, 0.0110, 0.0442, 0.0228, 0.0444]) \n",
      "Test Loss tensor([0.0061, 0.0096, 0.0483, 0.0227, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4739999771118164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0098, 0.0429, 0.0205, 0.0464]) \n",
      "Test Loss tensor([0.0064, 0.0104, 0.0475, 0.0217, 0.0445])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4783909320831299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0119, 0.0483, 0.0231, 0.0416]) \n",
      "Test Loss tensor([0.0062, 0.0103, 0.0483, 0.0230, 0.0456])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47730469703674316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0077, 0.0404, 0.0211, 0.0464]) \n",
      "Test Loss tensor([0.0063, 0.0106, 0.0477, 0.0233, 0.0450])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.48562073707580566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0122, 0.0516, 0.0235, 0.0456]) \n",
      "Test Loss tensor([0.0061, 0.0102, 0.0474, 0.0221, 0.0443])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.4752848148345947 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0075, 0.0092, 0.0454, 0.0221, 0.0445]) \n",
      "Test Loss tensor([0.0064, 0.0103, 0.0469, 0.0222, 0.0436])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4705214500427246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0089, 0.0487, 0.0254, 0.0436]) \n",
      "Test Loss tensor([0.0066, 0.0103, 0.0483, 0.0228, 0.0446])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4719970226287842 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0064, 0.0105, 0.0397, 0.0226, 0.0411]) \n",
      "Test Loss tensor([0.0060, 0.0100, 0.0468, 0.0219, 0.0446])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4727475643157959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0101, 0.0442, 0.0224, 0.0439]) \n",
      "Test Loss tensor([0.0063, 0.0103, 0.0478, 0.0226, 0.0439])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.47601938247680664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0082, 0.0436, 0.0212, 0.0442]) \n",
      "Test Loss tensor([0.0060, 0.0096, 0.0459, 0.0218, 0.0445])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4692704677581787 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0118, 0.0428, 0.0213, 0.0444]) \n",
      "Test Loss tensor([0.0059, 0.0101, 0.0455, 0.0214, 0.0448])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4729757308959961 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0074, 0.0089, 0.0417, 0.0216, 0.0438]) \n",
      "Test Loss tensor([0.0062, 0.0093, 0.0461, 0.0218, 0.0443])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 208 in 0.47066521644592285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0110, 0.0466, 0.0204, 0.0435]) \n",
      "Test Loss tensor([0.0062, 0.0106, 0.0463, 0.0222, 0.0444])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.470597505569458 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0110, 0.0476, 0.0229, 0.0435]) \n",
      "Test Loss tensor([0.0061, 0.0097, 0.0470, 0.0220, 0.0441])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.4716958999633789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0087, 0.0462, 0.0266, 0.0447]) \n",
      "Test Loss tensor([0.0061, 0.0100, 0.0471, 0.0218, 0.0437])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.469179630279541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0064, 0.0121, 0.0448, 0.0246, 0.0433]) \n",
      "Test Loss tensor([0.0055, 0.0103, 0.0458, 0.0229, 0.0439])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4820983409881592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0132, 0.0476, 0.0197, 0.0455]) \n",
      "Test Loss tensor([0.0057, 0.0104, 0.0459, 0.0224, 0.0449])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.46926403045654297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0133, 0.0520, 0.0232, 0.0415]) \n",
      "Test Loss tensor([0.0064, 0.0093, 0.0483, 0.0222, 0.0438])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47199392318725586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0089, 0.0482, 0.0243, 0.0453]) \n",
      "Test Loss tensor([0.0060, 0.0100, 0.0456, 0.0218, 0.0441])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.46872615814208984 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0088, 0.0080, 0.0455, 0.0200, 0.0446]) \n",
      "Test Loss tensor([0.0063, 0.0109, 0.0461, 0.0220, 0.0444])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4729025363922119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0094, 0.0468, 0.0218, 0.0428]) \n",
      "Test Loss tensor([0.0060, 0.0097, 0.0457, 0.0219, 0.0442])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.46970582008361816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0080, 0.0450, 0.0234, 0.0430]) \n",
      "Test Loss tensor([0.0057, 0.0099, 0.0458, 0.0221, 0.0439])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4707980155944824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0078, 0.0433, 0.0226, 0.0425]) \n",
      "Test Loss tensor([0.0059, 0.0097, 0.0454, 0.0220, 0.0442])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.47283339500427246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0084, 0.0443, 0.0249, 0.0442]) \n",
      "Test Loss tensor([0.0062, 0.0099, 0.0458, 0.0220, 0.0435])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.47093796730041504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0071, 0.0112, 0.0436, 0.0207, 0.0440]) \n",
      "Test Loss tensor([0.0061, 0.0089, 0.0470, 0.0222, 0.0434])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4695322513580322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0091, 0.0091, 0.0446, 0.0249, 0.0418]) \n",
      "Test Loss tensor([0.0062, 0.0097, 0.0449, 0.0218, 0.0438])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.4716658592224121 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0091, 0.0403, 0.0201, 0.0440]) \n",
      "Test Loss tensor([0.0061, 0.0098, 0.0458, 0.0224, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.47256040573120117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0090, 0.0453, 0.0209, 0.0419]) \n",
      "Test Loss tensor([0.0063, 0.0090, 0.0457, 0.0223, 0.0432])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.47179126739501953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0064, 0.0109, 0.0492, 0.0241, 0.0448]) \n",
      "Test Loss tensor([0.0062, 0.0103, 0.0455, 0.0217, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4711320400238037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0073, 0.0097, 0.0459, 0.0251, 0.0430]) \n",
      "Test Loss tensor([0.0057, 0.0095, 0.0445, 0.0218, 0.0434])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.47120141983032227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0104, 0.0432, 0.0219, 0.0444]) \n",
      "Test Loss tensor([0.0060, 0.0103, 0.0456, 0.0217, 0.0437])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.47377514839172363 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0113, 0.0410, 0.0225, 0.0425]) \n",
      "Test Loss tensor([0.0065, 0.0097, 0.0452, 0.0225, 0.0432])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.474562406539917 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0077, 0.0093, 0.0439, 0.0226, 0.0446]) \n",
      "Test Loss tensor([0.0062, 0.0099, 0.0452, 0.0226, 0.0437])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.48308372497558594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0082, 0.0498, 0.0248, 0.0410]) \n",
      "Test Loss tensor([0.0058, 0.0101, 0.0454, 0.0222, 0.0435])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47088623046875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0095, 0.0440, 0.0216, 0.0450]) \n",
      "Test Loss tensor([0.0060, 0.0094, 0.0444, 0.0214, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47337770462036133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0085, 0.0417, 0.0200, 0.0453]) \n",
      "Test Loss tensor([0.0060, 0.0095, 0.0456, 0.0220, 0.0429])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4742414951324463 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0126, 0.0476, 0.0239, 0.0411]) \n",
      "Test Loss tensor([0.0058, 0.0102, 0.0442, 0.0218, 0.0428])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.48772597312927246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0073, 0.0085, 0.0442, 0.0227, 0.0429]) \n",
      "Test Loss tensor([0.0059, 0.0087, 0.0440, 0.0218, 0.0431])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.4724140167236328 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0084, 0.0085, 0.0487, 0.0235, 0.0428]) \n",
      "Test Loss tensor([0.0060, 0.0097, 0.0437, 0.0216, 0.0437])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4761836528778076 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0086, 0.0413, 0.0223, 0.0422]) \n",
      "Test Loss tensor([0.0056, 0.0095, 0.0446, 0.0216, 0.0433])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4759676456451416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0090, 0.0431, 0.0234, 0.0438]) \n",
      "Test Loss tensor([0.0056, 0.0104, 0.0443, 0.0214, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.47588396072387695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0097, 0.0428, 0.0215, 0.0429]) \n",
      "Test Loss tensor([0.0060, 0.0096, 0.0436, 0.0223, 0.0431])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4728405475616455 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0094, 0.0408, 0.0215, 0.0425]) \n",
      "Test Loss tensor([0.0058, 0.0093, 0.0427, 0.0218, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.47454285621643066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0106, 0.0480, 0.0230, 0.0427]) \n",
      "Test Loss tensor([0.0053, 0.0091, 0.0436, 0.0218, 0.0433])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47351717948913574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0093, 0.0448, 0.0213, 0.0429]) \n",
      "Test Loss tensor([0.0060, 0.0091, 0.0448, 0.0219, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.4800591468811035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0088, 0.0394, 0.0206, 0.0422]) \n",
      "Test Loss tensor([0.0059, 0.0102, 0.0444, 0.0213, 0.0435])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.47660183906555176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0123, 0.0494, 0.0223, 0.0428]) \n",
      "Test Loss tensor([0.0057, 0.0097, 0.0438, 0.0213, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47556209564208984 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0083, 0.0447, 0.0208, 0.0444]) \n",
      "Test Loss tensor([0.0055, 0.0096, 0.0433, 0.0212, 0.0435])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4756028652191162 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0100, 0.0444, 0.0220, 0.0419]) \n",
      "Test Loss tensor([0.0053, 0.0097, 0.0424, 0.0216, 0.0432])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4742255210876465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0095, 0.0419, 0.0232, 0.0422]) \n",
      "Test Loss tensor([0.0058, 0.0091, 0.0428, 0.0213, 0.0425])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4734926223754883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0096, 0.0398, 0.0188, 0.0399]) \n",
      "Test Loss tensor([0.0051, 0.0089, 0.0433, 0.0211, 0.0432])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5023877620697021 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0104, 0.0449, 0.0242, 0.0434]) \n",
      "Test Loss tensor([0.0054, 0.0088, 0.0428, 0.0217, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.46985292434692383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0087, 0.0411, 0.0219, 0.0397]) \n",
      "Test Loss tensor([0.0056, 0.0092, 0.0432, 0.0215, 0.0428])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 372 in 0.4766826629638672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0103, 0.0421, 0.0244, 0.0429]) \n",
      "Test Loss tensor([0.0054, 0.0090, 0.0436, 0.0220, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4736521244049072 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0086, 0.0431, 0.0203, 0.0405]) \n",
      "Test Loss tensor([0.0059, 0.0096, 0.0427, 0.0218, 0.0426])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4728407859802246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0105, 0.0464, 0.0230, 0.0432]) \n",
      "Test Loss tensor([0.0059, 0.0092, 0.0443, 0.0219, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.47231101989746094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0101, 0.0390, 0.0237, 0.0429]) \n",
      "Test Loss tensor([0.0059, 0.0091, 0.0438, 0.0223, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4754769802093506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0091, 0.0425, 0.0220, 0.0412]) \n",
      "Test Loss tensor([0.0054, 0.0091, 0.0428, 0.0214, 0.0430])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4834129810333252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0074, 0.0448, 0.0216, 0.0425]) \n",
      "Test Loss tensor([0.0057, 0.0086, 0.0413, 0.0214, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.47383761405944824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0093, 0.0392, 0.0223, 0.0423]) \n",
      "Test Loss tensor([0.0056, 0.0092, 0.0420, 0.0214, 0.0424])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.47187185287475586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0091, 0.0386, 0.0212, 0.0400]) \n",
      "Test Loss tensor([0.0054, 0.0087, 0.0424, 0.0211, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4722294807434082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0107, 0.0439, 0.0202, 0.0430]) \n",
      "Test Loss tensor([0.0053, 0.0089, 0.0422, 0.0212, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4725778102874756 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0088, 0.0387, 0.0241, 0.0439]) \n",
      "Test Loss tensor([0.0056, 0.0093, 0.0425, 0.0216, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47190284729003906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0078, 0.0353, 0.0189, 0.0408]) \n",
      "Test Loss tensor([0.0055, 0.0094, 0.0434, 0.0215, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4762132167816162 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0112, 0.0386, 0.0246, 0.0431]) \n",
      "Test Loss tensor([0.0059, 0.0085, 0.0423, 0.0217, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.47322773933410645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0089, 0.0446, 0.0246, 0.0450]) \n",
      "Test Loss tensor([0.0055, 0.0087, 0.0428, 0.0221, 0.0422])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.471463680267334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0079, 0.0463, 0.0202, 0.0431]) \n",
      "Test Loss tensor([0.0052, 0.0089, 0.0423, 0.0213, 0.0427])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.47423291206359863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0082, 0.0411, 0.0217, 0.0407]) \n",
      "Test Loss tensor([0.0053, 0.0093, 0.0423, 0.0206, 0.0425])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.47248101234436035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0101, 0.0451, 0.0233, 0.0401]) \n",
      "Test Loss tensor([0.0053, 0.0088, 0.0420, 0.0210, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4716172218322754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0066, 0.0386, 0.0228, 0.0404]) \n",
      "Test Loss tensor([0.0052, 0.0090, 0.0429, 0.0204, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4770359992980957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0084, 0.0416, 0.0221, 0.0433]) \n",
      "Test Loss tensor([0.0058, 0.0087, 0.0421, 0.0210, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47186708450317383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0072, 0.0420, 0.0224, 0.0420]) \n",
      "Test Loss tensor([0.0054, 0.0077, 0.0420, 0.0210, 0.0419])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4713134765625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0085, 0.0385, 0.0172, 0.0398]) \n",
      "Test Loss tensor([0.0049, 0.0083, 0.0413, 0.0215, 0.0423])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.4703090190887451 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0087, 0.0420, 0.0200, 0.0427]) \n",
      "Test Loss tensor([0.0051, 0.0086, 0.0420, 0.0216, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.47028422355651855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0067, 0.0096, 0.0451, 0.0234, 0.0406]) \n",
      "Test Loss tensor([0.0054, 0.0088, 0.0419, 0.0210, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.47075915336608887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0094, 0.0361, 0.0211, 0.0412]) \n",
      "Test Loss tensor([0.0053, 0.0086, 0.0427, 0.0217, 0.0419])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4696769714355469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0071, 0.0432, 0.0217, 0.0443]) \n",
      "Test Loss tensor([0.0053, 0.0083, 0.0425, 0.0216, 0.0419])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47252607345581055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0092, 0.0391, 0.0211, 0.0427]) \n",
      "Test Loss tensor([0.0053, 0.0084, 0.0408, 0.0218, 0.0421])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.47582197189331055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0090, 0.0401, 0.0194, 0.0405]) \n",
      "Test Loss tensor([0.0049, 0.0080, 0.0408, 0.0211, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4846487045288086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0106, 0.0397, 0.0204, 0.0414]) \n",
      "Test Loss tensor([0.0058, 0.0083, 0.0423, 0.0219, 0.0416])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.46990036964416504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0085, 0.0373, 0.0200, 0.0406]) \n",
      "Test Loss tensor([0.0053, 0.0083, 0.0418, 0.0218, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47151708602905273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0062, 0.0382, 0.0226, 0.0388]) \n",
      "Test Loss tensor([0.0054, 0.0088, 0.0422, 0.0213, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4707169532775879 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0072, 0.0400, 0.0191, 0.0393]) \n",
      "Test Loss tensor([0.0053, 0.0088, 0.0408, 0.0212, 0.0415])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.473663330078125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0083, 0.0340, 0.0205, 0.0419]) \n",
      "Test Loss tensor([0.0049, 0.0084, 0.0409, 0.0212, 0.0419])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.46857404708862305 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0072, 0.0376, 0.0226, 0.0406]) \n",
      "Test Loss tensor([0.0056, 0.0082, 0.0418, 0.0218, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.47334742546081543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0073, 0.0412, 0.0240, 0.0430]) \n",
      "Test Loss tensor([0.0053, 0.0085, 0.0416, 0.0218, 0.0420])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4673006534576416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0093, 0.0415, 0.0187, 0.0383]) \n",
      "Test Loss tensor([0.0057, 0.0083, 0.0402, 0.0211, 0.0408])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4909205436706543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0070, 0.0420, 0.0221, 0.0411]) \n",
      "Test Loss tensor([0.0055, 0.0078, 0.0401, 0.0208, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4681980609893799 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0082, 0.0362, 0.0222, 0.0444]) \n",
      "Test Loss tensor([0.0054, 0.0077, 0.0408, 0.0217, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.47074317932128906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0085, 0.0407, 0.0239, 0.0420]) \n",
      "Test Loss tensor([0.0055, 0.0080, 0.0404, 0.0207, 0.0408])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4703211784362793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0072, 0.0405, 0.0229, 0.0438]) \n",
      "Test Loss tensor([0.0052, 0.0083, 0.0389, 0.0210, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.47191619873046875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0076, 0.0434, 0.0187, 0.0413]) \n",
      "Test Loss tensor([0.0052, 0.0077, 0.0402, 0.0210, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4732186794281006 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0096, 0.0418, 0.0218, 0.0413]) \n",
      "Test Loss tensor([0.0053, 0.0081, 0.0396, 0.0208, 0.0407])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.46792078018188477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0095, 0.0406, 0.0217, 0.0406]) \n",
      "Test Loss tensor([0.0049, 0.0087, 0.0394, 0.0201, 0.0409])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 536 in 0.47263073921203613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0082, 0.0394, 0.0200, 0.0388]) \n",
      "Test Loss tensor([0.0055, 0.0076, 0.0397, 0.0203, 0.0412])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4714810848236084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0057, 0.0359, 0.0206, 0.0411]) \n",
      "Test Loss tensor([0.0052, 0.0082, 0.0413, 0.0213, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.47126054763793945 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0091, 0.0340, 0.0209, 0.0416]) \n",
      "Test Loss tensor([0.0054, 0.0086, 0.0407, 0.0213, 0.0411])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4689040184020996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0055, 0.0355, 0.0214, 0.0416]) \n",
      "Test Loss tensor([0.0051, 0.0081, 0.0408, 0.0208, 0.0405])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.4720592498779297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0070, 0.0072, 0.0386, 0.0189, 0.0417]) \n",
      "Test Loss tensor([0.0053, 0.0091, 0.0393, 0.0209, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.469160795211792 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0104, 0.0404, 0.0220, 0.0379]) \n",
      "Test Loss tensor([0.0051, 0.0079, 0.0389, 0.0213, 0.0413])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4701206684112549 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0065, 0.0381, 0.0235, 0.0401]) \n",
      "Test Loss tensor([0.0048, 0.0081, 0.0399, 0.0200, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.46775174140930176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0072, 0.0354, 0.0227, 0.0405]) \n",
      "Test Loss tensor([0.0051, 0.0081, 0.0399, 0.0210, 0.0411])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4709644317626953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0056, 0.0404, 0.0200, 0.0435]) \n",
      "Test Loss tensor([0.0053, 0.0086, 0.0400, 0.0215, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4696476459503174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0068, 0.0430, 0.0223, 0.0403]) \n",
      "Test Loss tensor([0.0054, 0.0071, 0.0396, 0.0212, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4715464115142822 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0066, 0.0410, 0.0236, 0.0400]) \n",
      "Test Loss tensor([0.0053, 0.0081, 0.0394, 0.0206, 0.0407])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.46967601776123047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0092, 0.0438, 0.0196, 0.0395]) \n",
      "Test Loss tensor([0.0052, 0.0081, 0.0393, 0.0219, 0.0410])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4680757522583008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0062, 0.0387, 0.0203, 0.0411]) \n",
      "Test Loss tensor([0.0052, 0.0080, 0.0398, 0.0223, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.46849966049194336 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0093, 0.0360, 0.0212, 0.0392]) \n",
      "Test Loss tensor([0.0050, 0.0078, 0.0409, 0.0208, 0.0405])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.46947312355041504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0117, 0.0381, 0.0221, 0.0415]) \n",
      "Test Loss tensor([0.0051, 0.0078, 0.0402, 0.0209, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.4702179431915283 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0075, 0.0420, 0.0204, 0.0391]) \n",
      "Test Loss tensor([0.0049, 0.0084, 0.0398, 0.0213, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4702792167663574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0073, 0.0345, 0.0218, 0.0414]) \n",
      "Test Loss tensor([0.0049, 0.0078, 0.0400, 0.0214, 0.0408])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.4707458019256592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0093, 0.0379, 0.0252, 0.0391]) \n",
      "Test Loss tensor([0.0050, 0.0079, 0.0405, 0.0214, 0.0408])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.47518014907836914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0081, 0.0429, 0.0206, 0.0414]) \n",
      "Test Loss tensor([0.0050, 0.0079, 0.0387, 0.0211, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4751274585723877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0082, 0.0372, 0.0183, 0.0382]) \n",
      "Test Loss tensor([0.0056, 0.0080, 0.0398, 0.0216, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.47403597831726074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0057, 0.0442, 0.0248, 0.0385]) \n",
      "Test Loss tensor([0.0053, 0.0076, 0.0386, 0.0212, 0.0406])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4765634536743164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0086, 0.0403, 0.0218, 0.0391]) \n",
      "Test Loss tensor([0.0052, 0.0074, 0.0381, 0.0210, 0.0395])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.47580647468566895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0074, 0.0414, 0.0175, 0.0371]) \n",
      "Test Loss tensor([0.0049, 0.0079, 0.0384, 0.0221, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47237086296081543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0075, 0.0359, 0.0182, 0.0403]) \n",
      "Test Loss tensor([0.0047, 0.0081, 0.0403, 0.0209, 0.0395])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.474454402923584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0105, 0.0352, 0.0217, 0.0390]) \n",
      "Test Loss tensor([0.0051, 0.0080, 0.0411, 0.0209, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4746410846710205 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0087, 0.0366, 0.0254, 0.0378]) \n",
      "Test Loss tensor([0.0051, 0.0082, 0.0376, 0.0208, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.46825671195983887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0065, 0.0373, 0.0201, 0.0391]) \n",
      "Test Loss tensor([0.0054, 0.0079, 0.0393, 0.0205, 0.0400])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4847393035888672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0110, 0.0424, 0.0237, 0.0417]) \n",
      "Test Loss tensor([0.0047, 0.0077, 0.0378, 0.0219, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.46973395347595215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0076, 0.0385, 0.0263, 0.0393]) \n",
      "Test Loss tensor([0.0051, 0.0077, 0.0367, 0.0208, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4683871269226074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0080, 0.0401, 0.0205, 0.0387]) \n",
      "Test Loss tensor([0.0052, 0.0071, 0.0391, 0.0205, 0.0397])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.471088171005249 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0101, 0.0349, 0.0228, 0.0397]) \n",
      "Test Loss tensor([0.0048, 0.0071, 0.0386, 0.0206, 0.0404])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47081828117370605 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0072, 0.0363, 0.0196, 0.0378]) \n",
      "Test Loss tensor([0.0047, 0.0077, 0.0375, 0.0203, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.46929049491882324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0090, 0.0381, 0.0226, 0.0385]) \n",
      "Test Loss tensor([0.0051, 0.0076, 0.0395, 0.0203, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.47036123275756836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0081, 0.0417, 0.0196, 0.0409]) \n",
      "Test Loss tensor([0.0050, 0.0077, 0.0384, 0.0215, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4698042869567871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0056, 0.0387, 0.0224, 0.0415]) \n",
      "Test Loss tensor([0.0051, 0.0079, 0.0379, 0.0215, 0.0400])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.47229671478271484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0086, 0.0366, 0.0196, 0.0411]) \n",
      "Test Loss tensor([0.0048, 0.0072, 0.0392, 0.0211, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.4709129333496094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0073, 0.0367, 0.0191, 0.0391]) \n",
      "Test Loss tensor([0.0053, 0.0067, 0.0395, 0.0213, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.517179012298584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0068, 0.0082, 0.0387, 0.0230, 0.0419]) \n",
      "Test Loss tensor([0.0051, 0.0081, 0.0376, 0.0204, 0.0403])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.47799181938171387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0088, 0.0347, 0.0199, 0.0411]) \n",
      "Test Loss tensor([0.0050, 0.0076, 0.0386, 0.0203, 0.0402])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4690883159637451 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0079, 0.0387, 0.0211, 0.0389]) \n",
      "Test Loss tensor([0.0052, 0.0075, 0.0382, 0.0199, 0.0400])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4759342670440674 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0093, 0.0310, 0.0208, 0.0385]) \n",
      "Test Loss tensor([0.0050, 0.0073, 0.0387, 0.0203, 0.0399])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 700 in 0.47098207473754883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0079, 0.0357, 0.0207, 0.0402]) \n",
      "Test Loss tensor([0.0049, 0.0077, 0.0390, 0.0199, 0.0399])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4795217514038086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0090, 0.0332, 0.0214, 0.0413]) \n",
      "Test Loss tensor([0.0052, 0.0075, 0.0378, 0.0203, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.4735424518585205 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0077, 0.0392, 0.0211, 0.0393]) \n",
      "Test Loss tensor([0.0048, 0.0076, 0.0376, 0.0208, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.47603726387023926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0080, 0.0346, 0.0204, 0.0405]) \n",
      "Test Loss tensor([0.0047, 0.0076, 0.0395, 0.0209, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4772200584411621 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0085, 0.0400, 0.0216, 0.0380]) \n",
      "Test Loss tensor([0.0049, 0.0080, 0.0382, 0.0210, 0.0397])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4875359535217285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0117, 0.0355, 0.0205, 0.0380]) \n",
      "Test Loss tensor([0.0047, 0.0074, 0.0381, 0.0207, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4750838279724121 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0079, 0.0378, 0.0221, 0.0422]) \n",
      "Test Loss tensor([0.0052, 0.0072, 0.0384, 0.0208, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4815793037414551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0078, 0.0369, 0.0204, 0.0405]) \n",
      "Test Loss tensor([0.0051, 0.0076, 0.0396, 0.0211, 0.0391])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47645139694213867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0073, 0.0390, 0.0210, 0.0377]) \n",
      "Test Loss tensor([0.0051, 0.0075, 0.0397, 0.0211, 0.0388])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.47743868827819824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0082, 0.0373, 0.0210, 0.0398]) \n",
      "Test Loss tensor([0.0050, 0.0070, 0.0389, 0.0208, 0.0389])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4765779972076416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0098, 0.0411, 0.0226, 0.0394]) \n",
      "Test Loss tensor([0.0051, 0.0076, 0.0394, 0.0200, 0.0386])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4786412715911865 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0077, 0.0379, 0.0221, 0.0392]) \n",
      "Test Loss tensor([0.0051, 0.0069, 0.0372, 0.0207, 0.0383])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4847755432128906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0077, 0.0374, 0.0209, 0.0382]) \n",
      "Test Loss tensor([0.0048, 0.0069, 0.0377, 0.0209, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.48100972175598145 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0063, 0.0365, 0.0176, 0.0410]) \n",
      "Test Loss tensor([0.0052, 0.0069, 0.0379, 0.0208, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.4787452220916748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0076, 0.0378, 0.0186, 0.0380]) \n",
      "Test Loss tensor([0.0048, 0.0071, 0.0378, 0.0223, 0.0386])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4773225784301758 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0060, 0.0407, 0.0217, 0.0367]) \n",
      "Test Loss tensor([0.0051, 0.0070, 0.0375, 0.0204, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.4746870994567871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0058, 0.0370, 0.0207, 0.0366]) \n",
      "Test Loss tensor([0.0051, 0.0078, 0.0373, 0.0210, 0.0398])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.47700953483581543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0060, 0.0378, 0.0212, 0.0413]) \n",
      "Test Loss tensor([0.0050, 0.0073, 0.0385, 0.0209, 0.0401])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.4752180576324463 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0061, 0.0385, 0.0208, 0.0403]) \n",
      "Test Loss tensor([0.0053, 0.0070, 0.0379, 0.0199, 0.0397])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.47069525718688965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0071, 0.0374, 0.0225, 0.0411]) \n",
      "Test Loss tensor([0.0050, 0.0069, 0.0384, 0.0199, 0.0396])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4723200798034668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0071, 0.0351, 0.0198, 0.0425]) \n",
      "Test Loss tensor([0.0047, 0.0072, 0.0372, 0.0208, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4698193073272705 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0065, 0.0376, 0.0212, 0.0393]) \n",
      "Test Loss tensor([0.0053, 0.0074, 0.0373, 0.0203, 0.0396])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47220587730407715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0064, 0.0359, 0.0215, 0.0383]) \n",
      "Test Loss tensor([0.0045, 0.0067, 0.0369, 0.0207, 0.0389])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.46826767921447754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0065, 0.0365, 0.0216, 0.0405]) \n",
      "Test Loss tensor([0.0046, 0.0070, 0.0378, 0.0215, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47452569007873535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0080, 0.0419, 0.0209, 0.0377]) \n",
      "Test Loss tensor([0.0047, 0.0071, 0.0367, 0.0204, 0.0396])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4713304042816162 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0075, 0.0372, 0.0196, 0.0366]) \n",
      "Test Loss tensor([0.0050, 0.0073, 0.0378, 0.0207, 0.0389])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4731330871582031 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0078, 0.0391, 0.0231, 0.0400]) \n",
      "Test Loss tensor([0.0047, 0.0074, 0.0374, 0.0199, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4704892635345459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0091, 0.0405, 0.0237, 0.0392]) \n",
      "Test Loss tensor([0.0048, 0.0072, 0.0370, 0.0205, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4864647388458252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0086, 0.0355, 0.0219, 0.0391]) \n",
      "Test Loss tensor([0.0049, 0.0076, 0.0391, 0.0199, 0.0393])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47086524963378906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0080, 0.0412, 0.0219, 0.0380]) \n",
      "Test Loss tensor([0.0048, 0.0072, 0.0393, 0.0212, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47292399406433105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0087, 0.0387, 0.0199, 0.0370]) \n",
      "Test Loss tensor([0.0048, 0.0069, 0.0365, 0.0205, 0.0387])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.4702460765838623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0060, 0.0383, 0.0215, 0.0404]) \n",
      "Test Loss tensor([0.0047, 0.0071, 0.0362, 0.0210, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.4713859558105469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0091, 0.0370, 0.0201, 0.0406]) \n",
      "Test Loss tensor([0.0045, 0.0070, 0.0369, 0.0218, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.472348690032959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0067, 0.0408, 0.0211, 0.0373]) \n",
      "Test Loss tensor([0.0048, 0.0067, 0.0380, 0.0225, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4701712131500244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0088, 0.0365, 0.0218, 0.0378]) \n",
      "Test Loss tensor([0.0047, 0.0073, 0.0377, 0.0213, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4679718017578125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0059, 0.0425, 0.0201, 0.0407]) \n",
      "Test Loss tensor([0.0046, 0.0070, 0.0368, 0.0206, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4716644287109375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0066, 0.0328, 0.0201, 0.0389]) \n",
      "Test Loss tensor([0.0051, 0.0072, 0.0370, 0.0200, 0.0392])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.47110438346862793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0073, 0.0324, 0.0180, 0.0378]) \n",
      "Test Loss tensor([0.0048, 0.0070, 0.0380, 0.0202, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4700946807861328 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0065, 0.0342, 0.0212, 0.0398]) \n",
      "Test Loss tensor([0.0046, 0.0068, 0.0379, 0.0193, 0.0387])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4703059196472168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0062, 0.0353, 0.0222, 0.0369]) \n",
      "Test Loss tensor([0.0047, 0.0064, 0.0368, 0.0202, 0.0394])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4686579704284668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0075, 0.0356, 0.0197, 0.0384]) \n",
      "Test Loss tensor([0.0044, 0.0070, 0.0371, 0.0202, 0.0391])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.47242116928100586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0070, 0.0401, 0.0253, 0.0397]) \n",
      "Test Loss tensor([0.0048, 0.0069, 0.0371, 0.0208, 0.0386])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4678955078125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0070, 0.0317, 0.0195, 0.0378]) \n",
      "Test Loss tensor([0.0046, 0.0067, 0.0366, 0.0210, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.47206759452819824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0064, 0.0348, 0.0209, 0.0392]) \n",
      "Test Loss tensor([0.0050, 0.0069, 0.0361, 0.0212, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4521796703338623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0025, 0.0063, 0.0255, 0.0169, 0.0307]) \n",
      "Test Loss tensor([0.0046, 0.0074, 0.0368, 0.0212, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.507819652557373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0068, 0.0354, 0.0218, 0.0397]) \n",
      "Test Loss tensor([0.0047, 0.0069, 0.0355, 0.0202, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.47048330307006836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0054, 0.0396, 0.0195, 0.0398]) \n",
      "Test Loss tensor([0.0048, 0.0068, 0.0347, 0.0203, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.4728987216949463 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0076, 0.0374, 0.0194, 0.0400]) \n",
      "Test Loss tensor([0.0048, 0.0071, 0.0384, 0.0202, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4702136516571045 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0082, 0.0330, 0.0189, 0.0358]) \n",
      "Test Loss tensor([0.0048, 0.0068, 0.0374, 0.0217, 0.0390])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.47271060943603516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0066, 0.0383, 0.0198, 0.0378]) \n",
      "Test Loss tensor([0.0048, 0.0069, 0.0372, 0.0205, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47191309928894043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0066, 0.0351, 0.0192, 0.0383]) \n",
      "Test Loss tensor([0.0047, 0.0072, 0.0370, 0.0197, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47115612030029297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0065, 0.0294, 0.0210, 0.0379]) \n",
      "Test Loss tensor([0.0047, 0.0070, 0.0374, 0.0200, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4698474407196045 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0062, 0.0356, 0.0203, 0.0400]) \n",
      "Test Loss tensor([0.0045, 0.0066, 0.0350, 0.0198, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4875624179840088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0067, 0.0317, 0.0226, 0.0366]) \n",
      "Test Loss tensor([0.0047, 0.0069, 0.0360, 0.0204, 0.0373])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4725840091705322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0050, 0.0347, 0.0225, 0.0388]) \n",
      "Test Loss tensor([0.0047, 0.0070, 0.0367, 0.0204, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4736301898956299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0059, 0.0380, 0.0197, 0.0371]) \n",
      "Test Loss tensor([0.0048, 0.0068, 0.0370, 0.0199, 0.0374])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4704105854034424 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0060, 0.0357, 0.0220, 0.0377]) \n",
      "Test Loss tensor([0.0048, 0.0068, 0.0358, 0.0197, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4747471809387207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0053, 0.0366, 0.0215, 0.0392]) \n",
      "Test Loss tensor([0.0045, 0.0065, 0.0362, 0.0197, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4711759090423584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0063, 0.0369, 0.0194, 0.0379]) \n",
      "Test Loss tensor([0.0047, 0.0065, 0.0374, 0.0201, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4765152931213379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0054, 0.0365, 0.0198, 0.0376]) \n",
      "Test Loss tensor([0.0046, 0.0070, 0.0359, 0.0202, 0.0382])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4719357490539551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0064, 0.0348, 0.0184, 0.0366]) \n",
      "Test Loss tensor([0.0050, 0.0068, 0.0382, 0.0197, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4712073802947998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0068, 0.0341, 0.0202, 0.0366]) \n",
      "Test Loss tensor([0.0048, 0.0067, 0.0348, 0.0198, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.47263669967651367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0064, 0.0348, 0.0207, 0.0380]) \n",
      "Test Loss tensor([0.0049, 0.0068, 0.0348, 0.0192, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.47066664695739746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0047, 0.0384, 0.0224, 0.0367]) \n",
      "Test Loss tensor([0.0047, 0.0070, 0.0355, 0.0204, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4740028381347656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0074, 0.0380, 0.0208, 0.0362]) \n",
      "Test Loss tensor([0.0047, 0.0064, 0.0354, 0.0189, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4726078510284424 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0049, 0.0329, 0.0170, 0.0387]) \n",
      "Test Loss tensor([0.0049, 0.0068, 0.0370, 0.0201, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.47120237350463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0066, 0.0368, 0.0241, 0.0375]) \n",
      "Test Loss tensor([0.0049, 0.0066, 0.0359, 0.0197, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.47184038162231445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0078, 0.0340, 0.0200, 0.0396]) \n",
      "Test Loss tensor([0.0050, 0.0066, 0.0355, 0.0192, 0.0386])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4737863540649414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0067, 0.0390, 0.0188, 0.0381]) \n",
      "Test Loss tensor([0.0048, 0.0062, 0.0359, 0.0202, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4701383113861084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0061, 0.0328, 0.0221, 0.0377]) \n",
      "Test Loss tensor([0.0050, 0.0063, 0.0347, 0.0195, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.482327938079834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0065, 0.0372, 0.0189, 0.0391]) \n",
      "Test Loss tensor([0.0049, 0.0069, 0.0350, 0.0195, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47322607040405273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0067, 0.0340, 0.0178, 0.0378]) \n",
      "Test Loss tensor([0.0048, 0.0068, 0.0350, 0.0195, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.47286486625671387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0072, 0.0315, 0.0195, 0.0400]) \n",
      "Test Loss tensor([0.0046, 0.0065, 0.0355, 0.0197, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.47345614433288574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0073, 0.0344, 0.0203, 0.0403]) \n",
      "Test Loss tensor([0.0049, 0.0061, 0.0357, 0.0190, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4713706970214844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0061, 0.0357, 0.0199, 0.0356]) \n",
      "Test Loss tensor([0.0048, 0.0064, 0.0349, 0.0195, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.47097349166870117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0073, 0.0358, 0.0187, 0.0382]) \n",
      "Test Loss tensor([0.0048, 0.0065, 0.0342, 0.0196, 0.0381])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4741330146789551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0066, 0.0071, 0.0365, 0.0190, 0.0373]) \n",
      "Test Loss tensor([0.0050, 0.0059, 0.0347, 0.0190, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.46970224380493164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0054, 0.0355, 0.0194, 0.0372]) \n",
      "Test Loss tensor([0.0051, 0.0058, 0.0341, 0.0196, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4723060131072998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0056, 0.0338, 0.0218, 0.0370]) \n",
      "Test Loss tensor([0.0048, 0.0061, 0.0337, 0.0198, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.48032355308532715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0043, 0.0360, 0.0182, 0.0371]) \n",
      "Test Loss tensor([0.0047, 0.0063, 0.0342, 0.0206, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4706113338470459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0082, 0.0334, 0.0234, 0.0374]) \n",
      "Test Loss tensor([0.0046, 0.0066, 0.0352, 0.0208, 0.0372])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.47202396392822266 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0053, 0.0361, 0.0192, 0.0386]) \n",
      "Test Loss tensor([0.0049, 0.0062, 0.0344, 0.0196, 0.0377])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 148 in 0.4707636833190918 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0065, 0.0323, 0.0198, 0.0373]) \n",
      "Test Loss tensor([0.0046, 0.0065, 0.0366, 0.0199, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4744272232055664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0067, 0.0365, 0.0196, 0.0388]) \n",
      "Test Loss tensor([0.0044, 0.0065, 0.0353, 0.0192, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.4708845615386963 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0052, 0.0377, 0.0201, 0.0396]) \n",
      "Test Loss tensor([0.0045, 0.0061, 0.0357, 0.0195, 0.0383])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.4709022045135498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0072, 0.0340, 0.0198, 0.0392]) \n",
      "Test Loss tensor([0.0044, 0.0065, 0.0351, 0.0200, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4696390628814697 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0047, 0.0318, 0.0205, 0.0362]) \n",
      "Test Loss tensor([0.0048, 0.0062, 0.0344, 0.0199, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4734790325164795 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0075, 0.0361, 0.0187, 0.0352]) \n",
      "Test Loss tensor([0.0046, 0.0060, 0.0349, 0.0196, 0.0384])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47199511528015137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0051, 0.0337, 0.0178, 0.0367]) \n",
      "Test Loss tensor([0.0046, 0.0061, 0.0334, 0.0198, 0.0378])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47129106521606445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0049, 0.0329, 0.0187, 0.0371]) \n",
      "Test Loss tensor([0.0046, 0.0062, 0.0352, 0.0198, 0.0372])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.47245168685913086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0066, 0.0325, 0.0169, 0.0372]) \n",
      "Test Loss tensor([0.0047, 0.0060, 0.0346, 0.0197, 0.0380])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.4722013473510742 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0050, 0.0351, 0.0175, 0.0377]) \n",
      "Test Loss tensor([0.0045, 0.0062, 0.0344, 0.0185, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4714975357055664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0070, 0.0368, 0.0209, 0.0364]) \n",
      "Test Loss tensor([0.0047, 0.0060, 0.0344, 0.0201, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.47165513038635254 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0052, 0.0340, 0.0200, 0.0373]) \n",
      "Test Loss tensor([0.0048, 0.0064, 0.0337, 0.0196, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.47087764739990234 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0069, 0.0285, 0.0194, 0.0374]) \n",
      "Test Loss tensor([0.0046, 0.0064, 0.0349, 0.0207, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4735128879547119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0069, 0.0347, 0.0194, 0.0374]) \n",
      "Test Loss tensor([0.0043, 0.0059, 0.0346, 0.0196, 0.0377])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.4724762439727783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0052, 0.0352, 0.0219, 0.0394]) \n",
      "Test Loss tensor([0.0044, 0.0059, 0.0336, 0.0196, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4692823886871338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0046, 0.0306, 0.0221, 0.0383]) \n",
      "Test Loss tensor([0.0044, 0.0063, 0.0339, 0.0193, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.47175168991088867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0058, 0.0307, 0.0201, 0.0355]) \n",
      "Test Loss tensor([0.0046, 0.0061, 0.0346, 0.0191, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.467470645904541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0058, 0.0338, 0.0204, 0.0341]) \n",
      "Test Loss tensor([0.0043, 0.0056, 0.0333, 0.0185, 0.0373])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4724760055541992 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0049, 0.0286, 0.0167, 0.0377]) \n",
      "Test Loss tensor([0.0046, 0.0062, 0.0356, 0.0196, 0.0379])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.46996569633483887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0045, 0.0328, 0.0209, 0.0370]) \n",
      "Test Loss tensor([0.0047, 0.0061, 0.0356, 0.0197, 0.0373])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.473879337310791 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0059, 0.0339, 0.0212, 0.0376]) \n",
      "Test Loss tensor([0.0045, 0.0059, 0.0343, 0.0191, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.47072863578796387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0062, 0.0309, 0.0178, 0.0369]) \n",
      "Test Loss tensor([0.0045, 0.0061, 0.0344, 0.0192, 0.0372])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.4733142852783203 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0048, 0.0372, 0.0216, 0.0382]) \n",
      "Test Loss tensor([0.0044, 0.0061, 0.0337, 0.0199, 0.0365])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.47116827964782715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0060, 0.0066, 0.0372, 0.0195, 0.0369]) \n",
      "Test Loss tensor([0.0045, 0.0063, 0.0343, 0.0205, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.4701707363128662 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0053, 0.0361, 0.0208, 0.0372]) \n",
      "Test Loss tensor([0.0048, 0.0059, 0.0335, 0.0194, 0.0365])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.4693479537963867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0064, 0.0309, 0.0215, 0.0377]) \n",
      "Test Loss tensor([0.0046, 0.0059, 0.0337, 0.0194, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.4718198776245117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0063, 0.0301, 0.0195, 0.0401]) \n",
      "Test Loss tensor([0.0047, 0.0057, 0.0330, 0.0191, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.4685661792755127 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0058, 0.0376, 0.0207, 0.0370]) \n",
      "Test Loss tensor([0.0045, 0.0054, 0.0352, 0.0188, 0.0376])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.4723656177520752 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0051, 0.0301, 0.0206, 0.0356]) \n",
      "Test Loss tensor([0.0046, 0.0056, 0.0351, 0.0187, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.47101807594299316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0051, 0.0365, 0.0180, 0.0364]) \n",
      "Test Loss tensor([0.0048, 0.0057, 0.0345, 0.0186, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.476855993270874 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0042, 0.0303, 0.0204, 0.0391]) \n",
      "Test Loss tensor([0.0045, 0.0056, 0.0346, 0.0190, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.47904348373413086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0059, 0.0370, 0.0171, 0.0367]) \n",
      "Test Loss tensor([0.0044, 0.0057, 0.0336, 0.0186, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.47249531745910645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0075, 0.0314, 0.0166, 0.0381]) \n",
      "Test Loss tensor([0.0047, 0.0054, 0.0330, 0.0186, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.47696638107299805 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0046, 0.0343, 0.0197, 0.0384]) \n",
      "Test Loss tensor([0.0047, 0.0058, 0.0334, 0.0202, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.4704477787017822 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0046, 0.0372, 0.0200, 0.0353]) \n",
      "Test Loss tensor([0.0044, 0.0060, 0.0331, 0.0200, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4725804328918457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0058, 0.0341, 0.0188, 0.0356]) \n",
      "Test Loss tensor([0.0046, 0.0062, 0.0344, 0.0193, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.47144341468811035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0064, 0.0317, 0.0205, 0.0360]) \n",
      "Test Loss tensor([0.0048, 0.0053, 0.0342, 0.0180, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.47174620628356934 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0054, 0.0307, 0.0184, 0.0358]) \n",
      "Test Loss tensor([0.0045, 0.0054, 0.0339, 0.0186, 0.0373])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.47327494621276855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0044, 0.0314, 0.0182, 0.0359]) \n",
      "Test Loss tensor([0.0046, 0.0056, 0.0342, 0.0185, 0.0370])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.47252631187438965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0049, 0.0330, 0.0224, 0.0362]) \n",
      "Test Loss tensor([0.0047, 0.0054, 0.0348, 0.0183, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.47170543670654297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0055, 0.0346, 0.0193, 0.0378]) \n",
      "Test Loss tensor([0.0045, 0.0053, 0.0334, 0.0188, 0.0372])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 312 in 0.4731252193450928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0054, 0.0355, 0.0206, 0.0378]) \n",
      "Test Loss tensor([0.0046, 0.0053, 0.0345, 0.0181, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.4724395275115967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0044, 0.0356, 0.0185, 0.0358]) \n",
      "Test Loss tensor([0.0051, 0.0057, 0.0322, 0.0188, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4738779067993164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0058, 0.0333, 0.0201, 0.0392]) \n",
      "Test Loss tensor([0.0043, 0.0054, 0.0326, 0.0194, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.47278904914855957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0059, 0.0309, 0.0200, 0.0382]) \n",
      "Test Loss tensor([0.0044, 0.0058, 0.0338, 0.0203, 0.0359])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.4748537540435791 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0068, 0.0354, 0.0186, 0.0353]) \n",
      "Test Loss tensor([0.0048, 0.0056, 0.0319, 0.0201, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4698340892791748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0044, 0.0336, 0.0203, 0.0368]) \n",
      "Test Loss tensor([0.0047, 0.0055, 0.0327, 0.0192, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.47295570373535156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0057, 0.0298, 0.0206, 0.0361]) \n",
      "Test Loss tensor([0.0048, 0.0051, 0.0329, 0.0187, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.46953344345092773 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0043, 0.0325, 0.0170, 0.0360]) \n",
      "Test Loss tensor([0.0047, 0.0054, 0.0337, 0.0190, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4871487617492676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0048, 0.0343, 0.0203, 0.0372]) \n",
      "Test Loss tensor([0.0048, 0.0052, 0.0343, 0.0187, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5090606212615967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0055, 0.0362, 0.0186, 0.0376]) \n",
      "Test Loss tensor([0.0047, 0.0052, 0.0307, 0.0185, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.4714970588684082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0051, 0.0306, 0.0198, 0.0359]) \n",
      "Test Loss tensor([0.0043, 0.0054, 0.0316, 0.0180, 0.0359])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.47295093536376953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0046, 0.0318, 0.0207, 0.0390]) \n",
      "Test Loss tensor([0.0044, 0.0051, 0.0321, 0.0185, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.4698355197906494 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0048, 0.0340, 0.0200, 0.0368]) \n",
      "Test Loss tensor([0.0043, 0.0052, 0.0321, 0.0203, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.47366976737976074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0045, 0.0287, 0.0185, 0.0355]) \n",
      "Test Loss tensor([0.0043, 0.0053, 0.0330, 0.0203, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4692060947418213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0048, 0.0316, 0.0196, 0.0373]) \n",
      "Test Loss tensor([0.0045, 0.0052, 0.0316, 0.0187, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.4705312252044678 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0061, 0.0369, 0.0175, 0.0360]) \n",
      "Test Loss tensor([0.0051, 0.0048, 0.0321, 0.0183, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4716670513153076 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0057, 0.0366, 0.0204, 0.0376]) \n",
      "Test Loss tensor([0.0046, 0.0048, 0.0326, 0.0189, 0.0371])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4920520782470703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0049, 0.0342, 0.0190, 0.0402]) \n",
      "Test Loss tensor([0.0044, 0.0049, 0.0319, 0.0187, 0.0369])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.472212553024292 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0044, 0.0335, 0.0173, 0.0338]) \n",
      "Test Loss tensor([0.0050, 0.0047, 0.0336, 0.0185, 0.0366])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.4759244918823242 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0044, 0.0287, 0.0204, 0.0371]) \n",
      "Test Loss tensor([0.0044, 0.0051, 0.0322, 0.0181, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4667015075683594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0056, 0.0326, 0.0185, 0.0366]) \n",
      "Test Loss tensor([0.0046, 0.0049, 0.0309, 0.0195, 0.0357])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4712710380554199 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0050, 0.0289, 0.0199, 0.0345]) \n",
      "Test Loss tensor([0.0044, 0.0051, 0.0315, 0.0202, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4680771827697754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0058, 0.0319, 0.0212, 0.0382]) \n",
      "Test Loss tensor([0.0045, 0.0049, 0.0314, 0.0197, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4718587398529053 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0058, 0.0313, 0.0191, 0.0335]) \n",
      "Test Loss tensor([0.0046, 0.0051, 0.0302, 0.0179, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.4692549705505371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0048, 0.0302, 0.0179, 0.0364]) \n",
      "Test Loss tensor([0.0046, 0.0045, 0.0326, 0.0183, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.47084879875183105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0058, 0.0340, 0.0184, 0.0362]) \n",
      "Test Loss tensor([0.0043, 0.0054, 0.0324, 0.0190, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4704287052154541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0044, 0.0313, 0.0174, 0.0356]) \n",
      "Test Loss tensor([0.0050, 0.0046, 0.0317, 0.0181, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4698493480682373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0326, 0.0156, 0.0376]) \n",
      "Test Loss tensor([0.0042, 0.0048, 0.0324, 0.0189, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4735291004180908 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0356, 0.0195, 0.0374]) \n",
      "Test Loss tensor([0.0046, 0.0051, 0.0318, 0.0183, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.47197937965393066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0048, 0.0294, 0.0197, 0.0341]) \n",
      "Test Loss tensor([0.0041, 0.0051, 0.0311, 0.0201, 0.0362])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.46994566917419434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0045, 0.0338, 0.0187, 0.0363]) \n",
      "Test Loss tensor([0.0040, 0.0053, 0.0318, 0.0201, 0.0357])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4752671718597412 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0051, 0.0325, 0.0191, 0.0358]) \n",
      "Test Loss tensor([0.0042, 0.0049, 0.0300, 0.0183, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.48458051681518555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0051, 0.0283, 0.0179, 0.0357]) \n",
      "Test Loss tensor([0.0045, 0.0048, 0.0305, 0.0179, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47147536277770996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0055, 0.0290, 0.0178, 0.0365]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0306, 0.0178, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.4718918800354004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0042, 0.0266, 0.0183, 0.0371]) \n",
      "Test Loss tensor([0.0046, 0.0050, 0.0327, 0.0186, 0.0368])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.47078704833984375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0044, 0.0320, 0.0173, 0.0367]) \n",
      "Test Loss tensor([0.0043, 0.0049, 0.0304, 0.0181, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4741816520690918 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0042, 0.0350, 0.0176, 0.0345]) \n",
      "Test Loss tensor([0.0047, 0.0049, 0.0314, 0.0182, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4690272808074951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0055, 0.0328, 0.0152, 0.0350]) \n",
      "Test Loss tensor([0.0047, 0.0050, 0.0297, 0.0179, 0.0359])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4720799922943115 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0294, 0.0187, 0.0357]) \n",
      "Test Loss tensor([0.0041, 0.0049, 0.0299, 0.0190, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4695103168487549 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0051, 0.0279, 0.0170, 0.0394]) \n",
      "Test Loss tensor([0.0046, 0.0050, 0.0298, 0.0192, 0.0360])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4722445011138916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0053, 0.0287, 0.0191, 0.0347]) \n",
      "Test Loss tensor([0.0045, 0.0050, 0.0300, 0.0181, 0.0358])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 476 in 0.4714937210083008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0038, 0.0336, 0.0185, 0.0347]) \n",
      "Test Loss tensor([0.0043, 0.0053, 0.0305, 0.0184, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4703795909881592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0048, 0.0304, 0.0142, 0.0358]) \n",
      "Test Loss tensor([0.0044, 0.0050, 0.0302, 0.0181, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.4707190990447998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0063, 0.0307, 0.0196, 0.0362]) \n",
      "Test Loss tensor([0.0044, 0.0051, 0.0297, 0.0188, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.4705500602722168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0047, 0.0324, 0.0192, 0.0343]) \n",
      "Test Loss tensor([0.0043, 0.0053, 0.0315, 0.0185, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.47118449211120605 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0058, 0.0276, 0.0203, 0.0357]) \n",
      "Test Loss tensor([0.0045, 0.0048, 0.0301, 0.0182, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5035901069641113 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0046, 0.0271, 0.0198, 0.0371]) \n",
      "Test Loss tensor([0.0043, 0.0049, 0.0297, 0.0185, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4844064712524414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0047, 0.0296, 0.0167, 0.0351]) \n",
      "Test Loss tensor([0.0045, 0.0047, 0.0297, 0.0180, 0.0356])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.48287296295166016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0045, 0.0321, 0.0182, 0.0351]) \n",
      "Test Loss tensor([0.0046, 0.0047, 0.0297, 0.0182, 0.0357])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.47121262550354004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0050, 0.0279, 0.0173, 0.0357]) \n",
      "Test Loss tensor([0.0045, 0.0049, 0.0304, 0.0185, 0.0364])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.47060608863830566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0051, 0.0279, 0.0171, 0.0338]) \n",
      "Test Loss tensor([0.0043, 0.0048, 0.0293, 0.0179, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.468735933303833 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0051, 0.0281, 0.0168, 0.0362]) \n",
      "Test Loss tensor([0.0040, 0.0048, 0.0293, 0.0181, 0.0358])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.46904492378234863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0044, 0.0269, 0.0191, 0.0371]) \n",
      "Test Loss tensor([0.0044, 0.0049, 0.0283, 0.0177, 0.0361])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.48410916328430176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0041, 0.0269, 0.0188, 0.0356]) \n",
      "Test Loss tensor([0.0044, 0.0050, 0.0278, 0.0184, 0.0359])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4719882011413574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0040, 0.0262, 0.0193, 0.0357]) \n",
      "Test Loss tensor([0.0047, 0.0048, 0.0297, 0.0189, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4717855453491211 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0041, 0.0301, 0.0201, 0.0376]) \n",
      "Test Loss tensor([0.0042, 0.0048, 0.0288, 0.0181, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4677433967590332 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0049, 0.0288, 0.0206, 0.0353]) \n",
      "Test Loss tensor([0.0044, 0.0048, 0.0285, 0.0179, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.4723937511444092 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0043, 0.0283, 0.0202, 0.0345]) \n",
      "Test Loss tensor([0.0046, 0.0047, 0.0290, 0.0189, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4679124355316162 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0056, 0.0266, 0.0167, 0.0356]) \n",
      "Test Loss tensor([0.0040, 0.0050, 0.0298, 0.0191, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.47049856185913086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0044, 0.0285, 0.0159, 0.0348]) \n",
      "Test Loss tensor([0.0042, 0.0048, 0.0283, 0.0182, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.47029972076416016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0048, 0.0235, 0.0190, 0.0353]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0279, 0.0178, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47228336334228516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0058, 0.0257, 0.0179, 0.0348]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0299, 0.0176, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.475970983505249 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0053, 0.0248, 0.0172, 0.0360]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0289, 0.0170, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.47278451919555664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0048, 0.0301, 0.0182, 0.0355]) \n",
      "Test Loss tensor([0.0045, 0.0049, 0.0280, 0.0174, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4731314182281494 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0045, 0.0284, 0.0178, 0.0358]) \n",
      "Test Loss tensor([0.0044, 0.0047, 0.0279, 0.0177, 0.0353])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.4705038070678711 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0049, 0.0257, 0.0163, 0.0339]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0276, 0.0171, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4719357490539551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0043, 0.0299, 0.0165, 0.0349]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0289, 0.0176, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.4717123508453369 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0050, 0.0312, 0.0159, 0.0341]) \n",
      "Test Loss tensor([0.0042, 0.0049, 0.0281, 0.0172, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4704008102416992 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0041, 0.0279, 0.0189, 0.0359]) \n",
      "Test Loss tensor([0.0048, 0.0044, 0.0290, 0.0173, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.47023963928222656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0052, 0.0272, 0.0161, 0.0357]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0288, 0.0174, 0.0354])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.46988654136657715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0252, 0.0186, 0.0360]) \n",
      "Test Loss tensor([0.0041, 0.0048, 0.0284, 0.0170, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.46729612350463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0042, 0.0251, 0.0161, 0.0334]) \n",
      "Test Loss tensor([0.0046, 0.0048, 0.0302, 0.0175, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.4674854278564453 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0047, 0.0219, 0.0166, 0.0368]) \n",
      "Test Loss tensor([0.0041, 0.0047, 0.0274, 0.0169, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.469088077545166 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0045, 0.0270, 0.0177, 0.0359]) \n",
      "Test Loss tensor([0.0045, 0.0047, 0.0293, 0.0176, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.48432350158691406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0051, 0.0265, 0.0208, 0.0345]) \n",
      "Test Loss tensor([0.0046, 0.0048, 0.0291, 0.0184, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.46749067306518555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0054, 0.0310, 0.0201, 0.0321]) \n",
      "Test Loss tensor([0.0046, 0.0047, 0.0278, 0.0181, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.47077202796936035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0042, 0.0264, 0.0168, 0.0340]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0283, 0.0175, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.4712045192718506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0260, 0.0171, 0.0332]) \n",
      "Test Loss tensor([0.0046, 0.0046, 0.0283, 0.0177, 0.0346])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4732182025909424 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0044, 0.0298, 0.0176, 0.0359]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0283, 0.0176, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47095489501953125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0051, 0.0291, 0.0166, 0.0362]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0281, 0.0174, 0.0349])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.47246885299682617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0037, 0.0294, 0.0177, 0.0345]) \n",
      "Test Loss tensor([0.0039, 0.0048, 0.0283, 0.0181, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4698634147644043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0047, 0.0329, 0.0156, 0.0365]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0278, 0.0178, 0.0351])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 640 in 0.47194480895996094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0280, 0.0175, 0.0373]) \n",
      "Test Loss tensor([0.0050, 0.0043, 0.0290, 0.0168, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.469348669052124 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0044, 0.0249, 0.0150, 0.0336]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0281, 0.0174, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47538113594055176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0056, 0.0277, 0.0182, 0.0349]) \n",
      "Test Loss tensor([0.0047, 0.0045, 0.0285, 0.0175, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.46907615661621094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0051, 0.0301, 0.0201, 0.0348]) \n",
      "Test Loss tensor([0.0045, 0.0046, 0.0282, 0.0167, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4728546142578125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0056, 0.0258, 0.0183, 0.0385]) \n",
      "Test Loss tensor([0.0046, 0.0046, 0.0285, 0.0167, 0.0351])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.47208189964294434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0048, 0.0248, 0.0161, 0.0362]) \n",
      "Test Loss tensor([0.0044, 0.0044, 0.0275, 0.0170, 0.0345])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.47078728675842285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0039, 0.0265, 0.0169, 0.0340]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0281, 0.0179, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4701714515686035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0065, 0.0054, 0.0286, 0.0168, 0.0358]) \n",
      "Test Loss tensor([0.0044, 0.0048, 0.0281, 0.0180, 0.0345])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.467235803604126 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0052, 0.0274, 0.0170, 0.0345]) \n",
      "Test Loss tensor([0.0044, 0.0047, 0.0271, 0.0180, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.47452425956726074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0048, 0.0251, 0.0186, 0.0329]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0275, 0.0164, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47091221809387207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0059, 0.0258, 0.0142, 0.0326]) \n",
      "Test Loss tensor([0.0045, 0.0044, 0.0276, 0.0173, 0.0357])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.47133493423461914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0043, 0.0335, 0.0186, 0.0341]) \n",
      "Test Loss tensor([0.0045, 0.0047, 0.0270, 0.0175, 0.0350])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.4703230857849121 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0052, 0.0253, 0.0191, 0.0359]) \n",
      "Test Loss tensor([0.0046, 0.0044, 0.0269, 0.0167, 0.0352])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4724555015563965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0045, 0.0264, 0.0186, 0.0363]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0270, 0.0178, 0.0348])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4690890312194824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0279, 0.0193, 0.0340]) \n",
      "Test Loss tensor([0.0043, 0.0046, 0.0276, 0.0180, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.4750549793243408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0280, 0.0176, 0.0337]) \n",
      "Test Loss tensor([0.0039, 0.0046, 0.0260, 0.0179, 0.0339])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.4745597839355469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0048, 0.0271, 0.0172, 0.0328]) \n",
      "Test Loss tensor([0.0042, 0.0047, 0.0263, 0.0175, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.47243523597717285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0042, 0.0256, 0.0188, 0.0336]) \n",
      "Test Loss tensor([0.0046, 0.0045, 0.0272, 0.0176, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.471088171005249 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0051, 0.0292, 0.0173, 0.0306]) \n",
      "Test Loss tensor([0.0046, 0.0046, 0.0283, 0.0173, 0.0346])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4712233543395996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0050, 0.0268, 0.0155, 0.0343]) \n",
      "Test Loss tensor([0.0046, 0.0048, 0.0261, 0.0176, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4702775478363037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0043, 0.0269, 0.0206, 0.0356]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0260, 0.0177, 0.0340])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47078919410705566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0047, 0.0307, 0.0176, 0.0318]) \n",
      "Test Loss tensor([0.0041, 0.0047, 0.0262, 0.0182, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4712986946105957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0069, 0.0042, 0.0241, 0.0169, 0.0361]) \n",
      "Test Loss tensor([0.0042, 0.0047, 0.0271, 0.0176, 0.0346])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.46959710121154785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0040, 0.0267, 0.0151, 0.0356]) \n",
      "Test Loss tensor([0.0046, 0.0044, 0.0254, 0.0174, 0.0355])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4691951274871826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0050, 0.0225, 0.0164, 0.0346]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0258, 0.0174, 0.0346])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4695100784301758 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0039, 0.0269, 0.0170, 0.0347]) \n",
      "Test Loss tensor([0.0048, 0.0041, 0.0269, 0.0173, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.471588134765625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0042, 0.0284, 0.0161, 0.0350]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0257, 0.0170, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4674670696258545 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0045, 0.0241, 0.0185, 0.0344]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0255, 0.0166, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4747002124786377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0039, 0.0280, 0.0195, 0.0376]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0253, 0.0174, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.47135114669799805 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0271, 0.0174, 0.0343]) \n",
      "Test Loss tensor([0.0042, 0.0047, 0.0270, 0.0172, 0.0340])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4733254909515381 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0056, 0.0250, 0.0186, 0.0331]) \n",
      "Test Loss tensor([0.0042, 0.0048, 0.0259, 0.0171, 0.0337])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.46842098236083984 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0041, 0.0253, 0.0182, 0.0335]) \n",
      "Test Loss tensor([0.0046, 0.0047, 0.0259, 0.0170, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4710123538970947 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0053, 0.0252, 0.0176, 0.0329]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0257, 0.0167, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.46987152099609375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0044, 0.0258, 0.0155, 0.0324]) \n",
      "Test Loss tensor([0.0048, 0.0044, 0.0263, 0.0168, 0.0345])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.4841439723968506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0308, 0.0168, 0.0337]) \n",
      "Test Loss tensor([0.0041, 0.0044, 0.0261, 0.0174, 0.0335])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.47841405868530273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0044, 0.0239, 0.0156, 0.0357]) \n",
      "Test Loss tensor([0.0043, 0.0049, 0.0260, 0.0174, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.47297000885009766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0237, 0.0165, 0.0341]) \n",
      "Test Loss tensor([0.0041, 0.0048, 0.0250, 0.0175, 0.0339])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.47141075134277344 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0050, 0.0266, 0.0181, 0.0338]) \n",
      "Test Loss tensor([0.0043, 0.0043, 0.0257, 0.0173, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.473341703414917 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0047, 0.0216, 0.0166, 0.0353]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0260, 0.0174, 0.0340])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.47115135192871094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0051, 0.0239, 0.0176, 0.0333]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0257, 0.0174, 0.0347])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4716074466705322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0059, 0.0250, 0.0149, 0.0352]) \n",
      "Test Loss tensor([0.0046, 0.0045, 0.0255, 0.0173, 0.0336])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 804 in 0.4719510078430176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0245, 0.0161, 0.0347]) \n",
      "Test Loss tensor([0.0043, 0.0044, 0.0250, 0.0177, 0.0341])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4709596633911133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0040, 0.0243, 0.0168, 0.0311]) \n",
      "Test Loss tensor([0.0044, 0.0049, 0.0258, 0.0179, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.47263336181640625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0043, 0.0251, 0.0188, 0.0323]) \n",
      "Test Loss tensor([0.0042, 0.0047, 0.0239, 0.0176, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4682743549346924 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0051, 0.0274, 0.0170, 0.0337]) \n",
      "Test Loss tensor([0.0045, 0.0048, 0.0249, 0.0168, 0.0343])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.47000694274902344 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0049, 0.0230, 0.0140, 0.0329]) \n",
      "Test Loss tensor([0.0045, 0.0044, 0.0257, 0.0174, 0.0342])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.47000765800476074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0248, 0.0178, 0.0365]) \n",
      "Test Loss tensor([0.0044, 0.0044, 0.0256, 0.0169, 0.0339])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.47296786308288574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0041, 0.0275, 0.0177, 0.0350]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0250, 0.0168, 0.0339])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4707779884338379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0045, 0.0267, 0.0164, 0.0325]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0242, 0.0176, 0.0337])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.47386932373046875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0040, 0.0260, 0.0167, 0.0358]) \n",
      "Test Loss tensor([0.0045, 0.0046, 0.0248, 0.0176, 0.0338])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.46920061111450195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0046, 0.0217, 0.0168, 0.0338]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0242, 0.0175, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.472470760345459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0052, 0.0269, 0.0181, 0.0325]) \n",
      "Test Loss tensor([0.0042, 0.0044, 0.0236, 0.0170, 0.0337])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4698662757873535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0036, 0.0283, 0.0158, 0.0347]) \n",
      "Test Loss tensor([0.0042, 0.0046, 0.0254, 0.0175, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.4693460464477539 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0048, 0.0268, 0.0166, 0.0343]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0243, 0.0170, 0.0334])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.47171783447265625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0039, 0.0244, 0.0200, 0.0341]) \n",
      "Test Loss tensor([0.0045, 0.0043, 0.0248, 0.0169, 0.0334])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4715907573699951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0240, 0.0173, 0.0332]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0245, 0.0172, 0.0334])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.46994829177856445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0232, 0.0171, 0.0334]) \n",
      "Test Loss tensor([0.0041, 0.0046, 0.0242, 0.0175, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.46994972229003906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0215, 0.0167, 0.0332]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0245, 0.0174, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.4718637466430664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0049, 0.0231, 0.0170, 0.0305]) \n",
      "Test Loss tensor([0.0047, 0.0046, 0.0239, 0.0172, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.45376157760620117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0027, 0.0034, 0.0172, 0.0149, 0.0247]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0240, 0.0167, 0.0334])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5059640407562256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0042, 0.0264, 0.0199, 0.0331]) \n",
      "Test Loss tensor([0.0045, 0.0044, 0.0243, 0.0169, 0.0325])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4735860824584961 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0049, 0.0230, 0.0186, 0.0322]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0239, 0.0170, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5300271511077881 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0046, 0.0257, 0.0143, 0.0344]) \n",
      "Test Loss tensor([0.0044, 0.0047, 0.0242, 0.0171, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4715850353240967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0040, 0.0233, 0.0142, 0.0337]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0246, 0.0171, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4719247817993164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0043, 0.0227, 0.0167, 0.0315]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0237, 0.0171, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.4696216583251953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0046, 0.0224, 0.0184, 0.0324]) \n",
      "Test Loss tensor([0.0041, 0.0045, 0.0237, 0.0168, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4719390869140625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0048, 0.0228, 0.0129, 0.0329]) \n",
      "Test Loss tensor([0.0047, 0.0045, 0.0243, 0.0168, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4706406593322754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0037, 0.0227, 0.0189, 0.0330]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0234, 0.0165, 0.0328])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.4755229949951172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0044, 0.0207, 0.0171, 0.0315]) \n",
      "Test Loss tensor([0.0046, 0.0046, 0.0240, 0.0174, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.47034382820129395 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0054, 0.0271, 0.0195, 0.0313]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0243, 0.0172, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.47387051582336426 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0047, 0.0262, 0.0175, 0.0335]) \n",
      "Test Loss tensor([0.0043, 0.0044, 0.0228, 0.0164, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.49492979049682617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0040, 0.0202, 0.0180, 0.0336]) \n",
      "Test Loss tensor([0.0040, 0.0045, 0.0234, 0.0164, 0.0329])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.47136712074279785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0264, 0.0155, 0.0323]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0252, 0.0169, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47017407417297363 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0044, 0.0259, 0.0156, 0.0338]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0228, 0.0163, 0.0333])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.47182250022888184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0047, 0.0245, 0.0165, 0.0341]) \n",
      "Test Loss tensor([0.0042, 0.0049, 0.0234, 0.0172, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4720289707183838 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0043, 0.0247, 0.0170, 0.0345]) \n",
      "Test Loss tensor([0.0043, 0.0047, 0.0240, 0.0172, 0.0326])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4872870445251465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0052, 0.0252, 0.0153, 0.0316]) \n",
      "Test Loss tensor([0.0042, 0.0045, 0.0253, 0.0174, 0.0324])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4715900421142578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0052, 0.0195, 0.0168, 0.0339]) \n",
      "Test Loss tensor([0.0045, 0.0047, 0.0231, 0.0172, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.46979403495788574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0201, 0.0158, 0.0317]) \n",
      "Test Loss tensor([0.0042, 0.0046, 0.0233, 0.0171, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.47136664390563965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0048, 0.0205, 0.0164, 0.0323]) \n",
      "Test Loss tensor([0.0046, 0.0044, 0.0263, 0.0164, 0.0338])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.4711039066314697 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0042, 0.0233, 0.0176, 0.0344]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0250, 0.0168, 0.0340])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4707672595977783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0056, 0.0259, 0.0182, 0.0347]) \n",
      "Test Loss tensor([0.0041, 0.0045, 0.0237, 0.0163, 0.0328])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 88 in 0.47083258628845215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0042, 0.0257, 0.0181, 0.0337]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0238, 0.0169, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.46910953521728516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0040, 0.0207, 0.0176, 0.0335]) \n",
      "Test Loss tensor([0.0040, 0.0046, 0.0235, 0.0165, 0.0325])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.4712810516357422 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0026, 0.0042, 0.0228, 0.0158, 0.0325]) \n",
      "Test Loss tensor([0.0047, 0.0046, 0.0225, 0.0165, 0.0328])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47382378578186035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0043, 0.0228, 0.0159, 0.0307]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0243, 0.0173, 0.0336])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.47112011909484863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0039, 0.0257, 0.0169, 0.0354]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0233, 0.0165, 0.0328])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4718129634857178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0047, 0.0230, 0.0180, 0.0333]) \n",
      "Test Loss tensor([0.0046, 0.0047, 0.0232, 0.0170, 0.0325])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4678955078125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0049, 0.0214, 0.0173, 0.0322]) \n",
      "Test Loss tensor([0.0042, 0.0047, 0.0235, 0.0166, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4742574691772461 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0051, 0.0225, 0.0138, 0.0306]) \n",
      "Test Loss tensor([0.0040, 0.0045, 0.0239, 0.0171, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4697549343109131 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0052, 0.0228, 0.0208, 0.0329]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0233, 0.0159, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.47231435775756836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0046, 0.0230, 0.0165, 0.0315]) \n",
      "Test Loss tensor([0.0047, 0.0040, 0.0231, 0.0166, 0.0331])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.47292113304138184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0038, 0.0221, 0.0199, 0.0333]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0237, 0.0168, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4722139835357666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0216, 0.0187, 0.0334]) \n",
      "Test Loss tensor([0.0049, 0.0044, 0.0244, 0.0160, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.47004222869873047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0042, 0.0284, 0.0146, 0.0355]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0242, 0.0173, 0.0332])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.47098731994628906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0049, 0.0242, 0.0167, 0.0315]) \n",
      "Test Loss tensor([0.0046, 0.0045, 0.0231, 0.0169, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.4709460735321045 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0205, 0.0168, 0.0321]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0235, 0.0174, 0.0321])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4743208885192871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0237, 0.0175, 0.0313]) \n",
      "Test Loss tensor([0.0045, 0.0045, 0.0240, 0.0167, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.47020459175109863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0042, 0.0232, 0.0170, 0.0344]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0223, 0.0169, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47248315811157227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0044, 0.0227, 0.0174, 0.0332]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0227, 0.0168, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.47296762466430664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0051, 0.0232, 0.0164, 0.0316]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0235, 0.0174, 0.0318])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4731431007385254 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0241, 0.0176, 0.0324]) \n",
      "Test Loss tensor([0.0043, 0.0042, 0.0220, 0.0167, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.47121238708496094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0045, 0.0208, 0.0168, 0.0334]) \n",
      "Test Loss tensor([0.0047, 0.0043, 0.0226, 0.0167, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.47315430641174316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0247, 0.0180, 0.0326]) \n",
      "Test Loss tensor([0.0039, 0.0045, 0.0224, 0.0176, 0.0328])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.47521042823791504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0046, 0.0235, 0.0173, 0.0344]) \n",
      "Test Loss tensor([0.0042, 0.0045, 0.0227, 0.0168, 0.0330])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.46866464614868164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0237, 0.0165, 0.0320]) \n",
      "Test Loss tensor([0.0039, 0.0044, 0.0224, 0.0173, 0.0325])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.47346949577331543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0047, 0.0250, 0.0172, 0.0327]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0237, 0.0164, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.47699761390686035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0048, 0.0259, 0.0156, 0.0325]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0240, 0.0169, 0.0326])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4721980094909668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0042, 0.0202, 0.0163, 0.0328]) \n",
      "Test Loss tensor([0.0051, 0.0042, 0.0247, 0.0160, 0.0316])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.46982860565185547 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0040, 0.0246, 0.0153, 0.0320]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0236, 0.0161, 0.0317])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.4739809036254883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0241, 0.0159, 0.0304]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0222, 0.0169, 0.0320])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.46981120109558105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0047, 0.0235, 0.0175, 0.0312]) \n",
      "Test Loss tensor([0.0044, 0.0048, 0.0237, 0.0175, 0.0323])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.47314929962158203 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0046, 0.0258, 0.0191, 0.0314]) \n",
      "Test Loss tensor([0.0045, 0.0047, 0.0226, 0.0168, 0.0317])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.471311092376709 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0048, 0.0238, 0.0154, 0.0317]) \n",
      "Test Loss tensor([0.0043, 0.0048, 0.0227, 0.0170, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.47242069244384766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0043, 0.0209, 0.0159, 0.0326]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0230, 0.0160, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4699838161468506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0043, 0.0240, 0.0180, 0.0330]) \n",
      "Test Loss tensor([0.0042, 0.0045, 0.0219, 0.0168, 0.0328])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.4726228713989258 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0039, 0.0206, 0.0139, 0.0310]) \n",
      "Test Loss tensor([0.0043, 0.0042, 0.0227, 0.0169, 0.0326])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.4715592861175537 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0047, 0.0236, 0.0195, 0.0325]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0225, 0.0160, 0.0322])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.48389339447021484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0048, 0.0219, 0.0173, 0.0313]) \n",
      "Test Loss tensor([0.0043, 0.0043, 0.0225, 0.0167, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5715255737304688 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0042, 0.0202, 0.0137, 0.0294]) \n",
      "Test Loss tensor([0.0043, 0.0043, 0.0220, 0.0163, 0.0317])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4789612293243408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0043, 0.0208, 0.0165, 0.0312]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0221, 0.0166, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.49153852462768555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0047, 0.0225, 0.0154, 0.0328]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0219, 0.0170, 0.0316])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.493572473526001 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0038, 0.0209, 0.0159, 0.0341]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0225, 0.0163, 0.0312])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 252 in 0.48741745948791504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0043, 0.0192, 0.0180, 0.0322]) \n",
      "Test Loss tensor([0.0046, 0.0044, 0.0209, 0.0161, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.48060011863708496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0049, 0.0220, 0.0155, 0.0313]) \n",
      "Test Loss tensor([0.0044, 0.0045, 0.0209, 0.0165, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6416149139404297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0046, 0.0204, 0.0178, 0.0339]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0217, 0.0170, 0.0316])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6301281452178955 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0040, 0.0235, 0.0170, 0.0312]) \n",
      "Test Loss tensor([0.0044, 0.0046, 0.0225, 0.0172, 0.0319])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5450925827026367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0042, 0.0214, 0.0164, 0.0315]) \n",
      "Test Loss tensor([0.0047, 0.0040, 0.0221, 0.0166, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5345232486724854 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0042, 0.0203, 0.0154, 0.0317]) \n",
      "Test Loss tensor([0.0044, 0.0044, 0.0224, 0.0168, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.500730037689209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0038, 0.0222, 0.0168, 0.0306]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0224, 0.0165, 0.0310])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5231742858886719 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0046, 0.0194, 0.0198, 0.0323]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0223, 0.0168, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5597071647644043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0040, 0.0205, 0.0170, 0.0306]) \n",
      "Test Loss tensor([0.0043, 0.0045, 0.0215, 0.0170, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.673966646194458 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0040, 0.0232, 0.0155, 0.0307]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0213, 0.0169, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5446147918701172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0044, 0.0233, 0.0146, 0.0306]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0223, 0.0165, 0.0315])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5147132873535156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0040, 0.0195, 0.0167, 0.0330]) \n",
      "Test Loss tensor([0.0043, 0.0042, 0.0209, 0.0157, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5372116565704346 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0050, 0.0265, 0.0161, 0.0308]) \n",
      "Test Loss tensor([0.0044, 0.0047, 0.0211, 0.0171, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5433163642883301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0044, 0.0215, 0.0137, 0.0311]) \n",
      "Test Loss tensor([0.0041, 0.0042, 0.0216, 0.0160, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.527472972869873 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0041, 0.0213, 0.0205, 0.0303]) \n",
      "Test Loss tensor([0.0045, 0.0042, 0.0222, 0.0164, 0.0317])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5737226009368896 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0048, 0.0203, 0.0164, 0.0310]) \n",
      "Test Loss tensor([0.0043, 0.0043, 0.0230, 0.0169, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5235016345977783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0048, 0.0197, 0.0163, 0.0300]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0213, 0.0155, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5013399124145508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0035, 0.0188, 0.0183, 0.0297]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0222, 0.0162, 0.0312])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5648524761199951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0051, 0.0264, 0.0154, 0.0310]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0211, 0.0166, 0.0311])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5634591579437256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0038, 0.0205, 0.0164, 0.0304]) \n",
      "Test Loss tensor([0.0045, 0.0042, 0.0207, 0.0166, 0.0314])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5370001792907715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0040, 0.0218, 0.0153, 0.0318]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0215, 0.0162, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5612835884094238 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0037, 0.0224, 0.0153, 0.0322]) \n",
      "Test Loss tensor([0.0050, 0.0040, 0.0212, 0.0152, 0.0309])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5197844505310059 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0045, 0.0244, 0.0182, 0.0318]) \n",
      "Test Loss tensor([0.0043, 0.0044, 0.0215, 0.0154, 0.0310])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5714116096496582 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0207, 0.0140, 0.0322]) \n",
      "Test Loss tensor([0.0041, 0.0045, 0.0214, 0.0162, 0.0309])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5015411376953125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0047, 0.0212, 0.0166, 0.0314]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0218, 0.0157, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5842223167419434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0044, 0.0231, 0.0145, 0.0291]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0212, 0.0155, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5455520153045654 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0047, 0.0212, 0.0174, 0.0297]) \n",
      "Test Loss tensor([0.0047, 0.0043, 0.0211, 0.0158, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5319886207580566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0061, 0.0045, 0.0249, 0.0167, 0.0292]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0219, 0.0166, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.49868178367614746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0039, 0.0191, 0.0168, 0.0329]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0207, 0.0167, 0.0307])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.49867677688598633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0211, 0.0150, 0.0304]) \n",
      "Test Loss tensor([0.0045, 0.0042, 0.0210, 0.0166, 0.0307])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5980949401855469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0038, 0.0215, 0.0161, 0.0323]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0213, 0.0158, 0.0303])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6694743633270264 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0041, 0.0219, 0.0165, 0.0306]) \n",
      "Test Loss tensor([0.0046, 0.0039, 0.0213, 0.0154, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6102809906005859 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0039, 0.0191, 0.0164, 0.0306]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0222, 0.0159, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.49485158920288086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0045, 0.0202, 0.0178, 0.0303]) \n",
      "Test Loss tensor([0.0047, 0.0040, 0.0215, 0.0163, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.53153395652771 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0047, 0.0195, 0.0173, 0.0305]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0207, 0.0153, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5442166328430176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0029, 0.0201, 0.0146, 0.0308]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0202, 0.0161, 0.0303])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5441725254058838 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0195, 0.0159, 0.0313]) \n",
      "Test Loss tensor([0.0045, 0.0043, 0.0205, 0.0158, 0.0302])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5574846267700195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0044, 0.0207, 0.0154, 0.0302]) \n",
      "Test Loss tensor([0.0048, 0.0044, 0.0211, 0.0160, 0.0307])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5679428577423096 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0048, 0.0219, 0.0153, 0.0289]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0217, 0.0161, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5908482074737549 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0062, 0.0037, 0.0188, 0.0147, 0.0301]) \n",
      "Test Loss tensor([0.0048, 0.0045, 0.0209, 0.0163, 0.0297])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5612053871154785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0047, 0.0205, 0.0157, 0.0304]) \n",
      "Test Loss tensor([0.0042, 0.0044, 0.0203, 0.0155, 0.0302])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 416 in 0.6019251346588135 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0044, 0.0209, 0.0179, 0.0305]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0211, 0.0166, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5597288608551025 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0046, 0.0199, 0.0156, 0.0299]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0215, 0.0161, 0.0302])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5886111259460449 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0194, 0.0172, 0.0296]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0211, 0.0162, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5689735412597656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0182, 0.0174, 0.0306]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0213, 0.0158, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.58835768699646 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0185, 0.0160, 0.0283]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0204, 0.0164, 0.0308])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5654983520507812 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0042, 0.0223, 0.0147, 0.0311]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0209, 0.0164, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5500152111053467 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0038, 0.0197, 0.0150, 0.0302]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0215, 0.0163, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.563514232635498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0042, 0.0177, 0.0157, 0.0300]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0218, 0.0160, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.593804121017456 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0045, 0.0230, 0.0178, 0.0301]) \n",
      "Test Loss tensor([0.0047, 0.0041, 0.0203, 0.0161, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.614586353302002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0046, 0.0200, 0.0160, 0.0321]) \n",
      "Test Loss tensor([0.0051, 0.0040, 0.0220, 0.0160, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5470762252807617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0040, 0.0162, 0.0170, 0.0302]) \n",
      "Test Loss tensor([0.0048, 0.0043, 0.0212, 0.0168, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5207276344299316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0043, 0.0237, 0.0177, 0.0288]) \n",
      "Test Loss tensor([0.0048, 0.0041, 0.0207, 0.0158, 0.0306])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5295088291168213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0040, 0.0198, 0.0141, 0.0307]) \n",
      "Test Loss tensor([0.0047, 0.0044, 0.0211, 0.0165, 0.0296])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.4998812675476074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0040, 0.0171, 0.0152, 0.0296]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0225, 0.0165, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.49950456619262695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0039, 0.0220, 0.0165, 0.0310]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0212, 0.0169, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.4914531707763672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0042, 0.0184, 0.0143, 0.0302]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0216, 0.0164, 0.0305])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.49341607093811035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0041, 0.0221, 0.0174, 0.0301]) \n",
      "Test Loss tensor([0.0049, 0.0041, 0.0209, 0.0162, 0.0300])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.496903657913208 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0037, 0.0197, 0.0148, 0.0297]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0208, 0.0162, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.546196699142456 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0044, 0.0205, 0.0190, 0.0300]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0201, 0.0160, 0.0296])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.4958522319793701 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0032, 0.0196, 0.0145, 0.0285]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0210, 0.0169, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5799322128295898 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0208, 0.0170, 0.0309]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0198, 0.0161, 0.0301])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.4969630241394043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0045, 0.0193, 0.0160, 0.0286]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0197, 0.0161, 0.0293])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.49866724014282227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0044, 0.0201, 0.0185, 0.0299]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0205, 0.0161, 0.0293])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.524712324142456 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0189, 0.0137, 0.0289]) \n",
      "Test Loss tensor([0.0047, 0.0042, 0.0204, 0.0157, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.49901676177978516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0044, 0.0223, 0.0154, 0.0281]) \n",
      "Test Loss tensor([0.0044, 0.0038, 0.0193, 0.0159, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.49092769622802734 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0043, 0.0218, 0.0185, 0.0293]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0205, 0.0159, 0.0296])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.48769402503967285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0039, 0.0206, 0.0151, 0.0297]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0203, 0.0163, 0.0296])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4886019229888916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0043, 0.0185, 0.0171, 0.0285]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0203, 0.0159, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.4990408420562744 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0045, 0.0187, 0.0125, 0.0326]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0199, 0.0160, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6097321510314941 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0212, 0.0145, 0.0304]) \n",
      "Test Loss tensor([0.0048, 0.0041, 0.0204, 0.0159, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5631077289581299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0040, 0.0180, 0.0137, 0.0275]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0200, 0.0158, 0.0298])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5240123271942139 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0237, 0.0144, 0.0291]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0212, 0.0164, 0.0297])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5028700828552246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0043, 0.0200, 0.0149, 0.0292]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0187, 0.0160, 0.0296])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6599955558776855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0202, 0.0190, 0.0297]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0208, 0.0161, 0.0293])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5765724182128906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0043, 0.0210, 0.0153, 0.0314]) \n",
      "Test Loss tensor([0.0046, 0.0043, 0.0206, 0.0165, 0.0302])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5086123943328857 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0037, 0.0177, 0.0140, 0.0285]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0190, 0.0162, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4943358898162842 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0193, 0.0138, 0.0294]) \n",
      "Test Loss tensor([0.0045, 0.0042, 0.0205, 0.0169, 0.0294])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.49164509773254395 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0045, 0.0233, 0.0188, 0.0308]) \n",
      "Test Loss tensor([0.0041, 0.0042, 0.0208, 0.0159, 0.0287])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.49164438247680664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0035, 0.0211, 0.0148, 0.0293]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0200, 0.0159, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5139880180358887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0043, 0.0183, 0.0161, 0.0293]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0194, 0.0156, 0.0294])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5291821956634521 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0036, 0.0196, 0.0171, 0.0277]) \n",
      "Test Loss tensor([0.0048, 0.0040, 0.0209, 0.0159, 0.0299])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 580 in 0.5700838565826416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0196, 0.0156, 0.0290]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0198, 0.0161, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5005843639373779 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0046, 0.0192, 0.0150, 0.0288]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0196, 0.0162, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5072245597839355 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0037, 0.0196, 0.0160, 0.0290]) \n",
      "Test Loss tensor([0.0039, 0.0042, 0.0199, 0.0169, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5424740314483643 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0042, 0.0201, 0.0190, 0.0280]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0205, 0.0160, 0.0295])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.49741530418395996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0205, 0.0165, 0.0295]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0199, 0.0160, 0.0289])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5039329528808594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0040, 0.0187, 0.0174, 0.0279]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0201, 0.0165, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.520927906036377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0045, 0.0222, 0.0153, 0.0300]) \n",
      "Test Loss tensor([0.0044, 0.0043, 0.0204, 0.0165, 0.0290])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.48935437202453613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0041, 0.0204, 0.0153, 0.0278]) \n",
      "Test Loss tensor([0.0048, 0.0041, 0.0199, 0.0159, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.48830699920654297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0033, 0.0225, 0.0175, 0.0308]) \n",
      "Test Loss tensor([0.0045, 0.0042, 0.0198, 0.0151, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5055825710296631 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0042, 0.0174, 0.0164, 0.0287]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0199, 0.0161, 0.0285])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.49790263175964355 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0039, 0.0178, 0.0130, 0.0295]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0194, 0.0160, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.565401554107666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0040, 0.0198, 0.0173, 0.0289]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0201, 0.0162, 0.0290])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5341396331787109 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0181, 0.0136, 0.0289]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0196, 0.0157, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5941698551177979 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0041, 0.0189, 0.0163, 0.0302]) \n",
      "Test Loss tensor([0.0047, 0.0040, 0.0202, 0.0164, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5159509181976318 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0041, 0.0170, 0.0156, 0.0273]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0193, 0.0161, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.501777172088623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0042, 0.0195, 0.0157, 0.0277]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0199, 0.0158, 0.0287])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5264244079589844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0044, 0.0171, 0.0168, 0.0281]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0187, 0.0157, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4953432083129883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0035, 0.0172, 0.0169, 0.0288]) \n",
      "Test Loss tensor([0.0048, 0.0039, 0.0190, 0.0166, 0.0291])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4903726577758789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0054, 0.0195, 0.0148, 0.0281]) \n",
      "Test Loss tensor([0.0048, 0.0039, 0.0192, 0.0153, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5198624134063721 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0046, 0.0174, 0.0142, 0.0283]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0192, 0.0156, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.4880335330963135 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0039, 0.0177, 0.0169, 0.0284]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0200, 0.0161, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5188138484954834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0204, 0.0172, 0.0279]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0188, 0.0161, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5215432643890381 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0037, 0.0204, 0.0138, 0.0311]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0192, 0.0165, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5275297164916992 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0044, 0.0196, 0.0170, 0.0310]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0201, 0.0158, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.4852025508880615 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0041, 0.0212, 0.0153, 0.0282]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0192, 0.0162, 0.0288])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5495858192443848 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0174, 0.0174, 0.0287]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0194, 0.0164, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5009255409240723 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0036, 0.0202, 0.0150, 0.0286]) \n",
      "Test Loss tensor([0.0046, 0.0042, 0.0187, 0.0152, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.503887414932251 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0036, 0.0212, 0.0167, 0.0272]) \n",
      "Test Loss tensor([0.0047, 0.0039, 0.0198, 0.0157, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.4906609058380127 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0043, 0.0193, 0.0155, 0.0278]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0200, 0.0154, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5184879302978516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0181, 0.0161, 0.0267]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0193, 0.0159, 0.0285])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5368242263793945 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0037, 0.0196, 0.0173, 0.0300]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0192, 0.0155, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5250675678253174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0047, 0.0217, 0.0182, 0.0302]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0193, 0.0158, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5173120498657227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0186, 0.0155, 0.0283]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0189, 0.0151, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5362899303436279 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0047, 0.0160, 0.0162, 0.0283]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0196, 0.0160, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5661466121673584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0201, 0.0146, 0.0274]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0188, 0.0160, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5931298732757568 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0047, 0.0199, 0.0125, 0.0286]) \n",
      "Test Loss tensor([0.0045, 0.0043, 0.0184, 0.0157, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5990035533905029 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0191, 0.0157, 0.0300]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0198, 0.0164, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5178365707397461 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0038, 0.0178, 0.0179, 0.0280]) \n",
      "Test Loss tensor([0.0044, 0.0042, 0.0194, 0.0165, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5851016044616699 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0045, 0.0225, 0.0151, 0.0281]) \n",
      "Test Loss tensor([0.0049, 0.0041, 0.0195, 0.0159, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.567265510559082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0036, 0.0181, 0.0146, 0.0276]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0195, 0.0159, 0.0286])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5200891494750977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0180, 0.0180, 0.0269]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0192, 0.0164, 0.0283])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 744 in 0.4916980266571045 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0047, 0.0183, 0.0174, 0.0284]) \n",
      "Test Loss tensor([0.0045, 0.0043, 0.0188, 0.0164, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6900339126586914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0035, 0.0184, 0.0164, 0.0263]) \n",
      "Test Loss tensor([0.0047, 0.0039, 0.0182, 0.0152, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5785584449768066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0043, 0.0211, 0.0166, 0.0283]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0184, 0.0164, 0.0282])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6894509792327881 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0034, 0.0171, 0.0142, 0.0282]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0192, 0.0161, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5590255260467529 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0038, 0.0183, 0.0149, 0.0284]) \n",
      "Test Loss tensor([0.0043, 0.0042, 0.0181, 0.0159, 0.0283])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.565584659576416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0202, 0.0150, 0.0273]) \n",
      "Test Loss tensor([0.0047, 0.0040, 0.0196, 0.0162, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5987462997436523 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0037, 0.0175, 0.0181, 0.0263]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0177, 0.0156, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.55780029296875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0039, 0.0198, 0.0159, 0.0278]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0190, 0.0164, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6108696460723877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0042, 0.0179, 0.0172, 0.0279]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0193, 0.0157, 0.0277])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5214574337005615 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0047, 0.0187, 0.0155, 0.0283]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0188, 0.0161, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5683140754699707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0038, 0.0213, 0.0169, 0.0270]) \n",
      "Test Loss tensor([0.0046, 0.0039, 0.0191, 0.0161, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.549095869064331 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0193, 0.0158, 0.0278]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0187, 0.0164, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5335483551025391 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0063, 0.0040, 0.0189, 0.0175, 0.0295]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0187, 0.0164, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5332245826721191 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0042, 0.0184, 0.0162, 0.0278]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0190, 0.0164, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5365579128265381 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0214, 0.0171, 0.0279]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0193, 0.0165, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5341882705688477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0043, 0.0155, 0.0141, 0.0272]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0183, 0.0159, 0.0277])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.4933159351348877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0038, 0.0164, 0.0139, 0.0272]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0185, 0.0154, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5398969650268555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0035, 0.0220, 0.0177, 0.0260]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0183, 0.0167, 0.0281])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5331010818481445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0197, 0.0153, 0.0265]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0185, 0.0163, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5358800888061523 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0180, 0.0168, 0.0254]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0189, 0.0155, 0.0277])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5352048873901367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0043, 0.0163, 0.0130, 0.0296]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0190, 0.0162, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5371384620666504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0042, 0.0188, 0.0175, 0.0282]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0183, 0.0158, 0.0277])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.516808032989502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0209, 0.0157, 0.0269]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0177, 0.0166, 0.0278])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.4922330379486084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0073, 0.0036, 0.0183, 0.0178, 0.0274]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0187, 0.0158, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4830653667449951 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0042, 0.0166, 0.0147, 0.0251]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0188, 0.0165, 0.0279])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5273425579071045 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0040, 0.0192, 0.0175, 0.0272]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0185, 0.0159, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.555138111114502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0040, 0.0187, 0.0210, 0.0272]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0187, 0.0151, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5191442966461182 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0044, 0.0174, 0.0155, 0.0283]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0192, 0.0158, 0.0280])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.4942750930786133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0039, 0.0184, 0.0152, 0.0252]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0186, 0.0163, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4696953296661377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0043, 0.0175, 0.0164, 0.0276]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0182, 0.0161, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4732170104980469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0184, 0.0180, 0.0271]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0189, 0.0161, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.48315978050231934 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0034, 0.0157, 0.0148, 0.0282]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0176, 0.0150, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.473236083984375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0195, 0.0155, 0.0284]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0191, 0.0155, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.4558987617492676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0152, 0.0100, 0.0211]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0203, 0.0153, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5128331184387207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0038, 0.0210, 0.0151, 0.0280]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0192, 0.0154, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.4766252040863037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0041, 0.0180, 0.0156, 0.0271]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0180, 0.0155, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.47922754287719727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0040, 0.0183, 0.0148, 0.0271]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0187, 0.0162, 0.0275])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.4747612476348877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0040, 0.0202, 0.0183, 0.0284]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0193, 0.0162, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4765446186065674 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0037, 0.0193, 0.0144, 0.0267]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0180, 0.0160, 0.0272])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47028517723083496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0041, 0.0194, 0.0164, 0.0275]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0193, 0.0157, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.4662814140319824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0064, 0.0041, 0.0177, 0.0134, 0.0268]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0202, 0.0161, 0.0271])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 28 in 0.4709961414337158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0030, 0.0172, 0.0155, 0.0274]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0178, 0.0161, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.46978092193603516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0037, 0.0174, 0.0175, 0.0279]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0192, 0.0158, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.4715454578399658 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0178, 0.0143, 0.0278]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0182, 0.0158, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4688565731048584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0045, 0.0187, 0.0159, 0.0269]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0190, 0.0157, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.47067809104919434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0036, 0.0172, 0.0174, 0.0281]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0191, 0.0156, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.4685821533203125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0037, 0.0201, 0.0187, 0.0264]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0185, 0.0159, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.4666311740875244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0038, 0.0185, 0.0132, 0.0271]) \n",
      "Test Loss tensor([0.0045, 0.0043, 0.0192, 0.0158, 0.0274])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.46993184089660645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0174, 0.0125, 0.0269]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0174, 0.0153, 0.0276])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.46981096267700195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0036, 0.0162, 0.0177, 0.0264]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0190, 0.0169, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.4707908630371094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0038, 0.0202, 0.0150, 0.0281]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0188, 0.0159, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.4681282043457031 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0045, 0.0189, 0.0134, 0.0247]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0185, 0.0159, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.465869665145874 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0043, 0.0182, 0.0153, 0.0268]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0196, 0.0154, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4674205780029297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0044, 0.0175, 0.0161, 0.0285]) \n",
      "Test Loss tensor([0.0044, 0.0038, 0.0178, 0.0155, 0.0273])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.46809959411621094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0035, 0.0187, 0.0168, 0.0270]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0174, 0.0153, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.4675307273864746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0045, 0.0154, 0.0184, 0.0274]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0193, 0.0155, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.4664621353149414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0042, 0.0211, 0.0163, 0.0263]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0188, 0.0159, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.4664139747619629 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0045, 0.0192, 0.0150, 0.0264]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0172, 0.0155, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.47182130813598633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0045, 0.0184, 0.0143, 0.0272]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0193, 0.0148, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.47110438346862793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0046, 0.0199, 0.0163, 0.0258]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0188, 0.0156, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.4770224094390869 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0044, 0.0197, 0.0141, 0.0259]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0174, 0.0150, 0.0266])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4707815647125244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0041, 0.0157, 0.0127, 0.0256]) \n",
      "Test Loss tensor([0.0040, 0.0042, 0.0177, 0.0157, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.4800393581390381 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0038, 0.0144, 0.0164, 0.0269]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0180, 0.0159, 0.0266])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4674503803253174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0045, 0.0152, 0.0127, 0.0280]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0178, 0.0152, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4763176441192627 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0038, 0.0157, 0.0123, 0.0280]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0175, 0.0155, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4701240062713623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0177, 0.0135, 0.0271]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0179, 0.0158, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5152246952056885 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0034, 0.0166, 0.0164, 0.0258]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0181, 0.0153, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4729459285736084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0047, 0.0168, 0.0141, 0.0262]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0181, 0.0155, 0.0271])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.4722142219543457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0049, 0.0182, 0.0177, 0.0269]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0183, 0.0163, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.4765286445617676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0181, 0.0164, 0.0239]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0186, 0.0165, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.48281335830688477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0161, 0.0155, 0.0270]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0174, 0.0152, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.4743528366088867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0178, 0.0160, 0.0267]) \n",
      "Test Loss tensor([0.0046, 0.0039, 0.0181, 0.0164, 0.0269])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.4728565216064453 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0158, 0.0149, 0.0255]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0184, 0.0158, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.47695422172546387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0036, 0.0191, 0.0129, 0.0277]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0182, 0.0153, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.47217607498168945 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0037, 0.0213, 0.0166, 0.0259]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0178, 0.0161, 0.0268])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5076699256896973 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0038, 0.0183, 0.0152, 0.0257]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0188, 0.0165, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4979894161224365 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0039, 0.0180, 0.0152, 0.0253]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0177, 0.0151, 0.0266])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.48198819160461426 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0035, 0.0173, 0.0166, 0.0270]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0183, 0.0157, 0.0266])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.48172688484191895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0037, 0.0141, 0.0150, 0.0273]) \n",
      "Test Loss tensor([0.0044, 0.0038, 0.0184, 0.0154, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5188076496124268 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0044, 0.0171, 0.0146, 0.0266]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0175, 0.0162, 0.0266])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5392217636108398 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0033, 0.0185, 0.0154, 0.0257]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0184, 0.0158, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5010452270507812 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0195, 0.0163, 0.0279]) \n",
      "Test Loss tensor([0.0045, 0.0038, 0.0183, 0.0151, 0.0266])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 192 in 0.5395452976226807 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0048, 0.0174, 0.0142, 0.0268]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0178, 0.0152, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5336377620697021 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0181, 0.0145, 0.0277]) \n",
      "Test Loss tensor([0.0046, 0.0041, 0.0183, 0.0151, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5455405712127686 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0040, 0.0202, 0.0163, 0.0268]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0188, 0.0160, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5193431377410889 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0042, 0.0181, 0.0141, 0.0252]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0180, 0.0156, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5026147365570068 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0172, 0.0202, 0.0248]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0177, 0.0157, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.493208646774292 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0040, 0.0190, 0.0138, 0.0260]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0184, 0.0157, 0.0261])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.49041032791137695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0043, 0.0193, 0.0143, 0.0252]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0185, 0.0163, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5248327255249023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0037, 0.0182, 0.0168, 0.0274]) \n",
      "Test Loss tensor([0.0046, 0.0039, 0.0174, 0.0154, 0.0263])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5327115058898926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0040, 0.0182, 0.0149, 0.0254]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0181, 0.0153, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.520646333694458 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0176, 0.0163, 0.0267]) \n",
      "Test Loss tensor([0.0047, 0.0041, 0.0185, 0.0159, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5380649566650391 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0043, 0.0175, 0.0160, 0.0270]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0181, 0.0157, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.502286434173584 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0036, 0.0142, 0.0142, 0.0275]) \n",
      "Test Loss tensor([0.0045, 0.0038, 0.0179, 0.0157, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5502848625183105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0037, 0.0153, 0.0160, 0.0259]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0174, 0.0158, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5344288349151611 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0035, 0.0176, 0.0174, 0.0262]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0172, 0.0150, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.48546338081359863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0039, 0.0181, 0.0168, 0.0247]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0173, 0.0155, 0.0267])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.49526548385620117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0040, 0.0159, 0.0137, 0.0260]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0179, 0.0157, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5431580543518066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0042, 0.0175, 0.0163, 0.0252]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0180, 0.0156, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5081079006195068 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0042, 0.0157, 0.0162, 0.0251]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0179, 0.0158, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5195877552032471 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0177, 0.0156, 0.0244]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0174, 0.0156, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5082595348358154 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0175, 0.0135, 0.0253]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0180, 0.0165, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5353865623474121 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0164, 0.0172, 0.0266]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0172, 0.0153, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5399429798126221 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0037, 0.0171, 0.0174, 0.0244]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0179, 0.0150, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5555276870727539 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0040, 0.0169, 0.0176, 0.0262]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0188, 0.0155, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5309860706329346 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0184, 0.0139, 0.0260]) \n",
      "Test Loss tensor([0.0046, 0.0040, 0.0181, 0.0150, 0.0265])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5364797115325928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0043, 0.0153, 0.0166, 0.0264]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0173, 0.0156, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5236570835113525 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0047, 0.0186, 0.0163, 0.0265]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0177, 0.0155, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5167257785797119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0037, 0.0163, 0.0150, 0.0246]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0172, 0.0152, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.533278226852417 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0040, 0.0175, 0.0156, 0.0268]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0171, 0.0151, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5390329360961914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0038, 0.0159, 0.0134, 0.0255]) \n",
      "Test Loss tensor([0.0046, 0.0039, 0.0178, 0.0155, 0.0262])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5007531642913818 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0040, 0.0183, 0.0164, 0.0252]) \n",
      "Test Loss tensor([0.0047, 0.0041, 0.0190, 0.0151, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5277841091156006 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0035, 0.0194, 0.0147, 0.0272]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0180, 0.0160, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5366482734680176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0038, 0.0153, 0.0140, 0.0255]) \n",
      "Test Loss tensor([0.0045, 0.0038, 0.0174, 0.0151, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.4974477291107178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0039, 0.0143, 0.0150, 0.0264]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0181, 0.0163, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4742696285247803 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0034, 0.0172, 0.0140, 0.0258]) \n",
      "Test Loss tensor([0.0043, 0.0037, 0.0172, 0.0155, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5395224094390869 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0039, 0.0152, 0.0151, 0.0255]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0176, 0.0148, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.518883466720581 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0041, 0.0143, 0.0130, 0.0255]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0169, 0.0157, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5339882373809814 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0039, 0.0173, 0.0154, 0.0255]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0172, 0.0155, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5470147132873535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0039, 0.0185, 0.0170, 0.0259]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0177, 0.0153, 0.0254])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5102880001068115 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0147, 0.0119, 0.0256]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0178, 0.0155, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5289077758789062 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0040, 0.0162, 0.0144, 0.0263]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0171, 0.0152, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5386896133422852 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0056, 0.0037, 0.0174, 0.0150, 0.0256]) \n",
      "Test Loss tensor([0.0047, 0.0039, 0.0169, 0.0155, 0.0255])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 356 in 0.5814571380615234 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0040, 0.0189, 0.0157, 0.0264]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0173, 0.0155, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5453076362609863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0177, 0.0145, 0.0272]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0169, 0.0157, 0.0264])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5433821678161621 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0038, 0.0148, 0.0139, 0.0261]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0172, 0.0151, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.49172449111938477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0043, 0.0156, 0.0143, 0.0254]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0172, 0.0149, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.49768662452697754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0048, 0.0179, 0.0129, 0.0261]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0169, 0.0152, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.506009578704834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0045, 0.0173, 0.0131, 0.0260]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0185, 0.0155, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.54526686668396 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0038, 0.0181, 0.0185, 0.0260]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0170, 0.0157, 0.0260])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5192933082580566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0183, 0.0159, 0.0260]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0167, 0.0160, 0.0259])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5557997226715088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0042, 0.0168, 0.0164, 0.0267]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0180, 0.0151, 0.0257])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5564401149749756 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0168, 0.0154, 0.0268]) \n",
      "Test Loss tensor([0.0045, 0.0041, 0.0174, 0.0154, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.4954416751861572 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0043, 0.0158, 0.0131, 0.0258]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0172, 0.0154, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.519895076751709 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0043, 0.0170, 0.0159, 0.0244]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0169, 0.0155, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5226502418518066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0038, 0.0160, 0.0151, 0.0259]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0173, 0.0160, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5475516319274902 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0037, 0.0177, 0.0166, 0.0251]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0163, 0.0156, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.4929046630859375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0166, 0.0150, 0.0259]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0165, 0.0160, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4898488521575928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0043, 0.0165, 0.0163, 0.0253]) \n",
      "Test Loss tensor([0.0044, 0.0037, 0.0166, 0.0151, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.48523640632629395 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0049, 0.0167, 0.0144, 0.0260]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0169, 0.0151, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4910159111022949 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0042, 0.0152, 0.0181, 0.0263]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0163, 0.0156, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5000998973846436 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0040, 0.0154, 0.0157, 0.0247]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0163, 0.0157, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5480608940124512 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0043, 0.0193, 0.0143, 0.0252]) \n",
      "Test Loss tensor([0.0048, 0.0039, 0.0171, 0.0148, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5442144870758057 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0040, 0.0156, 0.0160, 0.0244]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0166, 0.0157, 0.0254])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5131995677947998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0143, 0.0152, 0.0254]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0169, 0.0148, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5467884540557861 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0152, 0.0166, 0.0249]) \n",
      "Test Loss tensor([0.0043, 0.0042, 0.0162, 0.0150, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5142724514007568 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0043, 0.0186, 0.0181, 0.0258]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0173, 0.0152, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.52557373046875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0041, 0.0144, 0.0169, 0.0255]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0163, 0.0163, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.529778242111206 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0036, 0.0163, 0.0176, 0.0246]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0169, 0.0150, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.4940669536590576 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0190, 0.0139, 0.0243]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0165, 0.0148, 0.0256])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5579156875610352 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0204, 0.0175, 0.0249]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0165, 0.0151, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5196712017059326 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0039, 0.0140, 0.0152, 0.0237]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0171, 0.0148, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5328152179718018 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0034, 0.0164, 0.0165, 0.0258]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0168, 0.0151, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5221052169799805 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0041, 0.0157, 0.0159, 0.0235]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0165, 0.0157, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.49026918411254883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0041, 0.0151, 0.0155, 0.0237]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0159, 0.0152, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5270082950592041 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0165, 0.0147, 0.0267]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0166, 0.0158, 0.0251])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5001640319824219 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0040, 0.0147, 0.0151, 0.0248]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0170, 0.0156, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.589454174041748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0037, 0.0150, 0.0160, 0.0246]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0171, 0.0153, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.49370718002319336 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0035, 0.0166, 0.0163, 0.0267]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0164, 0.0154, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6549134254455566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0038, 0.0199, 0.0157, 0.0244]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0166, 0.0150, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5834271907806396 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0172, 0.0164, 0.0250]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0168, 0.0163, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5873947143554688 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0040, 0.0165, 0.0148, 0.0262]) \n",
      "Test Loss tensor([0.0044, 0.0037, 0.0161, 0.0158, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5644090175628662 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0028, 0.0140, 0.0173, 0.0254]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0168, 0.0148, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6137068271636963 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0038, 0.0186, 0.0142, 0.0252]) \n",
      "Test Loss tensor([0.0047, 0.0038, 0.0169, 0.0149, 0.0249])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 520 in 0.5308506488800049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0043, 0.0148, 0.0157, 0.0242]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0163, 0.0153, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5544338226318359 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0153, 0.0157, 0.0240]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0161, 0.0155, 0.0253])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5779533386230469 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0043, 0.0145, 0.0152, 0.0240]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0163, 0.0157, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5045278072357178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0038, 0.0128, 0.0150, 0.0249]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0168, 0.0149, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.4965226650238037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0039, 0.0160, 0.0137, 0.0246]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0161, 0.0154, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5009737014770508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0046, 0.0161, 0.0146, 0.0234]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0159, 0.0148, 0.0247])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5485572814941406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0152, 0.0139, 0.0237]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0165, 0.0151, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5189580917358398 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0039, 0.0170, 0.0181, 0.0262]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0154, 0.0150, 0.0252])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5762016773223877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0037, 0.0145, 0.0152, 0.0248]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0164, 0.0151, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5224761962890625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0039, 0.0172, 0.0183, 0.0250]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0166, 0.0151, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5585205554962158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0042, 0.0148, 0.0157, 0.0249]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0162, 0.0151, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5660920143127441 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0165, 0.0141, 0.0248]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0165, 0.0151, 0.0247])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5064787864685059 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0035, 0.0188, 0.0169, 0.0249]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0161, 0.0151, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.568641185760498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0044, 0.0165, 0.0183, 0.0245]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0156, 0.0144, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5158238410949707 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0148, 0.0152, 0.0225]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0170, 0.0157, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5294783115386963 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0034, 0.0145, 0.0126, 0.0244]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0165, 0.0151, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5439894199371338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0045, 0.0162, 0.0156, 0.0244]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0163, 0.0149, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5002131462097168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0043, 0.0167, 0.0145, 0.0235]) \n",
      "Test Loss tensor([0.0045, 0.0040, 0.0162, 0.0154, 0.0250])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5016658306121826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0042, 0.0158, 0.0134, 0.0250]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0162, 0.0144, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5476295948028564 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0163, 0.0159, 0.0249]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0168, 0.0145, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5591385364532471 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0041, 0.0164, 0.0135, 0.0234]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0174, 0.0149, 0.0248])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5747754573822021 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0037, 0.0167, 0.0148, 0.0239]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0156, 0.0149, 0.0247])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5398190021514893 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0040, 0.0176, 0.0147, 0.0242]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0168, 0.0152, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5891594886779785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0034, 0.0154, 0.0157, 0.0247]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0157, 0.0150, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6110246181488037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0167, 0.0155, 0.0237]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0156, 0.0155, 0.0249])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5569159984588623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0138, 0.0155, 0.0252]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0161, 0.0144, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.610938549041748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0042, 0.0172, 0.0133, 0.0245]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0169, 0.0150, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6233499050140381 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0037, 0.0162, 0.0154, 0.0240]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0157, 0.0156, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5669107437133789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0041, 0.0153, 0.0132, 0.0247]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0167, 0.0156, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5318784713745117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0147, 0.0146, 0.0237]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0159, 0.0148, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5416703224182129 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0035, 0.0148, 0.0132, 0.0232]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0162, 0.0148, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5552608966827393 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0043, 0.0172, 0.0137, 0.0248]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0167, 0.0150, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6146044731140137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0178, 0.0149, 0.0238]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0159, 0.0152, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5216097831726074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0038, 0.0161, 0.0136, 0.0243]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0160, 0.0144, 0.0246])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6136555671691895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0169, 0.0132, 0.0238]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0161, 0.0149, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6269071102142334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0043, 0.0182, 0.0148, 0.0250]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0154, 0.0148, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5394284725189209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0047, 0.0159, 0.0150, 0.0249]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0156, 0.0158, 0.0247])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6973402500152588 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0036, 0.0163, 0.0146, 0.0236]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0153, 0.0157, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5932660102844238 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0040, 0.0137, 0.0146, 0.0239]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0157, 0.0146, 0.0244])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5855507850646973 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0037, 0.0191, 0.0173, 0.0241]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0157, 0.0150, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5624408721923828 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0040, 0.0137, 0.0150, 0.0247]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0154, 0.0152, 0.0242])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 684 in 0.6058745384216309 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0038, 0.0182, 0.0131, 0.0245]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0160, 0.0151, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5606086254119873 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0039, 0.0140, 0.0173, 0.0237]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0154, 0.0144, 0.0245])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5368657112121582 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0046, 0.0145, 0.0183, 0.0243]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0159, 0.0151, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5456554889678955 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0037, 0.0194, 0.0169, 0.0229]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0160, 0.0151, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5815436840057373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0166, 0.0165, 0.0257]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0154, 0.0150, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5347042083740234 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0043, 0.0123, 0.0157, 0.0239]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0164, 0.0152, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5347316265106201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0042, 0.0182, 0.0147, 0.0242]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0161, 0.0151, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5882806777954102 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0151, 0.0129, 0.0236]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0157, 0.0150, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6006734371185303 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0042, 0.0164, 0.0156, 0.0259]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0163, 0.0150, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5104584693908691 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0147, 0.0141, 0.0246]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0172, 0.0149, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5767378807067871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0044, 0.0167, 0.0174, 0.0239]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0156, 0.0142, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5843887329101562 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0141, 0.0148, 0.0230]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0160, 0.0153, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5887143611907959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0041, 0.0156, 0.0145, 0.0227]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0156, 0.0150, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.588331937789917 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0166, 0.0144, 0.0239]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0159, 0.0147, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5429661273956299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0040, 0.0152, 0.0156, 0.0248]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0156, 0.0150, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5059230327606201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0042, 0.0151, 0.0155, 0.0244]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0150, 0.0144, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5292644500732422 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0043, 0.0171, 0.0127, 0.0249]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0159, 0.0155, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5874059200286865 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0166, 0.0162, 0.0231]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0153, 0.0151, 0.0242])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.599492073059082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0042, 0.0149, 0.0163, 0.0252]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0150, 0.0154, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5448424816131592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0163, 0.0142, 0.0236]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0159, 0.0143, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5488102436065674 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0039, 0.0131, 0.0159, 0.0235]) \n",
      "Test Loss tensor([0.0044, 0.0041, 0.0154, 0.0140, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5298008918762207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0038, 0.0161, 0.0133, 0.0245]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0154, 0.0150, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5551760196685791 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0147, 0.0139, 0.0236]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0163, 0.0146, 0.0243])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5901510715484619 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0039, 0.0158, 0.0151, 0.0227]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0162, 0.0151, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5630273818969727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0126, 0.0126, 0.0243]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0148, 0.0148, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5146830081939697 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0034, 0.0149, 0.0141, 0.0221]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0150, 0.0146, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5723938941955566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0160, 0.0165, 0.0232]) \n",
      "Test Loss tensor([0.0040, 0.0042, 0.0161, 0.0153, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5528628826141357 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0170, 0.0155, 0.0247]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0148, 0.0144, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5361020565032959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0041, 0.0160, 0.0145, 0.0240]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0157, 0.0145, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5155410766601562 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0154, 0.0177, 0.0230]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0151, 0.0144, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5529866218566895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0042, 0.0161, 0.0140, 0.0246]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0157, 0.0146, 0.0241])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5465106964111328 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0046, 0.0152, 0.0169, 0.0230]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0155, 0.0153, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5596022605895996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0160, 0.0147, 0.0235]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0158, 0.0148, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5213236808776855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0048, 0.0145, 0.0157, 0.0240]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0154, 0.0150, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5460975170135498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0149, 0.0145, 0.0237]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0158, 0.0142, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5577080249786377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0040, 0.0177, 0.0141, 0.0241]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0156, 0.0155, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5398867130279541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0045, 0.0148, 0.0172, 0.0249]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0159, 0.0146, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5387167930603027 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0039, 0.0153, 0.0143, 0.0230]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0147, 0.0151, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.48290252685546875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0034, 0.0148, 0.0167, 0.0243]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0159, 0.0152, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5018954277038574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0045, 0.0135, 0.0140, 0.0229]) \n",
      "Test Loss tensor([0.0040, 0.0043, 0.0152, 0.0150, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5265319347381592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0037, 0.0161, 0.0142, 0.0228]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0166, 0.0151, 0.0237])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 848 in 0.5521321296691895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0038, 0.0153, 0.0180, 0.0229]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0153, 0.0150, 0.0240])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5276668071746826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0045, 0.0147, 0.0159, 0.0237]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0150, 0.0152, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5895285606384277 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0158, 0.0158, 0.0240]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0152, 0.0149, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5522148609161377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0040, 0.0149, 0.0172, 0.0233]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0150, 0.0150, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5816996097564697 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0038, 0.0136, 0.0149, 0.0227]) \n",
      "Test Loss tensor([0.0045, 0.0038, 0.0154, 0.0146, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5097088813781738 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0038, 0.0157, 0.0148, 0.0229]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0154, 0.0148, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.54166579246521 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0162, 0.0154, 0.0231]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0147, 0.0149, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5201187133789062 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0024, 0.0032, 0.0109, 0.0136, 0.0176]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0151, 0.0149, 0.0238])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5491921901702881 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0147, 0.0158, 0.0220]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0152, 0.0151, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5237374305725098 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0042, 0.0146, 0.0167, 0.0242]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0154, 0.0153, 0.0237])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5157339572906494 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0038, 0.0161, 0.0140, 0.0246]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0151, 0.0152, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5143849849700928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0043, 0.0147, 0.0139, 0.0224]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0153, 0.0147, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5020902156829834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0156, 0.0141, 0.0251]) \n",
      "Test Loss tensor([0.0042, 0.0043, 0.0156, 0.0159, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47896718978881836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0053, 0.0037, 0.0130, 0.0155, 0.0233]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0157, 0.0149, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47455859184265137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0045, 0.0135, 0.0141, 0.0229]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0150, 0.0143, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.51041579246521 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0037, 0.0139, 0.0139, 0.0222]) \n",
      "Test Loss tensor([0.0042, 0.0042, 0.0147, 0.0150, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.520686149597168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0044, 0.0134, 0.0136, 0.0213]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0152, 0.0150, 0.0239])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5071842670440674 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0149, 0.0179, 0.0234]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0153, 0.0150, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.48861050605773926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0174, 0.0142, 0.0244]) \n",
      "Test Loss tensor([0.0044, 0.0040, 0.0150, 0.0146, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.4736030101776123 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0038, 0.0156, 0.0132, 0.0234]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0154, 0.0151, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5222136974334717 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0036, 0.0162, 0.0128, 0.0237]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0153, 0.0146, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5480620861053467 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0161, 0.0183, 0.0229]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0153, 0.0147, 0.0235])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5226080417633057 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0136, 0.0151, 0.0222]) \n",
      "Test Loss tensor([0.0044, 0.0039, 0.0160, 0.0144, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5285003185272217 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0145, 0.0137, 0.0244]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0146, 0.0139, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.567082405090332 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0038, 0.0138, 0.0158, 0.0231]) \n",
      "Test Loss tensor([0.0041, 0.0042, 0.0151, 0.0153, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.48169898986816406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0042, 0.0153, 0.0136, 0.0228]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0146, 0.0150, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.4951472282409668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0045, 0.0138, 0.0166, 0.0232]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0156, 0.0148, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.53849196434021 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0142, 0.0137, 0.0223]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0158, 0.0149, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.515509843826294 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0041, 0.0117, 0.0128, 0.0227]) \n",
      "Test Loss tensor([0.0039, 0.0041, 0.0156, 0.0151, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5005292892456055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0041, 0.0139, 0.0121, 0.0219]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0152, 0.0143, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5397558212280273 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0153, 0.0136, 0.0234]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0145, 0.0156, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5459885597229004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0149, 0.0138, 0.0238]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0145, 0.0146, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.532534122467041 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0041, 0.0134, 0.0146, 0.0238]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0151, 0.0144, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5697097778320312 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0040, 0.0126, 0.0151, 0.0225]) \n",
      "Test Loss tensor([0.0041, 0.0041, 0.0149, 0.0144, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5725362300872803 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0045, 0.0166, 0.0140, 0.0221]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0142, 0.0145, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5420496463775635 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0037, 0.0150, 0.0156, 0.0224]) \n",
      "Test Loss tensor([0.0042, 0.0041, 0.0153, 0.0146, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5975453853607178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0038, 0.0135, 0.0169, 0.0227]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0153, 0.0145, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5625760555267334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0150, 0.0151, 0.0221]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0144, 0.0151, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5702502727508545 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0037, 0.0151, 0.0142, 0.0218]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0143, 0.0147, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.4957900047302246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0057, 0.0034, 0.0154, 0.0139, 0.0223]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0146, 0.0143, 0.0234])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.524813175201416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0048, 0.0132, 0.0160, 0.0226]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0147, 0.0144, 0.0230])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 132 in 0.6470053195953369 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0040, 0.0165, 0.0143, 0.0250]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0149, 0.0149, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5717477798461914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0124, 0.0136, 0.0227]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0146, 0.0154, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.587226390838623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0040, 0.0143, 0.0140, 0.0220]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0152, 0.0152, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5743732452392578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0147, 0.0126, 0.0218]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0156, 0.0149, 0.0232])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6078376770019531 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0047, 0.0155, 0.0136, 0.0237]) \n",
      "Test Loss tensor([0.0039, 0.0041, 0.0150, 0.0145, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5793442726135254 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0136, 0.0159, 0.0229]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0161, 0.0144, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5415389537811279 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0152, 0.0138, 0.0232]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0148, 0.0148, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5768899917602539 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0035, 0.0150, 0.0128, 0.0223]) \n",
      "Test Loss tensor([0.0039, 0.0041, 0.0159, 0.0154, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5618300437927246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0044, 0.0144, 0.0157, 0.0242]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0157, 0.0139, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5315823554992676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0141, 0.0151, 0.0223]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0151, 0.0144, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5240159034729004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0043, 0.0129, 0.0113, 0.0239]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0149, 0.0147, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5487885475158691 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0040, 0.0166, 0.0167, 0.0241]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0155, 0.0144, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5727274417877197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0041, 0.0141, 0.0129, 0.0227]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0154, 0.0148, 0.0231])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6012756824493408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0142, 0.0142, 0.0221]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0145, 0.0150, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5846226215362549 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0039, 0.0142, 0.0140, 0.0223]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0147, 0.0147, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6004788875579834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0059, 0.0040, 0.0152, 0.0139, 0.0229]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0151, 0.0145, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.4922912120819092 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0132, 0.0144, 0.0231]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0150, 0.0144, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5263867378234863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0043, 0.0140, 0.0147, 0.0227]) \n",
      "Test Loss tensor([0.0039, 0.0042, 0.0146, 0.0145, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.601459264755249 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0138, 0.0171, 0.0231]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0147, 0.0144, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4883604049682617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0037, 0.0140, 0.0150, 0.0240]) \n",
      "Test Loss tensor([0.0039, 0.0042, 0.0156, 0.0143, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.48288464546203613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0040, 0.0150, 0.0167, 0.0210]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0149, 0.0150, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.49514269828796387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0040, 0.0127, 0.0161, 0.0230]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0142, 0.0146, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.548297643661499 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0038, 0.0142, 0.0152, 0.0229]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0151, 0.0141, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5962972640991211 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0044, 0.0145, 0.0144, 0.0207]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0133, 0.0148, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5451779365539551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0038, 0.0131, 0.0156, 0.0215]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0147, 0.0141, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.4910728931427002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0037, 0.0148, 0.0174, 0.0228]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0144, 0.0148, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.48928189277648926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0041, 0.0135, 0.0157, 0.0229]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0149, 0.0136, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.48181986808776855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0149, 0.0177, 0.0239]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0154, 0.0142, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5161898136138916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0039, 0.0144, 0.0152, 0.0220]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0147, 0.0143, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5117158889770508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0173, 0.0154, 0.0214]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0149, 0.0149, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.568706750869751 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0040, 0.0133, 0.0138, 0.0225]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0153, 0.0145, 0.0230])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5347561836242676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0141, 0.0133, 0.0209]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0149, 0.0144, 0.0229])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5522494316101074 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0036, 0.0161, 0.0120, 0.0215]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0152, 0.0152, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5769991874694824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0039, 0.0163, 0.0162, 0.0219]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0160, 0.0147, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5757546424865723 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0040, 0.0147, 0.0137, 0.0232]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0145, 0.0147, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5425913333892822 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0051, 0.0153, 0.0131, 0.0226]) \n",
      "Test Loss tensor([0.0039, 0.0041, 0.0151, 0.0151, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5687727928161621 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0158, 0.0150, 0.0220]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0148, 0.0150, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5356564521789551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0148, 0.0165, 0.0224]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0155, 0.0145, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5359172821044922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0147, 0.0146, 0.0228]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0154, 0.0141, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5422325134277344 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0043, 0.0156, 0.0150, 0.0217]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0155, 0.0145, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.528083086013794 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0047, 0.0152, 0.0134, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0146, 0.0143, 0.0226])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 296 in 0.5438940525054932 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0141, 0.0159, 0.0216]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0151, 0.0146, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5327517986297607 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0035, 0.0159, 0.0145, 0.0223]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0153, 0.0144, 0.0227])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5420305728912354 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0140, 0.0148, 0.0229]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0153, 0.0146, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5298974514007568 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0039, 0.0158, 0.0172, 0.0239]) \n",
      "Test Loss tensor([0.0042, 0.0040, 0.0154, 0.0145, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5111980438232422 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0043, 0.0140, 0.0149, 0.0220]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0147, 0.0145, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5287625789642334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0042, 0.0152, 0.0166, 0.0217]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0138, 0.0145, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5564255714416504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0039, 0.0166, 0.0111, 0.0223]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0146, 0.0143, 0.0225])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5371325016021729 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0035, 0.0133, 0.0138, 0.0218]) \n",
      "Test Loss tensor([0.0040, 0.0041, 0.0148, 0.0145, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5238494873046875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0035, 0.0148, 0.0140, 0.0225]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0147, 0.0139, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4918026924133301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0042, 0.0148, 0.0157, 0.0223]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0147, 0.0147, 0.0228])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.479677677154541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0040, 0.0136, 0.0140, 0.0207]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0146, 0.0146, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5705506801605225 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0086, 0.0155, 0.0227]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0147, 0.0146, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4994385242462158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0051, 0.0138, 0.0169, 0.0220]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0144, 0.0144, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.47765231132507324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0038, 0.0118, 0.0140, 0.0219]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0148, 0.0139, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.48100852966308594 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0129, 0.0122, 0.0227]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0145, 0.0141, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.48789477348327637 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0160, 0.0160, 0.0235]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0147, 0.0141, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.48041701316833496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0153, 0.0138, 0.0213]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0145, 0.0146, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.48110032081604004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0135, 0.0149, 0.0211]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0145, 0.0142, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.47853946685791016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0042, 0.0153, 0.0117, 0.0219]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0150, 0.0140, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.48122358322143555 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0039, 0.0131, 0.0144, 0.0214]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0142, 0.0146, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.4837636947631836 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0140, 0.0127, 0.0216]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0148, 0.0144, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4788522720336914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0161, 0.0155, 0.0224]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0152, 0.0148, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5496482849121094 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0035, 0.0151, 0.0164, 0.0222]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0146, 0.0142, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5354583263397217 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0045, 0.0145, 0.0155, 0.0216]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0138, 0.0138, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.561622142791748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0120, 0.0144, 0.0225]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0138, 0.0144, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5101263523101807 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0123, 0.0147, 0.0217]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0152, 0.0140, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5245819091796875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0038, 0.0152, 0.0146, 0.0218]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0144, 0.0141, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5234799385070801 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0039, 0.0145, 0.0150, 0.0218]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0143, 0.0147, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.49279189109802246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0055, 0.0037, 0.0145, 0.0152, 0.0219]) \n",
      "Test Loss tensor([0.0036, 0.0039, 0.0146, 0.0145, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5273303985595703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0162, 0.0134, 0.0225]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0145, 0.0142, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.4792368412017822 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0115, 0.0182, 0.0219]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0140, 0.0149, 0.0226])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.4737703800201416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0042, 0.0150, 0.0146, 0.0233]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0139, 0.0142, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.4740140438079834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0039, 0.0132, 0.0151, 0.0223]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0141, 0.0150, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5045084953308105 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0036, 0.0135, 0.0151, 0.0217]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0143, 0.0143, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4902489185333252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0143, 0.0146, 0.0216]) \n",
      "Test Loss tensor([0.0040, 0.0040, 0.0138, 0.0146, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.4876728057861328 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0033, 0.0118, 0.0142, 0.0205]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0143, 0.0148, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.4796004295349121 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0039, 0.0131, 0.0155, 0.0228]) \n",
      "Test Loss tensor([0.0038, 0.0040, 0.0141, 0.0150, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.47481226921081543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0040, 0.0149, 0.0140, 0.0204]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0141, 0.0142, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.47714829444885254 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0043, 0.0137, 0.0176, 0.0211]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0142, 0.0144, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.47609829902648926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0037, 0.0163, 0.0152, 0.0217]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0144, 0.0141, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.4743795394897461 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0039, 0.0151, 0.0154, 0.0223]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0143, 0.0144, 0.0217])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 460 in 0.48783445358276367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0116, 0.0168, 0.0218]) \n",
      "Test Loss tensor([0.0043, 0.0040, 0.0142, 0.0149, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.47577667236328125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0123, 0.0131, 0.0216]) \n",
      "Test Loss tensor([0.0043, 0.0038, 0.0146, 0.0141, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.47542500495910645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0038, 0.0141, 0.0151, 0.0215]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0150, 0.0144, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.4744846820831299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0122, 0.0121, 0.0225]) \n",
      "Test Loss tensor([0.0043, 0.0041, 0.0149, 0.0149, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.475482702255249 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0127, 0.0142, 0.0222]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0141, 0.0149, 0.0223])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.4812126159667969 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0141, 0.0157, 0.0227]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0141, 0.0142, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.47852182388305664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0038, 0.0147, 0.0133, 0.0212]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0137, 0.0139, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.47473764419555664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0041, 0.0130, 0.0131, 0.0226]) \n",
      "Test Loss tensor([0.0041, 0.0040, 0.0145, 0.0145, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.472886323928833 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0139, 0.0180, 0.0212]) \n",
      "Test Loss tensor([0.0043, 0.0039, 0.0143, 0.0146, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5541963577270508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0042, 0.0149, 0.0147, 0.0215]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0149, 0.0141, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5070021152496338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0152, 0.0133, 0.0215]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0140, 0.0142, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.4758577346801758 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0162, 0.0130, 0.0218]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0141, 0.0142, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4723658561706543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0134, 0.0129, 0.0232]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0137, 0.0141, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.4738004207611084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0039, 0.0153, 0.0168, 0.0205]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0141, 0.0140, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.4725794792175293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0132, 0.0133, 0.0219]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0137, 0.0144, 0.0218])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.4791593551635742 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0038, 0.0130, 0.0134, 0.0230]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0141, 0.0149, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.4841172695159912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0037, 0.0148, 0.0175, 0.0210]) \n",
      "Test Loss tensor([0.0042, 0.0036, 0.0132, 0.0143, 0.0222])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.47548842430114746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0039, 0.0149, 0.0147, 0.0219]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0138, 0.0146, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.4911355972290039 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0040, 0.0136, 0.0132, 0.0213]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0147, 0.0148, 0.0220])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6086399555206299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0155, 0.0156, 0.0205]) \n",
      "Test Loss tensor([0.0042, 0.0036, 0.0141, 0.0142, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5069031715393066 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0038, 0.0125, 0.0136, 0.0224]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0140, 0.0141, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.4849412441253662 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0145, 0.0147, 0.0229]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0145, 0.0141, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.4761202335357666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0151, 0.0129, 0.0220]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0132, 0.0144, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.478696346282959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0040, 0.0155, 0.0137, 0.0213]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0140, 0.0144, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.47664308547973633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0148, 0.0140, 0.0209]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0136, 0.0144, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5561802387237549 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0039, 0.0147, 0.0133, 0.0212]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0142, 0.0146, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.536243200302124 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0041, 0.0143, 0.0144, 0.0221]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0143, 0.0143, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.4872629642486572 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0045, 0.0145, 0.0139, 0.0209]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0142, 0.0141, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.47612810134887695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0044, 0.0125, 0.0151, 0.0211]) \n",
      "Test Loss tensor([0.0039, 0.0040, 0.0144, 0.0147, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.4821135997772217 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0042, 0.0123, 0.0135, 0.0224]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0140, 0.0142, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.48054933547973633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0121, 0.0146, 0.0216]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0138, 0.0147, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.48992300033569336 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0129, 0.0125, 0.0231]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0141, 0.0145, 0.0221])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4834909439086914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0136, 0.0140, 0.0210]) \n",
      "Test Loss tensor([0.0042, 0.0036, 0.0135, 0.0144, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4773697853088379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0036, 0.0117, 0.0143, 0.0217]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0137, 0.0145, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.47802209854125977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0036, 0.0143, 0.0117, 0.0206]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0138, 0.0145, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.480222225189209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0041, 0.0146, 0.0140, 0.0216]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0135, 0.0146, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.47772979736328125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0135, 0.0151, 0.0222]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0142, 0.0148, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.4765899181365967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0042, 0.0156, 0.0173, 0.0208]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0139, 0.0139, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.47411251068115234 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0054, 0.0037, 0.0148, 0.0144, 0.0199]) \n",
      "Test Loss tensor([0.0037, 0.0038, 0.0144, 0.0146, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.4786407947540283 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0038, 0.0144, 0.0138, 0.0222]) \n",
      "Test Loss tensor([0.0037, 0.0039, 0.0134, 0.0151, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5561754703521729 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0149, 0.0159, 0.0219]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0139, 0.0147, 0.0214])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 624 in 0.4971950054168701 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0037, 0.0153, 0.0144, 0.0212]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0138, 0.0144, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.47847795486450195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0035, 0.0140, 0.0139, 0.0215]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0137, 0.0145, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.4786818027496338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0033, 0.0124, 0.0129, 0.0220]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0142, 0.0143, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.4769260883331299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0039, 0.0141, 0.0146, 0.0208]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0133, 0.0145, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.48016858100891113 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0038, 0.0150, 0.0154, 0.0213]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0134, 0.0151, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.48048949241638184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0039, 0.0144, 0.0151, 0.0223]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0139, 0.0145, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.47687482833862305 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0042, 0.0151, 0.0163, 0.0219]) \n",
      "Test Loss tensor([0.0037, 0.0038, 0.0142, 0.0143, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.4767012596130371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0042, 0.0160, 0.0153, 0.0219]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0142, 0.0140, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.4932985305786133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0042, 0.0140, 0.0119, 0.0215]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0140, 0.0142, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5093646049499512 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0038, 0.0115, 0.0128, 0.0205]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0136, 0.0139, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.4794015884399414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0036, 0.0115, 0.0132, 0.0217]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0137, 0.0142, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.4795668125152588 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0141, 0.0142, 0.0226]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0134, 0.0139, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.4785640239715576 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0037, 0.0142, 0.0156, 0.0217]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0140, 0.0141, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.47832489013671875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0037, 0.0150, 0.0125, 0.0217]) \n",
      "Test Loss tensor([0.0042, 0.0038, 0.0134, 0.0139, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.47763872146606445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0159, 0.0126, 0.0202]) \n",
      "Test Loss tensor([0.0035, 0.0039, 0.0135, 0.0147, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.511544942855835 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0133, 0.0167, 0.0211]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0140, 0.0144, 0.0216])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5364806652069092 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0136, 0.0132, 0.0201]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0132, 0.0148, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5324118137359619 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0041, 0.0151, 0.0144, 0.0208]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0136, 0.0141, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5203492641448975 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0157, 0.0148, 0.0215]) \n",
      "Test Loss tensor([0.0038, 0.0039, 0.0140, 0.0141, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.48691296577453613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0149, 0.0153, 0.0209]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0137, 0.0144, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.477994441986084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0032, 0.0127, 0.0141, 0.0220]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0138, 0.0144, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.48816895484924316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0037, 0.0113, 0.0169, 0.0203]) \n",
      "Test Loss tensor([0.0037, 0.0037, 0.0135, 0.0141, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5258562564849854 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0041, 0.0149, 0.0152, 0.0189]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0140, 0.0143, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4802882671356201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0117, 0.0148, 0.0217]) \n",
      "Test Loss tensor([0.0040, 0.0039, 0.0141, 0.0142, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.4753708839416504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0117, 0.0140, 0.0219]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0133, 0.0143, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.47730112075805664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0041, 0.0153, 0.0155, 0.0214]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0136, 0.0145, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.4742889404296875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0143, 0.0131, 0.0228]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0132, 0.0147, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.47783899307250977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0034, 0.0120, 0.0137, 0.0210]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0138, 0.0147, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.4725773334503174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0150, 0.0139, 0.0192]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0140, 0.0147, 0.0214])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.4768040180206299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0036, 0.0147, 0.0135, 0.0205]) \n",
      "Test Loss tensor([0.0037, 0.0037, 0.0140, 0.0135, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4740455150604248 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0136, 0.0149, 0.0225]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0140, 0.0150, 0.0217])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.490795373916626 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0040, 0.0148, 0.0154, 0.0209]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0136, 0.0147, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.4739964008331299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0128, 0.0142, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0131, 0.0138, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.533287763595581 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0041, 0.0142, 0.0157, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0143, 0.0141, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5251569747924805 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0040, 0.0146, 0.0133, 0.0208]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0136, 0.0144, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.571347713470459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0037, 0.0137, 0.0146, 0.0217]) \n",
      "Test Loss tensor([0.0042, 0.0039, 0.0139, 0.0138, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.530195951461792 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0039, 0.0139, 0.0149, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0132, 0.0133, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5733261108398438 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0138, 0.0130, 0.0205]) \n",
      "Test Loss tensor([0.0037, 0.0039, 0.0133, 0.0137, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.539351224899292 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0041, 0.0151, 0.0131, 0.0212]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0132, 0.0139, 0.0212])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5360677242279053 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0034, 0.0126, 0.0128, 0.0211]) \n",
      "Test Loss tensor([0.0037, 0.0038, 0.0133, 0.0143, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.48177647590637207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0143, 0.0145, 0.0206]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0130, 0.0140, 0.0209])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 788 in 0.5341935157775879 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0039, 0.0135, 0.0139, 0.0193]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0135, 0.0138, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.480440616607666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0039, 0.0127, 0.0130, 0.0205]) \n",
      "Test Loss tensor([0.0041, 0.0039, 0.0141, 0.0138, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.473543643951416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0029, 0.0133, 0.0145, 0.0207]) \n",
      "Test Loss tensor([0.0045, 0.0039, 0.0131, 0.0150, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4709041118621826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0045, 0.0133, 0.0148, 0.0193]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0138, 0.0137, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5046930313110352 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0037, 0.0140, 0.0127, 0.0202]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0136, 0.0140, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5871319770812988 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0031, 0.0129, 0.0140, 0.0201]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0134, 0.0137, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.48203420639038086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0042, 0.0151, 0.0171, 0.0205]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0136, 0.0140, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.47313737869262695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0033, 0.0126, 0.0142, 0.0212]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0132, 0.0140, 0.0215])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.46817684173583984 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0035, 0.0128, 0.0133, 0.0212]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0134, 0.0139, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.46805787086486816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0150, 0.0179, 0.0213]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0135, 0.0142, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.48204541206359863 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0040, 0.0157, 0.0134, 0.0220]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0135, 0.0136, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.47384190559387207 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0040, 0.0124, 0.0137, 0.0202]) \n",
      "Test Loss tensor([0.0041, 0.0038, 0.0135, 0.0138, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.48298001289367676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0040, 0.0140, 0.0142, 0.0223]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0138, 0.0132, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4701242446899414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0037, 0.0139, 0.0132, 0.0217]) \n",
      "Test Loss tensor([0.0044, 0.0038, 0.0141, 0.0143, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.47662806510925293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0045, 0.0128, 0.0154, 0.0211]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0133, 0.0143, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.46988892555236816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0037, 0.0130, 0.0134, 0.0205]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0133, 0.0137, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5129830837249756 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0131, 0.0149, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0139, 0.0136, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5179932117462158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0040, 0.0135, 0.0138, 0.0207]) \n",
      "Test Loss tensor([0.0035, 0.0038, 0.0136, 0.0140, 0.0213])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.47307372093200684 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0120, 0.0139, 0.0198]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0129, 0.0137, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4753434658050537 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0125, 0.0112, 0.0205]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0132, 0.0139, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.4791231155395508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0131, 0.0143, 0.0206]) \n",
      "Test Loss tensor([0.0043, 0.0035, 0.0130, 0.0139, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5119967460632324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0107, 0.0141, 0.0201]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0135, 0.0142, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5987579822540283 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0021, 0.0033, 0.0090, 0.0100, 0.0155]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0125, 0.0138, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5817153453826904 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0136, 0.0145, 0.0200]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0137, 0.0136, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6174297332763672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0034, 0.0120, 0.0146, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0132, 0.0141, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6498792171478271 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0044, 0.0121, 0.0128, 0.0201]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0134, 0.0143, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5644640922546387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0120, 0.0121, 0.0221]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0138, 0.0138, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.4862194061279297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0110, 0.0156, 0.0215]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0140, 0.0138, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.47308897972106934 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0039, 0.0146, 0.0130, 0.0211]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0137, 0.0136, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.47718071937561035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0038, 0.0108, 0.0150, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0134, 0.0140, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.4757375717163086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0142, 0.0127, 0.0208]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0136, 0.0138, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5272631645202637 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0128, 0.0123, 0.0199]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0134, 0.0138, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5233972072601318 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0044, 0.0142, 0.0162, 0.0193]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0130, 0.0136, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.4897332191467285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0044, 0.0106, 0.0121, 0.0203]) \n",
      "Test Loss tensor([0.0037, 0.0037, 0.0125, 0.0140, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6236166954040527 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0129, 0.0150, 0.0212]) \n",
      "Test Loss tensor([0.0040, 0.0038, 0.0126, 0.0137, 0.0209])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5560526847839355 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0034, 0.0100, 0.0135, 0.0207]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0135, 0.0143, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.47416234016418457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0107, 0.0145, 0.0210]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0137, 0.0145, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.47345566749572754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0038, 0.0128, 0.0140, 0.0206]) \n",
      "Test Loss tensor([0.0042, 0.0035, 0.0135, 0.0135, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.4960205554962158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0124, 0.0130, 0.0207]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0128, 0.0137, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5906288623809814 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0036, 0.0128, 0.0131, 0.0215]) \n",
      "Test Loss tensor([0.0043, 0.0037, 0.0130, 0.0142, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6158864498138428 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0038, 0.0147, 0.0142, 0.0196]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0137, 0.0144, 0.0210])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 72 in 0.5393874645233154 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0151, 0.0135, 0.0195]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0129, 0.0139, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.4869384765625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0038, 0.0121, 0.0135, 0.0207]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0148, 0.0138, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5236721038818359 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0034, 0.0148, 0.0137, 0.0199]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0141, 0.0139, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6543467044830322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0124, 0.0150, 0.0206]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0135, 0.0138, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5211935043334961 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0121, 0.0144, 0.0203]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0145, 0.0140, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5141122341156006 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0038, 0.0139, 0.0141, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0133, 0.0134, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5234794616699219 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0041, 0.0123, 0.0147, 0.0190]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0136, 0.0140, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.4759187698364258 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0106, 0.0132, 0.0208]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0140, 0.0141, 0.0211])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5545303821563721 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0037, 0.0153, 0.0163, 0.0205]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0134, 0.0137, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4831550121307373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0037, 0.0127, 0.0133, 0.0198]) \n",
      "Test Loss tensor([0.0037, 0.0037, 0.0135, 0.0136, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5124557018280029 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0039, 0.0130, 0.0140, 0.0201]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0133, 0.0138, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.4840738773345947 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0033, 0.0121, 0.0133, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0129, 0.0139, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.4807276725769043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0108, 0.0141, 0.0186]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0128, 0.0134, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.49103713035583496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0138, 0.0134, 0.0214]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0128, 0.0142, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5072896480560303 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0157, 0.0145, 0.0217]) \n",
      "Test Loss tensor([0.0039, 0.0039, 0.0130, 0.0140, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5306546688079834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0033, 0.0151, 0.0142, 0.0199]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0135, 0.0138, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5431113243103027 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0141, 0.0154, 0.0201]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0132, 0.0136, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6483948230743408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0039, 0.0132, 0.0137, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0132, 0.0137, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5322129726409912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0040, 0.0119, 0.0134, 0.0200]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0135, 0.0139, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5812525749206543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0032, 0.0144, 0.0103, 0.0204]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0126, 0.0138, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5542442798614502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0036, 0.0129, 0.0141, 0.0207]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0129, 0.0134, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6278841495513916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0130, 0.0153, 0.0209]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0128, 0.0138, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6275506019592285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0040, 0.0140, 0.0138, 0.0204]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0136, 0.0138, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5310707092285156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0037, 0.0101, 0.0151, 0.0207]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0133, 0.0136, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.624711275100708 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0132, 0.0129, 0.0212]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0130, 0.0135, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.676692008972168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0125, 0.0139, 0.0199]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0128, 0.0137, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5812201499938965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0120, 0.0142, 0.0205]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0130, 0.0140, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.55863356590271 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0040, 0.0147, 0.0134, 0.0195]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0127, 0.0146, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.587270975112915 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0038, 0.0135, 0.0161, 0.0202]) \n",
      "Test Loss tensor([0.0039, 0.0038, 0.0134, 0.0140, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6678497791290283 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0094, 0.0116, 0.0205]) \n",
      "Test Loss tensor([0.0041, 0.0036, 0.0121, 0.0140, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6579439640045166 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0036, 0.0132, 0.0136, 0.0220]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0130, 0.0135, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5865297317504883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0129, 0.0129, 0.0205]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0129, 0.0142, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5103640556335449 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0120, 0.0142, 0.0197]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0131, 0.0141, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.49946045875549316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0119, 0.0136, 0.0194]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0133, 0.0140, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.4827597141265869 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0036, 0.0110, 0.0151, 0.0208]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0127, 0.0136, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5730431079864502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0124, 0.0123, 0.0210]) \n",
      "Test Loss tensor([0.0043, 0.0035, 0.0128, 0.0136, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.547884464263916 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0037, 0.0124, 0.0149, 0.0204]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0133, 0.0140, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.4885232448577881 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0039, 0.0128, 0.0131, 0.0204]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0131, 0.0134, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5096516609191895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0128, 0.0139, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0128, 0.0137, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5740728378295898 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0138, 0.0147, 0.0206]) \n",
      "Test Loss tensor([0.0041, 0.0036, 0.0136, 0.0140, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5825998783111572 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0126, 0.0136, 0.0216]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0133, 0.0138, 0.0203])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 236 in 0.7574491500854492 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0034, 0.0120, 0.0122, 0.0200]) \n",
      "Test Loss tensor([0.0041, 0.0037, 0.0126, 0.0139, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.7772767543792725 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0038, 0.0135, 0.0136, 0.0201]) \n",
      "Test Loss tensor([0.0042, 0.0037, 0.0129, 0.0130, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7155873775482178 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0033, 0.0138, 0.0138, 0.0210]) \n",
      "Test Loss tensor([0.0037, 0.0038, 0.0128, 0.0135, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7171499729156494 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0136, 0.0138, 0.0199]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0125, 0.0136, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6184396743774414 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0034, 0.0136, 0.0130, 0.0210]) \n",
      "Test Loss tensor([0.0037, 0.0037, 0.0129, 0.0138, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7757809162139893 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0040, 0.0105, 0.0125, 0.0200]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0133, 0.0135, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7849266529083252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0035, 0.0134, 0.0131, 0.0191]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0134, 0.0138, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6236000061035156 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0041, 0.0121, 0.0120, 0.0207]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0142, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6886355876922607 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0118, 0.0134, 0.0203]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0131, 0.0143, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5692160129547119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0037, 0.0129, 0.0141, 0.0212]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0129, 0.0136, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6279640197753906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0031, 0.0141, 0.0138, 0.0198]) \n",
      "Test Loss tensor([0.0043, 0.0036, 0.0132, 0.0137, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.7098128795623779 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0036, 0.0146, 0.0136, 0.0200]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0128, 0.0141, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6483125686645508 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0038, 0.0120, 0.0140, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0126, 0.0139, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5581905841827393 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0037, 0.0137, 0.0124, 0.0194]) \n",
      "Test Loss tensor([0.0036, 0.0036, 0.0132, 0.0132, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5143511295318604 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0124, 0.0146, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0126, 0.0138, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5241012573242188 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0038, 0.0131, 0.0134, 0.0201]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0129, 0.0131, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5943536758422852 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0032, 0.0131, 0.0146, 0.0193]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0133, 0.0133, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6500928401947021 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0138, 0.0129, 0.0203]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0129, 0.0133, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7032043933868408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0033, 0.0136, 0.0150, 0.0196]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0127, 0.0134, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6643884181976318 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0133, 0.0129, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0124, 0.0133, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5785095691680908 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0041, 0.0136, 0.0124, 0.0195]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0133, 0.0133, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.593768835067749 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0040, 0.0139, 0.0132, 0.0196]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0132, 0.0137, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5345063209533691 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0133, 0.0153, 0.0199]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0133, 0.0134, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6258845329284668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0041, 0.0142, 0.0125, 0.0194]) \n",
      "Test Loss tensor([0.0042, 0.0035, 0.0125, 0.0132, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7243337631225586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0134, 0.0116, 0.0204]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0131, 0.0139, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.598189115524292 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0026, 0.0039, 0.0137, 0.0136, 0.0206]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0127, 0.0133, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5057482719421387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0118, 0.0120, 0.0216]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0134, 0.0135, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5417046546936035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0043, 0.0114, 0.0123, 0.0191]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0128, 0.0134, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6365621089935303 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0105, 0.0128, 0.0207]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0139, 0.0143, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7595105171203613 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0128, 0.0121, 0.0197]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0126, 0.0133, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6846320629119873 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0030, 0.0150, 0.0148, 0.0187]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0128, 0.0138, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5689520835876465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0038, 0.0133, 0.0162, 0.0200]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0134, 0.0135, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.524712085723877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0040, 0.0133, 0.0142, 0.0205]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0123, 0.0138, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5168743133544922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0033, 0.0125, 0.0152, 0.0196]) \n",
      "Test Loss tensor([0.0043, 0.0036, 0.0136, 0.0133, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5298254489898682 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0039, 0.0147, 0.0130, 0.0199]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0138, 0.0136, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5165760517120361 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0136, 0.0168, 0.0210]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0130, 0.0131, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5433270931243896 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0037, 0.0137, 0.0134, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0038, 0.0134, 0.0139, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.561948299407959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0119, 0.0166, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0127, 0.0136, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5607292652130127 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0125, 0.0138, 0.0199]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0141, 0.0133, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5713789463043213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0129, 0.0136, 0.0212]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0137, 0.0134, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5830976963043213 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0039, 0.0149, 0.0134, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0127, 0.0134, 0.0201])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.5545039176940918 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0126, 0.0135, 0.0201]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0137, 0.0138, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5033972263336182 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0037, 0.0143, 0.0163, 0.0212]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0124, 0.0132, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5915451049804688 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0030, 0.0117, 0.0128, 0.0209]) \n",
      "Test Loss tensor([0.0038, 0.0037, 0.0122, 0.0136, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5907573699951172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0036, 0.0131, 0.0123, 0.0207]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0127, 0.0139, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5089192390441895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0035, 0.0151, 0.0137, 0.0204]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0128, 0.0136, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5566020011901855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0130, 0.0151, 0.0204]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0135, 0.0134, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5021853446960449 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0134, 0.0144, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0124, 0.0133, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6544132232666016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0033, 0.0149, 0.0143, 0.0189]) \n",
      "Test Loss tensor([0.0039, 0.0037, 0.0130, 0.0134, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.4994466304779053 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0038, 0.0140, 0.0166, 0.0187]) \n",
      "Test Loss tensor([0.0042, 0.0035, 0.0129, 0.0134, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.554955005645752 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0038, 0.0141, 0.0156, 0.0197]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0130, 0.0137, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.48351335525512695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0127, 0.0139, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0131, 0.0135, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5099492073059082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0031, 0.0125, 0.0137, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0132, 0.0140, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5364522933959961 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0126, 0.0112, 0.0201]) \n",
      "Test Loss tensor([0.0035, 0.0038, 0.0127, 0.0135, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.564347505569458 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0034, 0.0128, 0.0151, 0.0208]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0130, 0.0132, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.513796329498291 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0031, 0.0101, 0.0119, 0.0196]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0132, 0.0130, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5394837856292725 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0036, 0.0138, 0.0132, 0.0217]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0127, 0.0131, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.4919114112854004 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0031, 0.0122, 0.0141, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0133, 0.0135, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5730855464935303 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0035, 0.0100, 0.0140, 0.0202]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0137, 0.0137, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5350878238677979 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0039, 0.0155, 0.0166, 0.0202]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0126, 0.0132, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5371029376983643 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0131, 0.0131, 0.0190]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0141, 0.0132, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5175693035125732 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0030, 0.0133, 0.0147, 0.0211]) \n",
      "Test Loss tensor([0.0040, 0.0037, 0.0136, 0.0140, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5022227764129639 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0127, 0.0127, 0.0207]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0124, 0.0132, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5035393238067627 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0031, 0.0133, 0.0141, 0.0197]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0139, 0.0135, 0.0210])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5106022357940674 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0136, 0.0133, 0.0212]) \n",
      "Test Loss tensor([0.0040, 0.0034, 0.0135, 0.0132, 0.0206])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5038042068481445 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0033, 0.0140, 0.0128, 0.0205]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0132, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5144703388214111 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0118, 0.0139, 0.0196]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0136, 0.0131, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5128028392791748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0140, 0.0149, 0.0194]) \n",
      "Test Loss tensor([0.0041, 0.0034, 0.0130, 0.0134, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.4956247806549072 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0129, 0.0136, 0.0204]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0126, 0.0133, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5101959705352783 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0120, 0.0137, 0.0193]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0136, 0.0131, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.49463987350463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0034, 0.0164, 0.0145, 0.0201]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0125, 0.0131, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5209074020385742 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0036, 0.0115, 0.0115, 0.0198]) \n",
      "Test Loss tensor([0.0043, 0.0036, 0.0128, 0.0135, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5070135593414307 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0040, 0.0137, 0.0151, 0.0199]) \n",
      "Test Loss tensor([0.0043, 0.0036, 0.0133, 0.0140, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.49922919273376465 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0139, 0.0143, 0.0212]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0121, 0.0134, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5030989646911621 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0115, 0.0117, 0.0198]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0126, 0.0130, 0.0205])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5070817470550537 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0027, 0.0122, 0.0141, 0.0214]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0124, 0.0137, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5101923942565918 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0034, 0.0113, 0.0122, 0.0204]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0127, 0.0138, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5088918209075928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0031, 0.0101, 0.0169, 0.0206]) \n",
      "Test Loss tensor([0.0035, 0.0035, 0.0131, 0.0130, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5034580230712891 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0035, 0.0109, 0.0148, 0.0201]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0131, 0.0133, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5086233615875244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0030, 0.0160, 0.0162, 0.0207]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0130, 0.0127, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.4900472164154053 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0121, 0.0128, 0.0200]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0128, 0.0131, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.4753754138946533 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0133, 0.0125, 0.0203]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0129, 0.0129, 0.0201])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 564 in 0.4889638423919678 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0126, 0.0137, 0.0199]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0125, 0.0132, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.483828067779541 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0034, 0.0139, 0.0116, 0.0205]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0126, 0.0130, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.48053598403930664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0128, 0.0132, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0127, 0.0133, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.48929715156555176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0035, 0.0124, 0.0146, 0.0192]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0122, 0.0130, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.4780092239379883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0032, 0.0158, 0.0119, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0118, 0.0134, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.4787886142730713 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0034, 0.0119, 0.0134, 0.0186]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0134, 0.0128, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.4816131591796875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0125, 0.0125, 0.0189]) \n",
      "Test Loss tensor([0.0041, 0.0036, 0.0121, 0.0134, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.4790158271789551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0131, 0.0124, 0.0201]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0123, 0.0132, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5023698806762695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0116, 0.0133, 0.0201]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0124, 0.0132, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.551755428314209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0035, 0.0119, 0.0131, 0.0195]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0128, 0.0126, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5722014904022217 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0034, 0.0108, 0.0123, 0.0207]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0127, 0.0133, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5046851634979248 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0033, 0.0119, 0.0129, 0.0194]) \n",
      "Test Loss tensor([0.0044, 0.0036, 0.0126, 0.0131, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5231537818908691 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0130, 0.0162, 0.0203]) \n",
      "Test Loss tensor([0.0034, 0.0035, 0.0129, 0.0133, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5074889659881592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0031, 0.0102, 0.0134, 0.0211]) \n",
      "Test Loss tensor([0.0042, 0.0034, 0.0129, 0.0136, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5604186058044434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0042, 0.0110, 0.0178, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0122, 0.0132, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5081119537353516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0129, 0.0118, 0.0189]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0123, 0.0131, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5204024314880371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0147, 0.0141, 0.0206]) \n",
      "Test Loss tensor([0.0040, 0.0036, 0.0125, 0.0134, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5119273662567139 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0036, 0.0151, 0.0136, 0.0196]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0122, 0.0131, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5161690711975098 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0133, 0.0128, 0.0195]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0127, 0.0135, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5178365707397461 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0121, 0.0127, 0.0195]) \n",
      "Test Loss tensor([0.0042, 0.0031, 0.0122, 0.0131, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4969351291656494 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0033, 0.0124, 0.0120, 0.0186]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0121, 0.0132, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.4954707622528076 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0034, 0.0102, 0.0114, 0.0198]) \n",
      "Test Loss tensor([0.0039, 0.0036, 0.0125, 0.0135, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5008175373077393 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0030, 0.0106, 0.0128, 0.0192]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0125, 0.0136, 0.0201])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5127730369567871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0036, 0.0123, 0.0129, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0122, 0.0130, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5015170574188232 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0041, 0.0109, 0.0133, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0127, 0.0135, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5479528903961182 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0036, 0.0114, 0.0118, 0.0205]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0128, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5201168060302734 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0028, 0.0110, 0.0149, 0.0199]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0127, 0.0128, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5653884410858154 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0109, 0.0118, 0.0198]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0122, 0.0132, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.49996304512023926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0100, 0.0125, 0.0187]) \n",
      "Test Loss tensor([0.0035, 0.0036, 0.0120, 0.0133, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5745477676391602 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0037, 0.0128, 0.0148, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0124, 0.0137, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5046327114105225 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0034, 0.0113, 0.0122, 0.0204]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0120, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.542593240737915 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0129, 0.0148, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0036, 0.0122, 0.0132, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5422430038452148 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0039, 0.0143, 0.0155, 0.0198]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0122, 0.0131, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.4919569492340088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0142, 0.0124, 0.0184]) \n",
      "Test Loss tensor([0.0036, 0.0036, 0.0117, 0.0132, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5574789047241211 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0036, 0.0117, 0.0116, 0.0190]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0124, 0.0131, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5398604869842529 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0030, 0.0137, 0.0146, 0.0203]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0121, 0.0129, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5516610145568848 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0029, 0.0103, 0.0122, 0.0193]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0122, 0.0125, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.49042487144470215 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0139, 0.0114, 0.0200]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0128, 0.0127, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4842653274536133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0122, 0.0126, 0.0201]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0120, 0.0130, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5107545852661133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0036, 0.0118, 0.0122, 0.0196]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0128, 0.0131, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.4906280040740967 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0033, 0.0124, 0.0135, 0.0195]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0132, 0.0199])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 728 in 0.48903822898864746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0127, 0.0131, 0.0194]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0122, 0.0132, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.4880032539367676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0031, 0.0121, 0.0138, 0.0198]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0120, 0.0129, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.48917245864868164 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0150, 0.0132, 0.0208]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0128, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.48796868324279785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0127, 0.0127, 0.0207]) \n",
      "Test Loss tensor([0.0037, 0.0036, 0.0119, 0.0133, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.4912436008453369 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0029, 0.0141, 0.0133, 0.0188]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0127, 0.0136, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.4862356185913086 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0033, 0.0106, 0.0145, 0.0208]) \n",
      "Test Loss tensor([0.0034, 0.0036, 0.0120, 0.0133, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.48703956604003906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0042, 0.0119, 0.0116, 0.0193]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0118, 0.0132, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.49677133560180664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0038, 0.0124, 0.0140, 0.0205]) \n",
      "Test Loss tensor([0.0036, 0.0036, 0.0121, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.4885265827178955 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0137, 0.0131, 0.0185]) \n",
      "Test Loss tensor([0.0035, 0.0036, 0.0124, 0.0137, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.4883697032928467 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0109, 0.0136, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0124, 0.0128, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.4938850402832031 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0030, 0.0139, 0.0132, 0.0197]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0123, 0.0129, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.49085378646850586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0037, 0.0114, 0.0135, 0.0212]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0122, 0.0130, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.496584415435791 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0032, 0.0132, 0.0122, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0124, 0.0135, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.4874870777130127 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0134, 0.0155, 0.0199]) \n",
      "Test Loss tensor([0.0034, 0.0036, 0.0120, 0.0129, 0.0200])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.4923257827758789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0115, 0.0159, 0.0197]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0131, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.4879109859466553 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0033, 0.0111, 0.0128, 0.0193]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0117, 0.0133, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5274922847747803 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0038, 0.0122, 0.0153, 0.0200]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0117, 0.0129, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.48494839668273926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0126, 0.0130, 0.0203]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0131, 0.0126, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.4859182834625244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0035, 0.0149, 0.0126, 0.0189]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0127, 0.0135, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.4863109588623047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0035, 0.0127, 0.0136, 0.0198]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0127, 0.0130, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.48969173431396484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0034, 0.0117, 0.0122, 0.0198]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0115, 0.0126, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4867236614227295 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0128, 0.0137, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0124, 0.0127, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.48694920539855957 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0033, 0.0105, 0.0136, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0125, 0.0126, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.4890761375427246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0114, 0.0115, 0.0183]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0117, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5063846111297607 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0030, 0.0117, 0.0153, 0.0192]) \n",
      "Test Loss tensor([0.0040, 0.0033, 0.0124, 0.0129, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5043637752532959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0037, 0.0116, 0.0133, 0.0198]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0123, 0.0123, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.4894413948059082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0037, 0.0121, 0.0121, 0.0203]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0123, 0.0134, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.485105037689209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0028, 0.0138, 0.0122, 0.0195]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0123, 0.0129, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.4871959686279297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0039, 0.0127, 0.0137, 0.0179]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0118, 0.0126, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.4831695556640625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0121, 0.0150, 0.0210]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0116, 0.0127, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.4900853633880615 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0036, 0.0119, 0.0110, 0.0183]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0116, 0.0128, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.48612213134765625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0041, 0.0107, 0.0161, 0.0181]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0126, 0.0130, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.48726868629455566 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0032, 0.0119, 0.0115, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0123, 0.0128, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.4864070415496826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0035, 0.0111, 0.0115, 0.0193]) \n",
      "Test Loss tensor([0.0042, 0.0034, 0.0126, 0.0129, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.4879150390625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0114, 0.0133, 0.0188]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0123, 0.0130, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.48262524604797363 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0038, 0.0121, 0.0122, 0.0195]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0125, 0.0129, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5069801807403564 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0026, 0.0116, 0.0112, 0.0184]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0110, 0.0127, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5525493621826172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0026, 0.0080, 0.0094, 0.0145]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0116, 0.0133, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.58990478515625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0040, 0.0111, 0.0138, 0.0194]) \n",
      "Test Loss tensor([0.0041, 0.0035, 0.0126, 0.0132, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5686516761779785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0109, 0.0125, 0.0195]) \n",
      "Test Loss tensor([0.0040, 0.0034, 0.0120, 0.0130, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5205349922180176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0030, 0.0124, 0.0139, 0.0198]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0117, 0.0128, 0.0191])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 12 in 0.5609784126281738 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0035, 0.0129, 0.0133, 0.0194]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0124, 0.0129, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5883915424346924 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0127, 0.0126, 0.0191]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0118, 0.0123, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6540215015411377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0035, 0.0121, 0.0143, 0.0200]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0119, 0.0130, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5296459197998047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0034, 0.0123, 0.0124, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0111, 0.0129, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5243203639984131 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0030, 0.0120, 0.0111, 0.0183]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0116, 0.0131, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5581824779510498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0101, 0.0103, 0.0188]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0119, 0.0123, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5596408843994141 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0120, 0.0149, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0122, 0.0132, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5245954990386963 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0037, 0.0112, 0.0114, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0117, 0.0131, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5723137855529785 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0031, 0.0113, 0.0132, 0.0197]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0110, 0.0127, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.49549269676208496 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0029, 0.0095, 0.0108, 0.0188]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0123, 0.0126, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5244534015655518 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0035, 0.0122, 0.0147, 0.0193]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0122, 0.0131, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.565664529800415 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0119, 0.0109, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0119, 0.0132, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5935573577880859 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0028, 0.0130, 0.0123, 0.0190]) \n",
      "Test Loss tensor([0.0040, 0.0034, 0.0116, 0.0129, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5220029354095459 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0111, 0.0141, 0.0190]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0119, 0.0133, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5371825695037842 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0037, 0.0121, 0.0126, 0.0186]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0124, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5114049911499023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0033, 0.0119, 0.0121, 0.0185]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0121, 0.0130, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5413599014282227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0030, 0.0106, 0.0137, 0.0180]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0129, 0.0125, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5145771503448486 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0113, 0.0120, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0124, 0.0127, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5430254936218262 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0033, 0.0129, 0.0129, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0036, 0.0129, 0.0127, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5221211910247803 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0039, 0.0120, 0.0139, 0.0180]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0122, 0.0130, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.561042308807373 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0033, 0.0107, 0.0156, 0.0192]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0120, 0.0126, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5230276584625244 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0037, 0.0123, 0.0129, 0.0175]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0113, 0.0127, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5190889835357666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0109, 0.0151, 0.0193]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0114, 0.0125, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5129976272583008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0035, 0.0109, 0.0118, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0122, 0.0127, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.4982142448425293 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0035, 0.0104, 0.0158, 0.0200]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0114, 0.0128, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5255246162414551 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0115, 0.0128, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0119, 0.0130, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5061712265014648 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0032, 0.0129, 0.0143, 0.0180]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0127, 0.0126, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5329325199127197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0035, 0.0123, 0.0123, 0.0183]) \n",
      "Test Loss tensor([0.0034, 0.0034, 0.0118, 0.0129, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5281224250793457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0030, 0.0149, 0.0120, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0125, 0.0127, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5021464824676514 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0120, 0.0169, 0.0184]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0121, 0.0121, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.553429365158081 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0122, 0.0142, 0.0184]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0112, 0.0129, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5066757202148438 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0033, 0.0123, 0.0130, 0.0195]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0115, 0.0127, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5234615802764893 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0030, 0.0113, 0.0135, 0.0192]) \n",
      "Test Loss tensor([0.0040, 0.0035, 0.0121, 0.0128, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5117940902709961 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0029, 0.0096, 0.0142, 0.0185]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0124, 0.0126, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5298030376434326 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0036, 0.0116, 0.0134, 0.0203]) \n",
      "Test Loss tensor([0.0040, 0.0034, 0.0119, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5127277374267578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0039, 0.0108, 0.0120, 0.0182]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0124, 0.0130, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5468487739562988 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0045, 0.0112, 0.0129, 0.0201]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0115, 0.0129, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5621118545532227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0032, 0.0110, 0.0143, 0.0189]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0119, 0.0127, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.49468398094177246 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0136, 0.0114, 0.0200]) \n",
      "Test Loss tensor([0.0037, 0.0035, 0.0122, 0.0126, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.4858543872833252 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0045, 0.0113, 0.0136, 0.0193]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0121, 0.0128, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.48871850967407227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0113, 0.0131, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0127, 0.0127, 0.0192])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 176 in 0.534949541091919 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0032, 0.0119, 0.0137, 0.0185]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0122, 0.0129, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.49011850357055664 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0129, 0.0141, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0123, 0.0126, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.48372507095336914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0031, 0.0098, 0.0118, 0.0187]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0123, 0.0128, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.4905283451080322 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0109, 0.0124, 0.0199]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0112, 0.0126, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5502688884735107 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0117, 0.0136, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0118, 0.0125, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5685973167419434 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0035, 0.0101, 0.0134, 0.0191]) \n",
      "Test Loss tensor([0.0041, 0.0032, 0.0122, 0.0121, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5215873718261719 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0037, 0.0123, 0.0124, 0.0188]) \n",
      "Test Loss tensor([0.0041, 0.0033, 0.0114, 0.0121, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5307574272155762 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0035, 0.0131, 0.0116, 0.0184]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0116, 0.0125, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5168633460998535 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0033, 0.0115, 0.0123, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0127, 0.0132, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5778477191925049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0031, 0.0111, 0.0112, 0.0191]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0114, 0.0125, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5707361698150635 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0033, 0.0116, 0.0134, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0124, 0.0132, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5755612850189209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0039, 0.0127, 0.0155, 0.0195]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0124, 0.0129, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5813806056976318 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0029, 0.0137, 0.0134, 0.0204]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0113, 0.0129, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5442206859588623 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0110, 0.0121, 0.0199]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0114, 0.0131, 0.0199])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5044732093811035 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0116, 0.0133, 0.0206]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0132, 0.0128, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5449435710906982 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0036, 0.0143, 0.0126, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0116, 0.0126, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5592820644378662 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0114, 0.0121, 0.0199]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0119, 0.0133, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7184391021728516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0114, 0.0149, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0123, 0.0132, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.854285478591919 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0037, 0.0123, 0.0122, 0.0198]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0113, 0.0123, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5941448211669922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0030, 0.0114, 0.0128, 0.0198]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0128, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6610474586486816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0137, 0.0126, 0.0185]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0124, 0.0124, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7248172760009766 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0033, 0.0102, 0.0123, 0.0184]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0116, 0.0126, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.707181453704834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0030, 0.0126, 0.0160, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0120, 0.0128, 0.0196])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6256325244903564 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0037, 0.0134, 0.0119, 0.0198]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0127, 0.0127, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5933189392089844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0035, 0.0114, 0.0107, 0.0182]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0122, 0.0127, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5924332141876221 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0058, 0.0027, 0.0112, 0.0125, 0.0185]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0123, 0.0125, 0.0197])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.4968435764312744 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0100, 0.0112, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0122, 0.0120, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5682861804962158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0038, 0.0110, 0.0135, 0.0196]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0116, 0.0128, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5289230346679688 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0033, 0.0123, 0.0127, 0.0205]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0118, 0.0127, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.48879528045654297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0109, 0.0113, 0.0193]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0120, 0.0124, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.4881911277770996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0036, 0.0107, 0.0136, 0.0194]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0114, 0.0125, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5178244113922119 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0032, 0.0114, 0.0150, 0.0202]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0121, 0.0130, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5709383487701416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0034, 0.0092, 0.0094, 0.0200]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0124, 0.0127, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6133553981781006 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0031, 0.0127, 0.0115, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0122, 0.0123, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5523507595062256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0035, 0.0119, 0.0099, 0.0186]) \n",
      "Test Loss tensor([0.0041, 0.0033, 0.0119, 0.0130, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5343527793884277 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0035, 0.0127, 0.0107, 0.0198]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0122, 0.0122, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5796751976013184 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0031, 0.0102, 0.0140, 0.0196]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0126, 0.0125, 0.0194])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5725288391113281 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0119, 0.0138, 0.0198]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0134, 0.0118, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5709013938903809 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0035, 0.0110, 0.0118, 0.0205]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0116, 0.0123, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5535624027252197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0036, 0.0113, 0.0133, 0.0195]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0117, 0.0128, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.542487382888794 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0036, 0.0113, 0.0144, 0.0188]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0122, 0.0130, 0.0192])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 340 in 0.5461652278900146 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0029, 0.0123, 0.0150, 0.0191]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0115, 0.0129, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5886991024017334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0040, 0.0128, 0.0115, 0.0201]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0115, 0.0125, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5718355178833008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0035, 0.0117, 0.0133, 0.0194]) \n",
      "Test Loss tensor([0.0035, 0.0035, 0.0120, 0.0132, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5505471229553223 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0029, 0.0128, 0.0131, 0.0191]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0113, 0.0125, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.573857307434082 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0027, 0.0035, 0.0106, 0.0129, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0112, 0.0122, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5627965927124023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0032, 0.0115, 0.0141, 0.0188]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0119, 0.0125, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5560281276702881 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0033, 0.0132, 0.0127, 0.0195]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0119, 0.0123, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5866763591766357 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0033, 0.0123, 0.0124, 0.0181]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0113, 0.0120, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5763232707977295 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0030, 0.0127, 0.0127, 0.0186]) \n",
      "Test Loss tensor([0.0035, 0.0035, 0.0115, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5240843296051025 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0034, 0.0106, 0.0119, 0.0189]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0119, 0.0128, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5479888916015625 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0037, 0.0114, 0.0142, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0124, 0.0121, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5405304431915283 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0029, 0.0099, 0.0135, 0.0193]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0123, 0.0127, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.499051570892334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0109, 0.0135, 0.0186]) \n",
      "Test Loss tensor([0.0040, 0.0033, 0.0111, 0.0125, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.573265790939331 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0033, 0.0122, 0.0136, 0.0183]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0114, 0.0126, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5547456741333008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0035, 0.0127, 0.0137, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0118, 0.0125, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5523471832275391 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0120, 0.0131, 0.0197]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0118, 0.0119, 0.0193])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5106456279754639 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0026, 0.0112, 0.0119, 0.0194]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0115, 0.0124, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5523273944854736 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0030, 0.0124, 0.0129, 0.0188]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0120, 0.0124, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5655093193054199 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0127, 0.0114, 0.0185]) \n",
      "Test Loss tensor([0.0040, 0.0034, 0.0113, 0.0123, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5358195304870605 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0106, 0.0123, 0.0184]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0118, 0.0128, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.530383825302124 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0034, 0.0119, 0.0127, 0.0195]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0113, 0.0123, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5445055961608887 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0124, 0.0147, 0.0185]) \n",
      "Test Loss tensor([0.0040, 0.0033, 0.0117, 0.0125, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5831446647644043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0033, 0.0116, 0.0126, 0.0188]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0112, 0.0125, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5394446849822998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0120, 0.0103, 0.0181]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0113, 0.0124, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5058917999267578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0029, 0.0107, 0.0110, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0115, 0.0122, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5391466617584229 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0031, 0.0120, 0.0109, 0.0193]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0112, 0.0121, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5818541049957275 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0030, 0.0102, 0.0118, 0.0181]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0114, 0.0120, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.542635440826416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0033, 0.0101, 0.0122, 0.0184]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0116, 0.0124, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5559346675872803 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0039, 0.0130, 0.0143, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0110, 0.0124, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5768253803253174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0031, 0.0114, 0.0124, 0.0182]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0114, 0.0126, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5389440059661865 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0035, 0.0121, 0.0126, 0.0193]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0109, 0.0122, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5384325981140137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0033, 0.0101, 0.0109, 0.0184]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0111, 0.0121, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5638556480407715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0034, 0.0126, 0.0133, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0113, 0.0121, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5540926456451416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0031, 0.0131, 0.0133, 0.0182]) \n",
      "Test Loss tensor([0.0039, 0.0031, 0.0114, 0.0123, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5743546485900879 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0037, 0.0114, 0.0127, 0.0195]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0109, 0.0128, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5854108333587646 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0031, 0.0117, 0.0127, 0.0185]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0110, 0.0126, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5664780139923096 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0030, 0.0110, 0.0130, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0113, 0.0124, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5224974155426025 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0036, 0.0103, 0.0108, 0.0190]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0112, 0.0121, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5453753471374512 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0032, 0.0105, 0.0130, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0116, 0.0125, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5468924045562744 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0030, 0.0108, 0.0117, 0.0176]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0119, 0.0122, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5258297920227051 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0030, 0.0133, 0.0136, 0.0190]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0116, 0.0124, 0.0190])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 504 in 0.5750637054443359 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0039, 0.0100, 0.0137, 0.0188]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0113, 0.0123, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5392544269561768 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0114, 0.0112, 0.0188]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0114, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5567550659179688 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0029, 0.0127, 0.0144, 0.0197]) \n",
      "Test Loss tensor([0.0036, 0.0035, 0.0112, 0.0123, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5502331256866455 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0032, 0.0121, 0.0120, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0122, 0.0120, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5651187896728516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0033, 0.0120, 0.0122, 0.0176]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0113, 0.0118, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5581941604614258 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0116, 0.0120, 0.0185]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0119, 0.0123, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5706148147583008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0100, 0.0132, 0.0183]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0114, 0.0124, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.548274040222168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0032, 0.0122, 0.0136, 0.0188]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0111, 0.0118, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5390965938568115 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0032, 0.0129, 0.0119, 0.0185]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0108, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.518341064453125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0097, 0.0102, 0.0184]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0112, 0.0122, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5840973854064941 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0037, 0.0108, 0.0124, 0.0179]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0112, 0.0123, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.822150707244873 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0034, 0.0101, 0.0137, 0.0188]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0109, 0.0126, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6080417633056641 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0034, 0.0115, 0.0138, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0112, 0.0122, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5704481601715088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0032, 0.0130, 0.0127, 0.0187]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0111, 0.0123, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5751967430114746 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0029, 0.0092, 0.0130, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0114, 0.0128, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6559009552001953 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0121, 0.0136, 0.0186]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0116, 0.0124, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.7807683944702148 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0097, 0.0128, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0109, 0.0122, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.7522525787353516 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0030, 0.0109, 0.0145, 0.0187]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0110, 0.0129, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6047849655151367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0026, 0.0125, 0.0127, 0.0186]) \n",
      "Test Loss tensor([0.0034, 0.0035, 0.0113, 0.0121, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5807645320892334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0137, 0.0105, 0.0178]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0116, 0.0120, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6754026412963867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0093, 0.0119, 0.0185]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0111, 0.0122, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5495085716247559 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0032, 0.0110, 0.0118, 0.0182]) \n",
      "Test Loss tensor([0.0041, 0.0032, 0.0109, 0.0117, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6501462459564209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0032, 0.0115, 0.0106, 0.0184]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0116, 0.0127, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6325089931488037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0033, 0.0092, 0.0119, 0.0202]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0114, 0.0124, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6480352878570557 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0034, 0.0095, 0.0124, 0.0182]) \n",
      "Test Loss tensor([0.0039, 0.0031, 0.0108, 0.0121, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7141244411468506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0035, 0.0118, 0.0122, 0.0188]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0120, 0.0122, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6723079681396484 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0032, 0.0113, 0.0129, 0.0192]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0108, 0.0120, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.646465539932251 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0028, 0.0114, 0.0126, 0.0175]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0120, 0.0118, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5028564929962158 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0112, 0.0129, 0.0195]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0121, 0.0122, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5697677135467529 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0032, 0.0131, 0.0138, 0.0189]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0116, 0.0124, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5049166679382324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0033, 0.0121, 0.0139, 0.0188]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0116, 0.0122, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.547471284866333 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0038, 0.0121, 0.0127, 0.0180]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0112, 0.0121, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6362819671630859 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0116, 0.0105, 0.0193]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0108, 0.0124, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6564171314239502 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0034, 0.0106, 0.0110, 0.0189]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0117, 0.0117, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6516151428222656 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0030, 0.0098, 0.0121, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0111, 0.0121, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6092805862426758 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0034, 0.0113, 0.0105, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0115, 0.0122, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5595436096191406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0037, 0.0132, 0.0142, 0.0184]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0110, 0.0121, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5451295375823975 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0028, 0.0091, 0.0116, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0119, 0.0117, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5405380725860596 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0096, 0.0113, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0113, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5284883975982666 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0032, 0.0111, 0.0113, 0.0194]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0115, 0.0122, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5726120471954346 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0030, 0.0112, 0.0119, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0120, 0.0123, 0.0187])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 668 in 0.6553623676300049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0031, 0.0104, 0.0108, 0.0190]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0115, 0.0123, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5135703086853027 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0031, 0.0133, 0.0129, 0.0186]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0110, 0.0120, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5031125545501709 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0034, 0.0109, 0.0109, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0115, 0.0126, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6094462871551514 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0033, 0.0117, 0.0144, 0.0188]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0112, 0.0121, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6045184135437012 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0033, 0.0119, 0.0109, 0.0190]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0118, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5678486824035645 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0134, 0.0124, 0.0196]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0112, 0.0120, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5398056507110596 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0035, 0.0118, 0.0118, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0111, 0.0120, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6053621768951416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0102, 0.0122, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0113, 0.0122, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5687546730041504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0030, 0.0123, 0.0109, 0.0189]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0111, 0.0123, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5543410778045654 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0033, 0.0117, 0.0145, 0.0200]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0116, 0.0131, 0.0192])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5300829410552979 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0034, 0.0120, 0.0127, 0.0181]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0119, 0.0118, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5646119117736816 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0038, 0.0118, 0.0117, 0.0183]) \n",
      "Test Loss tensor([0.0039, 0.0031, 0.0115, 0.0115, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5999820232391357 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0029, 0.0119, 0.0127, 0.0197]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0114, 0.0123, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5049517154693604 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0033, 0.0105, 0.0130, 0.0186]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0112, 0.0120, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.507195234298706 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0039, 0.0123, 0.0118, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0117, 0.0120, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.617469310760498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0030, 0.0105, 0.0145, 0.0199]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0111, 0.0115, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5917098522186279 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0037, 0.0107, 0.0106, 0.0194]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0122, 0.0115, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5875148773193359 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0119, 0.0112, 0.0185]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0113, 0.0117, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5050771236419678 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0035, 0.0116, 0.0126, 0.0178]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0112, 0.0124, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5656814575195312 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0033, 0.0110, 0.0111, 0.0188]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0116, 0.0122, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5029089450836182 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0030, 0.0118, 0.0112, 0.0179]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0111, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5746419429779053 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0121, 0.0107, 0.0181]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0109, 0.0119, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.522348165512085 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0031, 0.0116, 0.0110, 0.0174]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0119, 0.0119, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5545535087585449 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0028, 0.0097, 0.0113, 0.0185]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0113, 0.0119, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5479898452758789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0029, 0.0096, 0.0120, 0.0168]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0115, 0.0122, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5459151268005371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0037, 0.0131, 0.0130, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0122, 0.0120, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6232705116271973 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0040, 0.0119, 0.0132, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0119, 0.0119, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5317814350128174 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0025, 0.0032, 0.0128, 0.0121, 0.0189]) \n",
      "Test Loss tensor([0.0040, 0.0032, 0.0112, 0.0115, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5697371959686279 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0028, 0.0102, 0.0120, 0.0191]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0107, 0.0123, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6194760799407959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0109, 0.0126, 0.0181]) \n",
      "Test Loss tensor([0.0038, 0.0035, 0.0109, 0.0124, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6411561965942383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0106, 0.0119, 0.0187]) \n",
      "Test Loss tensor([0.0033, 0.0034, 0.0117, 0.0116, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5663347244262695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0037, 0.0120, 0.0113, 0.0192]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0110, 0.0117, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5226080417633057 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0032, 0.0124, 0.0130, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0111, 0.0119, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5584075450897217 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0101, 0.0128, 0.0212]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0116, 0.0119, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5812561511993408 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0031, 0.0123, 0.0135, 0.0191]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0113, 0.0120, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5080819129943848 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0045, 0.0034, 0.0128, 0.0107, 0.0192]) \n",
      "Test Loss tensor([0.0039, 0.0033, 0.0112, 0.0119, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.4964008331298828 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0027, 0.0093, 0.0111, 0.0173]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0114, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.4965174198150635 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0036, 0.0097, 0.0127, 0.0178]) \n",
      "Test Loss tensor([0.0038, 0.0034, 0.0113, 0.0118, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5887167453765869 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0026, 0.0032, 0.0118, 0.0123, 0.0188]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0119, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5452675819396973 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0031, 0.0099, 0.0111, 0.0172]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0112, 0.0118, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5549654960632324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0030, 0.0111, 0.0121, 0.0195]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0110, 0.0120, 0.0186])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 832 in 0.7129983901977539 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0104, 0.0134, 0.0185]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0118, 0.0120, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7540607452392578 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0110, 0.0115, 0.0188]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0115, 0.0116, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.591787576675415 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0029, 0.0105, 0.0126, 0.0176]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0112, 0.0119, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6533198356628418 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0032, 0.0116, 0.0109, 0.0176]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0112, 0.0115, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.7384274005889893 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0096, 0.0126, 0.0175]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0114, 0.0122, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.606825590133667 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0029, 0.0131, 0.0122, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0116, 0.0126, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5658705234527588 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0036, 0.0096, 0.0118, 0.0196]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0114, 0.0119, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.49999141693115234 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0030, 0.0122, 0.0109, 0.0199]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0113, 0.0121, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5567793846130371 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0035, 0.0128, 0.0107, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0112, 0.0118, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5444202423095703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0031, 0.0131, 0.0123, 0.0180]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0113, 0.0119, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5444142818450928 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0026, 0.0112, 0.0107, 0.0207]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0113, 0.0118, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.495211124420166 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0022, 0.0022, 0.0083, 0.0094, 0.0138]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0113, 0.0122, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.5657286643981934 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0032, 0.0107, 0.0130, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0114, 0.0117, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5786256790161133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0030, 0.0124, 0.0134, 0.0187]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0110, 0.0119, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5107955932617188 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0030, 0.0124, 0.0144, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0112, 0.0117, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.526688814163208 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0034, 0.0107, 0.0113, 0.0180]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0111, 0.0119, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5119454860687256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0031, 0.0139, 0.0120, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0117, 0.0119, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5324358940124512 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0029, 0.0122, 0.0144, 0.0179]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0102, 0.0121, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5802273750305176 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0035, 0.0141, 0.0123, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0111, 0.0119, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6164462566375732 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0037, 0.0111, 0.0128, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0111, 0.0121, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6805975437164307 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0039, 0.0100, 0.0125, 0.0189]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0104, 0.0121, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7320642471313477 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0028, 0.0127, 0.0124, 0.0175]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0109, 0.0117, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.7146041393280029 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0031, 0.0098, 0.0126, 0.0188]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0110, 0.0115, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6930639743804932 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0124, 0.0130, 0.0186]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0110, 0.0123, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5751731395721436 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0041, 0.0111, 0.0130, 0.0190]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0109, 0.0115, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5251150131225586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0031, 0.0105, 0.0121, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0109, 0.0119, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.4941399097442627 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0033, 0.0109, 0.0102, 0.0198]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0108, 0.0118, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5380752086639404 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0032, 0.0126, 0.0129, 0.0172]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0114, 0.0117, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5565948486328125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0032, 0.0109, 0.0120, 0.0183]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0116, 0.0118, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5572752952575684 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0031, 0.0119, 0.0134, 0.0185]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0108, 0.0117, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5467066764831543 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0121, 0.0107, 0.0192]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0111, 0.0117, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5842366218566895 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0032, 0.0108, 0.0137, 0.0175]) \n",
      "Test Loss tensor([0.0039, 0.0035, 0.0114, 0.0116, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6482670307159424 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0028, 0.0109, 0.0128, 0.0175]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0110, 0.0114, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5492644309997559 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0035, 0.0124, 0.0113, 0.0172]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0107, 0.0119, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6301100254058838 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0029, 0.0104, 0.0116, 0.0187]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0111, 0.0117, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7024667263031006 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0101, 0.0143, 0.0186]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0115, 0.0114, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.545586109161377 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0030, 0.0117, 0.0122, 0.0177]) \n",
      "Test Loss tensor([0.0033, 0.0032, 0.0106, 0.0116, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5241310596466064 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0033, 0.0118, 0.0115, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0108, 0.0115, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5386228561401367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0130, 0.0121, 0.0190]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0112, 0.0115, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5426712036132812 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0114, 0.0138, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0105, 0.0121, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5171909332275391 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0037, 0.0109, 0.0134, 0.0184]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0103, 0.0123, 0.0184])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 116 in 0.5350205898284912 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0030, 0.0104, 0.0113, 0.0184]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0111, 0.0121, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5370252132415771 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0035, 0.0115, 0.0116, 0.0185]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0107, 0.0117, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6746015548706055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0031, 0.0084, 0.0108, 0.0191]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0109, 0.0117, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5509803295135498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0031, 0.0104, 0.0112, 0.0179]) \n",
      "Test Loss tensor([0.0035, 0.0035, 0.0105, 0.0116, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.4991269111633301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0031, 0.0083, 0.0120, 0.0171]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0108, 0.0115, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.574185848236084 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0028, 0.0128, 0.0117, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0107, 0.0119, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5482151508331299 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0033, 0.0105, 0.0110, 0.0183]) \n",
      "Test Loss tensor([0.0034, 0.0034, 0.0113, 0.0118, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5162012577056885 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0029, 0.0097, 0.0116, 0.0181]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0107, 0.0118, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5655646324157715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0111, 0.0129, 0.0189]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0118, 0.0118, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5523116588592529 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0031, 0.0096, 0.0140, 0.0188]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0098, 0.0119, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5470209121704102 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0032, 0.0101, 0.0119, 0.0188]) \n",
      "Test Loss tensor([0.0032, 0.0033, 0.0117, 0.0117, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5183920860290527 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0034, 0.0135, 0.0117, 0.0190]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0105, 0.0114, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.4972078800201416 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0032, 0.0112, 0.0119, 0.0179]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0111, 0.0116, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5967657566070557 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0030, 0.0087, 0.0126, 0.0193]) \n",
      "Test Loss tensor([0.0040, 0.0032, 0.0120, 0.0117, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.4985501766204834 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0038, 0.0106, 0.0112, 0.0195]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0111, 0.0111, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5072264671325684 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0042, 0.0113, 0.0114, 0.0174]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0119, 0.0126, 0.0198])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5075418949127197 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0039, 0.0151, 0.0104, 0.0192]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0112, 0.0120, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5227198600769043 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0117, 0.0123, 0.0193]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0113, 0.0118, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.507136344909668 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0032, 0.0121, 0.0116, 0.0184]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0126, 0.0124, 0.0191])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.4978451728820801 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0031, 0.0120, 0.0108, 0.0195]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0110, 0.0115, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.59995436668396 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0027, 0.0100, 0.0103, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0109, 0.0118, 0.0195])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5017533302307129 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0027, 0.0105, 0.0126, 0.0192]) \n",
      "Test Loss tensor([0.0038, 0.0032, 0.0114, 0.0121, 0.0189])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5075368881225586 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0027, 0.0107, 0.0109, 0.0190]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0105, 0.0119, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.557647705078125 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0030, 0.0113, 0.0131, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0109, 0.0121, 0.0190])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5038633346557617 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0033, 0.0114, 0.0108, 0.0183]) \n",
      "Test Loss tensor([0.0034, 0.0034, 0.0112, 0.0120, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6545000076293945 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0034, 0.0094, 0.0122, 0.0180]) \n",
      "Test Loss tensor([0.0033, 0.0034, 0.0108, 0.0120, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5612361431121826 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0030, 0.0125, 0.0117, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0119, 0.0114, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5463283061981201 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0031, 0.0111, 0.0119, 0.0175]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0116, 0.0119, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.7213237285614014 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0033, 0.0106, 0.0113, 0.0193]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0110, 0.0123, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5223824977874756 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0028, 0.0097, 0.0117, 0.0187]) \n",
      "Test Loss tensor([0.0039, 0.0034, 0.0111, 0.0118, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5075681209564209 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0033, 0.0129, 0.0115, 0.0190]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0109, 0.0122, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.4928140640258789 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0090, 0.0099, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0105, 0.0117, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5530142784118652 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0031, 0.0099, 0.0114, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0113, 0.0119, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6123437881469727 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0031, 0.0127, 0.0111, 0.0197]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0111, 0.0115, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5866398811340332 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0040, 0.0092, 0.0114, 0.0178]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0111, 0.0126, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6713154315948486 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0114, 0.0110, 0.0179]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0104, 0.0120, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7595598697662354 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0032, 0.0106, 0.0127, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0110, 0.0118, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5051829814910889 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0034, 0.0103, 0.0124, 0.0190]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0113, 0.0117, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.48897814750671387 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0120, 0.0113, 0.0187]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0112, 0.0117, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.4849073886871338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0028, 0.0124, 0.0107, 0.0175]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0111, 0.0123, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.4848306179046631 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0104, 0.0130, 0.0192]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0108, 0.0119, 0.0183])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 280 in 0.4885838031768799 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0029, 0.0120, 0.0120, 0.0180]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0111, 0.0115, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.49478602409362793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0030, 0.0091, 0.0104, 0.0194]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0120, 0.0121, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.4836606979370117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0028, 0.0102, 0.0116, 0.0178]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0110, 0.0118, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.48403191566467285 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0028, 0.0102, 0.0116, 0.0182]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0116, 0.0117, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.518115758895874 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0036, 0.0093, 0.0119, 0.0170]) \n",
      "Test Loss tensor([0.0037, 0.0034, 0.0117, 0.0115, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.48798489570617676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0118, 0.0101, 0.0180]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0107, 0.0112, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.4882771968841553 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0031, 0.0089, 0.0129, 0.0189]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0112, 0.0116, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5060386657714844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0085, 0.0094, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0110, 0.0120, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.49578046798706055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0024, 0.0030, 0.0111, 0.0119, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0112, 0.0115, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5033142566680908 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0031, 0.0094, 0.0112, 0.0179]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0107, 0.0117, 0.0187])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.48638033866882324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0030, 0.0110, 0.0119, 0.0186]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0107, 0.0113, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.4842054843902588 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0036, 0.0105, 0.0121, 0.0185]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0106, 0.0120, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.48718738555908203 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0032, 0.0123, 0.0143, 0.0176]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0115, 0.0118, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.4944796562194824 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0032, 0.0116, 0.0109, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0111, 0.0116, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.4819297790527344 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0030, 0.0108, 0.0110, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0110, 0.0124, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.48031187057495117 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0108, 0.0119, 0.0167]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0114, 0.0117, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.4835777282714844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0106, 0.0110, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0110, 0.0116, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5054082870483398 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0034, 0.0107, 0.0122, 0.0172]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0113, 0.0121, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.48629117012023926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0049, 0.0033, 0.0092, 0.0131, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0106, 0.0116, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.4859049320220947 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0028, 0.0108, 0.0126, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0103, 0.0117, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.48702287673950195 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0116, 0.0127, 0.0182]) \n",
      "Test Loss tensor([0.0037, 0.0030, 0.0105, 0.0115, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.490429162979126 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0028, 0.0112, 0.0114, 0.0178]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0108, 0.0114, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.4876527786254883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0101, 0.0120, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0112, 0.0116, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.48971080780029297 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0035, 0.0111, 0.0103, 0.0180]) \n",
      "Test Loss tensor([0.0039, 0.0030, 0.0109, 0.0112, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.48910951614379883 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0037, 0.0106, 0.0124, 0.0176]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0109, 0.0114, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.4912278652191162 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0027, 0.0033, 0.0092, 0.0130, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0110, 0.0114, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.4966142177581787 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0052, 0.0034, 0.0115, 0.0117, 0.0174]) \n",
      "Test Loss tensor([0.0038, 0.0033, 0.0110, 0.0113, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.48880743980407715 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0034, 0.0095, 0.0106, 0.0163]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0106, 0.0113, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.4898087978363037 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0035, 0.0097, 0.0121, 0.0180]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0104, 0.0117, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.48822593688964844 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0032, 0.0087, 0.0110, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0107, 0.0120, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.4925658702850342 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0094, 0.0112, 0.0182]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0104, 0.0112, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.4999208450317383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0042, 0.0102, 0.0113, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0101, 0.0115, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5362975597381592 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0032, 0.0112, 0.0108, 0.0181]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0108, 0.0116, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6172432899475098 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0033, 0.0100, 0.0121, 0.0189]) \n",
      "Test Loss tensor([0.0039, 0.0031, 0.0109, 0.0111, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.7270143032073975 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0034, 0.0094, 0.0113, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0105, 0.0117, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5658085346221924 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0029, 0.0100, 0.0116, 0.0190]) \n",
      "Test Loss tensor([0.0033, 0.0031, 0.0108, 0.0113, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6036291122436523 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0035, 0.0120, 0.0138, 0.0179]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0107, 0.0117, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5652079582214355 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0028, 0.0114, 0.0107, 0.0160]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0115, 0.0112, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5379419326782227 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0033, 0.0106, 0.0131, 0.0178]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0104, 0.0113, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5170283317565918 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0035, 0.0097, 0.0123, 0.0180]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0104, 0.0113, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5213477611541748 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0032, 0.0102, 0.0101, 0.0175]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0108, 0.0114, 0.0185])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 444 in 0.5214109420776367 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0037, 0.0112, 0.0122, 0.0190]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0106, 0.0115, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5117883682250977 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0030, 0.0117, 0.0121, 0.0184]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0106, 0.0113, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5158202648162842 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0039, 0.0119, 0.0136, 0.0171]) \n",
      "Test Loss tensor([0.0037, 0.0033, 0.0105, 0.0115, 0.0185])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5352482795715332 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0031, 0.0110, 0.0119, 0.0181]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0105, 0.0120, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5067629814147949 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0033, 0.0097, 0.0094, 0.0177]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0110, 0.0112, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5122959613800049 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0031, 0.0099, 0.0115, 0.0185]) \n",
      "Test Loss tensor([0.0040, 0.0032, 0.0109, 0.0118, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.512516975402832 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0029, 0.0103, 0.0119, 0.0187]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0114, 0.0111, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5117838382720947 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0031, 0.0102, 0.0112, 0.0184]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0106, 0.0115, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5134742259979248 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0027, 0.0029, 0.0093, 0.0121, 0.0176]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0108, 0.0116, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5138444900512695 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0032, 0.0098, 0.0129, 0.0178]) \n",
      "Test Loss tensor([0.0034, 0.0030, 0.0104, 0.0112, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5136451721191406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0029, 0.0112, 0.0136, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0112, 0.0117, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5099637508392334 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0032, 0.0105, 0.0116, 0.0174]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0105, 0.0112, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5174374580383301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0050, 0.0034, 0.0103, 0.0109, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0099, 0.0112, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5113847255706787 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0034, 0.0119, 0.0128, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0107, 0.0116, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5146205425262451 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0029, 0.0110, 0.0109, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0107, 0.0113, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5114712715148926 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0028, 0.0110, 0.0123, 0.0176]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0113, 0.0115, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5141067504882812 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0027, 0.0107, 0.0110, 0.0181]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0112, 0.0110, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5117015838623047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0034, 0.0110, 0.0112, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0030, 0.0103, 0.0111, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5237460136413574 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0051, 0.0034, 0.0105, 0.0119, 0.0190]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0104, 0.0121, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5152146816253662 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0029, 0.0110, 0.0136, 0.0174]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0113, 0.0114, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5108869075775146 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0027, 0.0095, 0.0107, 0.0179]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0107, 0.0117, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5103452205657959 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0033, 0.0106, 0.0095, 0.0179]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0108, 0.0114, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5169343948364258 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0108, 0.0110, 0.0174]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0110, 0.0113, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6103973388671875 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0031, 0.0098, 0.0118, 0.0186]) \n",
      "Test Loss tensor([0.0035, 0.0034, 0.0109, 0.0117, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5998804569244385 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0033, 0.0118, 0.0117, 0.0188]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0103, 0.0110, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.674924373626709 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0028, 0.0121, 0.0102, 0.0183]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0107, 0.0115, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5686395168304443 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0029, 0.0108, 0.0115, 0.0174]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0107, 0.0111, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5106949806213379 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0030, 0.0116, 0.0122, 0.0176]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0114, 0.0118, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5038766860961914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0097, 0.0121, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0111, 0.0118, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5074303150177002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0029, 0.0119, 0.0117, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0108, 0.0111, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.507073163986206 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0030, 0.0110, 0.0112, 0.0184]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0116, 0.0114, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5140666961669922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0028, 0.0118, 0.0102, 0.0194]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0111, 0.0115, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5054302215576172 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0034, 0.0104, 0.0129, 0.0180]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0104, 0.0112, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5099036693572998 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0042, 0.0091, 0.0110, 0.0179]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0112, 0.0113, 0.0186])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5812814235687256 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0032, 0.0094, 0.0136, 0.0196]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0111, 0.0113, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5556366443634033 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0031, 0.0095, 0.0116, 0.0174]) \n",
      "Test Loss tensor([0.0034, 0.0030, 0.0107, 0.0114, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5287253856658936 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0031, 0.0123, 0.0093, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0111, 0.0117, 0.0184])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6225709915161133 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0029, 0.0112, 0.0115, 0.0174]) \n",
      "Test Loss tensor([0.0032, 0.0033, 0.0105, 0.0112, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5370454788208008 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0033, 0.0090, 0.0095, 0.0181]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0109, 0.0114, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5048172473907471 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0030, 0.0116, 0.0092, 0.0172]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0110, 0.0108, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.49055004119873047 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0032, 0.0107, 0.0107, 0.0184]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0106, 0.0112, 0.0179])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 608 in 0.49559760093688965 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0029, 0.0095, 0.0120, 0.0166]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0109, 0.0110, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.4897425174713135 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0034, 0.0107, 0.0129, 0.0182]) \n",
      "Test Loss tensor([0.0032, 0.0031, 0.0106, 0.0111, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.48851704597473145 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0030, 0.0120, 0.0124, 0.0184]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0105, 0.0111, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.49078893661499023 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0027, 0.0098, 0.0113, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0110, 0.0112, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.4914212226867676 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0033, 0.0117, 0.0109, 0.0168]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0109, 0.0114, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5178663730621338 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0034, 0.0117, 0.0153, 0.0167]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0105, 0.0113, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.48644137382507324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0027, 0.0095, 0.0114, 0.0183]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0107, 0.0116, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5109553337097168 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0033, 0.0097, 0.0115, 0.0187]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0099, 0.0116, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.4906344413757324 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0029, 0.0093, 0.0110, 0.0173]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0105, 0.0110, 0.0183])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.4855771064758301 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0028, 0.0119, 0.0121, 0.0182]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0109, 0.0109, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.48940372467041016 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0047, 0.0031, 0.0107, 0.0108, 0.0175]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0100, 0.0113, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.49176526069641113 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0112, 0.0143, 0.0175]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0107, 0.0110, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6358447074890137 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0030, 0.0105, 0.0107, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0104, 0.0115, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5814058780670166 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0041, 0.0036, 0.0109, 0.0127, 0.0180]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0107, 0.0118, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6052968502044678 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0038, 0.0101, 0.0094, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0106, 0.0114, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.654139518737793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0026, 0.0093, 0.0109, 0.0184]) \n",
      "Test Loss tensor([0.0034, 0.0033, 0.0102, 0.0114, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5381956100463867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0099, 0.0106, 0.0167]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0103, 0.0110, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.512007474899292 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0036, 0.0133, 0.0114, 0.0176]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0101, 0.0112, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5925769805908203 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0032, 0.0106, 0.0119, 0.0180]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0103, 0.0113, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6491954326629639 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0030, 0.0103, 0.0107, 0.0178]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0104, 0.0113, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5388612747192383 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0027, 0.0094, 0.0134, 0.0176]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0101, 0.0108, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5476729869842529 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0091, 0.0099, 0.0175]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0107, 0.0109, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5297629833221436 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0029, 0.0112, 0.0115, 0.0190]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0107, 0.0116, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5193281173706055 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0033, 0.0106, 0.0113, 0.0184]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0107, 0.0107, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5149319171905518 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0084, 0.0109, 0.0171]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0111, 0.0106, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5624165534973145 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0039, 0.0114, 0.0116, 0.0176]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0104, 0.0107, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5810108184814453 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0029, 0.0101, 0.0099, 0.0182]) \n",
      "Test Loss tensor([0.0035, 0.0029, 0.0102, 0.0107, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.4945993423461914 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0032, 0.0100, 0.0117, 0.0173]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0103, 0.0113, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.49745941162109375 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0114, 0.0100, 0.0171]) \n",
      "Test Loss tensor([0.0037, 0.0031, 0.0109, 0.0107, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.49025392532348633 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0029, 0.0035, 0.0124, 0.0108, 0.0166]) \n",
      "Test Loss tensor([0.0036, 0.0032, 0.0106, 0.0110, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.580437421798706 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0031, 0.0098, 0.0123, 0.0179]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0109, 0.0111, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5837068557739258 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0034, 0.0034, 0.0105, 0.0113, 0.0173]) \n",
      "Test Loss tensor([0.0036, 0.0029, 0.0107, 0.0110, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5107510089874268 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0030, 0.0082, 0.0110, 0.0182]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0104, 0.0108, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5084519386291504 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0027, 0.0096, 0.0138, 0.0171]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0102, 0.0115, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5071754455566406 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0031, 0.0100, 0.0103, 0.0188]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0106, 0.0110, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5108435153961182 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0033, 0.0114, 0.0111, 0.0177]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0106, 0.0109, 0.0173])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5157768726348877 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0028, 0.0092, 0.0131, 0.0171]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0103, 0.0113, 0.0180])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5115218162536621 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0032, 0.0097, 0.0119, 0.0174]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0107, 0.0111, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5104901790618896 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0040, 0.0029, 0.0118, 0.0114, 0.0167]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0102, 0.0106, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5128951072692871 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0034, 0.0076, 0.0103, 0.0176]) \n",
      "Test Loss tensor([0.0038, 0.0031, 0.0101, 0.0113, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5064289569854736 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0046, 0.0036, 0.0108, 0.0115, 0.0172]) \n",
      "Test Loss tensor([0.0033, 0.0031, 0.0106, 0.0109, 0.0177])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 772 in 0.5073356628417969 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0034, 0.0105, 0.0109, 0.0178]) \n",
      "Test Loss tensor([0.0035, 0.0030, 0.0103, 0.0111, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5072667598724365 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0030, 0.0100, 0.0089, 0.0166]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0105, 0.0116, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5095195770263672 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0027, 0.0111, 0.0107, 0.0185]) \n",
      "Test Loss tensor([0.0033, 0.0031, 0.0108, 0.0105, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5075263977050781 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0032, 0.0098, 0.0141, 0.0181]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0104, 0.0107, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.507340669631958 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0029, 0.0083, 0.0109, 0.0178]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0109, 0.0109, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5072364807128906 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0028, 0.0105, 0.0107, 0.0178]) \n",
      "Test Loss tensor([0.0034, 0.0031, 0.0103, 0.0113, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5095350742340088 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0032, 0.0041, 0.0104, 0.0104, 0.0175]) \n",
      "Test Loss tensor([0.0037, 0.0032, 0.0102, 0.0110, 0.0179])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.530311107635498 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0030, 0.0098, 0.0108, 0.0170]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0099, 0.0113, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5340156555175781 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0042, 0.0033, 0.0092, 0.0129, 0.0170]) \n",
      "Test Loss tensor([0.0036, 0.0030, 0.0102, 0.0110, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5456829071044922 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0037, 0.0031, 0.0087, 0.0109, 0.0178]) \n",
      "Test Loss tensor([0.0036, 0.0033, 0.0103, 0.0106, 0.0181])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5385329723358154 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0028, 0.0112, 0.0116, 0.0174]) \n",
      "Test Loss tensor([0.0039, 0.0032, 0.0103, 0.0115, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5310885906219482 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0030, 0.0079, 0.0105, 0.0174]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0109, 0.0107, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.565892219543457 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0033, 0.0031, 0.0095, 0.0106, 0.0183]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0094, 0.0111, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5801377296447754 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0039, 0.0028, 0.0135, 0.0129, 0.0175]) \n",
      "Test Loss tensor([0.0035, 0.0033, 0.0103, 0.0110, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6148812770843506 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0027, 0.0094, 0.0106, 0.0186]) \n",
      "Test Loss tensor([0.0036, 0.0029, 0.0103, 0.0109, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.516930341720581 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0030, 0.0030, 0.0096, 0.0110, 0.0176]) \n",
      "Test Loss tensor([0.0035, 0.0030, 0.0106, 0.0108, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.510390043258667 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0038, 0.0031, 0.0104, 0.0122, 0.0170]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0100, 0.0111, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5121684074401855 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0048, 0.0033, 0.0098, 0.0107, 0.0170]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0109, 0.0106, 0.0174])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5130481719970703 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0034, 0.0109, 0.0122, 0.0183]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0109, 0.0108, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5165610313415527 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0027, 0.0032, 0.0095, 0.0112, 0.0169]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0100, 0.0113, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5245680809020996 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0031, 0.0033, 0.0104, 0.0105, 0.0167]) \n",
      "Test Loss tensor([0.0035, 0.0032, 0.0103, 0.0111, 0.0177])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5139744281768799 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0044, 0.0033, 0.0123, 0.0107, 0.0173]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0101, 0.0110, 0.0175])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5138916969299316 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0036, 0.0038, 0.0106, 0.0107, 0.0168]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0108, 0.0113, 0.0182])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5134117603302002 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0043, 0.0038, 0.0114, 0.0096, 0.0174]) \n",
      "Test Loss tensor([0.0034, 0.0032, 0.0102, 0.0110, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.518080472946167 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0035, 0.0031, 0.0093, 0.0105, 0.0199]) \n",
      "Test Loss tensor([0.0036, 0.0031, 0.0110, 0.0112, 0.0176])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5178098678588867 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0028, 0.0038, 0.0102, 0.0113, 0.0189]) \n",
      "Test Loss tensor([0.0036, 0.0034, 0.0111, 0.0115, 0.0178])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.49313807487487793 **************\n",
      "\n",
      "Training Idx 3 \n",
      "Train Loss tensor([0.0026, 0.0022, 0.0069, 0.0080, 0.0119]) \n",
      "Test Loss tensor([0.0035, 0.0031, 0.0101, 0.0109, 0.0177])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.6238353252410889 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3452, 0.5904, 0.5116, 0.3925, 0.3496, 0.4567, 0.3454]) \n",
      "Test Loss tensor([0.3441, 0.5921, 0.5129, 0.3935, 0.3510, 0.4568, 0.3448])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5911900997161865 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3442, 0.5921, 0.5146, 0.3922, 0.3513, 0.4573, 0.3446]) \n",
      "Test Loss tensor([0.3435, 0.5943, 0.5139, 0.3928, 0.3491, 0.4576, 0.3441])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6008996963500977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3463, 0.5945, 0.5167, 0.3913, 0.3526, 0.4563, 0.3439]) \n",
      "Test Loss tensor([0.3416, 0.5958, 0.5144, 0.3934, 0.3505, 0.4574, 0.3418])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5994997024536133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3433, 0.5958, 0.5137, 0.3898, 0.3512, 0.4559, 0.3433]) \n",
      "Test Loss tensor([0.3413, 0.5971, 0.5158, 0.3918, 0.3512, 0.4578, 0.3406])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5970945358276367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3407, 0.5985, 0.5160, 0.3927, 0.3502, 0.4614, 0.3391]) \n",
      "Test Loss tensor([0.3405, 0.5988, 0.5165, 0.3924, 0.3515, 0.4569, 0.3388])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5991833209991455 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3390, 0.5989, 0.5133, 0.3934, 0.3505, 0.4541, 0.3386]) \n",
      "Test Loss tensor([0.3392, 0.6002, 0.5180, 0.3912, 0.3493, 0.4582, 0.3383])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6254236698150635 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3396, 0.6008, 0.5151, 0.3950, 0.3506, 0.4553, 0.3362]) \n",
      "Test Loss tensor([0.3392, 0.6018, 0.5182, 0.3920, 0.3520, 0.4573, 0.3365])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6239686012268066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3375, 0.6029, 0.5200, 0.3923, 0.3482, 0.4633, 0.3359]) \n",
      "Test Loss tensor([0.3378, 0.6035, 0.5195, 0.3911, 0.3517, 0.4574, 0.3355])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5956614017486572 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3373, 0.6045, 0.5230, 0.3840, 0.3519, 0.4571, 0.3348]) \n",
      "Test Loss tensor([0.3361, 0.6048, 0.5205, 0.3907, 0.3494, 0.4564, 0.3341])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5947351455688477 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3356, 0.6048, 0.5168, 0.3931, 0.3554, 0.4549, 0.3343]) \n",
      "Test Loss tensor([0.3351, 0.6067, 0.5222, 0.3901, 0.3496, 0.4575, 0.3332])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5897090435028076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3333, 0.6078, 0.5205, 0.3874, 0.3451, 0.4539, 0.3324]) \n",
      "Test Loss tensor([0.3347, 0.6083, 0.5220, 0.3900, 0.3502, 0.4571, 0.3318])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5939548015594482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3347, 0.6070, 0.5259, 0.3907, 0.3480, 0.4591, 0.3314]) \n",
      "Test Loss tensor([0.3336, 0.6095, 0.5231, 0.3894, 0.3499, 0.4578, 0.3305])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5953619480133057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3312, 0.6080, 0.5279, 0.3881, 0.3454, 0.4624, 0.3300]) \n",
      "Test Loss tensor([0.3325, 0.6110, 0.5250, 0.3888, 0.3499, 0.4590, 0.3295])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6173810958862305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3324, 0.6114, 0.5251, 0.3858, 0.3496, 0.4588, 0.3296]) \n",
      "Test Loss tensor([0.3309, 0.6124, 0.5261, 0.3889, 0.3493, 0.4594, 0.3280])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6375210285186768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3326, 0.6112, 0.5223, 0.3910, 0.3507, 0.4546, 0.3272]) \n",
      "Test Loss tensor([0.3300, 0.6140, 0.5255, 0.3877, 0.3494, 0.4585, 0.3266])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6935782432556152 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3306, 0.6128, 0.5284, 0.3897, 0.3530, 0.4530, 0.3273]) \n",
      "Test Loss tensor([0.3298, 0.6152, 0.5282, 0.3871, 0.3502, 0.4596, 0.3258])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.594327449798584 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3302, 0.6177, 0.5263, 0.3898, 0.3492, 0.4538, 0.3263]) \n",
      "Test Loss tensor([0.3284, 0.6167, 0.5276, 0.3878, 0.3499, 0.4576, 0.3247])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5878391265869141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3290, 0.6178, 0.5258, 0.3871, 0.3483, 0.4569, 0.3241]) \n",
      "Test Loss tensor([0.3277, 0.6179, 0.5292, 0.3869, 0.3494, 0.4579, 0.3234])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5940172672271729 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3291, 0.6191, 0.5331, 0.3845, 0.3486, 0.4616, 0.3242]) \n",
      "Test Loss tensor([0.3273, 0.6197, 0.5290, 0.3872, 0.3499, 0.4580, 0.3227])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5951147079467773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3266, 0.6202, 0.5356, 0.3834, 0.3497, 0.4602, 0.3222]) \n",
      "Test Loss tensor([0.3262, 0.6202, 0.5301, 0.3870, 0.3497, 0.4588, 0.3217])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7235579490661621 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3253, 0.6216, 0.5297, 0.3841, 0.3498, 0.4560, 0.3224]) \n",
      "Test Loss tensor([0.3254, 0.6220, 0.5323, 0.3860, 0.3490, 0.4593, 0.3208])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7288179397583008 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3223, 0.6219, 0.5349, 0.3859, 0.3468, 0.4611, 0.3205]) \n",
      "Test Loss tensor([0.3236, 0.6233, 0.5330, 0.3864, 0.3490, 0.4580, 0.3193])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6304159164428711 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3222, 0.6219, 0.5334, 0.3840, 0.3500, 0.4584, 0.3189]) \n",
      "Test Loss tensor([0.3231, 0.6239, 0.5336, 0.3859, 0.3490, 0.4601, 0.3181])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5926687717437744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3237, 0.6244, 0.5350, 0.3817, 0.3481, 0.4604, 0.3178]) \n",
      "Test Loss tensor([0.3226, 0.6254, 0.5334, 0.3856, 0.3488, 0.4584, 0.3174])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5919427871704102 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3199, 0.6256, 0.5276, 0.3858, 0.3453, 0.4621, 0.3175]) \n",
      "Test Loss tensor([0.3215, 0.6266, 0.5345, 0.3855, 0.3486, 0.4585, 0.3169])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5893983840942383 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3208, 0.6271, 0.5314, 0.3883, 0.3475, 0.4575, 0.3164]) \n",
      "Test Loss tensor([0.3218, 0.6283, 0.5337, 0.3857, 0.3488, 0.4589, 0.3157])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5989871025085449 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3231, 0.6284, 0.5328, 0.3827, 0.3468, 0.4539, 0.3160]) \n",
      "Test Loss tensor([0.3205, 0.6286, 0.5340, 0.3861, 0.3491, 0.4586, 0.3152])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.590815544128418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3199, 0.6265, 0.5387, 0.3800, 0.3499, 0.4622, 0.3143]) \n",
      "Test Loss tensor([0.3200, 0.6294, 0.5357, 0.3853, 0.3482, 0.4592, 0.3144])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5902345180511475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3214, 0.6278, 0.5347, 0.3838, 0.3430, 0.4581, 0.3153]) \n",
      "Test Loss tensor([0.3196, 0.6305, 0.5380, 0.3844, 0.3484, 0.4598, 0.3136])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5873556137084961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3185, 0.6307, 0.5320, 0.3838, 0.3452, 0.4567, 0.3131]) \n",
      "Test Loss tensor([0.3193, 0.6314, 0.5374, 0.3831, 0.3484, 0.4601, 0.3132])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6311013698577881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3207, 0.6320, 0.5374, 0.3827, 0.3538, 0.4561, 0.3128]) \n",
      "Test Loss tensor([0.3184, 0.6317, 0.5370, 0.3845, 0.3503, 0.4591, 0.3124])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.7355396747589111 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3195, 0.6330, 0.5371, 0.3863, 0.3431, 0.4576, 0.3133]) \n",
      "Test Loss tensor([0.3178, 0.6326, 0.5376, 0.3844, 0.3493, 0.4584, 0.3120])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6269428730010986 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3176, 0.6319, 0.5394, 0.3840, 0.3490, 0.4587, 0.3112]) \n",
      "Test Loss tensor([0.3186, 0.6335, 0.5380, 0.3845, 0.3482, 0.4597, 0.3113])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5948982238769531 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3224, 0.6330, 0.5398, 0.3776, 0.3491, 0.4638, 0.3119]) \n",
      "Test Loss tensor([0.3180, 0.6343, 0.5389, 0.3843, 0.3487, 0.4593, 0.3107])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5847876071929932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3178, 0.6335, 0.5406, 0.3829, 0.3495, 0.4571, 0.3103]) \n",
      "Test Loss tensor([0.3169, 0.6347, 0.5394, 0.3828, 0.3492, 0.4594, 0.3106])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6054885387420654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3151, 0.6354, 0.5435, 0.3794, 0.3519, 0.4563, 0.3102]) \n",
      "Test Loss tensor([0.3168, 0.6351, 0.5392, 0.3831, 0.3492, 0.4595, 0.3100])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 144 in 0.5900444984436035 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3181, 0.6335, 0.5403, 0.3839, 0.3461, 0.4580, 0.3103]) \n",
      "Test Loss tensor([0.3173, 0.6351, 0.5401, 0.3820, 0.3496, 0.4600, 0.3095])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5901501178741455 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3151, 0.6355, 0.5385, 0.3841, 0.3512, 0.4545, 0.3098]) \n",
      "Test Loss tensor([0.3159, 0.6362, 0.5399, 0.3827, 0.3486, 0.4596, 0.3093])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5947244167327881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3148, 0.6355, 0.5436, 0.3768, 0.3465, 0.4619, 0.3084]) \n",
      "Test Loss tensor([0.3159, 0.6358, 0.5396, 0.3834, 0.3489, 0.4594, 0.3086])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5933501720428467 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3138, 0.6365, 0.5371, 0.3828, 0.3513, 0.4586, 0.3081]) \n",
      "Test Loss tensor([0.3154, 0.6364, 0.5393, 0.3843, 0.3483, 0.4587, 0.3088])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5999965667724609 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3151, 0.6354, 0.5401, 0.3805, 0.3480, 0.4560, 0.3075]) \n",
      "Test Loss tensor([0.3152, 0.6365, 0.5397, 0.3835, 0.3497, 0.4599, 0.3084])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6109015941619873 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3148, 0.6356, 0.5423, 0.3797, 0.3394, 0.4618, 0.3084]) \n",
      "Test Loss tensor([0.3151, 0.6369, 0.5421, 0.3820, 0.3486, 0.4600, 0.3080])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5769798755645752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3151, 0.6376, 0.5429, 0.3835, 0.3506, 0.4596, 0.3084]) \n",
      "Test Loss tensor([0.3156, 0.6375, 0.5409, 0.3827, 0.3482, 0.4603, 0.3078])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5729458332061768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3125, 0.6373, 0.5396, 0.3840, 0.3464, 0.4607, 0.3066]) \n",
      "Test Loss tensor([0.3152, 0.6370, 0.5425, 0.3817, 0.3476, 0.4604, 0.3079])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7038741111755371 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3163, 0.6363, 0.5470, 0.3818, 0.3476, 0.4573, 0.3067]) \n",
      "Test Loss tensor([0.3154, 0.6375, 0.5408, 0.3825, 0.3486, 0.4592, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7233734130859375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3142, 0.6361, 0.5423, 0.3799, 0.3485, 0.4557, 0.3069]) \n",
      "Test Loss tensor([0.3156, 0.6371, 0.5405, 0.3824, 0.3484, 0.4603, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6596217155456543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3139, 0.6376, 0.5407, 0.3834, 0.3458, 0.4593, 0.3073]) \n",
      "Test Loss tensor([0.3152, 0.6376, 0.5410, 0.3827, 0.3486, 0.4607, 0.3076])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.7539315223693848 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3157, 0.6375, 0.5407, 0.3799, 0.3483, 0.4589, 0.3077]) \n",
      "Test Loss tensor([0.3155, 0.6372, 0.5406, 0.3829, 0.3493, 0.4592, 0.3074])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6121935844421387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3153, 0.6375, 0.5477, 0.3749, 0.3512, 0.4610, 0.3072]) \n",
      "Test Loss tensor([0.3153, 0.6372, 0.5407, 0.3825, 0.3483, 0.4592, 0.3074])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5830693244934082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3160, 0.6380, 0.5422, 0.3802, 0.3452, 0.4620, 0.3063]) \n",
      "Test Loss tensor([0.3156, 0.6369, 0.5396, 0.3834, 0.3495, 0.4595, 0.3074])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.567021369934082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3144, 0.6367, 0.5393, 0.3781, 0.3519, 0.4598, 0.3063]) \n",
      "Test Loss tensor([0.3147, 0.6368, 0.5401, 0.3841, 0.3493, 0.4589, 0.3075])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5709726810455322 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3141, 0.6374, 0.5397, 0.3814, 0.3463, 0.4623, 0.3070]) \n",
      "Test Loss tensor([0.3144, 0.6366, 0.5403, 0.3826, 0.3482, 0.4591, 0.3072])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5734148025512695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3128, 0.6386, 0.5401, 0.3836, 0.3440, 0.4596, 0.3068]) \n",
      "Test Loss tensor([0.3146, 0.6365, 0.5415, 0.3818, 0.3487, 0.4583, 0.3071])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6782104969024658 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3158, 0.6350, 0.5427, 0.3814, 0.3470, 0.4620, 0.3062]) \n",
      "Test Loss tensor([0.3158, 0.6365, 0.5394, 0.3832, 0.3482, 0.4589, 0.3073])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7037146091461182 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3149, 0.6366, 0.5405, 0.3789, 0.3469, 0.4595, 0.3067]) \n",
      "Test Loss tensor([0.3154, 0.6360, 0.5413, 0.3815, 0.3482, 0.4596, 0.3078])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6706881523132324 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3136, 0.6379, 0.5390, 0.3819, 0.3497, 0.4581, 0.3074]) \n",
      "Test Loss tensor([0.3156, 0.6357, 0.5394, 0.3847, 0.3494, 0.4584, 0.3073])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6024038791656494 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3138, 0.6365, 0.5390, 0.3811, 0.3480, 0.4603, 0.3084]) \n",
      "Test Loss tensor([0.3159, 0.6355, 0.5402, 0.3832, 0.3485, 0.4599, 0.3076])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5922160148620605 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3176, 0.6354, 0.5394, 0.3857, 0.3492, 0.4557, 0.3065]) \n",
      "Test Loss tensor([0.3156, 0.6358, 0.5400, 0.3825, 0.3487, 0.4592, 0.3080])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5986263751983643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3166, 0.6347, 0.5457, 0.3819, 0.3506, 0.4621, 0.3069]) \n",
      "Test Loss tensor([0.3161, 0.6354, 0.5374, 0.3849, 0.3496, 0.4584, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5866198539733887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3166, 0.6342, 0.5319, 0.3882, 0.3474, 0.4554, 0.3075]) \n",
      "Test Loss tensor([0.3158, 0.6343, 0.5383, 0.3837, 0.3485, 0.4585, 0.3075])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5851929187774658 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3175, 0.6350, 0.5402, 0.3835, 0.3495, 0.4586, 0.3079]) \n",
      "Test Loss tensor([0.3164, 0.6349, 0.5393, 0.3818, 0.3507, 0.4594, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5829222202301025 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3171, 0.6332, 0.5339, 0.3849, 0.3510, 0.4590, 0.3082]) \n",
      "Test Loss tensor([0.3165, 0.6346, 0.5387, 0.3825, 0.3496, 0.4599, 0.3080])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6780951023101807 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3197, 0.6366, 0.5374, 0.3858, 0.3493, 0.4582, 0.3081]) \n",
      "Test Loss tensor([0.3163, 0.6341, 0.5374, 0.3838, 0.3489, 0.4587, 0.3083])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.8868112564086914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3142, 0.6367, 0.5370, 0.3825, 0.3508, 0.4573, 0.3076]) \n",
      "Test Loss tensor([0.3164, 0.6337, 0.5398, 0.3825, 0.3477, 0.4607, 0.3074])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7825007438659668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3181, 0.6322, 0.5410, 0.3762, 0.3480, 0.4607, 0.3073]) \n",
      "Test Loss tensor([0.3164, 0.6340, 0.5367, 0.3843, 0.3486, 0.4584, 0.3075])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7414484024047852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3167, 0.6333, 0.5405, 0.3805, 0.3460, 0.4562, 0.3077]) \n",
      "Test Loss tensor([0.3164, 0.6331, 0.5381, 0.3836, 0.3479, 0.4578, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.8085758686065674 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3142, 0.6328, 0.5370, 0.3815, 0.3520, 0.4608, 0.3076]) \n",
      "Test Loss tensor([0.3170, 0.6330, 0.5383, 0.3842, 0.3471, 0.4596, 0.3075])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.78739333152771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3161, 0.6340, 0.5353, 0.3832, 0.3500, 0.4604, 0.3087]) \n",
      "Test Loss tensor([0.3172, 0.6330, 0.5380, 0.3822, 0.3508, 0.4601, 0.3077])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7433934211730957 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3166, 0.6328, 0.5334, 0.3856, 0.3483, 0.4570, 0.3073]) \n",
      "Test Loss tensor([0.3162, 0.6325, 0.5385, 0.3836, 0.3469, 0.4589, 0.3074])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7411072254180908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3162, 0.6335, 0.5421, 0.3778, 0.3466, 0.4599, 0.3088]) \n",
      "Test Loss tensor([0.3173, 0.6325, 0.5379, 0.3820, 0.3487, 0.4590, 0.3069])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6539585590362549 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3160, 0.6320, 0.5353, 0.3851, 0.3475, 0.4554, 0.3072]) \n",
      "Test Loss tensor([0.3176, 0.6319, 0.5367, 0.3830, 0.3503, 0.4588, 0.3067])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7179441452026367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3170, 0.6319, 0.5391, 0.3833, 0.3531, 0.4569, 0.3064]) \n",
      "Test Loss tensor([0.3167, 0.6313, 0.5363, 0.3836, 0.3498, 0.4567, 0.3066])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 288 in 0.7890439033508301 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3160, 0.6316, 0.5381, 0.3838, 0.3500, 0.4560, 0.3066]) \n",
      "Test Loss tensor([0.3162, 0.6316, 0.5368, 0.3831, 0.3474, 0.4588, 0.3064])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.8519494533538818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3150, 0.6309, 0.5362, 0.3792, 0.3428, 0.4619, 0.3058]) \n",
      "Test Loss tensor([0.3164, 0.6322, 0.5378, 0.3823, 0.3480, 0.4583, 0.3064])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7695870399475098 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3201, 0.6327, 0.5378, 0.3776, 0.3449, 0.4583, 0.3068]) \n",
      "Test Loss tensor([0.3167, 0.6317, 0.5380, 0.3819, 0.3482, 0.4589, 0.3058])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7862210273742676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3175, 0.6304, 0.5430, 0.3821, 0.3517, 0.4572, 0.3068]) \n",
      "Test Loss tensor([0.3162, 0.6315, 0.5370, 0.3838, 0.3490, 0.4582, 0.3056])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7644107341766357 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3168, 0.6328, 0.5354, 0.3854, 0.3544, 0.4588, 0.3064]) \n",
      "Test Loss tensor([0.3160, 0.6305, 0.5367, 0.3819, 0.3480, 0.4585, 0.3053])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7467129230499268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3186, 0.6332, 0.5375, 0.3835, 0.3448, 0.4589, 0.3048]) \n",
      "Test Loss tensor([0.3160, 0.6304, 0.5361, 0.3816, 0.3493, 0.4583, 0.3044])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7695913314819336 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3117, 0.6318, 0.5406, 0.3744, 0.3494, 0.4588, 0.3058]) \n",
      "Test Loss tensor([0.3160, 0.6303, 0.5361, 0.3823, 0.3507, 0.4591, 0.3043])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7438979148864746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3155, 0.6310, 0.5407, 0.3772, 0.3488, 0.4603, 0.3041]) \n",
      "Test Loss tensor([0.3162, 0.6303, 0.5366, 0.3830, 0.3487, 0.4594, 0.3038])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7382056713104248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3159, 0.6300, 0.5369, 0.3802, 0.3429, 0.4611, 0.3024]) \n",
      "Test Loss tensor([0.3153, 0.6303, 0.5358, 0.3818, 0.3485, 0.4592, 0.3034])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7641665935516357 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3161, 0.6284, 0.5390, 0.3775, 0.3484, 0.4617, 0.3034]) \n",
      "Test Loss tensor([0.3160, 0.6302, 0.5359, 0.3823, 0.3490, 0.4583, 0.3028])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.7729558944702148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3140, 0.6300, 0.5363, 0.3818, 0.3487, 0.4556, 0.3024]) \n",
      "Test Loss tensor([0.3157, 0.6293, 0.5358, 0.3813, 0.3479, 0.4587, 0.3018])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.8092091083526611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3174, 0.6282, 0.5335, 0.3858, 0.3508, 0.4572, 0.3023]) \n",
      "Test Loss tensor([0.3152, 0.6292, 0.5354, 0.3812, 0.3491, 0.4589, 0.3016])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7569839954376221 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3145, 0.6301, 0.5383, 0.3839, 0.3477, 0.4599, 0.3018]) \n",
      "Test Loss tensor([0.3149, 0.6290, 0.5349, 0.3815, 0.3495, 0.4595, 0.3011])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.8276252746582031 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3159, 0.6301, 0.5356, 0.3806, 0.3472, 0.4563, 0.3019]) \n",
      "Test Loss tensor([0.3158, 0.6278, 0.5349, 0.3805, 0.3491, 0.4578, 0.3007])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.8059558868408203 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3165, 0.6284, 0.5361, 0.3836, 0.3509, 0.4568, 0.2999]) \n",
      "Test Loss tensor([0.3157, 0.6268, 0.5335, 0.3810, 0.3484, 0.4578, 0.2998])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.8207495212554932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3150, 0.6274, 0.5318, 0.3787, 0.3470, 0.4577, 0.3008]) \n",
      "Test Loss tensor([0.3158, 0.6269, 0.5341, 0.3804, 0.3490, 0.4602, 0.2990])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.8189413547515869 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3120, 0.6271, 0.5376, 0.3782, 0.3493, 0.4600, 0.2999]) \n",
      "Test Loss tensor([0.3150, 0.6267, 0.5343, 0.3805, 0.3486, 0.4595, 0.2983])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.8906443119049072 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3162, 0.6265, 0.5304, 0.3850, 0.3472, 0.4587, 0.2980]) \n",
      "Test Loss tensor([0.3149, 0.6258, 0.5333, 0.3792, 0.3490, 0.4579, 0.2978])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.8376147747039795 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3139, 0.6265, 0.5321, 0.3818, 0.3464, 0.4576, 0.2978]) \n",
      "Test Loss tensor([0.3146, 0.6247, 0.5325, 0.3804, 0.3493, 0.4582, 0.2967])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7930433750152588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3163, 0.6262, 0.5288, 0.3848, 0.3501, 0.4591, 0.2961]) \n",
      "Test Loss tensor([0.3143, 0.6231, 0.5327, 0.3794, 0.3490, 0.4583, 0.2960])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.799030065536499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3135, 0.6236, 0.5310, 0.3757, 0.3482, 0.4574, 0.2958]) \n",
      "Test Loss tensor([0.3155, 0.6222, 0.5305, 0.3797, 0.3498, 0.4582, 0.2945])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.8153276443481445 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3150, 0.6218, 0.5324, 0.3790, 0.3460, 0.4566, 0.2945]) \n",
      "Test Loss tensor([0.3154, 0.6212, 0.5310, 0.3780, 0.3507, 0.4592, 0.2942])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7704355716705322 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3146, 0.6216, 0.5282, 0.3766, 0.3464, 0.4603, 0.2944]) \n",
      "Test Loss tensor([0.3147, 0.6197, 0.5296, 0.3803, 0.3499, 0.4588, 0.2932])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.7487859725952148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3148, 0.6198, 0.5314, 0.3747, 0.3481, 0.4601, 0.2927]) \n",
      "Test Loss tensor([0.3145, 0.6181, 0.5277, 0.3791, 0.3507, 0.4589, 0.2920])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.758812427520752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3144, 0.6201, 0.5309, 0.3765, 0.3481, 0.4592, 0.2927]) \n",
      "Test Loss tensor([0.3148, 0.6173, 0.5292, 0.3776, 0.3476, 0.4586, 0.2910])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7539525032043457 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3170, 0.6157, 0.5279, 0.3773, 0.3508, 0.4575, 0.2907]) \n",
      "Test Loss tensor([0.3141, 0.6157, 0.5265, 0.3775, 0.3491, 0.4585, 0.2901])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.745657205581665 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3130, 0.6151, 0.5291, 0.3747, 0.3493, 0.4608, 0.2890]) \n",
      "Test Loss tensor([0.3152, 0.6141, 0.5268, 0.3772, 0.3492, 0.4591, 0.2885])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.7479736804962158 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3098, 0.6145, 0.5297, 0.3751, 0.3485, 0.4588, 0.2879]) \n",
      "Test Loss tensor([0.3155, 0.6122, 0.5246, 0.3786, 0.3498, 0.4589, 0.2873])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.761542797088623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3168, 0.6123, 0.5257, 0.3761, 0.3468, 0.4584, 0.2869]) \n",
      "Test Loss tensor([0.3141, 0.6103, 0.5217, 0.3785, 0.3490, 0.4571, 0.2858])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7510461807250977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3177, 0.6119, 0.5236, 0.3742, 0.3524, 0.4571, 0.2855]) \n",
      "Test Loss tensor([0.3142, 0.6082, 0.5221, 0.3759, 0.3502, 0.4581, 0.2837])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.7409961223602295 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3152, 0.6079, 0.5242, 0.3760, 0.3434, 0.4603, 0.2833]) \n",
      "Test Loss tensor([0.3141, 0.6064, 0.5221, 0.3740, 0.3498, 0.4580, 0.2823])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7725272178649902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3130, 0.6081, 0.5237, 0.3764, 0.3462, 0.4593, 0.2817]) \n",
      "Test Loss tensor([0.3134, 0.6051, 0.5195, 0.3749, 0.3499, 0.4580, 0.2806])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.7765848636627197 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3132, 0.6051, 0.5209, 0.3723, 0.3564, 0.4569, 0.2809]) \n",
      "Test Loss tensor([0.3134, 0.6024, 0.5178, 0.3754, 0.3496, 0.4581, 0.2784])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7516045570373535 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3125, 0.6022, 0.5172, 0.3814, 0.3492, 0.4550, 0.2785]) \n",
      "Test Loss tensor([0.3137, 0.6001, 0.5171, 0.3744, 0.3503, 0.4574, 0.2762])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.8083269596099854 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3111, 0.5998, 0.5202, 0.3691, 0.3518, 0.4622, 0.2760]) \n",
      "Test Loss tensor([0.3114, 0.5984, 0.5152, 0.3751, 0.3498, 0.4576, 0.2743])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.8220829963684082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3117, 0.5972, 0.5169, 0.3751, 0.3463, 0.4556, 0.2749]) \n",
      "Test Loss tensor([0.3114, 0.5958, 0.5138, 0.3741, 0.3520, 0.4569, 0.2716])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.8250224590301514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3116, 0.5953, 0.5192, 0.3707, 0.3498, 0.4568, 0.2731]) \n",
      "Test Loss tensor([0.3096, 0.5939, 0.5128, 0.3722, 0.3498, 0.4579, 0.2694])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.8248677253723145 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3102, 0.5946, 0.5125, 0.3763, 0.3531, 0.4562, 0.2679]) \n",
      "Test Loss tensor([0.3088, 0.5906, 0.5101, 0.3735, 0.3502, 0.4562, 0.2671])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.7302165031433105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3088, 0.5919, 0.5136, 0.3680, 0.3512, 0.4576, 0.2667]) \n",
      "Test Loss tensor([0.3076, 0.5887, 0.5099, 0.3721, 0.3511, 0.4575, 0.2644])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.7690331935882568 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3076, 0.5889, 0.5090, 0.3720, 0.3495, 0.4589, 0.2650]) \n",
      "Test Loss tensor([0.3047, 0.5865, 0.5089, 0.3704, 0.3505, 0.4583, 0.2616])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.758699893951416 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3065, 0.5857, 0.5080, 0.3697, 0.3528, 0.4537, 0.2618]) \n",
      "Test Loss tensor([0.3037, 0.5838, 0.5059, 0.3700, 0.3509, 0.4559, 0.2582])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.8197281360626221 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3023, 0.5830, 0.5073, 0.3626, 0.3499, 0.4576, 0.2576]) \n",
      "Test Loss tensor([0.3015, 0.5816, 0.5051, 0.3684, 0.3515, 0.4578, 0.2552])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.7588741779327393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.3003, 0.5829, 0.5062, 0.3677, 0.3518, 0.4549, 0.2539]) \n",
      "Test Loss tensor([0.2987, 0.5789, 0.5046, 0.3664, 0.3502, 0.4569, 0.2516])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7689383029937744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2980, 0.5779, 0.5040, 0.3729, 0.3486, 0.4533, 0.2511]) \n",
      "Test Loss tensor([0.2955, 0.5765, 0.5016, 0.3666, 0.3516, 0.4565, 0.2481])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7902324199676514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2960, 0.5771, 0.5008, 0.3756, 0.3509, 0.4596, 0.2479]) \n",
      "Test Loss tensor([0.2923, 0.5737, 0.4996, 0.3672, 0.3503, 0.4565, 0.2441])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.7763121128082275 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2966, 0.5716, 0.5005, 0.3654, 0.3514, 0.4569, 0.2430]) \n",
      "Test Loss tensor([0.2891, 0.5708, 0.4989, 0.3660, 0.3503, 0.4559, 0.2401])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7648317813873291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2906, 0.5714, 0.4986, 0.3671, 0.3531, 0.4549, 0.2405]) \n",
      "Test Loss tensor([0.2849, 0.5681, 0.4975, 0.3634, 0.3507, 0.4566, 0.2363])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.7450237274169922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2875, 0.5665, 0.4936, 0.3682, 0.3504, 0.4548, 0.2353]) \n",
      "Test Loss tensor([0.2814, 0.5642, 0.4947, 0.3644, 0.3507, 0.4551, 0.2318])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.7798259258270264 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2798, 0.5656, 0.4972, 0.3653, 0.3501, 0.4557, 0.2322]) \n",
      "Test Loss tensor([0.2778, 0.5616, 0.4923, 0.3644, 0.3502, 0.4541, 0.2281])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.7718393802642822 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2800, 0.5614, 0.4929, 0.3602, 0.3510, 0.4566, 0.2273]) \n",
      "Test Loss tensor([0.2736, 0.5584, 0.4905, 0.3621, 0.3509, 0.4544, 0.2237])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.8137564659118652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2737, 0.5592, 0.4889, 0.3620, 0.3511, 0.4507, 0.2250]) \n",
      "Test Loss tensor([0.2700, 0.5544, 0.4886, 0.3611, 0.3499, 0.4537, 0.2196])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.7964410781860352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2691, 0.5552, 0.4864, 0.3640, 0.3498, 0.4508, 0.2186]) \n",
      "Test Loss tensor([0.2654, 0.5512, 0.4868, 0.3587, 0.3502, 0.4529, 0.2150])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7772798538208008 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2654, 0.5517, 0.4882, 0.3622, 0.3530, 0.4506, 0.2155]) \n",
      "Test Loss tensor([0.2611, 0.5474, 0.4842, 0.3600, 0.3488, 0.4510, 0.2109])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.7632477283477783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2582, 0.5480, 0.4846, 0.3608, 0.3472, 0.4500, 0.2095]) \n",
      "Test Loss tensor([0.2570, 0.5439, 0.4825, 0.3589, 0.3484, 0.4504, 0.2066])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7570171356201172 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2580, 0.5452, 0.4825, 0.3548, 0.3460, 0.4497, 0.2059]) \n",
      "Test Loss tensor([0.2524, 0.5409, 0.4815, 0.3590, 0.3472, 0.4481, 0.2015])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.7335336208343506 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2533, 0.5419, 0.4794, 0.3531, 0.3455, 0.4479, 0.2015]) \n",
      "Test Loss tensor([0.2485, 0.5373, 0.4787, 0.3587, 0.3468, 0.4457, 0.1966])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.7495906352996826 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2457, 0.5376, 0.4811, 0.3557, 0.3464, 0.4438, 0.1970]) \n",
      "Test Loss tensor([0.2422, 0.5344, 0.4770, 0.3566, 0.3444, 0.4432, 0.1918])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.7557697296142578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2403, 0.5353, 0.4771, 0.3483, 0.3409, 0.4452, 0.1905]) \n",
      "Test Loss tensor([0.2395, 0.5304, 0.4747, 0.3556, 0.3434, 0.4410, 0.1863])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.85390305519104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2411, 0.5315, 0.4739, 0.3553, 0.3422, 0.4379, 0.1862]) \n",
      "Test Loss tensor([0.2345, 0.5259, 0.4705, 0.3569, 0.3387, 0.4388, 0.1816])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.8247725963592529 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2362, 0.5270, 0.4710, 0.3565, 0.3370, 0.4379, 0.1828]) \n",
      "Test Loss tensor([0.2315, 0.5216, 0.4670, 0.3546, 0.3385, 0.4361, 0.1768])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7631397247314453 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2293, 0.5211, 0.4659, 0.3513, 0.3380, 0.4364, 0.1767]) \n",
      "Test Loss tensor([0.2275, 0.5167, 0.4638, 0.3549, 0.3352, 0.4321, 0.1711])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.748950719833374 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2278, 0.5178, 0.4624, 0.3520, 0.3336, 0.4335, 0.1713]) \n",
      "Test Loss tensor([0.2239, 0.5130, 0.4613, 0.3525, 0.3346, 0.4287, 0.1655])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.7629313468933105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2270, 0.5130, 0.4623, 0.3418, 0.3354, 0.4270, 0.1652]) \n",
      "Test Loss tensor([0.2187, 0.5085, 0.4576, 0.3546, 0.3296, 0.4229, 0.1593])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.8014445304870605 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2190, 0.5083, 0.4549, 0.3565, 0.3302, 0.4194, 0.1592]) \n",
      "Test Loss tensor([0.2138, 0.5045, 0.4546, 0.3530, 0.3254, 0.4177, 0.1540])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.8033840656280518 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2130, 0.5040, 0.4571, 0.3393, 0.3327, 0.4198, 0.1532]) \n",
      "Test Loss tensor([0.2108, 0.5007, 0.4506, 0.3507, 0.3230, 0.4127, 0.1480])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.8380436897277832 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2115, 0.5005, 0.4485, 0.3543, 0.3225, 0.4120, 0.1459]) \n",
      "Test Loss tensor([0.2046, 0.4961, 0.4469, 0.3519, 0.3170, 0.4067, 0.1414])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.8650448322296143 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2062, 0.4971, 0.4472, 0.3474, 0.3178, 0.4052, 0.1410]) \n",
      "Test Loss tensor([0.2000, 0.4918, 0.4426, 0.3497, 0.3111, 0.3996, 0.1355])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.831125020980835 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.2002, 0.4921, 0.4423, 0.3575, 0.3113, 0.4014, 0.1349]) \n",
      "Test Loss tensor([0.1948, 0.4865, 0.4373, 0.3500, 0.3062, 0.3927, 0.1284])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.8827123641967773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1942, 0.4882, 0.4369, 0.3486, 0.3066, 0.3902, 0.1287]) \n",
      "Test Loss tensor([0.1921, 0.4823, 0.4326, 0.3520, 0.2998, 0.3846, 0.1225])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.7829592227935791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1901, 0.4816, 0.4304, 0.3522, 0.3025, 0.3833, 0.1231]) \n",
      "Test Loss tensor([0.1857, 0.4776, 0.4294, 0.3488, 0.2926, 0.3764, 0.1155])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.7531657218933105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1831, 0.4768, 0.4290, 0.3655, 0.2976, 0.3731, 0.1148]) \n",
      "Test Loss tensor([0.1784, 0.4723, 0.4243, 0.3491, 0.2860, 0.3685, 0.1086])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.7338688373565674 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1811, 0.4732, 0.4269, 0.3283, 0.2882, 0.3692, 0.1080]) \n",
      "Test Loss tensor([0.1786, 0.4674, 0.4171, 0.3537, 0.2816, 0.3608, 0.1022])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 576 in 0.7337548732757568 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1715, 0.4665, 0.4157, 0.3493, 0.2765, 0.3626, 0.1017]) \n",
      "Test Loss tensor([0.1735, 0.4615, 0.4115, 0.3517, 0.2753, 0.3522, 0.0952])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.7494680881500244 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1741, 0.4617, 0.4130, 0.3496, 0.2792, 0.3542, 0.0965]) \n",
      "Test Loss tensor([0.1663, 0.4569, 0.4062, 0.3531, 0.2679, 0.3440, 0.0890])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.7648763656616211 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1651, 0.4563, 0.4072, 0.3484, 0.2681, 0.3444, 0.0897]) \n",
      "Test Loss tensor([0.1620, 0.4518, 0.4025, 0.3551, 0.2631, 0.3324, 0.0818])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.7530112266540527 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1663, 0.4525, 0.4005, 0.3621, 0.2649, 0.3306, 0.0819]) \n",
      "Test Loss tensor([0.1566, 0.4469, 0.3965, 0.3557, 0.2585, 0.3246, 0.0757])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.7389090061187744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1482, 0.4468, 0.4013, 0.3456, 0.2584, 0.3219, 0.0766]) \n",
      "Test Loss tensor([0.1531, 0.4412, 0.3919, 0.3542, 0.2506, 0.3162, 0.0701])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.7592177391052246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1534, 0.4407, 0.3928, 0.3517, 0.2519, 0.3195, 0.0677]) \n",
      "Test Loss tensor([0.1486, 0.4358, 0.3873, 0.3540, 0.2458, 0.3097, 0.0633])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.7637689113616943 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1517, 0.4353, 0.3872, 0.3548, 0.2433, 0.3072, 0.0640]) \n",
      "Test Loss tensor([0.1427, 0.4290, 0.3819, 0.3551, 0.2395, 0.3002, 0.0576])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7401065826416016 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1466, 0.4292, 0.3827, 0.3636, 0.2346, 0.3053, 0.0572]) \n",
      "Test Loss tensor([0.1373, 0.4239, 0.3766, 0.3595, 0.2333, 0.2935, 0.0521])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.7636699676513672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1408, 0.4240, 0.3777, 0.3543, 0.2346, 0.2966, 0.0529]) \n",
      "Test Loss tensor([0.1358, 0.4184, 0.3710, 0.3600, 0.2292, 0.2843, 0.0470])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.7758362293243408 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1292, 0.4192, 0.3756, 0.3598, 0.2302, 0.2821, 0.0464]) \n",
      "Test Loss tensor([0.1337, 0.4137, 0.3657, 0.3635, 0.2247, 0.2770, 0.0414])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.7768435478210449 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1309, 0.4132, 0.3667, 0.3567, 0.2223, 0.2742, 0.0431]) \n",
      "Test Loss tensor([0.1280, 0.4087, 0.3603, 0.3663, 0.2178, 0.2703, 0.0375])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.8464977741241455 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1280, 0.4082, 0.3609, 0.3607, 0.2167, 0.2685, 0.0358]) \n",
      "Test Loss tensor([0.1232, 0.4036, 0.3536, 0.3714, 0.2128, 0.2631, 0.0327])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.7386250495910645 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1298, 0.4043, 0.3568, 0.3737, 0.2150, 0.2684, 0.0349]) \n",
      "Test Loss tensor([0.1223, 0.3976, 0.3486, 0.3702, 0.2094, 0.2567, 0.0299])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.7492480278015137 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1256, 0.3991, 0.3480, 0.3672, 0.2076, 0.2597, 0.0282]) \n",
      "Test Loss tensor([0.1176, 0.3931, 0.3444, 0.3740, 0.2042, 0.2511, 0.0258])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.7662403583526611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1254, 0.3933, 0.3416, 0.3835, 0.2073, 0.2474, 0.0269]) \n",
      "Test Loss tensor([0.1149, 0.3873, 0.3387, 0.3749, 0.1992, 0.2457, 0.0236])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.807746171951294 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1126, 0.3880, 0.3374, 0.3758, 0.2021, 0.2412, 0.0222]) \n",
      "Test Loss tensor([0.1131, 0.3811, 0.3331, 0.3779, 0.1948, 0.2377, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.7326269149780273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1158, 0.3812, 0.3295, 0.3960, 0.1919, 0.2412, 0.0213]) \n",
      "Test Loss tensor([0.1100, 0.3754, 0.3272, 0.3795, 0.1917, 0.2344, 0.0188])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.7670564651489258 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1059, 0.3758, 0.3335, 0.3701, 0.1897, 0.2350, 0.0185]) \n",
      "Test Loss tensor([0.1112, 0.3694, 0.3203, 0.3899, 0.1884, 0.2261, 0.0165])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.7771852016448975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1031, 0.3693, 0.3215, 0.3739, 0.1866, 0.2250, 0.0142]) \n",
      "Test Loss tensor([0.1086, 0.3632, 0.3141, 0.3905, 0.1851, 0.2203, 0.0150])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.8023943901062012 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1114, 0.3640, 0.3142, 0.3904, 0.1854, 0.2231, 0.0117]) \n",
      "Test Loss tensor([0.1070, 0.3571, 0.3089, 0.3912, 0.1815, 0.2163, 0.0149])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.8069777488708496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1165, 0.3572, 0.3116, 0.3878, 0.1786, 0.2167, 0.0121]) \n",
      "Test Loss tensor([0.1053, 0.3498, 0.3033, 0.3937, 0.1757, 0.2109, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.7835292816162109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1098, 0.3497, 0.3061, 0.3766, 0.1795, 0.2126, 0.0126]) \n",
      "Test Loss tensor([0.1035, 0.3424, 0.2973, 0.3943, 0.1745, 0.2056, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.7725653648376465 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1054, 0.3443, 0.2995, 0.3973, 0.1753, 0.2078, 0.0138]) \n",
      "Test Loss tensor([0.1047, 0.3353, 0.2915, 0.3983, 0.1717, 0.2007, 0.0117])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.7704982757568359 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1098, 0.3358, 0.2941, 0.3921, 0.1685, 0.2034, 0.0113]) \n",
      "Test Loss tensor([0.1053, 0.3271, 0.2856, 0.3950, 0.1685, 0.1946, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.7450041770935059 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1102, 0.3256, 0.2887, 0.3951, 0.1649, 0.1955, 0.0105]) \n",
      "Test Loss tensor([0.1040, 0.3185, 0.2773, 0.3984, 0.1650, 0.1887, 0.0104])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.7671804428100586 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1031, 0.3188, 0.2732, 0.4081, 0.1680, 0.1859, 0.0116]) \n",
      "Test Loss tensor([0.1045, 0.3097, 0.2708, 0.4023, 0.1665, 0.1805, 0.0099])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.7613871097564697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1019, 0.3094, 0.2753, 0.3927, 0.1667, 0.1766, 0.0117]) \n",
      "Test Loss tensor([0.1055, 0.2998, 0.2626, 0.4058, 0.1646, 0.1690, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.7363259792327881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1106, 0.3001, 0.2664, 0.4025, 0.1646, 0.1705, 0.0097]) \n",
      "Test Loss tensor([0.1013, 0.2904, 0.2562, 0.4034, 0.1627, 0.1603, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.7491459846496582 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1086, 0.2912, 0.2545, 0.4091, 0.1660, 0.1597, 0.0080]) \n",
      "Test Loss tensor([0.1017, 0.2792, 0.2491, 0.4080, 0.1594, 0.1518, 0.0092])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.7444841861724854 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1083, 0.2795, 0.2482, 0.3980, 0.1576, 0.1473, 0.0077]) \n",
      "Test Loss tensor([0.1018, 0.2681, 0.2419, 0.4050, 0.1571, 0.1428, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7379333972930908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1122, 0.2690, 0.2415, 0.4104, 0.1623, 0.1404, 0.0086]) \n",
      "Test Loss tensor([0.1040, 0.2562, 0.2326, 0.4090, 0.1582, 0.1351, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.7395040988922119 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1016, 0.2563, 0.2372, 0.3864, 0.1569, 0.1307, 0.0077]) \n",
      "Test Loss tensor([0.1061, 0.2441, 0.2260, 0.4067, 0.1577, 0.1269, 0.0084])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.7513630390167236 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1037, 0.2452, 0.2273, 0.4031, 0.1570, 0.1284, 0.0109]) \n",
      "Test Loss tensor([0.1028, 0.2316, 0.2176, 0.4038, 0.1571, 0.1211, 0.0086])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.7627224922180176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0965, 0.2319, 0.2207, 0.4078, 0.1588, 0.1198, 0.0088]) \n",
      "Test Loss tensor([0.1046, 0.2186, 0.2088, 0.4043, 0.1541, 0.1143, 0.0081])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.7597768306732178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1102, 0.2189, 0.2090, 0.3994, 0.1512, 0.1141, 0.0085]) \n",
      "Test Loss tensor([0.1068, 0.2057, 0.1992, 0.4075, 0.1551, 0.1073, 0.0083])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.7362618446350098 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1138, 0.2069, 0.1981, 0.4074, 0.1574, 0.1052, 0.0094]) \n",
      "Test Loss tensor([0.1038, 0.1930, 0.1886, 0.4083, 0.1531, 0.1004, 0.0081])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.7661991119384766 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1039, 0.1921, 0.1890, 0.3885, 0.1524, 0.1006, 0.0098]) \n",
      "Test Loss tensor([0.1010, 0.1789, 0.1782, 0.4014, 0.1483, 0.0929, 0.0066])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.8157079219818115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1126, 0.1786, 0.1799, 0.4095, 0.1461, 0.0930, 0.0073]) \n",
      "Test Loss tensor([0.1018, 0.1656, 0.1664, 0.4006, 0.1475, 0.0863, 0.0079])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.7472171783447266 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1074, 0.1650, 0.1683, 0.3960, 0.1494, 0.0858, 0.0074]) \n",
      "Test Loss tensor([0.1033, 0.1516, 0.1559, 0.4007, 0.1472, 0.0791, 0.0071])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.7778277397155762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0990, 0.1529, 0.1573, 0.3985, 0.1437, 0.0823, 0.0088]) \n",
      "Test Loss tensor([0.1029, 0.1368, 0.1455, 0.3958, 0.1472, 0.0722, 0.0074])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.7318003177642822 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1059, 0.1393, 0.1469, 0.4060, 0.1475, 0.0747, 0.0070]) \n",
      "Test Loss tensor([0.1035, 0.1223, 0.1345, 0.3933, 0.1469, 0.0665, 0.0075])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.738853931427002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1074, 0.1218, 0.1338, 0.4004, 0.1414, 0.0663, 0.0064]) \n",
      "Test Loss tensor([0.1053, 0.1084, 0.1232, 0.3884, 0.1469, 0.0599, 0.0072])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.7380895614624023 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1018, 0.1096, 0.1260, 0.3967, 0.1575, 0.0605, 0.0057]) \n",
      "Test Loss tensor([0.1087, 0.0943, 0.1140, 0.3827, 0.1469, 0.0539, 0.0073])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7731602191925049 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1095, 0.0943, 0.1166, 0.3740, 0.1411, 0.0522, 0.0078]) \n",
      "Test Loss tensor([0.1061, 0.0804, 0.1043, 0.3591, 0.1477, 0.0499, 0.0062])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.7415482997894287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1052, 0.0812, 0.1041, 0.3407, 0.1484, 0.0520, 0.0068]) \n",
      "Test Loss tensor([0.1069, 0.0685, 0.0970, 0.3196, 0.1562, 0.0481, 0.0064])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.7766742706298828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0994, 0.0700, 0.0972, 0.3182, 0.1510, 0.0505, 0.0057]) \n",
      "Test Loss tensor([0.1066, 0.0569, 0.0930, 0.2428, 0.1635, 0.0520, 0.0054])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7554299831390381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1089, 0.0571, 0.0970, 0.2460, 0.1656, 0.0580, 0.0062]) \n",
      "Test Loss tensor([0.1126, 0.0466, 0.0915, 0.1720, 0.1812, 0.0570, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7302157878875732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1038, 0.0471, 0.0853, 0.1591, 0.1800, 0.0568, 0.0055]) \n",
      "Test Loss tensor([0.1149, 0.0380, 0.0890, 0.1147, 0.2042, 0.0601, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.7188012599945068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1195, 0.0382, 0.0912, 0.1180, 0.1911, 0.0616, 0.0048]) \n",
      "Test Loss tensor([0.1155, 0.0311, 0.0841, 0.0913, 0.2047, 0.0513, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.7263402938842773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1162, 0.0312, 0.0890, 0.0916, 0.1923, 0.0515, 0.0032]) \n",
      "Test Loss tensor([0.1165, 0.0256, 0.0760, 0.0802, 0.1951, 0.0381, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7336862087249756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1227, 0.0258, 0.0848, 0.0869, 0.1907, 0.0401, 0.0047]) \n",
      "Test Loss tensor([0.1166, 0.0208, 0.0686, 0.0785, 0.1806, 0.0285, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.8347008228302002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1170, 0.0217, 0.0737, 0.0818, 0.1919, 0.0292, 0.0036]) \n",
      "Test Loss tensor([0.1138, 0.0175, 0.0608, 0.0765, 0.1794, 0.0219, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.7636620998382568 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1240, 0.0177, 0.0573, 0.0731, 0.1833, 0.0236, 0.0053]) \n",
      "Test Loss tensor([0.1141, 0.0142, 0.0542, 0.0716, 0.1817, 0.0193, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.8082184791564941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1162, 0.0136, 0.0587, 0.0787, 0.1790, 0.0153, 0.0032]) \n",
      "Test Loss tensor([0.1149, 0.0119, 0.0507, 0.0662, 0.1811, 0.0186, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.7851042747497559 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1130, 0.0130, 0.0534, 0.0673, 0.1821, 0.0173, 0.0035]) \n",
      "Test Loss tensor([0.1147, 0.0105, 0.0485, 0.0586, 0.1845, 0.0169, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.7548067569732666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1103, 0.0093, 0.0484, 0.0591, 0.1901, 0.0155, 0.0046]) \n",
      "Test Loss tensor([0.1133, 0.0085, 0.0470, 0.0514, 0.1847, 0.0167, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.7535717487335205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1220, 0.0084, 0.0467, 0.0504, 0.1814, 0.0152, 0.0027]) \n",
      "Test Loss tensor([0.1125, 0.0076, 0.0455, 0.0432, 0.1926, 0.0161, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.783390998840332 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1025, 0.0065, 0.0468, 0.0409, 0.1952, 0.0211, 0.0027]) \n",
      "Test Loss tensor([0.1144, 0.0069, 0.0452, 0.0372, 0.1922, 0.0157, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7613468170166016 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1195, 0.0068, 0.0439, 0.0355, 0.1918, 0.0154, 0.0038]) \n",
      "Test Loss tensor([0.1165, 0.0056, 0.0442, 0.0334, 0.1954, 0.0156, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.7622711658477783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1252, 0.0050, 0.0446, 0.0341, 0.1886, 0.0184, 0.0053]) \n",
      "Test Loss tensor([0.1163, 0.0053, 0.0448, 0.0292, 0.1934, 0.0141, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.76763916015625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1095, 0.0049, 0.0494, 0.0261, 0.1942, 0.0101, 0.0044]) \n",
      "Test Loss tensor([0.1158, 0.0048, 0.0432, 0.0267, 0.1943, 0.0152, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7364840507507324 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1153, 0.0054, 0.0452, 0.0257, 0.1864, 0.0167, 0.0032]) \n",
      "Test Loss tensor([0.1151, 0.0043, 0.0428, 0.0258, 0.1926, 0.0142, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.7360694408416748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1181, 0.0059, 0.0465, 0.0273, 0.1949, 0.0158, 0.0046]) \n",
      "Test Loss tensor([0.1121, 0.0042, 0.0397, 0.0255, 0.1943, 0.0140, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.7556955814361572 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1200, 0.0039, 0.0407, 0.0263, 0.1988, 0.0156, 0.0034]) \n",
      "Test Loss tensor([0.1113, 0.0046, 0.0382, 0.0265, 0.1932, 0.0145, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7414870262145996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1157, 0.0059, 0.0382, 0.0263, 0.1953, 0.0160, 0.0057]) \n",
      "Test Loss tensor([0.1103, 0.0044, 0.0365, 0.0267, 0.1917, 0.0145, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.8205206394195557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1143, 0.0069, 0.0385, 0.0283, 0.2038, 0.0126, 0.0030]) \n",
      "Test Loss tensor([0.1079, 0.0044, 0.0360, 0.0280, 0.1954, 0.0143, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7689611911773682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1106, 0.0037, 0.0395, 0.0275, 0.2049, 0.0120, 0.0047]) \n",
      "Test Loss tensor([0.1079, 0.0045, 0.0350, 0.0294, 0.1970, 0.0155, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.7903923988342285 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1076, 0.0035, 0.0369, 0.0279, 0.1974, 0.0134, 0.0044]) \n",
      "Test Loss tensor([0.1050, 0.0045, 0.0346, 0.0286, 0.1976, 0.0146, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.8075597286224365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1006, 0.0030, 0.0341, 0.0277, 0.1959, 0.0148, 0.0050]) \n",
      "Test Loss tensor([0.1057, 0.0043, 0.0356, 0.0278, 0.1961, 0.0143, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.8185036182403564 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0965, 0.0035, 0.0347, 0.0278, 0.1905, 0.0116, 0.0038]) \n",
      "Test Loss tensor([0.1035, 0.0041, 0.0343, 0.0274, 0.1960, 0.0153, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.8021290302276611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1034, 0.0058, 0.0348, 0.0208, 0.1837, 0.0140, 0.0051]) \n",
      "Test Loss tensor([0.1036, 0.0043, 0.0361, 0.0251, 0.1894, 0.0155, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7508010864257812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1091, 0.0052, 0.0342, 0.0267, 0.1896, 0.0192, 0.0049]) \n",
      "Test Loss tensor([0.1013, 0.0038, 0.0352, 0.0241, 0.1939, 0.0165, 0.0047])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.8169026374816895 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1156, 0.0064, 0.0351, 0.0221, 0.2011, 0.0165, 0.0058]) \n",
      "Test Loss tensor([0.1044, 0.0043, 0.0361, 0.0232, 0.1921, 0.0174, 0.0057])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.7766633033752441 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0973, 0.0062, 0.0324, 0.0216, 0.1898, 0.0212, 0.0053]) \n",
      "Test Loss tensor([0.1037, 0.0041, 0.0364, 0.0230, 0.1902, 0.0162, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.8532545566558838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1018, 0.0055, 0.0350, 0.0234, 0.1912, 0.0144, 0.0051]) \n",
      "Test Loss tensor([0.1020, 0.0039, 0.0340, 0.0230, 0.1845, 0.0157, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.7201273441314697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0747, 0.0029, 0.0263, 0.0201, 0.1415, 0.0092, 0.0036]) \n",
      "Test Loss tensor([0.1032, 0.0041, 0.0349, 0.0229, 0.1898, 0.0153, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7701621055603027 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0940, 0.0038, 0.0371, 0.0234, 0.1960, 0.0153, 0.0056]) \n",
      "Test Loss tensor([0.1037, 0.0040, 0.0349, 0.0232, 0.1887, 0.0149, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.74542236328125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1037, 0.0051, 0.0348, 0.0203, 0.1844, 0.0155, 0.0053]) \n",
      "Test Loss tensor([0.0998, 0.0043, 0.0343, 0.0232, 0.1856, 0.0135, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7306323051452637 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1016, 0.0048, 0.0352, 0.0240, 0.1911, 0.0127, 0.0049]) \n",
      "Test Loss tensor([0.0996, 0.0047, 0.0340, 0.0242, 0.1872, 0.0132, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7594249248504639 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1075, 0.0036, 0.0325, 0.0245, 0.1975, 0.0137, 0.0037]) \n",
      "Test Loss tensor([0.0985, 0.0042, 0.0339, 0.0227, 0.1841, 0.0132, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.7334270477294922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1042, 0.0050, 0.0367, 0.0219, 0.2019, 0.0137, 0.0038]) \n",
      "Test Loss tensor([0.1023, 0.0043, 0.0336, 0.0230, 0.1861, 0.0124, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7529933452606201 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1054, 0.0044, 0.0355, 0.0242, 0.1677, 0.0105, 0.0039]) \n",
      "Test Loss tensor([0.1005, 0.0046, 0.0338, 0.0222, 0.1842, 0.0133, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.7442607879638672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1061, 0.0039, 0.0360, 0.0232, 0.1804, 0.0107, 0.0045]) \n",
      "Test Loss tensor([0.0996, 0.0046, 0.0331, 0.0222, 0.1829, 0.0127, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.8104076385498047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1019, 0.0038, 0.0341, 0.0201, 0.1802, 0.0125, 0.0037]) \n",
      "Test Loss tensor([0.0995, 0.0046, 0.0328, 0.0223, 0.1823, 0.0129, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.7985935211181641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0968, 0.0055, 0.0352, 0.0223, 0.1882, 0.0147, 0.0042]) \n",
      "Test Loss tensor([0.1023, 0.0039, 0.0339, 0.0211, 0.1797, 0.0122, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7565648555755615 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0923, 0.0045, 0.0350, 0.0200, 0.1917, 0.0149, 0.0041]) \n",
      "Test Loss tensor([0.0985, 0.0044, 0.0341, 0.0209, 0.1810, 0.0123, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.7700114250183105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1029, 0.0050, 0.0317, 0.0205, 0.1790, 0.0110, 0.0043]) \n",
      "Test Loss tensor([0.1015, 0.0045, 0.0326, 0.0205, 0.1809, 0.0120, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7351462841033936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1031, 0.0049, 0.0309, 0.0217, 0.1808, 0.0133, 0.0058]) \n",
      "Test Loss tensor([0.0985, 0.0046, 0.0328, 0.0210, 0.1806, 0.0117, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7370054721832275 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0906, 0.0043, 0.0342, 0.0221, 0.1906, 0.0107, 0.0043]) \n",
      "Test Loss tensor([0.0997, 0.0046, 0.0341, 0.0213, 0.1764, 0.0120, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.7776570320129395 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1085, 0.0046, 0.0348, 0.0191, 0.1732, 0.0148, 0.0040]) \n",
      "Test Loss tensor([0.0981, 0.0051, 0.0329, 0.0215, 0.1765, 0.0122, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.787844181060791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1034, 0.0059, 0.0352, 0.0233, 0.1729, 0.0123, 0.0044]) \n",
      "Test Loss tensor([0.0993, 0.0051, 0.0339, 0.0226, 0.1775, 0.0118, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.8271670341491699 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1038, 0.0072, 0.0366, 0.0217, 0.1793, 0.0105, 0.0040]) \n",
      "Test Loss tensor([0.1024, 0.0056, 0.0341, 0.0225, 0.1790, 0.0122, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7556378841400146 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0861, 0.0050, 0.0311, 0.0209, 0.1863, 0.0109, 0.0037]) \n",
      "Test Loss tensor([0.0959, 0.0056, 0.0324, 0.0235, 0.1788, 0.0126, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7533149719238281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0948, 0.0056, 0.0349, 0.0212, 0.1795, 0.0146, 0.0044]) \n",
      "Test Loss tensor([0.0973, 0.0056, 0.0337, 0.0225, 0.1760, 0.0123, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.7552285194396973 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1033, 0.0059, 0.0314, 0.0213, 0.1709, 0.0105, 0.0037]) \n",
      "Test Loss tensor([0.0964, 0.0060, 0.0332, 0.0222, 0.1720, 0.0121, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7371623516082764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0927, 0.0079, 0.0322, 0.0219, 0.1839, 0.0115, 0.0047]) \n",
      "Test Loss tensor([0.0941, 0.0057, 0.0315, 0.0218, 0.1706, 0.0119, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7605569362640381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1028, 0.0044, 0.0332, 0.0216, 0.1746, 0.0142, 0.0047]) \n",
      "Test Loss tensor([0.0965, 0.0059, 0.0326, 0.0219, 0.1704, 0.0117, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7862577438354492 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0958, 0.0058, 0.0338, 0.0228, 0.1767, 0.0113, 0.0048]) \n",
      "Test Loss tensor([0.0972, 0.0056, 0.0328, 0.0211, 0.1721, 0.0131, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.7891006469726562 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0987, 0.0059, 0.0333, 0.0205, 0.1650, 0.0105, 0.0046]) \n",
      "Test Loss tensor([0.0949, 0.0058, 0.0335, 0.0205, 0.1711, 0.0135, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7471189498901367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0911, 0.0063, 0.0298, 0.0206, 0.1759, 0.0117, 0.0055]) \n",
      "Test Loss tensor([0.0968, 0.0053, 0.0340, 0.0212, 0.1697, 0.0134, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7508516311645508 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0970, 0.0073, 0.0345, 0.0236, 0.1683, 0.0126, 0.0047]) \n",
      "Test Loss tensor([0.0964, 0.0056, 0.0330, 0.0207, 0.1697, 0.0128, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7531285285949707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0995, 0.0055, 0.0345, 0.0224, 0.1760, 0.0150, 0.0054]) \n",
      "Test Loss tensor([0.0948, 0.0060, 0.0323, 0.0211, 0.1708, 0.0132, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.795828104019165 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1003, 0.0056, 0.0334, 0.0203, 0.1655, 0.0134, 0.0040]) \n",
      "Test Loss tensor([0.0955, 0.0061, 0.0337, 0.0218, 0.1673, 0.0127, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.769399881362915 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0925, 0.0065, 0.0337, 0.0215, 0.1607, 0.0114, 0.0049]) \n",
      "Test Loss tensor([0.0927, 0.0063, 0.0332, 0.0219, 0.1683, 0.0124, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7962286472320557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0940, 0.0064, 0.0306, 0.0209, 0.1727, 0.0141, 0.0051]) \n",
      "Test Loss tensor([0.0949, 0.0064, 0.0325, 0.0237, 0.1663, 0.0118, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.7460496425628662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0915, 0.0061, 0.0335, 0.0249, 0.1673, 0.0090, 0.0040]) \n",
      "Test Loss tensor([0.0947, 0.0064, 0.0328, 0.0231, 0.1662, 0.0126, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7609872817993164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1017, 0.0082, 0.0315, 0.0244, 0.1659, 0.0123, 0.0050]) \n",
      "Test Loss tensor([0.0976, 0.0065, 0.0331, 0.0232, 0.1658, 0.0127, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.7573723793029785 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1042, 0.0054, 0.0313, 0.0237, 0.1666, 0.0115, 0.0044]) \n",
      "Test Loss tensor([0.0939, 0.0064, 0.0320, 0.0221, 0.1653, 0.0125, 0.0046])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 128 in 0.7834975719451904 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0951, 0.0061, 0.0335, 0.0224, 0.1702, 0.0119, 0.0050]) \n",
      "Test Loss tensor([0.0966, 0.0061, 0.0317, 0.0224, 0.1644, 0.0125, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.7553608417510986 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0934, 0.0061, 0.0367, 0.0227, 0.1706, 0.0138, 0.0055]) \n",
      "Test Loss tensor([0.0978, 0.0058, 0.0332, 0.0218, 0.1654, 0.0122, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.7624809741973877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0951, 0.0062, 0.0295, 0.0194, 0.1641, 0.0112, 0.0044]) \n",
      "Test Loss tensor([0.0960, 0.0059, 0.0329, 0.0214, 0.1646, 0.0126, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7546594142913818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1009, 0.0053, 0.0324, 0.0220, 0.1767, 0.0120, 0.0049]) \n",
      "Test Loss tensor([0.0948, 0.0060, 0.0323, 0.0221, 0.1610, 0.0126, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.7527234554290771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0912, 0.0061, 0.0305, 0.0214, 0.1648, 0.0120, 0.0051]) \n",
      "Test Loss tensor([0.0947, 0.0060, 0.0328, 0.0218, 0.1642, 0.0124, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.771674394607544 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0912, 0.0059, 0.0326, 0.0218, 0.1472, 0.0122, 0.0043]) \n",
      "Test Loss tensor([0.0936, 0.0059, 0.0316, 0.0216, 0.1627, 0.0121, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7718391418457031 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0886, 0.0062, 0.0317, 0.0222, 0.1622, 0.0138, 0.0043]) \n",
      "Test Loss tensor([0.0941, 0.0059, 0.0322, 0.0227, 0.1596, 0.0121, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7423088550567627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0869, 0.0047, 0.0312, 0.0220, 0.1600, 0.0095, 0.0040]) \n",
      "Test Loss tensor([0.0925, 0.0064, 0.0322, 0.0237, 0.1608, 0.0120, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7539553642272949 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0902, 0.0052, 0.0322, 0.0229, 0.1683, 0.0119, 0.0040]) \n",
      "Test Loss tensor([0.0934, 0.0060, 0.0314, 0.0234, 0.1607, 0.0121, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.7618134021759033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0988, 0.0062, 0.0318, 0.0239, 0.1605, 0.0132, 0.0042]) \n",
      "Test Loss tensor([0.0938, 0.0061, 0.0315, 0.0232, 0.1587, 0.0117, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7433419227600098 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0908, 0.0050, 0.0336, 0.0220, 0.1569, 0.0100, 0.0043]) \n",
      "Test Loss tensor([0.0947, 0.0059, 0.0313, 0.0226, 0.1584, 0.0120, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.7651126384735107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0965, 0.0059, 0.0333, 0.0208, 0.1660, 0.0094, 0.0039]) \n",
      "Test Loss tensor([0.0934, 0.0055, 0.0320, 0.0218, 0.1563, 0.0118, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.780921459197998 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0987, 0.0051, 0.0347, 0.0225, 0.1572, 0.0119, 0.0046]) \n",
      "Test Loss tensor([0.0938, 0.0054, 0.0326, 0.0205, 0.1601, 0.0111, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7407910823822021 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0879, 0.0045, 0.0284, 0.0205, 0.1671, 0.0123, 0.0053]) \n",
      "Test Loss tensor([0.0934, 0.0053, 0.0316, 0.0209, 0.1585, 0.0121, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7637512683868408 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0933, 0.0058, 0.0326, 0.0207, 0.1477, 0.0133, 0.0045]) \n",
      "Test Loss tensor([0.0920, 0.0052, 0.0322, 0.0206, 0.1587, 0.0116, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.8058772087097168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0925, 0.0057, 0.0315, 0.0198, 0.1540, 0.0127, 0.0054]) \n",
      "Test Loss tensor([0.0926, 0.0054, 0.0310, 0.0213, 0.1555, 0.0118, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.7671496868133545 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0988, 0.0057, 0.0328, 0.0222, 0.1623, 0.0111, 0.0045]) \n",
      "Test Loss tensor([0.0940, 0.0056, 0.0312, 0.0229, 0.1533, 0.0127, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7643451690673828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0907, 0.0068, 0.0276, 0.0220, 0.1592, 0.0137, 0.0046]) \n",
      "Test Loss tensor([0.0895, 0.0061, 0.0308, 0.0223, 0.1538, 0.0112, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.7398886680603027 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0849, 0.0060, 0.0357, 0.0200, 0.1586, 0.0125, 0.0038]) \n",
      "Test Loss tensor([0.0953, 0.0056, 0.0312, 0.0228, 0.1527, 0.0119, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7485461235046387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0959, 0.0056, 0.0309, 0.0211, 0.1511, 0.0108, 0.0044]) \n",
      "Test Loss tensor([0.0958, 0.0056, 0.0317, 0.0227, 0.1555, 0.0115, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.7811474800109863 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0979, 0.0054, 0.0315, 0.0197, 0.1518, 0.0111, 0.0038]) \n",
      "Test Loss tensor([0.0929, 0.0055, 0.0320, 0.0220, 0.1505, 0.0124, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.7808313369750977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0888, 0.0068, 0.0328, 0.0220, 0.1551, 0.0143, 0.0038]) \n",
      "Test Loss tensor([0.0955, 0.0053, 0.0323, 0.0213, 0.1498, 0.0118, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7570772171020508 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0943, 0.0053, 0.0305, 0.0199, 0.1552, 0.0108, 0.0040]) \n",
      "Test Loss tensor([0.0912, 0.0053, 0.0306, 0.0212, 0.1506, 0.0121, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.7477898597717285 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0902, 0.0044, 0.0268, 0.0208, 0.1542, 0.0126, 0.0043]) \n",
      "Test Loss tensor([0.0928, 0.0054, 0.0310, 0.0212, 0.1499, 0.0117, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7740128040313721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0954, 0.0041, 0.0333, 0.0195, 0.1525, 0.0126, 0.0037]) \n",
      "Test Loss tensor([0.0915, 0.0053, 0.0311, 0.0209, 0.1497, 0.0120, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.8196008205413818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0926, 0.0057, 0.0286, 0.0207, 0.1503, 0.0144, 0.0048]) \n",
      "Test Loss tensor([0.0937, 0.0049, 0.0314, 0.0215, 0.1468, 0.0120, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.7589473724365234 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0933, 0.0057, 0.0324, 0.0232, 0.1417, 0.0123, 0.0054]) \n",
      "Test Loss tensor([0.0911, 0.0050, 0.0313, 0.0208, 0.1442, 0.0115, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.8060905933380127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0978, 0.0051, 0.0334, 0.0187, 0.1435, 0.0137, 0.0046]) \n",
      "Test Loss tensor([0.0924, 0.0052, 0.0317, 0.0218, 0.1442, 0.0120, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.7978694438934326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0889, 0.0038, 0.0302, 0.0212, 0.1429, 0.0112, 0.0045]) \n",
      "Test Loss tensor([0.0924, 0.0054, 0.0314, 0.0228, 0.1421, 0.0115, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7874174118041992 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0936, 0.0048, 0.0320, 0.0222, 0.1454, 0.0113, 0.0045]) \n",
      "Test Loss tensor([0.0911, 0.0053, 0.0306, 0.0221, 0.1385, 0.0119, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7655031681060791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0934, 0.0068, 0.0286, 0.0230, 0.1462, 0.0104, 0.0049]) \n",
      "Test Loss tensor([0.0906, 0.0054, 0.0321, 0.0220, 0.1397, 0.0122, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7619490623474121 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0964, 0.0062, 0.0285, 0.0213, 0.1429, 0.0125, 0.0041]) \n",
      "Test Loss tensor([0.0925, 0.0056, 0.0315, 0.0221, 0.1396, 0.0118, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7514476776123047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0904, 0.0046, 0.0319, 0.0231, 0.1442, 0.0103, 0.0051]) \n",
      "Test Loss tensor([0.0953, 0.0051, 0.0319, 0.0212, 0.1365, 0.0117, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7814157009124756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0921, 0.0047, 0.0307, 0.0219, 0.1312, 0.0114, 0.0036]) \n",
      "Test Loss tensor([0.0915, 0.0048, 0.0314, 0.0208, 0.1382, 0.0117, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.7967367172241211 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0837, 0.0045, 0.0306, 0.0232, 0.1329, 0.0118, 0.0044]) \n",
      "Test Loss tensor([0.0922, 0.0047, 0.0309, 0.0209, 0.1348, 0.0122, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.7454802989959717 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0885, 0.0057, 0.0314, 0.0209, 0.1389, 0.0147, 0.0046]) \n",
      "Test Loss tensor([0.0910, 0.0048, 0.0305, 0.0206, 0.1359, 0.0116, 0.0042])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 272 in 0.7464311122894287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0953, 0.0067, 0.0292, 0.0209, 0.1299, 0.0129, 0.0050]) \n",
      "Test Loss tensor([0.0912, 0.0046, 0.0316, 0.0215, 0.1359, 0.0120, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7410681247711182 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0864, 0.0046, 0.0281, 0.0194, 0.1329, 0.0128, 0.0045]) \n",
      "Test Loss tensor([0.0882, 0.0049, 0.0307, 0.0218, 0.1325, 0.0115, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.751061201095581 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0920, 0.0047, 0.0311, 0.0199, 0.1361, 0.0121, 0.0043]) \n",
      "Test Loss tensor([0.0911, 0.0051, 0.0303, 0.0220, 0.1297, 0.0117, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7447199821472168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0925, 0.0044, 0.0275, 0.0231, 0.1291, 0.0123, 0.0043]) \n",
      "Test Loss tensor([0.0916, 0.0051, 0.0311, 0.0230, 0.1278, 0.0119, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.741363525390625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0993, 0.0052, 0.0307, 0.0237, 0.1220, 0.0117, 0.0042]) \n",
      "Test Loss tensor([0.0911, 0.0050, 0.0311, 0.0217, 0.1265, 0.0118, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.7414491176605225 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0928, 0.0050, 0.0367, 0.0213, 0.1207, 0.0134, 0.0041]) \n",
      "Test Loss tensor([0.0917, 0.0049, 0.0308, 0.0217, 0.1283, 0.0114, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7334954738616943 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0910, 0.0042, 0.0304, 0.0205, 0.1254, 0.0118, 0.0045]) \n",
      "Test Loss tensor([0.0902, 0.0043, 0.0312, 0.0208, 0.1254, 0.0116, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.732398271560669 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0915, 0.0051, 0.0284, 0.0200, 0.1344, 0.0117, 0.0048]) \n",
      "Test Loss tensor([0.0925, 0.0044, 0.0310, 0.0224, 0.1246, 0.0116, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7582013607025146 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0980, 0.0046, 0.0339, 0.0207, 0.1310, 0.0168, 0.0052]) \n",
      "Test Loss tensor([0.0903, 0.0047, 0.0309, 0.0223, 0.1221, 0.0119, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7656183242797852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0925, 0.0049, 0.0305, 0.0221, 0.1186, 0.0129, 0.0042]) \n",
      "Test Loss tensor([0.0892, 0.0047, 0.0309, 0.0225, 0.1195, 0.0116, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7884466648101807 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0948, 0.0050, 0.0340, 0.0232, 0.1237, 0.0108, 0.0041]) \n",
      "Test Loss tensor([0.0930, 0.0043, 0.0311, 0.0224, 0.1190, 0.0120, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7692110538482666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0950, 0.0061, 0.0330, 0.0223, 0.1192, 0.0106, 0.0040]) \n",
      "Test Loss tensor([0.0927, 0.0045, 0.0320, 0.0218, 0.1172, 0.0116, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7545099258422852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0990, 0.0043, 0.0381, 0.0223, 0.1221, 0.0103, 0.0046]) \n",
      "Test Loss tensor([0.0897, 0.0041, 0.0322, 0.0200, 0.1178, 0.0120, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7614820003509521 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1001, 0.0038, 0.0337, 0.0211, 0.1160, 0.0114, 0.0049]) \n",
      "Test Loss tensor([0.0902, 0.0040, 0.0324, 0.0205, 0.1154, 0.0116, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.7454931735992432 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0878, 0.0040, 0.0309, 0.0217, 0.1181, 0.0155, 0.0042]) \n",
      "Test Loss tensor([0.0892, 0.0040, 0.0322, 0.0206, 0.1120, 0.0115, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7418010234832764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0868, 0.0047, 0.0327, 0.0199, 0.1170, 0.0103, 0.0047]) \n",
      "Test Loss tensor([0.0923, 0.0043, 0.0321, 0.0219, 0.1116, 0.0126, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7424776554107666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1012, 0.0045, 0.0361, 0.0241, 0.1131, 0.0124, 0.0051]) \n",
      "Test Loss tensor([0.0898, 0.0038, 0.0315, 0.0212, 0.1111, 0.0116, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.7339510917663574 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0960, 0.0046, 0.0314, 0.0238, 0.1133, 0.0120, 0.0044]) \n",
      "Test Loss tensor([0.0915, 0.0044, 0.0319, 0.0218, 0.1090, 0.0117, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.7394835948944092 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0909, 0.0048, 0.0346, 0.0220, 0.1138, 0.0111, 0.0041]) \n",
      "Test Loss tensor([0.0926, 0.0043, 0.0325, 0.0215, 0.1074, 0.0122, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.7465946674346924 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0921, 0.0040, 0.0378, 0.0222, 0.1110, 0.0117, 0.0042]) \n",
      "Test Loss tensor([0.0908, 0.0043, 0.0310, 0.0201, 0.1073, 0.0112, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7421958446502686 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0955, 0.0038, 0.0329, 0.0196, 0.1099, 0.0124, 0.0039]) \n",
      "Test Loss tensor([0.0910, 0.0039, 0.0328, 0.0206, 0.1070, 0.0119, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.7386975288391113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.1004, 0.0043, 0.0328, 0.0188, 0.1044, 0.0122, 0.0056]) \n",
      "Test Loss tensor([0.0902, 0.0038, 0.0323, 0.0196, 0.1065, 0.0115, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.7545008659362793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0858, 0.0040, 0.0359, 0.0168, 0.1040, 0.0096, 0.0054]) \n",
      "Test Loss tensor([0.0916, 0.0041, 0.0330, 0.0202, 0.1039, 0.0117, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7476644515991211 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0893, 0.0037, 0.0312, 0.0196, 0.1079, 0.0107, 0.0034]) \n",
      "Test Loss tensor([0.0898, 0.0041, 0.0319, 0.0207, 0.1047, 0.0111, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.760352611541748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0923, 0.0035, 0.0348, 0.0227, 0.1068, 0.0117, 0.0038]) \n",
      "Test Loss tensor([0.0908, 0.0041, 0.0322, 0.0211, 0.0990, 0.0126, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7936813831329346 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0931, 0.0058, 0.0372, 0.0206, 0.1091, 0.0124, 0.0035]) \n",
      "Test Loss tensor([0.0892, 0.0039, 0.0325, 0.0190, 0.1020, 0.0114, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7936077117919922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0848, 0.0031, 0.0369, 0.0217, 0.1046, 0.0108, 0.0043]) \n",
      "Test Loss tensor([0.0894, 0.0040, 0.0325, 0.0192, 0.1019, 0.0120, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.7515702247619629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0905, 0.0031, 0.0350, 0.0192, 0.1082, 0.0114, 0.0049]) \n",
      "Test Loss tensor([0.0940, 0.0040, 0.0320, 0.0194, 0.1022, 0.0123, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.7546498775482178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0907, 0.0037, 0.0314, 0.0210, 0.1017, 0.0101, 0.0035]) \n",
      "Test Loss tensor([0.0896, 0.0037, 0.0315, 0.0198, 0.1014, 0.0113, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7497901916503906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0906, 0.0040, 0.0331, 0.0212, 0.1041, 0.0091, 0.0041]) \n",
      "Test Loss tensor([0.0919, 0.0042, 0.0330, 0.0202, 0.1006, 0.0115, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7350285053253174 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0865, 0.0027, 0.0330, 0.0198, 0.0944, 0.0089, 0.0039]) \n",
      "Test Loss tensor([0.0909, 0.0037, 0.0318, 0.0191, 0.0994, 0.0111, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.75974440574646 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0920, 0.0030, 0.0315, 0.0165, 0.0995, 0.0119, 0.0039]) \n",
      "Test Loss tensor([0.0886, 0.0037, 0.0310, 0.0200, 0.0988, 0.0116, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.7505192756652832 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0915, 0.0033, 0.0289, 0.0160, 0.1051, 0.0130, 0.0037]) \n",
      "Test Loss tensor([0.0919, 0.0040, 0.0333, 0.0192, 0.0967, 0.0112, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7857978343963623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0860, 0.0034, 0.0309, 0.0192, 0.0980, 0.0108, 0.0044]) \n",
      "Test Loss tensor([0.0901, 0.0038, 0.0323, 0.0196, 0.0995, 0.0103, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.7406725883483887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0991, 0.0041, 0.0317, 0.0209, 0.0992, 0.0112, 0.0052]) \n",
      "Test Loss tensor([0.0899, 0.0039, 0.0320, 0.0203, 0.0983, 0.0107, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7581584453582764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0897, 0.0040, 0.0350, 0.0195, 0.0957, 0.0100, 0.0038]) \n",
      "Test Loss tensor([0.0894, 0.0039, 0.0316, 0.0198, 0.0968, 0.0106, 0.0042])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 416 in 0.7627465724945068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0879, 0.0045, 0.0312, 0.0234, 0.1006, 0.0104, 0.0054]) \n",
      "Test Loss tensor([0.0886, 0.0034, 0.0303, 0.0193, 0.0977, 0.0105, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7719371318817139 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0879, 0.0052, 0.0314, 0.0157, 0.0954, 0.0111, 0.0035]) \n",
      "Test Loss tensor([0.0900, 0.0035, 0.0308, 0.0190, 0.0970, 0.0112, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.7767667770385742 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0870, 0.0039, 0.0311, 0.0194, 0.0980, 0.0100, 0.0048]) \n",
      "Test Loss tensor([0.0886, 0.0037, 0.0307, 0.0189, 0.0971, 0.0113, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.7646198272705078 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0876, 0.0029, 0.0342, 0.0175, 0.0986, 0.0104, 0.0052]) \n",
      "Test Loss tensor([0.0887, 0.0041, 0.0317, 0.0198, 0.0958, 0.0101, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.7870118618011475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0880, 0.0033, 0.0343, 0.0225, 0.0928, 0.0122, 0.0034]) \n",
      "Test Loss tensor([0.0911, 0.0040, 0.0311, 0.0194, 0.0968, 0.0104, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.7895081043243408 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0893, 0.0036, 0.0305, 0.0209, 0.1019, 0.0101, 0.0045]) \n",
      "Test Loss tensor([0.0910, 0.0045, 0.0329, 0.0200, 0.0935, 0.0099, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.7502903938293457 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0893, 0.0037, 0.0334, 0.0207, 0.0977, 0.0088, 0.0042]) \n",
      "Test Loss tensor([0.0867, 0.0039, 0.0310, 0.0208, 0.0940, 0.0095, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.778904914855957 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0776, 0.0045, 0.0274, 0.0220, 0.0989, 0.0097, 0.0034]) \n",
      "Test Loss tensor([0.0888, 0.0039, 0.0302, 0.0194, 0.0928, 0.0103, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.7572674751281738 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0850, 0.0037, 0.0303, 0.0177, 0.0987, 0.0095, 0.0045]) \n",
      "Test Loss tensor([0.0873, 0.0038, 0.0307, 0.0191, 0.0955, 0.0105, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.8079793453216553 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0837, 0.0042, 0.0303, 0.0199, 0.0960, 0.0092, 0.0048]) \n",
      "Test Loss tensor([0.0868, 0.0037, 0.0311, 0.0184, 0.0986, 0.0108, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.7576444149017334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0871, 0.0029, 0.0292, 0.0190, 0.0967, 0.0101, 0.0043]) \n",
      "Test Loss tensor([0.0888, 0.0037, 0.0305, 0.0186, 0.0947, 0.0104, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7735373973846436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0781, 0.0032, 0.0330, 0.0186, 0.0892, 0.0089, 0.0042]) \n",
      "Test Loss tensor([0.0863, 0.0041, 0.0307, 0.0192, 0.0905, 0.0099, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7635886669158936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0923, 0.0032, 0.0322, 0.0210, 0.0923, 0.0095, 0.0046]) \n",
      "Test Loss tensor([0.0868, 0.0039, 0.0307, 0.0198, 0.0948, 0.0101, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.7406449317932129 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0889, 0.0047, 0.0298, 0.0198, 0.0945, 0.0099, 0.0035]) \n",
      "Test Loss tensor([0.0851, 0.0042, 0.0307, 0.0201, 0.0938, 0.0097, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7735316753387451 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0901, 0.0032, 0.0326, 0.0191, 0.0933, 0.0097, 0.0044]) \n",
      "Test Loss tensor([0.0880, 0.0040, 0.0305, 0.0195, 0.0922, 0.0091, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.7434868812561035 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0887, 0.0043, 0.0301, 0.0208, 0.0896, 0.0090, 0.0039]) \n",
      "Test Loss tensor([0.0858, 0.0036, 0.0305, 0.0181, 0.0941, 0.0091, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.7447690963745117 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0910, 0.0034, 0.0258, 0.0152, 0.0842, 0.0096, 0.0045]) \n",
      "Test Loss tensor([0.0864, 0.0038, 0.0313, 0.0178, 0.0914, 0.0096, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.7573318481445312 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0877, 0.0034, 0.0290, 0.0191, 0.0862, 0.0088, 0.0049]) \n",
      "Test Loss tensor([0.0860, 0.0034, 0.0308, 0.0178, 0.0939, 0.0094, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.7362346649169922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0911, 0.0031, 0.0341, 0.0144, 0.0921, 0.0108, 0.0058]) \n",
      "Test Loss tensor([0.0858, 0.0037, 0.0297, 0.0187, 0.0913, 0.0093, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.7582230567932129 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0845, 0.0036, 0.0278, 0.0181, 0.0873, 0.0103, 0.0037]) \n",
      "Test Loss tensor([0.0857, 0.0039, 0.0291, 0.0193, 0.0901, 0.0091, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7492165565490723 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0837, 0.0045, 0.0274, 0.0180, 0.0830, 0.0119, 0.0039]) \n",
      "Test Loss tensor([0.0872, 0.0040, 0.0302, 0.0195, 0.0900, 0.0092, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.7743842601776123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0824, 0.0040, 0.0315, 0.0190, 0.0870, 0.0074, 0.0033]) \n",
      "Test Loss tensor([0.0869, 0.0035, 0.0301, 0.0184, 0.0899, 0.0094, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7800812721252441 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0821, 0.0034, 0.0309, 0.0169, 0.0872, 0.0100, 0.0046]) \n",
      "Test Loss tensor([0.0864, 0.0038, 0.0305, 0.0189, 0.0897, 0.0094, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.7864434719085693 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0861, 0.0038, 0.0298, 0.0176, 0.0845, 0.0076, 0.0048]) \n",
      "Test Loss tensor([0.0843, 0.0037, 0.0298, 0.0185, 0.0881, 0.0097, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.7440207004547119 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0820, 0.0028, 0.0297, 0.0196, 0.0872, 0.0094, 0.0044]) \n",
      "Test Loss tensor([0.0841, 0.0036, 0.0300, 0.0188, 0.0880, 0.0098, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.7553820610046387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0820, 0.0030, 0.0293, 0.0151, 0.0883, 0.0084, 0.0039]) \n",
      "Test Loss tensor([0.0844, 0.0037, 0.0298, 0.0191, 0.0894, 0.0091, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.756777286529541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0861, 0.0041, 0.0298, 0.0204, 0.0853, 0.0082, 0.0038]) \n",
      "Test Loss tensor([0.0847, 0.0038, 0.0300, 0.0192, 0.0885, 0.0088, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.7704563140869141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0849, 0.0036, 0.0305, 0.0187, 0.0912, 0.0115, 0.0037]) \n",
      "Test Loss tensor([0.0851, 0.0037, 0.0293, 0.0188, 0.0870, 0.0083, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7848575115203857 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0833, 0.0038, 0.0315, 0.0196, 0.0876, 0.0100, 0.0042]) \n",
      "Test Loss tensor([0.0848, 0.0038, 0.0297, 0.0191, 0.0866, 0.0089, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.7738323211669922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0838, 0.0036, 0.0279, 0.0184, 0.0890, 0.0101, 0.0056]) \n",
      "Test Loss tensor([0.0833, 0.0039, 0.0295, 0.0188, 0.0853, 0.0099, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.7956223487854004 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0849, 0.0041, 0.0328, 0.0180, 0.0879, 0.0096, 0.0046]) \n",
      "Test Loss tensor([0.0844, 0.0036, 0.0297, 0.0185, 0.0879, 0.0092, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.7968299388885498 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0842, 0.0034, 0.0321, 0.0177, 0.0910, 0.0097, 0.0047]) \n",
      "Test Loss tensor([0.0818, 0.0036, 0.0291, 0.0186, 0.0850, 0.0090, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.7673547267913818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0753, 0.0030, 0.0306, 0.0170, 0.0827, 0.0081, 0.0039]) \n",
      "Test Loss tensor([0.0815, 0.0038, 0.0294, 0.0192, 0.0833, 0.0091, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.7818572521209717 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0878, 0.0038, 0.0284, 0.0182, 0.0862, 0.0099, 0.0050]) \n",
      "Test Loss tensor([0.0837, 0.0039, 0.0292, 0.0187, 0.0846, 0.0085, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.8193740844726562 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0782, 0.0045, 0.0267, 0.0149, 0.0854, 0.0103, 0.0041]) \n",
      "Test Loss tensor([0.0832, 0.0039, 0.0294, 0.0190, 0.0854, 0.0087, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.7642149925231934 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0943, 0.0039, 0.0271, 0.0185, 0.0890, 0.0088, 0.0044]) \n",
      "Test Loss tensor([0.0830, 0.0041, 0.0295, 0.0190, 0.0818, 0.0089, 0.0040])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 560 in 0.7681460380554199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0868, 0.0039, 0.0293, 0.0176, 0.0878, 0.0075, 0.0047]) \n",
      "Test Loss tensor([0.0840, 0.0037, 0.0298, 0.0174, 0.0834, 0.0091, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.7491304874420166 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0816, 0.0034, 0.0260, 0.0163, 0.0818, 0.0096, 0.0037]) \n",
      "Test Loss tensor([0.0832, 0.0034, 0.0297, 0.0178, 0.0849, 0.0086, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.7714545726776123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0817, 0.0032, 0.0282, 0.0180, 0.0881, 0.0095, 0.0040]) \n",
      "Test Loss tensor([0.0819, 0.0037, 0.0296, 0.0175, 0.0836, 0.0087, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.7675385475158691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0798, 0.0043, 0.0287, 0.0190, 0.0863, 0.0078, 0.0035]) \n",
      "Test Loss tensor([0.0825, 0.0036, 0.0296, 0.0178, 0.0836, 0.0092, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.7427914142608643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0852, 0.0035, 0.0309, 0.0165, 0.0891, 0.0092, 0.0036]) \n",
      "Test Loss tensor([0.0833, 0.0038, 0.0296, 0.0178, 0.0824, 0.0089, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.7684075832366943 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0824, 0.0040, 0.0327, 0.0163, 0.0849, 0.0090, 0.0038]) \n",
      "Test Loss tensor([0.0827, 0.0036, 0.0288, 0.0186, 0.0822, 0.0085, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.8057889938354492 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0807, 0.0031, 0.0291, 0.0208, 0.0780, 0.0082, 0.0034]) \n",
      "Test Loss tensor([0.0813, 0.0037, 0.0296, 0.0185, 0.0816, 0.0082, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.7516589164733887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0794, 0.0037, 0.0310, 0.0176, 0.0804, 0.0077, 0.0038]) \n",
      "Test Loss tensor([0.0825, 0.0037, 0.0294, 0.0177, 0.0818, 0.0087, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.7701447010040283 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0874, 0.0039, 0.0296, 0.0193, 0.0854, 0.0077, 0.0039]) \n",
      "Test Loss tensor([0.0825, 0.0036, 0.0290, 0.0178, 0.0825, 0.0091, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.764087438583374 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0794, 0.0041, 0.0288, 0.0165, 0.0790, 0.0095, 0.0045]) \n",
      "Test Loss tensor([0.0812, 0.0038, 0.0295, 0.0174, 0.0819, 0.0088, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.7762718200683594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0765, 0.0042, 0.0304, 0.0176, 0.0827, 0.0116, 0.0039]) \n",
      "Test Loss tensor([0.0793, 0.0037, 0.0294, 0.0177, 0.0794, 0.0089, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7777955532073975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0804, 0.0033, 0.0269, 0.0186, 0.0741, 0.0086, 0.0046]) \n",
      "Test Loss tensor([0.0796, 0.0041, 0.0297, 0.0189, 0.0796, 0.0086, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.7616262435913086 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0831, 0.0036, 0.0320, 0.0187, 0.0819, 0.0078, 0.0038]) \n",
      "Test Loss tensor([0.0806, 0.0036, 0.0297, 0.0181, 0.0821, 0.0085, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.7435548305511475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0759, 0.0038, 0.0274, 0.0165, 0.0775, 0.0092, 0.0045]) \n",
      "Test Loss tensor([0.0812, 0.0037, 0.0294, 0.0180, 0.0796, 0.0091, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.7892360687255859 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0773, 0.0053, 0.0310, 0.0171, 0.0790, 0.0091, 0.0045]) \n",
      "Test Loss tensor([0.0762, 0.0035, 0.0284, 0.0177, 0.0805, 0.0086, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.7685501575469971 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0743, 0.0033, 0.0306, 0.0157, 0.0733, 0.0100, 0.0039]) \n",
      "Test Loss tensor([0.0783, 0.0032, 0.0292, 0.0175, 0.0817, 0.0094, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.7546520233154297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0705, 0.0036, 0.0279, 0.0173, 0.0833, 0.0062, 0.0039]) \n",
      "Test Loss tensor([0.0751, 0.0031, 0.0283, 0.0174, 0.0792, 0.0088, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.7549095153808594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0816, 0.0038, 0.0291, 0.0183, 0.0783, 0.0096, 0.0049]) \n",
      "Test Loss tensor([0.0776, 0.0034, 0.0283, 0.0182, 0.0777, 0.0082, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.7447209358215332 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0805, 0.0037, 0.0274, 0.0156, 0.0762, 0.0104, 0.0037]) \n",
      "Test Loss tensor([0.0794, 0.0039, 0.0292, 0.0186, 0.0772, 0.0091, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.7836704254150391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0780, 0.0039, 0.0310, 0.0205, 0.0790, 0.0079, 0.0041]) \n",
      "Test Loss tensor([0.0754, 0.0038, 0.0294, 0.0178, 0.0777, 0.0087, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.8243014812469482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0821, 0.0041, 0.0293, 0.0186, 0.0750, 0.0093, 0.0046]) \n",
      "Test Loss tensor([0.0760, 0.0036, 0.0284, 0.0180, 0.0774, 0.0078, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.7795262336730957 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0800, 0.0035, 0.0283, 0.0182, 0.0797, 0.0077, 0.0043]) \n",
      "Test Loss tensor([0.0774, 0.0036, 0.0288, 0.0177, 0.0763, 0.0088, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.8103103637695312 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0696, 0.0027, 0.0295, 0.0172, 0.0775, 0.0081, 0.0044]) \n",
      "Test Loss tensor([0.0794, 0.0039, 0.0297, 0.0176, 0.0756, 0.0085, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.7531192302703857 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0780, 0.0042, 0.0324, 0.0182, 0.0796, 0.0084, 0.0041]) \n",
      "Test Loss tensor([0.0747, 0.0039, 0.0292, 0.0180, 0.0750, 0.0086, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.7588317394256592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0831, 0.0050, 0.0295, 0.0180, 0.0746, 0.0088, 0.0043]) \n",
      "Test Loss tensor([0.0761, 0.0039, 0.0289, 0.0184, 0.0759, 0.0086, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.7423632144927979 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0723, 0.0040, 0.0271, 0.0161, 0.0792, 0.0094, 0.0044]) \n",
      "Test Loss tensor([0.0743, 0.0037, 0.0287, 0.0179, 0.0750, 0.0089, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.7873365879058838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0725, 0.0035, 0.0294, 0.0164, 0.0762, 0.0081, 0.0043]) \n",
      "Test Loss tensor([0.0745, 0.0038, 0.0284, 0.0183, 0.0745, 0.0083, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.7554042339324951 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0784, 0.0036, 0.0305, 0.0175, 0.0771, 0.0075, 0.0039]) \n",
      "Test Loss tensor([0.0749, 0.0035, 0.0286, 0.0185, 0.0757, 0.0083, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.7604329586029053 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0761, 0.0034, 0.0283, 0.0171, 0.0779, 0.0090, 0.0036]) \n",
      "Test Loss tensor([0.0757, 0.0033, 0.0311, 0.0177, 0.0749, 0.0091, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.8089301586151123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0797, 0.0039, 0.0296, 0.0178, 0.0814, 0.0088, 0.0037]) \n",
      "Test Loss tensor([0.0751, 0.0033, 0.0294, 0.0171, 0.0753, 0.0097, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.8190526962280273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0785, 0.0039, 0.0293, 0.0170, 0.0778, 0.0094, 0.0047]) \n",
      "Test Loss tensor([0.0748, 0.0037, 0.0289, 0.0178, 0.0725, 0.0090, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.7812836170196533 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0738, 0.0028, 0.0271, 0.0161, 0.0684, 0.0084, 0.0033]) \n",
      "Test Loss tensor([0.0719, 0.0036, 0.0288, 0.0177, 0.0749, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.7447552680969238 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0708, 0.0041, 0.0312, 0.0155, 0.0739, 0.0077, 0.0029]) \n",
      "Test Loss tensor([0.0741, 0.0036, 0.0285, 0.0184, 0.0742, 0.0089, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.8394598960876465 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0751, 0.0040, 0.0310, 0.0177, 0.0722, 0.0086, 0.0053]) \n",
      "Test Loss tensor([0.0742, 0.0037, 0.0296, 0.0179, 0.0720, 0.0089, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.8140826225280762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0681, 0.0026, 0.0283, 0.0176, 0.0708, 0.0073, 0.0036]) \n",
      "Test Loss tensor([0.0725, 0.0036, 0.0283, 0.0176, 0.0732, 0.0086, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.7550070285797119 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0762, 0.0034, 0.0306, 0.0151, 0.0715, 0.0081, 0.0044]) \n",
      "Test Loss tensor([0.0709, 0.0036, 0.0290, 0.0175, 0.0716, 0.0089, 0.0038])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 704 in 0.7398889064788818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0668, 0.0044, 0.0306, 0.0189, 0.0725, 0.0080, 0.0039]) \n",
      "Test Loss tensor([0.0715, 0.0039, 0.0294, 0.0180, 0.0714, 0.0083, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.8102798461914062 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0762, 0.0040, 0.0292, 0.0166, 0.0678, 0.0082, 0.0035]) \n",
      "Test Loss tensor([0.0734, 0.0038, 0.0285, 0.0181, 0.0733, 0.0088, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.765855073928833 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0721, 0.0029, 0.0278, 0.0172, 0.0698, 0.0097, 0.0039]) \n",
      "Test Loss tensor([0.0705, 0.0036, 0.0284, 0.0180, 0.0710, 0.0088, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.7575933933258057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0733, 0.0051, 0.0276, 0.0194, 0.0756, 0.0085, 0.0037]) \n",
      "Test Loss tensor([0.0718, 0.0034, 0.0288, 0.0174, 0.0721, 0.0088, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.7825725078582764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0693, 0.0040, 0.0300, 0.0145, 0.0667, 0.0077, 0.0035]) \n",
      "Test Loss tensor([0.0701, 0.0037, 0.0283, 0.0176, 0.0735, 0.0085, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.7516963481903076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0718, 0.0035, 0.0318, 0.0184, 0.0694, 0.0076, 0.0032]) \n",
      "Test Loss tensor([0.0702, 0.0038, 0.0287, 0.0172, 0.0696, 0.0085, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.7725160121917725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0760, 0.0045, 0.0285, 0.0169, 0.0695, 0.0067, 0.0037]) \n",
      "Test Loss tensor([0.0702, 0.0039, 0.0295, 0.0182, 0.0706, 0.0083, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.7659945487976074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0692, 0.0027, 0.0267, 0.0167, 0.0733, 0.0080, 0.0036]) \n",
      "Test Loss tensor([0.0714, 0.0036, 0.0284, 0.0179, 0.0719, 0.0084, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.7958028316497803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0761, 0.0035, 0.0315, 0.0203, 0.0697, 0.0085, 0.0038]) \n",
      "Test Loss tensor([0.0706, 0.0040, 0.0290, 0.0174, 0.0691, 0.0084, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.7602941989898682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0794, 0.0043, 0.0317, 0.0178, 0.0741, 0.0097, 0.0040]) \n",
      "Test Loss tensor([0.0695, 0.0034, 0.0283, 0.0172, 0.0696, 0.0087, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.750429630279541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0693, 0.0030, 0.0259, 0.0161, 0.0651, 0.0090, 0.0041]) \n",
      "Test Loss tensor([0.0707, 0.0037, 0.0280, 0.0169, 0.0707, 0.0087, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7653298377990723 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0685, 0.0045, 0.0302, 0.0163, 0.0712, 0.0086, 0.0041]) \n",
      "Test Loss tensor([0.0683, 0.0038, 0.0291, 0.0172, 0.0684, 0.0083, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.7741594314575195 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0696, 0.0045, 0.0291, 0.0154, 0.0662, 0.0089, 0.0030]) \n",
      "Test Loss tensor([0.0699, 0.0036, 0.0292, 0.0166, 0.0691, 0.0091, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.7827584743499756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0661, 0.0039, 0.0286, 0.0155, 0.0653, 0.0084, 0.0038]) \n",
      "Test Loss tensor([0.0692, 0.0036, 0.0281, 0.0170, 0.0695, 0.0088, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7672009468078613 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0682, 0.0048, 0.0278, 0.0175, 0.0698, 0.0092, 0.0035]) \n",
      "Test Loss tensor([0.0687, 0.0041, 0.0285, 0.0172, 0.0689, 0.0082, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7518057823181152 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0710, 0.0048, 0.0274, 0.0187, 0.0668, 0.0108, 0.0036]) \n",
      "Test Loss tensor([0.0669, 0.0035, 0.0278, 0.0172, 0.0692, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.8048465251922607 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0701, 0.0031, 0.0278, 0.0178, 0.0718, 0.0080, 0.0030]) \n",
      "Test Loss tensor([0.0694, 0.0033, 0.0272, 0.0165, 0.0696, 0.0087, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.7978959083557129 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0779, 0.0045, 0.0287, 0.0164, 0.0680, 0.0095, 0.0043]) \n",
      "Test Loss tensor([0.0658, 0.0035, 0.0283, 0.0172, 0.0685, 0.0085, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7765324115753174 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0703, 0.0030, 0.0241, 0.0175, 0.0747, 0.0090, 0.0033]) \n",
      "Test Loss tensor([0.0657, 0.0034, 0.0278, 0.0171, 0.0673, 0.0083, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.8091168403625488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0610, 0.0041, 0.0270, 0.0175, 0.0629, 0.0078, 0.0037]) \n",
      "Test Loss tensor([0.0659, 0.0036, 0.0276, 0.0173, 0.0685, 0.0085, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.7736287117004395 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0694, 0.0039, 0.0269, 0.0162, 0.0651, 0.0096, 0.0032]) \n",
      "Test Loss tensor([0.0653, 0.0035, 0.0279, 0.0172, 0.0673, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.7631070613861084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0700, 0.0034, 0.0306, 0.0184, 0.0679, 0.0100, 0.0033]) \n",
      "Test Loss tensor([0.0671, 0.0035, 0.0279, 0.0171, 0.0654, 0.0093, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.9185764789581299 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0621, 0.0033, 0.0236, 0.0170, 0.0670, 0.0092, 0.0036]) \n",
      "Test Loss tensor([0.0659, 0.0038, 0.0280, 0.0169, 0.0639, 0.0096, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.7975735664367676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0617, 0.0028, 0.0278, 0.0171, 0.0630, 0.0091, 0.0029]) \n",
      "Test Loss tensor([0.0683, 0.0036, 0.0280, 0.0167, 0.0653, 0.0088, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.7608418464660645 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0631, 0.0031, 0.0296, 0.0159, 0.0664, 0.0089, 0.0032]) \n",
      "Test Loss tensor([0.0655, 0.0037, 0.0272, 0.0173, 0.0663, 0.0083, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.7450814247131348 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0640, 0.0031, 0.0295, 0.0163, 0.0631, 0.0058, 0.0029]) \n",
      "Test Loss tensor([0.0652, 0.0036, 0.0274, 0.0170, 0.0661, 0.0089, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7466943264007568 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0652, 0.0043, 0.0261, 0.0182, 0.0651, 0.0089, 0.0043]) \n",
      "Test Loss tensor([0.0667, 0.0033, 0.0284, 0.0169, 0.0647, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.8602800369262695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0606, 0.0040, 0.0295, 0.0166, 0.0670, 0.0117, 0.0045]) \n",
      "Test Loss tensor([0.0652, 0.0034, 0.0285, 0.0164, 0.0656, 0.0091, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.7514169216156006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0677, 0.0030, 0.0289, 0.0171, 0.0642, 0.0086, 0.0034]) \n",
      "Test Loss tensor([0.0664, 0.0035, 0.0282, 0.0169, 0.0659, 0.0086, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.770709753036499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0652, 0.0036, 0.0265, 0.0176, 0.0626, 0.0095, 0.0031]) \n",
      "Test Loss tensor([0.0660, 0.0036, 0.0285, 0.0172, 0.0635, 0.0088, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.7535591125488281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0649, 0.0040, 0.0262, 0.0171, 0.0644, 0.0095, 0.0038]) \n",
      "Test Loss tensor([0.0650, 0.0035, 0.0279, 0.0176, 0.0650, 0.0084, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.7456879615783691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0542, 0.0040, 0.0277, 0.0163, 0.0634, 0.0097, 0.0029]) \n",
      "Test Loss tensor([0.0661, 0.0036, 0.0275, 0.0173, 0.0640, 0.0086, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7751398086547852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0656, 0.0047, 0.0282, 0.0156, 0.0618, 0.0065, 0.0034]) \n",
      "Test Loss tensor([0.0645, 0.0035, 0.0273, 0.0169, 0.0628, 0.0086, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7946181297302246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0667, 0.0039, 0.0255, 0.0162, 0.0626, 0.0099, 0.0045]) \n",
      "Test Loss tensor([0.0642, 0.0035, 0.0266, 0.0162, 0.0627, 0.0086, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7635829448699951 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0657, 0.0042, 0.0320, 0.0160, 0.0639, 0.0078, 0.0037]) \n",
      "Test Loss tensor([0.0647, 0.0034, 0.0267, 0.0174, 0.0638, 0.0087, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.7447426319122314 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0550, 0.0038, 0.0258, 0.0157, 0.0664, 0.0101, 0.0043]) \n",
      "Test Loss tensor([0.0657, 0.0041, 0.0280, 0.0175, 0.0617, 0.0094, 0.0037])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 848 in 0.7451536655426025 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0597, 0.0035, 0.0280, 0.0199, 0.0651, 0.0077, 0.0034]) \n",
      "Test Loss tensor([0.0638, 0.0035, 0.0280, 0.0177, 0.0622, 0.0086, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.7520251274108887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0616, 0.0045, 0.0282, 0.0158, 0.0634, 0.0084, 0.0043]) \n",
      "Test Loss tensor([0.0665, 0.0036, 0.0271, 0.0168, 0.0634, 0.0086, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.7797832489013672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0611, 0.0040, 0.0250, 0.0187, 0.0636, 0.0078, 0.0026]) \n",
      "Test Loss tensor([0.0636, 0.0034, 0.0273, 0.0173, 0.0631, 0.0084, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7499420642852783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0602, 0.0027, 0.0252, 0.0170, 0.0615, 0.0071, 0.0040]) \n",
      "Test Loss tensor([0.0636, 0.0036, 0.0260, 0.0163, 0.0615, 0.0089, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.7391269207000732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0583, 0.0037, 0.0270, 0.0164, 0.0616, 0.0079, 0.0031]) \n",
      "Test Loss tensor([0.0606, 0.0035, 0.0271, 0.0174, 0.0601, 0.0085, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.7374284267425537 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0584, 0.0051, 0.0264, 0.0147, 0.0676, 0.0087, 0.0032]) \n",
      "Test Loss tensor([0.0621, 0.0037, 0.0278, 0.0169, 0.0617, 0.0081, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.7682113647460938 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0682, 0.0030, 0.0274, 0.0159, 0.0652, 0.0107, 0.0038]) \n",
      "Test Loss tensor([0.0630, 0.0037, 0.0261, 0.0164, 0.0614, 0.0093, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.7651205062866211 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0450, 0.0024, 0.0196, 0.0124, 0.0441, 0.0064, 0.0026]) \n",
      "Test Loss tensor([0.0617, 0.0037, 0.0263, 0.0169, 0.0633, 0.0084, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7856709957122803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0584, 0.0038, 0.0256, 0.0181, 0.0587, 0.0098, 0.0038]) \n",
      "Test Loss tensor([0.0625, 0.0033, 0.0263, 0.0165, 0.0612, 0.0086, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.80010986328125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0608, 0.0033, 0.0267, 0.0162, 0.0581, 0.0088, 0.0032]) \n",
      "Test Loss tensor([0.0638, 0.0038, 0.0274, 0.0166, 0.0599, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7984259128570557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0598, 0.0035, 0.0241, 0.0159, 0.0573, 0.0080, 0.0024]) \n",
      "Test Loss tensor([0.0615, 0.0036, 0.0267, 0.0164, 0.0608, 0.0086, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7776930332183838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0634, 0.0035, 0.0271, 0.0162, 0.0562, 0.0078, 0.0038]) \n",
      "Test Loss tensor([0.0605, 0.0036, 0.0268, 0.0165, 0.0629, 0.0089, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.7628707885742188 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0595, 0.0032, 0.0268, 0.0173, 0.0605, 0.0107, 0.0030]) \n",
      "Test Loss tensor([0.0621, 0.0034, 0.0268, 0.0170, 0.0600, 0.0086, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.753929615020752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0623, 0.0030, 0.0262, 0.0157, 0.0576, 0.0095, 0.0042]) \n",
      "Test Loss tensor([0.0601, 0.0033, 0.0273, 0.0172, 0.0607, 0.0084, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.8172059059143066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0569, 0.0041, 0.0277, 0.0165, 0.0551, 0.0088, 0.0037]) \n",
      "Test Loss tensor([0.0593, 0.0034, 0.0256, 0.0171, 0.0595, 0.0081, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.8239138126373291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0607, 0.0031, 0.0272, 0.0168, 0.0551, 0.0092, 0.0037]) \n",
      "Test Loss tensor([0.0615, 0.0037, 0.0261, 0.0168, 0.0602, 0.0089, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.9579324722290039 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0606, 0.0036, 0.0264, 0.0158, 0.0563, 0.0072, 0.0031]) \n",
      "Test Loss tensor([0.0604, 0.0036, 0.0259, 0.0168, 0.0594, 0.0091, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7760500907897949 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0609, 0.0051, 0.0271, 0.0151, 0.0566, 0.0077, 0.0032]) \n",
      "Test Loss tensor([0.0634, 0.0034, 0.0263, 0.0167, 0.0593, 0.0090, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.76043701171875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0684, 0.0042, 0.0269, 0.0158, 0.0655, 0.0107, 0.0047]) \n",
      "Test Loss tensor([0.0603, 0.0036, 0.0263, 0.0170, 0.0582, 0.0089, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7725155353546143 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0565, 0.0030, 0.0230, 0.0169, 0.0566, 0.0085, 0.0034]) \n",
      "Test Loss tensor([0.0602, 0.0037, 0.0258, 0.0169, 0.0589, 0.0087, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7755768299102783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0596, 0.0037, 0.0271, 0.0160, 0.0535, 0.0083, 0.0034]) \n",
      "Test Loss tensor([0.0609, 0.0033, 0.0260, 0.0164, 0.0595, 0.0094, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.7655887603759766 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0598, 0.0034, 0.0256, 0.0164, 0.0564, 0.0113, 0.0045]) \n",
      "Test Loss tensor([0.0596, 0.0033, 0.0254, 0.0171, 0.0590, 0.0087, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.7629806995391846 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0556, 0.0045, 0.0269, 0.0159, 0.0577, 0.0096, 0.0039]) \n",
      "Test Loss tensor([0.0592, 0.0037, 0.0269, 0.0169, 0.0566, 0.0091, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.7529566287994385 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0635, 0.0033, 0.0270, 0.0169, 0.0556, 0.0072, 0.0037]) \n",
      "Test Loss tensor([0.0595, 0.0035, 0.0254, 0.0166, 0.0580, 0.0085, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7725896835327148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0594, 0.0030, 0.0277, 0.0154, 0.0516, 0.0088, 0.0041]) \n",
      "Test Loss tensor([0.0603, 0.0036, 0.0258, 0.0161, 0.0578, 0.0089, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7821030616760254 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0625, 0.0039, 0.0235, 0.0163, 0.0561, 0.0072, 0.0034]) \n",
      "Test Loss tensor([0.0572, 0.0036, 0.0259, 0.0168, 0.0573, 0.0079, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.7398788928985596 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0595, 0.0031, 0.0269, 0.0150, 0.0559, 0.0063, 0.0032]) \n",
      "Test Loss tensor([0.0587, 0.0035, 0.0253, 0.0167, 0.0602, 0.0084, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7627062797546387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0601, 0.0039, 0.0260, 0.0158, 0.0622, 0.0083, 0.0038]) \n",
      "Test Loss tensor([0.0597, 0.0035, 0.0258, 0.0167, 0.0568, 0.0086, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7449402809143066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0565, 0.0045, 0.0277, 0.0163, 0.0596, 0.0091, 0.0032]) \n",
      "Test Loss tensor([0.0592, 0.0036, 0.0256, 0.0156, 0.0587, 0.0084, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7764158248901367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0637, 0.0031, 0.0281, 0.0167, 0.0572, 0.0089, 0.0039]) \n",
      "Test Loss tensor([0.0588, 0.0033, 0.0255, 0.0163, 0.0576, 0.0080, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.7599716186523438 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0618, 0.0038, 0.0247, 0.0161, 0.0581, 0.0082, 0.0031]) \n",
      "Test Loss tensor([0.0591, 0.0034, 0.0257, 0.0159, 0.0599, 0.0082, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7724928855895996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0587, 0.0026, 0.0234, 0.0158, 0.0573, 0.0069, 0.0036]) \n",
      "Test Loss tensor([0.0581, 0.0034, 0.0258, 0.0164, 0.0561, 0.0080, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7621829509735107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0579, 0.0042, 0.0216, 0.0157, 0.0541, 0.0103, 0.0045]) \n",
      "Test Loss tensor([0.0589, 0.0034, 0.0262, 0.0161, 0.0596, 0.0080, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7375245094299316 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0544, 0.0040, 0.0247, 0.0157, 0.0570, 0.0083, 0.0036]) \n",
      "Test Loss tensor([0.0574, 0.0034, 0.0247, 0.0162, 0.0582, 0.0077, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.7820088863372803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0501, 0.0046, 0.0258, 0.0159, 0.0590, 0.0074, 0.0038]) \n",
      "Test Loss tensor([0.0578, 0.0033, 0.0248, 0.0157, 0.0571, 0.0082, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.78322434425354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0505, 0.0029, 0.0240, 0.0154, 0.0583, 0.0080, 0.0031]) \n",
      "Test Loss tensor([0.0569, 0.0034, 0.0251, 0.0160, 0.0562, 0.0078, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 112 in 0.8136763572692871 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0567, 0.0029, 0.0209, 0.0178, 0.0538, 0.0084, 0.0029]) \n",
      "Test Loss tensor([0.0558, 0.0034, 0.0251, 0.0171, 0.0559, 0.0076, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.770672082901001 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0533, 0.0035, 0.0268, 0.0160, 0.0533, 0.0093, 0.0039]) \n",
      "Test Loss tensor([0.0552, 0.0035, 0.0254, 0.0164, 0.0549, 0.0085, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.8406984806060791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0549, 0.0042, 0.0249, 0.0158, 0.0569, 0.0076, 0.0027]) \n",
      "Test Loss tensor([0.0553, 0.0034, 0.0263, 0.0167, 0.0563, 0.0085, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.8341741561889648 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0545, 0.0030, 0.0238, 0.0184, 0.0570, 0.0091, 0.0040]) \n",
      "Test Loss tensor([0.0560, 0.0034, 0.0251, 0.0167, 0.0548, 0.0081, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.863304853439331 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0541, 0.0034, 0.0281, 0.0169, 0.0546, 0.0088, 0.0026]) \n",
      "Test Loss tensor([0.0547, 0.0036, 0.0244, 0.0169, 0.0539, 0.0081, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.8339872360229492 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0618, 0.0045, 0.0269, 0.0150, 0.0577, 0.0078, 0.0031]) \n",
      "Test Loss tensor([0.0568, 0.0035, 0.0251, 0.0168, 0.0551, 0.0080, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.7738015651702881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0600, 0.0037, 0.0270, 0.0144, 0.0586, 0.0088, 0.0027]) \n",
      "Test Loss tensor([0.0554, 0.0034, 0.0257, 0.0162, 0.0554, 0.0080, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7525947093963623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0485, 0.0040, 0.0239, 0.0163, 0.0553, 0.0065, 0.0028]) \n",
      "Test Loss tensor([0.0556, 0.0036, 0.0247, 0.0163, 0.0549, 0.0085, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.8453834056854248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0610, 0.0033, 0.0279, 0.0170, 0.0525, 0.0069, 0.0041]) \n",
      "Test Loss tensor([0.0563, 0.0033, 0.0253, 0.0159, 0.0542, 0.0079, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.8207855224609375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0569, 0.0030, 0.0263, 0.0160, 0.0506, 0.0079, 0.0031]) \n",
      "Test Loss tensor([0.0546, 0.0033, 0.0245, 0.0166, 0.0552, 0.0084, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.8445580005645752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0542, 0.0036, 0.0230, 0.0153, 0.0553, 0.0082, 0.0029]) \n",
      "Test Loss tensor([0.0561, 0.0034, 0.0247, 0.0163, 0.0541, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7824079990386963 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0462, 0.0049, 0.0251, 0.0148, 0.0520, 0.0066, 0.0023]) \n",
      "Test Loss tensor([0.0560, 0.0036, 0.0248, 0.0157, 0.0530, 0.0077, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7763431072235107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0540, 0.0048, 0.0239, 0.0177, 0.0569, 0.0084, 0.0039]) \n",
      "Test Loss tensor([0.0551, 0.0033, 0.0252, 0.0161, 0.0532, 0.0075, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.7685239315032959 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0548, 0.0032, 0.0267, 0.0148, 0.0559, 0.0082, 0.0024]) \n",
      "Test Loss tensor([0.0556, 0.0034, 0.0242, 0.0165, 0.0538, 0.0080, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7626018524169922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0532, 0.0041, 0.0236, 0.0162, 0.0526, 0.0073, 0.0029]) \n",
      "Test Loss tensor([0.0563, 0.0035, 0.0251, 0.0163, 0.0524, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.7431292533874512 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0580, 0.0033, 0.0252, 0.0169, 0.0544, 0.0082, 0.0033]) \n",
      "Test Loss tensor([0.0545, 0.0032, 0.0249, 0.0164, 0.0523, 0.0076, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7915704250335693 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0467, 0.0034, 0.0235, 0.0169, 0.0524, 0.0082, 0.0030]) \n",
      "Test Loss tensor([0.0567, 0.0036, 0.0245, 0.0163, 0.0532, 0.0076, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7809462547302246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0550, 0.0028, 0.0240, 0.0166, 0.0487, 0.0076, 0.0033]) \n",
      "Test Loss tensor([0.0542, 0.0033, 0.0248, 0.0164, 0.0522, 0.0079, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7575006484985352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0575, 0.0037, 0.0274, 0.0170, 0.0545, 0.0083, 0.0036]) \n",
      "Test Loss tensor([0.0549, 0.0032, 0.0244, 0.0159, 0.0534, 0.0087, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.747093915939331 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0550, 0.0021, 0.0297, 0.0160, 0.0509, 0.0090, 0.0028]) \n",
      "Test Loss tensor([0.0527, 0.0035, 0.0247, 0.0162, 0.0518, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.7568378448486328 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0515, 0.0043, 0.0256, 0.0165, 0.0534, 0.0096, 0.0027]) \n",
      "Test Loss tensor([0.0542, 0.0034, 0.0243, 0.0156, 0.0527, 0.0082, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7741835117340088 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0590, 0.0034, 0.0248, 0.0181, 0.0547, 0.0074, 0.0025]) \n",
      "Test Loss tensor([0.0541, 0.0034, 0.0244, 0.0161, 0.0513, 0.0082, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.7599217891693115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0495, 0.0036, 0.0241, 0.0165, 0.0551, 0.0089, 0.0034]) \n",
      "Test Loss tensor([0.0551, 0.0036, 0.0240, 0.0160, 0.0523, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.750230073928833 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0574, 0.0037, 0.0266, 0.0153, 0.0481, 0.0072, 0.0037]) \n",
      "Test Loss tensor([0.0534, 0.0035, 0.0243, 0.0162, 0.0525, 0.0081, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.742870569229126 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0540, 0.0041, 0.0233, 0.0169, 0.0510, 0.0080, 0.0031]) \n",
      "Test Loss tensor([0.0545, 0.0034, 0.0248, 0.0163, 0.0505, 0.0080, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.752647876739502 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0538, 0.0041, 0.0227, 0.0182, 0.0527, 0.0068, 0.0035]) \n",
      "Test Loss tensor([0.0532, 0.0035, 0.0242, 0.0154, 0.0535, 0.0081, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7850492000579834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0524, 0.0034, 0.0273, 0.0161, 0.0555, 0.0085, 0.0038]) \n",
      "Test Loss tensor([0.0539, 0.0033, 0.0240, 0.0162, 0.0523, 0.0080, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.7837762832641602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0535, 0.0032, 0.0249, 0.0136, 0.0500, 0.0086, 0.0036]) \n",
      "Test Loss tensor([0.0539, 0.0035, 0.0247, 0.0166, 0.0514, 0.0073, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7562682628631592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0576, 0.0032, 0.0252, 0.0179, 0.0513, 0.0075, 0.0040]) \n",
      "Test Loss tensor([0.0528, 0.0033, 0.0238, 0.0159, 0.0529, 0.0080, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.7692358493804932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0513, 0.0028, 0.0239, 0.0158, 0.0528, 0.0067, 0.0036]) \n",
      "Test Loss tensor([0.0542, 0.0034, 0.0248, 0.0161, 0.0526, 0.0080, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.7452425956726074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0537, 0.0044, 0.0258, 0.0162, 0.0507, 0.0084, 0.0035]) \n",
      "Test Loss tensor([0.0546, 0.0033, 0.0248, 0.0155, 0.0512, 0.0079, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.7728798389434814 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0542, 0.0032, 0.0265, 0.0152, 0.0519, 0.0083, 0.0032]) \n",
      "Test Loss tensor([0.0520, 0.0033, 0.0244, 0.0155, 0.0507, 0.0078, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.7783522605895996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0557, 0.0026, 0.0255, 0.0161, 0.0523, 0.0083, 0.0027]) \n",
      "Test Loss tensor([0.0527, 0.0034, 0.0247, 0.0160, 0.0499, 0.0081, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7292361259460449 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0598, 0.0038, 0.0233, 0.0179, 0.0520, 0.0091, 0.0039]) \n",
      "Test Loss tensor([0.0531, 0.0031, 0.0236, 0.0159, 0.0520, 0.0078, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7658121585845947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0547, 0.0032, 0.0240, 0.0155, 0.0457, 0.0082, 0.0037]) \n",
      "Test Loss tensor([0.0518, 0.0035, 0.0234, 0.0161, 0.0507, 0.0081, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7664563655853271 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0500, 0.0037, 0.0263, 0.0160, 0.0516, 0.0094, 0.0030]) \n",
      "Test Loss tensor([0.0523, 0.0035, 0.0245, 0.0154, 0.0493, 0.0080, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 256 in 0.7650527954101562 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0626, 0.0044, 0.0298, 0.0164, 0.0486, 0.0087, 0.0030]) \n",
      "Test Loss tensor([0.0508, 0.0037, 0.0237, 0.0163, 0.0498, 0.0078, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.9679255485534668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0542, 0.0029, 0.0222, 0.0159, 0.0492, 0.0072, 0.0028]) \n",
      "Test Loss tensor([0.0529, 0.0033, 0.0239, 0.0158, 0.0493, 0.0077, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.8528926372528076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0501, 0.0031, 0.0253, 0.0155, 0.0506, 0.0095, 0.0035]) \n",
      "Test Loss tensor([0.0529, 0.0035, 0.0241, 0.0157, 0.0498, 0.0079, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.8294098377227783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0456, 0.0046, 0.0216, 0.0152, 0.0493, 0.0089, 0.0034]) \n",
      "Test Loss tensor([0.0520, 0.0035, 0.0241, 0.0156, 0.0489, 0.0080, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7458925247192383 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0511, 0.0026, 0.0240, 0.0168, 0.0513, 0.0122, 0.0037]) \n",
      "Test Loss tensor([0.0525, 0.0034, 0.0243, 0.0155, 0.0500, 0.0078, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.8835177421569824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0502, 0.0039, 0.0238, 0.0161, 0.0482, 0.0078, 0.0032]) \n",
      "Test Loss tensor([0.0511, 0.0035, 0.0239, 0.0156, 0.0497, 0.0080, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.8705992698669434 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0479, 0.0024, 0.0248, 0.0150, 0.0518, 0.0075, 0.0029]) \n",
      "Test Loss tensor([0.0502, 0.0032, 0.0233, 0.0159, 0.0504, 0.0077, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7346279621124268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0532, 0.0027, 0.0259, 0.0157, 0.0513, 0.0081, 0.0036]) \n",
      "Test Loss tensor([0.0520, 0.0034, 0.0234, 0.0155, 0.0505, 0.0081, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.710191011428833 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0469, 0.0036, 0.0232, 0.0150, 0.0561, 0.0064, 0.0032]) \n",
      "Test Loss tensor([0.0515, 0.0033, 0.0240, 0.0159, 0.0492, 0.0075, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.7391319274902344 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0485, 0.0035, 0.0245, 0.0161, 0.0479, 0.0063, 0.0034]) \n",
      "Test Loss tensor([0.0525, 0.0033, 0.0236, 0.0152, 0.0497, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6964499950408936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0471, 0.0044, 0.0286, 0.0153, 0.0503, 0.0077, 0.0033]) \n",
      "Test Loss tensor([0.0511, 0.0037, 0.0232, 0.0160, 0.0487, 0.0077, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7986950874328613 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0507, 0.0033, 0.0253, 0.0154, 0.0508, 0.0084, 0.0037]) \n",
      "Test Loss tensor([0.0506, 0.0037, 0.0245, 0.0157, 0.0494, 0.0083, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7611355781555176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0508, 0.0038, 0.0242, 0.0167, 0.0537, 0.0061, 0.0031]) \n",
      "Test Loss tensor([0.0512, 0.0035, 0.0230, 0.0157, 0.0499, 0.0080, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6404211521148682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0508, 0.0044, 0.0236, 0.0138, 0.0493, 0.0073, 0.0031]) \n",
      "Test Loss tensor([0.0508, 0.0033, 0.0244, 0.0158, 0.0487, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5715301036834717 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0462, 0.0031, 0.0228, 0.0148, 0.0512, 0.0058, 0.0032]) \n",
      "Test Loss tensor([0.0506, 0.0034, 0.0232, 0.0152, 0.0485, 0.0082, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5968723297119141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0548, 0.0039, 0.0243, 0.0159, 0.0459, 0.0090, 0.0037]) \n",
      "Test Loss tensor([0.0517, 0.0031, 0.0227, 0.0155, 0.0497, 0.0083, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7149083614349365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0464, 0.0033, 0.0232, 0.0147, 0.0446, 0.0071, 0.0025]) \n",
      "Test Loss tensor([0.0496, 0.0033, 0.0229, 0.0154, 0.0480, 0.0084, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6106836795806885 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0534, 0.0035, 0.0236, 0.0147, 0.0502, 0.0060, 0.0047]) \n",
      "Test Loss tensor([0.0501, 0.0036, 0.0234, 0.0155, 0.0479, 0.0079, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5669722557067871 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0554, 0.0037, 0.0230, 0.0158, 0.0476, 0.0077, 0.0026]) \n",
      "Test Loss tensor([0.0490, 0.0032, 0.0236, 0.0157, 0.0480, 0.0076, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5899143218994141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0486, 0.0033, 0.0253, 0.0155, 0.0499, 0.0090, 0.0029]) \n",
      "Test Loss tensor([0.0507, 0.0035, 0.0233, 0.0165, 0.0472, 0.0080, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5684256553649902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0511, 0.0029, 0.0230, 0.0157, 0.0506, 0.0072, 0.0041]) \n",
      "Test Loss tensor([0.0505, 0.0032, 0.0237, 0.0158, 0.0473, 0.0084, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5769948959350586 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0523, 0.0038, 0.0233, 0.0153, 0.0500, 0.0071, 0.0032]) \n",
      "Test Loss tensor([0.0504, 0.0035, 0.0231, 0.0158, 0.0467, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6639330387115479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0495, 0.0023, 0.0236, 0.0166, 0.0495, 0.0076, 0.0031]) \n",
      "Test Loss tensor([0.0490, 0.0036, 0.0235, 0.0153, 0.0457, 0.0080, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5961577892303467 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0505, 0.0024, 0.0267, 0.0153, 0.0501, 0.0095, 0.0032]) \n",
      "Test Loss tensor([0.0502, 0.0033, 0.0235, 0.0154, 0.0474, 0.0079, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5837705135345459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0515, 0.0026, 0.0233, 0.0167, 0.0461, 0.0071, 0.0033]) \n",
      "Test Loss tensor([0.0490, 0.0033, 0.0234, 0.0155, 0.0460, 0.0077, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5944085121154785 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0546, 0.0034, 0.0244, 0.0156, 0.0448, 0.0096, 0.0040]) \n",
      "Test Loss tensor([0.0502, 0.0031, 0.0237, 0.0155, 0.0488, 0.0081, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.642841100692749 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0484, 0.0040, 0.0253, 0.0149, 0.0508, 0.0074, 0.0041]) \n",
      "Test Loss tensor([0.0490, 0.0032, 0.0228, 0.0157, 0.0462, 0.0080, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6759026050567627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0466, 0.0036, 0.0232, 0.0147, 0.0514, 0.0083, 0.0033]) \n",
      "Test Loss tensor([0.0500, 0.0033, 0.0232, 0.0155, 0.0476, 0.0076, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6410057544708252 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0500, 0.0036, 0.0234, 0.0145, 0.0484, 0.0069, 0.0023]) \n",
      "Test Loss tensor([0.0496, 0.0034, 0.0236, 0.0151, 0.0448, 0.0085, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6037988662719727 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0512, 0.0039, 0.0241, 0.0158, 0.0423, 0.0062, 0.0027]) \n",
      "Test Loss tensor([0.0484, 0.0031, 0.0235, 0.0155, 0.0463, 0.0080, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7036483287811279 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0475, 0.0024, 0.0242, 0.0148, 0.0466, 0.0079, 0.0035]) \n",
      "Test Loss tensor([0.0496, 0.0031, 0.0229, 0.0153, 0.0460, 0.0079, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.7074058055877686 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0524, 0.0037, 0.0231, 0.0150, 0.0473, 0.0084, 0.0036]) \n",
      "Test Loss tensor([0.0476, 0.0034, 0.0238, 0.0153, 0.0471, 0.0080, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6172783374786377 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0512, 0.0022, 0.0237, 0.0154, 0.0502, 0.0075, 0.0040]) \n",
      "Test Loss tensor([0.0485, 0.0034, 0.0225, 0.0156, 0.0458, 0.0081, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6989223957061768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0510, 0.0037, 0.0240, 0.0154, 0.0455, 0.0078, 0.0033]) \n",
      "Test Loss tensor([0.0495, 0.0031, 0.0230, 0.0155, 0.0452, 0.0084, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6388609409332275 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0469, 0.0020, 0.0247, 0.0150, 0.0460, 0.0100, 0.0030]) \n",
      "Test Loss tensor([0.0475, 0.0033, 0.0232, 0.0156, 0.0460, 0.0084, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6493864059448242 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0499, 0.0036, 0.0228, 0.0145, 0.0479, 0.0087, 0.0026]) \n",
      "Test Loss tensor([0.0492, 0.0034, 0.0227, 0.0156, 0.0452, 0.0077, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.5852365493774414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0480, 0.0030, 0.0234, 0.0143, 0.0419, 0.0084, 0.0040]) \n",
      "Test Loss tensor([0.0495, 0.0035, 0.0234, 0.0154, 0.0456, 0.0079, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5776469707489014 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0471, 0.0046, 0.0232, 0.0149, 0.0444, 0.0093, 0.0048]) \n",
      "Test Loss tensor([0.0483, 0.0031, 0.0225, 0.0159, 0.0449, 0.0075, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5829572677612305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0470, 0.0028, 0.0233, 0.0140, 0.0457, 0.0080, 0.0033]) \n",
      "Test Loss tensor([0.0497, 0.0031, 0.0235, 0.0155, 0.0457, 0.0076, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6008727550506592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0466, 0.0032, 0.0228, 0.0145, 0.0418, 0.0085, 0.0041]) \n",
      "Test Loss tensor([0.0482, 0.0036, 0.0218, 0.0151, 0.0449, 0.0076, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5724289417266846 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0426, 0.0029, 0.0216, 0.0153, 0.0452, 0.0072, 0.0031]) \n",
      "Test Loss tensor([0.0500, 0.0034, 0.0232, 0.0155, 0.0453, 0.0075, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6255261898040771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0472, 0.0039, 0.0247, 0.0154, 0.0465, 0.0075, 0.0037]) \n",
      "Test Loss tensor([0.0488, 0.0031, 0.0229, 0.0153, 0.0445, 0.0072, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6542134284973145 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0461, 0.0036, 0.0199, 0.0140, 0.0454, 0.0071, 0.0022]) \n",
      "Test Loss tensor([0.0493, 0.0030, 0.0228, 0.0153, 0.0457, 0.0074, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6559343338012695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0518, 0.0030, 0.0254, 0.0159, 0.0507, 0.0080, 0.0046]) \n",
      "Test Loss tensor([0.0489, 0.0033, 0.0237, 0.0153, 0.0443, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6305665969848633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0476, 0.0024, 0.0234, 0.0168, 0.0424, 0.0096, 0.0035]) \n",
      "Test Loss tensor([0.0490, 0.0033, 0.0228, 0.0152, 0.0441, 0.0075, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6520593166351318 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0494, 0.0029, 0.0240, 0.0152, 0.0437, 0.0070, 0.0040]) \n",
      "Test Loss tensor([0.0495, 0.0031, 0.0224, 0.0154, 0.0461, 0.0078, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6098265647888184 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0518, 0.0040, 0.0236, 0.0174, 0.0416, 0.0070, 0.0023]) \n",
      "Test Loss tensor([0.0485, 0.0030, 0.0224, 0.0154, 0.0453, 0.0076, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.7655019760131836 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0457, 0.0042, 0.0242, 0.0146, 0.0435, 0.0078, 0.0037]) \n",
      "Test Loss tensor([0.0466, 0.0030, 0.0231, 0.0156, 0.0445, 0.0075, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6293563842773438 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0414, 0.0033, 0.0227, 0.0171, 0.0421, 0.0071, 0.0034]) \n",
      "Test Loss tensor([0.0467, 0.0029, 0.0221, 0.0154, 0.0454, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6955857276916504 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0435, 0.0028, 0.0221, 0.0158, 0.0429, 0.0073, 0.0028]) \n",
      "Test Loss tensor([0.0486, 0.0034, 0.0231, 0.0154, 0.0445, 0.0072, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6499919891357422 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0487, 0.0020, 0.0210, 0.0155, 0.0478, 0.0071, 0.0023]) \n",
      "Test Loss tensor([0.0470, 0.0034, 0.0229, 0.0155, 0.0428, 0.0076, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6016852855682373 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0518, 0.0033, 0.0203, 0.0142, 0.0504, 0.0068, 0.0030]) \n",
      "Test Loss tensor([0.0478, 0.0033, 0.0232, 0.0148, 0.0447, 0.0073, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.647573709487915 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0497, 0.0025, 0.0190, 0.0162, 0.0441, 0.0078, 0.0026]) \n",
      "Test Loss tensor([0.0468, 0.0030, 0.0223, 0.0153, 0.0445, 0.0073, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.702481746673584 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0516, 0.0036, 0.0228, 0.0163, 0.0469, 0.0084, 0.0034]) \n",
      "Test Loss tensor([0.0473, 0.0035, 0.0221, 0.0153, 0.0436, 0.0074, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.592771053314209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0449, 0.0033, 0.0243, 0.0157, 0.0426, 0.0061, 0.0030]) \n",
      "Test Loss tensor([0.0469, 0.0036, 0.0224, 0.0149, 0.0466, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6174905300140381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0516, 0.0034, 0.0261, 0.0159, 0.0470, 0.0066, 0.0032]) \n",
      "Test Loss tensor([0.0468, 0.0031, 0.0217, 0.0151, 0.0443, 0.0076, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6779055595397949 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0493, 0.0029, 0.0236, 0.0134, 0.0448, 0.0071, 0.0046]) \n",
      "Test Loss tensor([0.0475, 0.0031, 0.0222, 0.0152, 0.0446, 0.0078, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.701075553894043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0443, 0.0035, 0.0202, 0.0144, 0.0430, 0.0066, 0.0032]) \n",
      "Test Loss tensor([0.0457, 0.0033, 0.0221, 0.0148, 0.0437, 0.0078, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5712852478027344 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0438, 0.0032, 0.0234, 0.0140, 0.0448, 0.0071, 0.0029]) \n",
      "Test Loss tensor([0.0455, 0.0036, 0.0234, 0.0153, 0.0435, 0.0078, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5967352390289307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0510, 0.0031, 0.0226, 0.0154, 0.0460, 0.0077, 0.0037]) \n",
      "Test Loss tensor([0.0468, 0.0033, 0.0225, 0.0154, 0.0436, 0.0078, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6708378791809082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0465, 0.0033, 0.0238, 0.0149, 0.0422, 0.0074, 0.0035]) \n",
      "Test Loss tensor([0.0467, 0.0031, 0.0221, 0.0149, 0.0440, 0.0074, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6537137031555176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0500, 0.0032, 0.0219, 0.0140, 0.0445, 0.0064, 0.0032]) \n",
      "Test Loss tensor([0.0470, 0.0031, 0.0228, 0.0154, 0.0428, 0.0072, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6309850215911865 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0495, 0.0026, 0.0228, 0.0138, 0.0423, 0.0075, 0.0037]) \n",
      "Test Loss tensor([0.0465, 0.0031, 0.0217, 0.0152, 0.0421, 0.0074, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6838617324829102 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0482, 0.0024, 0.0238, 0.0152, 0.0446, 0.0079, 0.0039]) \n",
      "Test Loss tensor([0.0462, 0.0033, 0.0221, 0.0152, 0.0429, 0.0075, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6659407615661621 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0452, 0.0032, 0.0209, 0.0134, 0.0390, 0.0061, 0.0025]) \n",
      "Test Loss tensor([0.0450, 0.0033, 0.0219, 0.0149, 0.0431, 0.0078, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6461553573608398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0455, 0.0026, 0.0217, 0.0164, 0.0408, 0.0060, 0.0036]) \n",
      "Test Loss tensor([0.0458, 0.0031, 0.0218, 0.0152, 0.0434, 0.0078, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5927243232727051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0446, 0.0032, 0.0249, 0.0152, 0.0449, 0.0072, 0.0025]) \n",
      "Test Loss tensor([0.0475, 0.0032, 0.0221, 0.0155, 0.0437, 0.0079, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5943317413330078 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0462, 0.0037, 0.0208, 0.0155, 0.0417, 0.0082, 0.0045]) \n",
      "Test Loss tensor([0.0464, 0.0032, 0.0224, 0.0146, 0.0432, 0.0083, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6046497821807861 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0427, 0.0031, 0.0208, 0.0152, 0.0399, 0.0073, 0.0036]) \n",
      "Test Loss tensor([0.0450, 0.0033, 0.0229, 0.0153, 0.0422, 0.0071, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6278400421142578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0446, 0.0038, 0.0223, 0.0147, 0.0401, 0.0067, 0.0026]) \n",
      "Test Loss tensor([0.0452, 0.0031, 0.0215, 0.0151, 0.0432, 0.0072, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.661865234375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0442, 0.0031, 0.0234, 0.0161, 0.0445, 0.0059, 0.0040]) \n",
      "Test Loss tensor([0.0468, 0.0031, 0.0224, 0.0148, 0.0416, 0.0073, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6383817195892334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0420, 0.0034, 0.0229, 0.0165, 0.0373, 0.0068, 0.0022]) \n",
      "Test Loss tensor([0.0462, 0.0032, 0.0216, 0.0154, 0.0433, 0.0081, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 544 in 0.6432445049285889 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0461, 0.0035, 0.0233, 0.0157, 0.0395, 0.0061, 0.0033]) \n",
      "Test Loss tensor([0.0448, 0.0033, 0.0225, 0.0151, 0.0421, 0.0072, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6125695705413818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0438, 0.0030, 0.0244, 0.0155, 0.0401, 0.0070, 0.0037]) \n",
      "Test Loss tensor([0.0468, 0.0031, 0.0212, 0.0149, 0.0422, 0.0077, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6312627792358398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0475, 0.0039, 0.0193, 0.0136, 0.0424, 0.0071, 0.0046]) \n",
      "Test Loss tensor([0.0454, 0.0031, 0.0210, 0.0154, 0.0421, 0.0080, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6781628131866455 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0446, 0.0034, 0.0256, 0.0164, 0.0386, 0.0076, 0.0030]) \n",
      "Test Loss tensor([0.0443, 0.0034, 0.0222, 0.0151, 0.0413, 0.0082, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6653234958648682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0480, 0.0028, 0.0211, 0.0153, 0.0417, 0.0086, 0.0022]) \n",
      "Test Loss tensor([0.0454, 0.0033, 0.0222, 0.0150, 0.0419, 0.0073, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.7151827812194824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0433, 0.0026, 0.0228, 0.0160, 0.0407, 0.0059, 0.0035]) \n",
      "Test Loss tensor([0.0468, 0.0030, 0.0220, 0.0150, 0.0411, 0.0076, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6957132816314697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0445, 0.0023, 0.0263, 0.0160, 0.0424, 0.0065, 0.0030]) \n",
      "Test Loss tensor([0.0447, 0.0030, 0.0220, 0.0149, 0.0420, 0.0076, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6892766952514648 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0449, 0.0031, 0.0238, 0.0166, 0.0433, 0.0071, 0.0029]) \n",
      "Test Loss tensor([0.0457, 0.0031, 0.0213, 0.0146, 0.0417, 0.0082, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6304934024810791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0436, 0.0023, 0.0236, 0.0146, 0.0398, 0.0073, 0.0039]) \n",
      "Test Loss tensor([0.0445, 0.0035, 0.0219, 0.0146, 0.0409, 0.0078, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.8223123550415039 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0475, 0.0036, 0.0230, 0.0149, 0.0394, 0.0085, 0.0029]) \n",
      "Test Loss tensor([0.0442, 0.0034, 0.0222, 0.0149, 0.0416, 0.0078, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.898430585861206 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0466, 0.0031, 0.0204, 0.0145, 0.0444, 0.0073, 0.0033]) \n",
      "Test Loss tensor([0.0461, 0.0029, 0.0211, 0.0150, 0.0407, 0.0080, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.7669799327850342 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0507, 0.0028, 0.0219, 0.0154, 0.0443, 0.0082, 0.0035]) \n",
      "Test Loss tensor([0.0455, 0.0033, 0.0222, 0.0150, 0.0411, 0.0073, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6955187320709229 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0441, 0.0031, 0.0225, 0.0154, 0.0384, 0.0078, 0.0024]) \n",
      "Test Loss tensor([0.0447, 0.0034, 0.0224, 0.0151, 0.0407, 0.0073, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.8076584339141846 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0429, 0.0031, 0.0212, 0.0136, 0.0395, 0.0071, 0.0029]) \n",
      "Test Loss tensor([0.0441, 0.0032, 0.0216, 0.0149, 0.0404, 0.0072, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.7754673957824707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0441, 0.0039, 0.0189, 0.0153, 0.0420, 0.0067, 0.0030]) \n",
      "Test Loss tensor([0.0445, 0.0032, 0.0211, 0.0148, 0.0411, 0.0072, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7149567604064941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0431, 0.0029, 0.0190, 0.0131, 0.0407, 0.0074, 0.0037]) \n",
      "Test Loss tensor([0.0443, 0.0030, 0.0209, 0.0148, 0.0410, 0.0074, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6552994251251221 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0468, 0.0033, 0.0204, 0.0141, 0.0435, 0.0066, 0.0038]) \n",
      "Test Loss tensor([0.0447, 0.0032, 0.0209, 0.0154, 0.0415, 0.0072, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.8398563861846924 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0453, 0.0030, 0.0233, 0.0143, 0.0413, 0.0074, 0.0028]) \n",
      "Test Loss tensor([0.0431, 0.0030, 0.0207, 0.0147, 0.0417, 0.0074, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.7640669345855713 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0450, 0.0026, 0.0248, 0.0159, 0.0398, 0.0070, 0.0030]) \n",
      "Test Loss tensor([0.0445, 0.0034, 0.0215, 0.0152, 0.0419, 0.0072, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.8482282161712646 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0452, 0.0036, 0.0210, 0.0135, 0.0416, 0.0077, 0.0042]) \n",
      "Test Loss tensor([0.0453, 0.0031, 0.0214, 0.0152, 0.0413, 0.0075, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.8267579078674316 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0453, 0.0028, 0.0224, 0.0135, 0.0397, 0.0063, 0.0031]) \n",
      "Test Loss tensor([0.0456, 0.0032, 0.0219, 0.0151, 0.0409, 0.0077, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.8299987316131592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0454, 0.0029, 0.0209, 0.0151, 0.0371, 0.0071, 0.0030]) \n",
      "Test Loss tensor([0.0453, 0.0031, 0.0213, 0.0149, 0.0410, 0.0073, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.7942492961883545 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0418, 0.0028, 0.0204, 0.0134, 0.0406, 0.0066, 0.0028]) \n",
      "Test Loss tensor([0.0444, 0.0031, 0.0213, 0.0146, 0.0407, 0.0070, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.764380693435669 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0393, 0.0038, 0.0227, 0.0151, 0.0405, 0.0076, 0.0030]) \n",
      "Test Loss tensor([0.0443, 0.0032, 0.0217, 0.0152, 0.0403, 0.0076, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.7535531520843506 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0438, 0.0037, 0.0200, 0.0146, 0.0404, 0.0077, 0.0041]) \n",
      "Test Loss tensor([0.0447, 0.0031, 0.0213, 0.0151, 0.0412, 0.0070, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.9034714698791504 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0432, 0.0034, 0.0203, 0.0141, 0.0392, 0.0069, 0.0036]) \n",
      "Test Loss tensor([0.0458, 0.0032, 0.0216, 0.0147, 0.0411, 0.0071, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.801938533782959 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0420, 0.0031, 0.0206, 0.0136, 0.0433, 0.0084, 0.0032]) \n",
      "Test Loss tensor([0.0440, 0.0030, 0.0213, 0.0146, 0.0395, 0.0074, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.7591190338134766 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0421, 0.0031, 0.0212, 0.0143, 0.0392, 0.0069, 0.0031]) \n",
      "Test Loss tensor([0.0442, 0.0031, 0.0210, 0.0145, 0.0406, 0.0067, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.8135585784912109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0468, 0.0036, 0.0214, 0.0158, 0.0407, 0.0089, 0.0038]) \n",
      "Test Loss tensor([0.0436, 0.0031, 0.0208, 0.0143, 0.0409, 0.0071, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.8368368148803711 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0474, 0.0030, 0.0200, 0.0144, 0.0381, 0.0066, 0.0040]) \n",
      "Test Loss tensor([0.0438, 0.0032, 0.0216, 0.0152, 0.0411, 0.0070, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.8015646934509277 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0444, 0.0025, 0.0207, 0.0134, 0.0394, 0.0065, 0.0034]) \n",
      "Test Loss tensor([0.0443, 0.0031, 0.0209, 0.0149, 0.0394, 0.0070, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.8190436363220215 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0429, 0.0028, 0.0199, 0.0135, 0.0376, 0.0063, 0.0028]) \n",
      "Test Loss tensor([0.0435, 0.0033, 0.0208, 0.0149, 0.0412, 0.0070, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.7612495422363281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0501, 0.0032, 0.0197, 0.0147, 0.0395, 0.0066, 0.0038]) \n",
      "Test Loss tensor([0.0447, 0.0033, 0.0207, 0.0153, 0.0401, 0.0074, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.7521734237670898 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0446, 0.0028, 0.0208, 0.0151, 0.0416, 0.0069, 0.0034]) \n",
      "Test Loss tensor([0.0444, 0.0029, 0.0207, 0.0148, 0.0400, 0.0071, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.7703092098236084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0415, 0.0028, 0.0202, 0.0135, 0.0407, 0.0063, 0.0030]) \n",
      "Test Loss tensor([0.0424, 0.0032, 0.0206, 0.0146, 0.0388, 0.0074, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.8049299716949463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0469, 0.0028, 0.0226, 0.0146, 0.0451, 0.0064, 0.0034]) \n",
      "Test Loss tensor([0.0440, 0.0030, 0.0211, 0.0147, 0.0399, 0.0069, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 688 in 0.8201107978820801 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0449, 0.0025, 0.0242, 0.0169, 0.0381, 0.0092, 0.0046]) \n",
      "Test Loss tensor([0.0433, 0.0032, 0.0203, 0.0146, 0.0389, 0.0071, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.7859323024749756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0414, 0.0022, 0.0186, 0.0132, 0.0405, 0.0070, 0.0031]) \n",
      "Test Loss tensor([0.0436, 0.0030, 0.0209, 0.0142, 0.0407, 0.0073, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7671267986297607 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0479, 0.0034, 0.0224, 0.0142, 0.0396, 0.0071, 0.0037]) \n",
      "Test Loss tensor([0.0419, 0.0028, 0.0210, 0.0152, 0.0389, 0.0071, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.7919013500213623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0441, 0.0036, 0.0209, 0.0149, 0.0430, 0.0066, 0.0038]) \n",
      "Test Loss tensor([0.0418, 0.0030, 0.0214, 0.0149, 0.0393, 0.0069, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.7952289581298828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0438, 0.0033, 0.0193, 0.0155, 0.0430, 0.0071, 0.0036]) \n",
      "Test Loss tensor([0.0411, 0.0028, 0.0206, 0.0147, 0.0398, 0.0073, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.7563269138336182 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0402, 0.0020, 0.0187, 0.0143, 0.0358, 0.0057, 0.0028]) \n",
      "Test Loss tensor([0.0415, 0.0029, 0.0204, 0.0149, 0.0384, 0.0070, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.7749068737030029 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0426, 0.0038, 0.0205, 0.0158, 0.0388, 0.0058, 0.0030]) \n",
      "Test Loss tensor([0.0429, 0.0030, 0.0213, 0.0153, 0.0396, 0.0070, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.7465779781341553 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0450, 0.0038, 0.0207, 0.0168, 0.0423, 0.0077, 0.0040]) \n",
      "Test Loss tensor([0.0449, 0.0032, 0.0207, 0.0148, 0.0392, 0.0077, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.8206980228424072 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0460, 0.0033, 0.0195, 0.0152, 0.0410, 0.0073, 0.0026]) \n",
      "Test Loss tensor([0.0417, 0.0031, 0.0204, 0.0149, 0.0376, 0.0073, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.7635493278503418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0429, 0.0028, 0.0224, 0.0142, 0.0389, 0.0076, 0.0037]) \n",
      "Test Loss tensor([0.0421, 0.0033, 0.0216, 0.0144, 0.0387, 0.0077, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.7784979343414307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0394, 0.0025, 0.0200, 0.0128, 0.0360, 0.0068, 0.0034]) \n",
      "Test Loss tensor([0.0430, 0.0034, 0.0212, 0.0149, 0.0382, 0.0078, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.8100521564483643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0476, 0.0024, 0.0233, 0.0152, 0.0410, 0.0065, 0.0037]) \n",
      "Test Loss tensor([0.0420, 0.0033, 0.0218, 0.0148, 0.0382, 0.0072, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.7803502082824707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0426, 0.0034, 0.0208, 0.0154, 0.0452, 0.0060, 0.0032]) \n",
      "Test Loss tensor([0.0427, 0.0035, 0.0203, 0.0150, 0.0383, 0.0075, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.7897775173187256 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0436, 0.0026, 0.0221, 0.0190, 0.0407, 0.0061, 0.0034]) \n",
      "Test Loss tensor([0.0421, 0.0030, 0.0204, 0.0152, 0.0382, 0.0070, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.7831122875213623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0388, 0.0035, 0.0181, 0.0140, 0.0375, 0.0060, 0.0027]) \n",
      "Test Loss tensor([0.0422, 0.0030, 0.0211, 0.0148, 0.0397, 0.0071, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7431561946868896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0465, 0.0024, 0.0216, 0.0132, 0.0412, 0.0062, 0.0033]) \n",
      "Test Loss tensor([0.0429, 0.0031, 0.0207, 0.0143, 0.0388, 0.0073, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.7444717884063721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0433, 0.0032, 0.0205, 0.0157, 0.0382, 0.0058, 0.0032]) \n",
      "Test Loss tensor([0.0426, 0.0031, 0.0214, 0.0149, 0.0375, 0.0071, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.7565639019012451 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0434, 0.0023, 0.0213, 0.0143, 0.0356, 0.0055, 0.0031]) \n",
      "Test Loss tensor([0.0412, 0.0029, 0.0203, 0.0144, 0.0377, 0.0070, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7473516464233398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0412, 0.0042, 0.0238, 0.0142, 0.0383, 0.0055, 0.0039]) \n",
      "Test Loss tensor([0.0416, 0.0031, 0.0214, 0.0145, 0.0380, 0.0070, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7505133152008057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0453, 0.0031, 0.0235, 0.0140, 0.0372, 0.0063, 0.0035]) \n",
      "Test Loss tensor([0.0423, 0.0033, 0.0206, 0.0145, 0.0384, 0.0068, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.7467973232269287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0446, 0.0030, 0.0194, 0.0135, 0.0368, 0.0065, 0.0030]) \n",
      "Test Loss tensor([0.0413, 0.0031, 0.0205, 0.0146, 0.0391, 0.0070, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.7715203762054443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0422, 0.0029, 0.0218, 0.0147, 0.0356, 0.0082, 0.0036]) \n",
      "Test Loss tensor([0.0430, 0.0031, 0.0206, 0.0149, 0.0383, 0.0065, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7408447265625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0421, 0.0043, 0.0226, 0.0151, 0.0393, 0.0069, 0.0034]) \n",
      "Test Loss tensor([0.0433, 0.0031, 0.0208, 0.0149, 0.0397, 0.0069, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.7590413093566895 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0403, 0.0028, 0.0208, 0.0150, 0.0365, 0.0069, 0.0035]) \n",
      "Test Loss tensor([0.0432, 0.0030, 0.0203, 0.0147, 0.0383, 0.0068, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.7540011405944824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0410, 0.0030, 0.0178, 0.0140, 0.0382, 0.0070, 0.0035]) \n",
      "Test Loss tensor([0.0429, 0.0031, 0.0204, 0.0149, 0.0392, 0.0071, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.7852253913879395 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0408, 0.0034, 0.0221, 0.0136, 0.0405, 0.0060, 0.0040]) \n",
      "Test Loss tensor([0.0420, 0.0030, 0.0204, 0.0150, 0.0381, 0.0067, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.820343017578125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0478, 0.0032, 0.0203, 0.0150, 0.0396, 0.0072, 0.0032]) \n",
      "Test Loss tensor([0.0418, 0.0033, 0.0205, 0.0147, 0.0387, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.8487532138824463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0418, 0.0025, 0.0209, 0.0152, 0.0385, 0.0064, 0.0032]) \n",
      "Test Loss tensor([0.0416, 0.0030, 0.0195, 0.0147, 0.0387, 0.0071, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.7815675735473633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0440, 0.0026, 0.0226, 0.0144, 0.0423, 0.0061, 0.0027]) \n",
      "Test Loss tensor([0.0390, 0.0030, 0.0198, 0.0148, 0.0378, 0.0067, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.7791433334350586 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0455, 0.0036, 0.0207, 0.0145, 0.0406, 0.0060, 0.0032]) \n",
      "Test Loss tensor([0.0419, 0.0033, 0.0211, 0.0141, 0.0381, 0.0073, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7857661247253418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0409, 0.0023, 0.0186, 0.0127, 0.0409, 0.0069, 0.0037]) \n",
      "Test Loss tensor([0.0427, 0.0032, 0.0206, 0.0143, 0.0373, 0.0071, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.7678627967834473 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0452, 0.0036, 0.0208, 0.0136, 0.0390, 0.0078, 0.0029]) \n",
      "Test Loss tensor([0.0421, 0.0031, 0.0202, 0.0146, 0.0370, 0.0071, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.7362890243530273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0399, 0.0036, 0.0203, 0.0140, 0.0399, 0.0058, 0.0031]) \n",
      "Test Loss tensor([0.0430, 0.0033, 0.0204, 0.0148, 0.0380, 0.0073, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7953040599822998 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0397, 0.0033, 0.0207, 0.0134, 0.0360, 0.0083, 0.0035]) \n",
      "Test Loss tensor([0.0409, 0.0030, 0.0202, 0.0144, 0.0365, 0.0074, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.7731282711029053 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0416, 0.0029, 0.0228, 0.0158, 0.0354, 0.0057, 0.0030]) \n",
      "Test Loss tensor([0.0411, 0.0029, 0.0203, 0.0149, 0.0375, 0.0072, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.8126816749572754 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0386, 0.0026, 0.0215, 0.0141, 0.0359, 0.0080, 0.0028]) \n",
      "Test Loss tensor([0.0392, 0.0031, 0.0198, 0.0152, 0.0367, 0.0066, 0.0029])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 832 in 0.7508947849273682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0435, 0.0037, 0.0217, 0.0139, 0.0393, 0.0078, 0.0040]) \n",
      "Test Loss tensor([0.0412, 0.0028, 0.0197, 0.0143, 0.0363, 0.0071, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.8655486106872559 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0394, 0.0039, 0.0187, 0.0152, 0.0373, 0.0066, 0.0034]) \n",
      "Test Loss tensor([0.0420, 0.0030, 0.0203, 0.0149, 0.0371, 0.0074, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7738862037658691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0503, 0.0033, 0.0198, 0.0129, 0.0396, 0.0079, 0.0034]) \n",
      "Test Loss tensor([0.0409, 0.0030, 0.0199, 0.0144, 0.0379, 0.0072, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6572186946868896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0443, 0.0025, 0.0218, 0.0142, 0.0380, 0.0082, 0.0027]) \n",
      "Test Loss tensor([0.0392, 0.0035, 0.0200, 0.0143, 0.0368, 0.0067, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.849679708480835 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0390, 0.0028, 0.0190, 0.0130, 0.0395, 0.0043, 0.0036]) \n",
      "Test Loss tensor([0.0407, 0.0033, 0.0207, 0.0144, 0.0390, 0.0068, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6195974349975586 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0416, 0.0038, 0.0219, 0.0144, 0.0384, 0.0077, 0.0035]) \n",
      "Test Loss tensor([0.0399, 0.0030, 0.0207, 0.0142, 0.0376, 0.0069, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.8233888149261475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0419, 0.0035, 0.0210, 0.0138, 0.0409, 0.0056, 0.0028]) \n",
      "Test Loss tensor([0.0413, 0.0029, 0.0191, 0.0145, 0.0381, 0.0071, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7754802703857422 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0456, 0.0034, 0.0212, 0.0140, 0.0426, 0.0080, 0.0039]) \n",
      "Test Loss tensor([0.0409, 0.0030, 0.0201, 0.0145, 0.0378, 0.0067, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.8152511119842529 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0379, 0.0029, 0.0215, 0.0151, 0.0394, 0.0072, 0.0036]) \n",
      "Test Loss tensor([0.0412, 0.0032, 0.0205, 0.0152, 0.0377, 0.0068, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.8814609050750732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0418, 0.0029, 0.0203, 0.0149, 0.0365, 0.0082, 0.0033]) \n",
      "Test Loss tensor([0.0422, 0.0029, 0.0199, 0.0143, 0.0369, 0.0071, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.8229129314422607 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0433, 0.0019, 0.0213, 0.0158, 0.0366, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0418, 0.0028, 0.0199, 0.0147, 0.0382, 0.0068, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.8845212459564209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0017, 0.0155, 0.0109, 0.0297, 0.0051, 0.0024]) \n",
      "Test Loss tensor([0.0400, 0.0034, 0.0202, 0.0145, 0.0373, 0.0068, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.8612208366394043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0436, 0.0032, 0.0218, 0.0140, 0.0389, 0.0086, 0.0039]) \n",
      "Test Loss tensor([0.0412, 0.0032, 0.0195, 0.0141, 0.0367, 0.0068, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.8032698631286621 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0480, 0.0025, 0.0215, 0.0146, 0.0388, 0.0067, 0.0039]) \n",
      "Test Loss tensor([0.0401, 0.0030, 0.0194, 0.0144, 0.0371, 0.0070, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7732322216033936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0380, 0.0042, 0.0217, 0.0127, 0.0382, 0.0080, 0.0037]) \n",
      "Test Loss tensor([0.0389, 0.0032, 0.0198, 0.0146, 0.0370, 0.0069, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7587058544158936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0408, 0.0031, 0.0206, 0.0141, 0.0378, 0.0062, 0.0030]) \n",
      "Test Loss tensor([0.0411, 0.0034, 0.0195, 0.0143, 0.0361, 0.0070, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.7839195728302002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0397, 0.0035, 0.0224, 0.0147, 0.0390, 0.0072, 0.0032]) \n",
      "Test Loss tensor([0.0409, 0.0031, 0.0200, 0.0143, 0.0371, 0.0074, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7642230987548828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0032, 0.0202, 0.0166, 0.0383, 0.0064, 0.0027]) \n",
      "Test Loss tensor([0.0401, 0.0030, 0.0199, 0.0143, 0.0360, 0.0074, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.7862393856048584 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0498, 0.0035, 0.0197, 0.0128, 0.0392, 0.0073, 0.0030]) \n",
      "Test Loss tensor([0.0388, 0.0031, 0.0193, 0.0144, 0.0362, 0.0070, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.807990312576294 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0026, 0.0188, 0.0144, 0.0414, 0.0071, 0.0030]) \n",
      "Test Loss tensor([0.0400, 0.0032, 0.0200, 0.0144, 0.0364, 0.0071, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.787726640701294 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0398, 0.0038, 0.0198, 0.0159, 0.0351, 0.0066, 0.0033]) \n",
      "Test Loss tensor([0.0404, 0.0033, 0.0194, 0.0144, 0.0368, 0.0073, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7863316535949707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0419, 0.0032, 0.0187, 0.0139, 0.0353, 0.0076, 0.0044]) \n",
      "Test Loss tensor([0.0418, 0.0031, 0.0197, 0.0144, 0.0369, 0.0072, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.7677013874053955 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0412, 0.0025, 0.0208, 0.0157, 0.0356, 0.0067, 0.0032]) \n",
      "Test Loss tensor([0.0401, 0.0033, 0.0199, 0.0143, 0.0362, 0.0071, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7639667987823486 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0409, 0.0028, 0.0200, 0.0156, 0.0328, 0.0071, 0.0038]) \n",
      "Test Loss tensor([0.0402, 0.0031, 0.0194, 0.0148, 0.0365, 0.0070, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7664399147033691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0386, 0.0028, 0.0204, 0.0155, 0.0339, 0.0076, 0.0036]) \n",
      "Test Loss tensor([0.0410, 0.0030, 0.0198, 0.0146, 0.0366, 0.0068, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.7521243095397949 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0393, 0.0027, 0.0212, 0.0137, 0.0378, 0.0058, 0.0039]) \n",
      "Test Loss tensor([0.0390, 0.0031, 0.0196, 0.0144, 0.0356, 0.0069, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.7384433746337891 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0442, 0.0029, 0.0219, 0.0140, 0.0350, 0.0073, 0.0034]) \n",
      "Test Loss tensor([0.0397, 0.0029, 0.0199, 0.0143, 0.0361, 0.0067, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.802166223526001 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0373, 0.0024, 0.0196, 0.0149, 0.0355, 0.0063, 0.0034]) \n",
      "Test Loss tensor([0.0399, 0.0031, 0.0191, 0.0143, 0.0372, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7591903209686279 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0401, 0.0036, 0.0181, 0.0142, 0.0326, 0.0064, 0.0030]) \n",
      "Test Loss tensor([0.0397, 0.0029, 0.0192, 0.0143, 0.0375, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.8778665065765381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0426, 0.0034, 0.0199, 0.0119, 0.0342, 0.0056, 0.0037]) \n",
      "Test Loss tensor([0.0391, 0.0031, 0.0197, 0.0148, 0.0363, 0.0067, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.8486323356628418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0450, 0.0031, 0.0196, 0.0133, 0.0384, 0.0061, 0.0036]) \n",
      "Test Loss tensor([0.0396, 0.0031, 0.0200, 0.0142, 0.0379, 0.0067, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.8341283798217773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0353, 0.0028, 0.0195, 0.0132, 0.0364, 0.0059, 0.0032]) \n",
      "Test Loss tensor([0.0395, 0.0030, 0.0195, 0.0140, 0.0357, 0.0070, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7232761383056641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0423, 0.0031, 0.0222, 0.0133, 0.0334, 0.0059, 0.0026]) \n",
      "Test Loss tensor([0.0407, 0.0031, 0.0203, 0.0142, 0.0366, 0.0066, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6644761562347412 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0367, 0.0026, 0.0210, 0.0149, 0.0400, 0.0063, 0.0037]) \n",
      "Test Loss tensor([0.0399, 0.0029, 0.0192, 0.0144, 0.0376, 0.0066, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6260595321655273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0397, 0.0030, 0.0186, 0.0137, 0.0334, 0.0073, 0.0032]) \n",
      "Test Loss tensor([0.0391, 0.0031, 0.0193, 0.0143, 0.0364, 0.0064, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6219766139984131 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0404, 0.0026, 0.0206, 0.0138, 0.0377, 0.0076, 0.0033]) \n",
      "Test Loss tensor([0.0402, 0.0031, 0.0194, 0.0148, 0.0372, 0.0067, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 96 in 0.6990859508514404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0465, 0.0030, 0.0189, 0.0143, 0.0372, 0.0067, 0.0033]) \n",
      "Test Loss tensor([0.0385, 0.0031, 0.0186, 0.0146, 0.0363, 0.0066, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.8022572994232178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0434, 0.0032, 0.0238, 0.0146, 0.0384, 0.0075, 0.0040]) \n",
      "Test Loss tensor([0.0394, 0.0034, 0.0200, 0.0145, 0.0381, 0.0074, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.8390598297119141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0430, 0.0028, 0.0194, 0.0134, 0.0375, 0.0064, 0.0026]) \n",
      "Test Loss tensor([0.0384, 0.0030, 0.0202, 0.0144, 0.0361, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.7718334197998047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0376, 0.0023, 0.0182, 0.0148, 0.0362, 0.0072, 0.0032]) \n",
      "Test Loss tensor([0.0397, 0.0031, 0.0194, 0.0142, 0.0366, 0.0067, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7921638488769531 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0393, 0.0027, 0.0184, 0.0133, 0.0397, 0.0067, 0.0033]) \n",
      "Test Loss tensor([0.0385, 0.0035, 0.0193, 0.0139, 0.0351, 0.0065, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.8216369152069092 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0432, 0.0023, 0.0204, 0.0122, 0.0340, 0.0069, 0.0032]) \n",
      "Test Loss tensor([0.0394, 0.0031, 0.0194, 0.0147, 0.0365, 0.0069, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7826530933380127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0434, 0.0029, 0.0199, 0.0152, 0.0367, 0.0066, 0.0035]) \n",
      "Test Loss tensor([0.0399, 0.0029, 0.0190, 0.0145, 0.0377, 0.0070, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.7279586791992188 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0395, 0.0033, 0.0217, 0.0151, 0.0396, 0.0070, 0.0035]) \n",
      "Test Loss tensor([0.0405, 0.0032, 0.0198, 0.0142, 0.0363, 0.0070, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.7423720359802246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0389, 0.0023, 0.0209, 0.0129, 0.0378, 0.0064, 0.0033]) \n",
      "Test Loss tensor([0.0406, 0.0032, 0.0199, 0.0142, 0.0357, 0.0065, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.7953026294708252 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0402, 0.0033, 0.0199, 0.0145, 0.0409, 0.0078, 0.0034]) \n",
      "Test Loss tensor([0.0397, 0.0030, 0.0190, 0.0145, 0.0353, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.752241849899292 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0358, 0.0032, 0.0198, 0.0153, 0.0361, 0.0061, 0.0041]) \n",
      "Test Loss tensor([0.0395, 0.0029, 0.0198, 0.0144, 0.0364, 0.0062, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.776658296585083 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0380, 0.0026, 0.0201, 0.0140, 0.0405, 0.0069, 0.0040]) \n",
      "Test Loss tensor([0.0389, 0.0030, 0.0189, 0.0141, 0.0356, 0.0064, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.7683489322662354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0401, 0.0034, 0.0208, 0.0153, 0.0342, 0.0060, 0.0033]) \n",
      "Test Loss tensor([0.0396, 0.0029, 0.0193, 0.0142, 0.0362, 0.0064, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7837510108947754 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0422, 0.0031, 0.0169, 0.0130, 0.0397, 0.0062, 0.0033]) \n",
      "Test Loss tensor([0.0393, 0.0028, 0.0183, 0.0140, 0.0365, 0.0067, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7888178825378418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0403, 0.0032, 0.0211, 0.0145, 0.0364, 0.0066, 0.0034]) \n",
      "Test Loss tensor([0.0388, 0.0029, 0.0190, 0.0142, 0.0352, 0.0067, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.8527107238769531 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0372, 0.0039, 0.0218, 0.0135, 0.0335, 0.0057, 0.0042]) \n",
      "Test Loss tensor([0.0384, 0.0029, 0.0199, 0.0145, 0.0352, 0.0062, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7265832424163818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0396, 0.0033, 0.0194, 0.0133, 0.0340, 0.0075, 0.0032]) \n",
      "Test Loss tensor([0.0388, 0.0030, 0.0197, 0.0141, 0.0367, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.7744936943054199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0037, 0.0183, 0.0142, 0.0362, 0.0063, 0.0041]) \n",
      "Test Loss tensor([0.0373, 0.0031, 0.0186, 0.0138, 0.0354, 0.0066, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7746140956878662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0430, 0.0026, 0.0198, 0.0130, 0.0351, 0.0069, 0.0041]) \n",
      "Test Loss tensor([0.0397, 0.0031, 0.0187, 0.0143, 0.0359, 0.0068, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.7866983413696289 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0405, 0.0037, 0.0185, 0.0134, 0.0372, 0.0064, 0.0032]) \n",
      "Test Loss tensor([0.0401, 0.0030, 0.0188, 0.0144, 0.0350, 0.0066, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.8680288791656494 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0393, 0.0029, 0.0192, 0.0169, 0.0371, 0.0068, 0.0030]) \n",
      "Test Loss tensor([0.0397, 0.0034, 0.0195, 0.0142, 0.0348, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.761347770690918 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0024, 0.0180, 0.0151, 0.0327, 0.0062, 0.0029]) \n",
      "Test Loss tensor([0.0402, 0.0031, 0.0190, 0.0144, 0.0358, 0.0066, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7464399337768555 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0391, 0.0033, 0.0188, 0.0148, 0.0363, 0.0068, 0.0031]) \n",
      "Test Loss tensor([0.0385, 0.0033, 0.0195, 0.0143, 0.0342, 0.0064, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.7528131008148193 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0376, 0.0043, 0.0186, 0.0128, 0.0376, 0.0070, 0.0038]) \n",
      "Test Loss tensor([0.0396, 0.0031, 0.0193, 0.0140, 0.0358, 0.0066, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.7829678058624268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0380, 0.0030, 0.0175, 0.0134, 0.0356, 0.0066, 0.0032]) \n",
      "Test Loss tensor([0.0400, 0.0031, 0.0191, 0.0143, 0.0341, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7807695865631104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0441, 0.0036, 0.0155, 0.0125, 0.0339, 0.0068, 0.0031]) \n",
      "Test Loss tensor([0.0382, 0.0032, 0.0188, 0.0137, 0.0349, 0.0067, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.8170561790466309 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0448, 0.0039, 0.0196, 0.0144, 0.0379, 0.0090, 0.0049]) \n",
      "Test Loss tensor([0.0385, 0.0029, 0.0190, 0.0143, 0.0358, 0.0059, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7604901790618896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0409, 0.0021, 0.0182, 0.0140, 0.0354, 0.0066, 0.0029]) \n",
      "Test Loss tensor([0.0376, 0.0030, 0.0194, 0.0144, 0.0342, 0.0061, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.7799384593963623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0374, 0.0026, 0.0219, 0.0151, 0.0341, 0.0063, 0.0039]) \n",
      "Test Loss tensor([0.0385, 0.0030, 0.0190, 0.0143, 0.0347, 0.0066, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.7535128593444824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0028, 0.0204, 0.0114, 0.0347, 0.0063, 0.0023]) \n",
      "Test Loss tensor([0.0386, 0.0031, 0.0186, 0.0140, 0.0343, 0.0068, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7440338134765625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0387, 0.0030, 0.0171, 0.0129, 0.0337, 0.0064, 0.0028]) \n",
      "Test Loss tensor([0.0384, 0.0031, 0.0189, 0.0142, 0.0355, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.7468891143798828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0408, 0.0024, 0.0185, 0.0149, 0.0318, 0.0073, 0.0035]) \n",
      "Test Loss tensor([0.0370, 0.0030, 0.0177, 0.0142, 0.0350, 0.0063, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.8475730419158936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0022, 0.0212, 0.0141, 0.0326, 0.0063, 0.0034]) \n",
      "Test Loss tensor([0.0370, 0.0032, 0.0194, 0.0140, 0.0344, 0.0064, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.7880492210388184 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0385, 0.0035, 0.0183, 0.0141, 0.0369, 0.0068, 0.0033]) \n",
      "Test Loss tensor([0.0384, 0.0033, 0.0193, 0.0141, 0.0340, 0.0066, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.753119945526123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0400, 0.0029, 0.0200, 0.0129, 0.0346, 0.0050, 0.0027]) \n",
      "Test Loss tensor([0.0385, 0.0031, 0.0190, 0.0141, 0.0343, 0.0068, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.7284765243530273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0367, 0.0024, 0.0206, 0.0146, 0.0337, 0.0061, 0.0034]) \n",
      "Test Loss tensor([0.0382, 0.0029, 0.0186, 0.0143, 0.0346, 0.0061, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 240 in 0.7969875335693359 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0377, 0.0028, 0.0187, 0.0142, 0.0345, 0.0069, 0.0033]) \n",
      "Test Loss tensor([0.0392, 0.0033, 0.0187, 0.0142, 0.0341, 0.0062, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.8427238464355469 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0369, 0.0029, 0.0173, 0.0141, 0.0330, 0.0058, 0.0037]) \n",
      "Test Loss tensor([0.0377, 0.0029, 0.0194, 0.0143, 0.0348, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7762846946716309 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0417, 0.0037, 0.0186, 0.0142, 0.0345, 0.0069, 0.0034]) \n",
      "Test Loss tensor([0.0376, 0.0032, 0.0186, 0.0144, 0.0354, 0.0061, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7654087543487549 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0440, 0.0040, 0.0175, 0.0144, 0.0340, 0.0056, 0.0031]) \n",
      "Test Loss tensor([0.0393, 0.0032, 0.0192, 0.0143, 0.0332, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7507240772247314 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0405, 0.0035, 0.0218, 0.0130, 0.0360, 0.0067, 0.0035]) \n",
      "Test Loss tensor([0.0394, 0.0028, 0.0188, 0.0148, 0.0352, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.8205950260162354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0028, 0.0176, 0.0141, 0.0359, 0.0062, 0.0040]) \n",
      "Test Loss tensor([0.0376, 0.0031, 0.0190, 0.0141, 0.0342, 0.0065, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.8040199279785156 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0370, 0.0031, 0.0204, 0.0129, 0.0366, 0.0058, 0.0032]) \n",
      "Test Loss tensor([0.0369, 0.0029, 0.0187, 0.0143, 0.0345, 0.0062, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.7747087478637695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0405, 0.0029, 0.0165, 0.0129, 0.0323, 0.0070, 0.0026]) \n",
      "Test Loss tensor([0.0383, 0.0029, 0.0189, 0.0143, 0.0350, 0.0065, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7552297115325928 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0397, 0.0035, 0.0172, 0.0126, 0.0309, 0.0061, 0.0032]) \n",
      "Test Loss tensor([0.0360, 0.0030, 0.0182, 0.0146, 0.0348, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7527787685394287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0427, 0.0029, 0.0199, 0.0132, 0.0361, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0369, 0.0030, 0.0184, 0.0139, 0.0348, 0.0067, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.7967491149902344 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0381, 0.0027, 0.0191, 0.0125, 0.0359, 0.0056, 0.0022]) \n",
      "Test Loss tensor([0.0378, 0.0032, 0.0183, 0.0141, 0.0337, 0.0066, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7637476921081543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0373, 0.0023, 0.0211, 0.0134, 0.0367, 0.0061, 0.0028]) \n",
      "Test Loss tensor([0.0378, 0.0034, 0.0188, 0.0139, 0.0346, 0.0069, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.7828705310821533 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0415, 0.0037, 0.0184, 0.0135, 0.0339, 0.0073, 0.0044]) \n",
      "Test Loss tensor([0.0381, 0.0032, 0.0191, 0.0141, 0.0341, 0.0069, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.8018679618835449 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0383, 0.0026, 0.0198, 0.0148, 0.0354, 0.0065, 0.0031]) \n",
      "Test Loss tensor([0.0375, 0.0029, 0.0188, 0.0139, 0.0339, 0.0062, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7483644485473633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0402, 0.0030, 0.0204, 0.0138, 0.0338, 0.0073, 0.0044]) \n",
      "Test Loss tensor([0.0370, 0.0033, 0.0193, 0.0143, 0.0358, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7439663410186768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0348, 0.0029, 0.0191, 0.0144, 0.0350, 0.0062, 0.0036]) \n",
      "Test Loss tensor([0.0370, 0.0032, 0.0187, 0.0141, 0.0329, 0.0068, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7691950798034668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0371, 0.0032, 0.0198, 0.0140, 0.0361, 0.0067, 0.0027]) \n",
      "Test Loss tensor([0.0385, 0.0030, 0.0191, 0.0141, 0.0349, 0.0064, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7424945831298828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0394, 0.0023, 0.0189, 0.0137, 0.0328, 0.0090, 0.0039]) \n",
      "Test Loss tensor([0.0373, 0.0030, 0.0190, 0.0143, 0.0337, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7350952625274658 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0409, 0.0031, 0.0185, 0.0135, 0.0339, 0.0051, 0.0032]) \n",
      "Test Loss tensor([0.0371, 0.0030, 0.0188, 0.0142, 0.0353, 0.0065, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7345287799835205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0385, 0.0028, 0.0174, 0.0158, 0.0374, 0.0062, 0.0038]) \n",
      "Test Loss tensor([0.0366, 0.0031, 0.0179, 0.0139, 0.0346, 0.0063, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7680792808532715 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0398, 0.0033, 0.0204, 0.0149, 0.0341, 0.0064, 0.0048]) \n",
      "Test Loss tensor([0.0382, 0.0030, 0.0185, 0.0138, 0.0363, 0.0069, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7583353519439697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0366, 0.0027, 0.0192, 0.0128, 0.0304, 0.0074, 0.0027]) \n",
      "Test Loss tensor([0.0372, 0.0032, 0.0185, 0.0137, 0.0345, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.8016278743743896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0025, 0.0188, 0.0150, 0.0318, 0.0056, 0.0029]) \n",
      "Test Loss tensor([0.0374, 0.0029, 0.0184, 0.0139, 0.0354, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7475512027740479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0367, 0.0024, 0.0178, 0.0141, 0.0308, 0.0051, 0.0027]) \n",
      "Test Loss tensor([0.0373, 0.0031, 0.0180, 0.0139, 0.0337, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7627148628234863 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0354, 0.0019, 0.0184, 0.0148, 0.0345, 0.0055, 0.0033]) \n",
      "Test Loss tensor([0.0371, 0.0032, 0.0179, 0.0139, 0.0344, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.7506852149963379 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0383, 0.0018, 0.0216, 0.0131, 0.0330, 0.0067, 0.0042]) \n",
      "Test Loss tensor([0.0367, 0.0028, 0.0182, 0.0142, 0.0347, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.7426259517669678 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0401, 0.0024, 0.0169, 0.0143, 0.0361, 0.0066, 0.0033]) \n",
      "Test Loss tensor([0.0365, 0.0034, 0.0192, 0.0142, 0.0335, 0.0062, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.750769853591919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0349, 0.0021, 0.0184, 0.0127, 0.0337, 0.0071, 0.0042]) \n",
      "Test Loss tensor([0.0384, 0.0032, 0.0188, 0.0143, 0.0335, 0.0061, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7669243812561035 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0384, 0.0039, 0.0193, 0.0117, 0.0401, 0.0060, 0.0034]) \n",
      "Test Loss tensor([0.0400, 0.0032, 0.0189, 0.0140, 0.0338, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.8181214332580566 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0391, 0.0027, 0.0188, 0.0135, 0.0327, 0.0053, 0.0036]) \n",
      "Test Loss tensor([0.0367, 0.0033, 0.0186, 0.0142, 0.0332, 0.0064, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.7619082927703857 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0432, 0.0027, 0.0171, 0.0133, 0.0319, 0.0059, 0.0036]) \n",
      "Test Loss tensor([0.0377, 0.0031, 0.0186, 0.0140, 0.0349, 0.0061, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7208654880523682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0402, 0.0032, 0.0186, 0.0142, 0.0388, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0386, 0.0029, 0.0180, 0.0145, 0.0334, 0.0060, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7335014343261719 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0025, 0.0209, 0.0140, 0.0322, 0.0059, 0.0022]) \n",
      "Test Loss tensor([0.0367, 0.0032, 0.0187, 0.0137, 0.0336, 0.0066, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7414398193359375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0400, 0.0033, 0.0186, 0.0136, 0.0286, 0.0065, 0.0031]) \n",
      "Test Loss tensor([0.0372, 0.0034, 0.0188, 0.0141, 0.0347, 0.0063, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7775826454162598 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0373, 0.0026, 0.0221, 0.0143, 0.0346, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0377, 0.0029, 0.0185, 0.0141, 0.0339, 0.0064, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6612582206726074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0372, 0.0029, 0.0191, 0.0155, 0.0330, 0.0068, 0.0034]) \n",
      "Test Loss tensor([0.0366, 0.0030, 0.0189, 0.0141, 0.0332, 0.0062, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 384 in 0.6002187728881836 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0348, 0.0029, 0.0185, 0.0142, 0.0313, 0.0067, 0.0034]) \n",
      "Test Loss tensor([0.0368, 0.0029, 0.0184, 0.0137, 0.0337, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5698699951171875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0378, 0.0031, 0.0209, 0.0150, 0.0355, 0.0066, 0.0027]) \n",
      "Test Loss tensor([0.0378, 0.0033, 0.0186, 0.0140, 0.0339, 0.0065, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5663573741912842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0370, 0.0029, 0.0195, 0.0137, 0.0361, 0.0070, 0.0049]) \n",
      "Test Loss tensor([0.0374, 0.0032, 0.0182, 0.0138, 0.0330, 0.0065, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5693674087524414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0356, 0.0024, 0.0161, 0.0132, 0.0326, 0.0065, 0.0035]) \n",
      "Test Loss tensor([0.0376, 0.0028, 0.0177, 0.0137, 0.0330, 0.0064, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5691924095153809 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0383, 0.0028, 0.0198, 0.0149, 0.0354, 0.0069, 0.0033]) \n",
      "Test Loss tensor([0.0363, 0.0029, 0.0187, 0.0144, 0.0335, 0.0064, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5796740055084229 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0347, 0.0026, 0.0193, 0.0136, 0.0342, 0.0068, 0.0030]) \n",
      "Test Loss tensor([0.0376, 0.0031, 0.0188, 0.0139, 0.0325, 0.0064, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5682406425476074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0395, 0.0029, 0.0213, 0.0119, 0.0325, 0.0064, 0.0043]) \n",
      "Test Loss tensor([0.0366, 0.0030, 0.0192, 0.0138, 0.0335, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5974738597869873 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0377, 0.0036, 0.0194, 0.0146, 0.0304, 0.0062, 0.0048]) \n",
      "Test Loss tensor([0.0356, 0.0031, 0.0190, 0.0136, 0.0339, 0.0060, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5973405838012695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0369, 0.0031, 0.0162, 0.0138, 0.0369, 0.0064, 0.0033]) \n",
      "Test Loss tensor([0.0361, 0.0029, 0.0187, 0.0145, 0.0331, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6480612754821777 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0364, 0.0021, 0.0184, 0.0136, 0.0351, 0.0062, 0.0030]) \n",
      "Test Loss tensor([0.0379, 0.0032, 0.0187, 0.0138, 0.0346, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5689730644226074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0360, 0.0028, 0.0189, 0.0163, 0.0351, 0.0096, 0.0040]) \n",
      "Test Loss tensor([0.0352, 0.0031, 0.0184, 0.0142, 0.0324, 0.0059, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5848178863525391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0029, 0.0190, 0.0122, 0.0348, 0.0044, 0.0034]) \n",
      "Test Loss tensor([0.0363, 0.0030, 0.0187, 0.0138, 0.0333, 0.0060, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5760056972503662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0373, 0.0029, 0.0179, 0.0144, 0.0327, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0372, 0.0036, 0.0184, 0.0139, 0.0331, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5839040279388428 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0029, 0.0211, 0.0154, 0.0309, 0.0065, 0.0029]) \n",
      "Test Loss tensor([0.0372, 0.0033, 0.0179, 0.0140, 0.0327, 0.0067, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6842761039733887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0364, 0.0024, 0.0191, 0.0127, 0.0334, 0.0059, 0.0034]) \n",
      "Test Loss tensor([0.0378, 0.0029, 0.0184, 0.0139, 0.0333, 0.0061, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6469438076019287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0038, 0.0189, 0.0157, 0.0331, 0.0076, 0.0039]) \n",
      "Test Loss tensor([0.0370, 0.0033, 0.0177, 0.0135, 0.0324, 0.0065, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6706638336181641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0405, 0.0029, 0.0202, 0.0120, 0.0322, 0.0059, 0.0046]) \n",
      "Test Loss tensor([0.0373, 0.0031, 0.0184, 0.0138, 0.0319, 0.0067, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6612889766693115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0327, 0.0040, 0.0168, 0.0139, 0.0334, 0.0071, 0.0042]) \n",
      "Test Loss tensor([0.0364, 0.0029, 0.0178, 0.0138, 0.0335, 0.0065, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6420626640319824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0361, 0.0031, 0.0172, 0.0144, 0.0334, 0.0080, 0.0049]) \n",
      "Test Loss tensor([0.0372, 0.0032, 0.0182, 0.0137, 0.0318, 0.0065, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6806232929229736 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0439, 0.0028, 0.0205, 0.0135, 0.0331, 0.0060, 0.0045]) \n",
      "Test Loss tensor([0.0360, 0.0031, 0.0181, 0.0140, 0.0331, 0.0065, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6664280891418457 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0392, 0.0030, 0.0191, 0.0132, 0.0338, 0.0072, 0.0033]) \n",
      "Test Loss tensor([0.0363, 0.0029, 0.0184, 0.0139, 0.0344, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5833041667938232 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0391, 0.0026, 0.0179, 0.0134, 0.0309, 0.0056, 0.0026]) \n",
      "Test Loss tensor([0.0357, 0.0030, 0.0186, 0.0141, 0.0333, 0.0062, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5843443870544434 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0360, 0.0017, 0.0190, 0.0116, 0.0297, 0.0053, 0.0031]) \n",
      "Test Loss tensor([0.0363, 0.0030, 0.0181, 0.0140, 0.0327, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5986247062683105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0370, 0.0023, 0.0162, 0.0138, 0.0358, 0.0074, 0.0024]) \n",
      "Test Loss tensor([0.0372, 0.0032, 0.0185, 0.0139, 0.0333, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.583890438079834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0389, 0.0031, 0.0190, 0.0127, 0.0326, 0.0056, 0.0043]) \n",
      "Test Loss tensor([0.0367, 0.0031, 0.0175, 0.0140, 0.0327, 0.0064, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5799939632415771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0356, 0.0033, 0.0206, 0.0125, 0.0302, 0.0053, 0.0030]) \n",
      "Test Loss tensor([0.0360, 0.0032, 0.0183, 0.0140, 0.0333, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6100425720214844 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0369, 0.0041, 0.0179, 0.0135, 0.0351, 0.0051, 0.0037]) \n",
      "Test Loss tensor([0.0359, 0.0029, 0.0178, 0.0136, 0.0337, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.7043821811676025 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0027, 0.0162, 0.0142, 0.0340, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0354, 0.0031, 0.0184, 0.0138, 0.0320, 0.0061, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5873985290527344 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0381, 0.0031, 0.0202, 0.0146, 0.0297, 0.0056, 0.0041]) \n",
      "Test Loss tensor([0.0356, 0.0030, 0.0178, 0.0137, 0.0327, 0.0065, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.666417121887207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0364, 0.0026, 0.0224, 0.0140, 0.0297, 0.0050, 0.0037]) \n",
      "Test Loss tensor([0.0359, 0.0027, 0.0177, 0.0139, 0.0341, 0.0061, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6992244720458984 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0391, 0.0027, 0.0189, 0.0148, 0.0343, 0.0060, 0.0031]) \n",
      "Test Loss tensor([0.0361, 0.0031, 0.0175, 0.0136, 0.0325, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6002235412597656 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0378, 0.0022, 0.0159, 0.0134, 0.0328, 0.0076, 0.0035]) \n",
      "Test Loss tensor([0.0352, 0.0029, 0.0179, 0.0140, 0.0324, 0.0063, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5827078819274902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0361, 0.0027, 0.0179, 0.0125, 0.0313, 0.0066, 0.0048]) \n",
      "Test Loss tensor([0.0355, 0.0030, 0.0177, 0.0134, 0.0329, 0.0062, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5963528156280518 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0394, 0.0029, 0.0199, 0.0139, 0.0342, 0.0057, 0.0033]) \n",
      "Test Loss tensor([0.0367, 0.0029, 0.0181, 0.0136, 0.0333, 0.0064, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5798423290252686 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0379, 0.0022, 0.0225, 0.0142, 0.0328, 0.0059, 0.0039]) \n",
      "Test Loss tensor([0.0353, 0.0032, 0.0178, 0.0138, 0.0329, 0.0064, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5768575668334961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0362, 0.0029, 0.0180, 0.0136, 0.0319, 0.0067, 0.0041]) \n",
      "Test Loss tensor([0.0366, 0.0033, 0.0182, 0.0140, 0.0325, 0.0063, 0.0036])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 528 in 0.6575558185577393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0028, 0.0207, 0.0145, 0.0319, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0363, 0.0033, 0.0183, 0.0138, 0.0321, 0.0062, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6109461784362793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0376, 0.0036, 0.0187, 0.0130, 0.0320, 0.0070, 0.0027]) \n",
      "Test Loss tensor([0.0353, 0.0029, 0.0179, 0.0138, 0.0323, 0.0064, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6036653518676758 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0359, 0.0031, 0.0159, 0.0131, 0.0336, 0.0047, 0.0043]) \n",
      "Test Loss tensor([0.0358, 0.0029, 0.0174, 0.0138, 0.0321, 0.0061, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6012389659881592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0371, 0.0030, 0.0191, 0.0121, 0.0297, 0.0063, 0.0040]) \n",
      "Test Loss tensor([0.0365, 0.0030, 0.0187, 0.0141, 0.0334, 0.0061, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6135680675506592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0030, 0.0198, 0.0149, 0.0293, 0.0064, 0.0038]) \n",
      "Test Loss tensor([0.0365, 0.0029, 0.0178, 0.0141, 0.0313, 0.0065, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.7748477458953857 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0020, 0.0181, 0.0130, 0.0315, 0.0058, 0.0031]) \n",
      "Test Loss tensor([0.0361, 0.0030, 0.0173, 0.0134, 0.0316, 0.0065, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6087970733642578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0026, 0.0201, 0.0135, 0.0346, 0.0056, 0.0028]) \n",
      "Test Loss tensor([0.0367, 0.0031, 0.0179, 0.0140, 0.0313, 0.0066, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6304891109466553 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0386, 0.0029, 0.0185, 0.0137, 0.0325, 0.0067, 0.0036]) \n",
      "Test Loss tensor([0.0350, 0.0030, 0.0175, 0.0134, 0.0320, 0.0064, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.7215595245361328 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0028, 0.0174, 0.0140, 0.0338, 0.0061, 0.0032]) \n",
      "Test Loss tensor([0.0368, 0.0030, 0.0183, 0.0136, 0.0317, 0.0068, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6342408657073975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0354, 0.0031, 0.0194, 0.0146, 0.0335, 0.0061, 0.0042]) \n",
      "Test Loss tensor([0.0352, 0.0033, 0.0183, 0.0137, 0.0319, 0.0060, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6857540607452393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0037, 0.0193, 0.0152, 0.0328, 0.0061, 0.0036]) \n",
      "Test Loss tensor([0.0352, 0.0030, 0.0178, 0.0136, 0.0319, 0.0062, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6640689373016357 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0390, 0.0035, 0.0180, 0.0140, 0.0300, 0.0059, 0.0040]) \n",
      "Test Loss tensor([0.0354, 0.0029, 0.0179, 0.0138, 0.0315, 0.0060, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6457805633544922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0387, 0.0036, 0.0193, 0.0129, 0.0339, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0343, 0.0031, 0.0182, 0.0135, 0.0322, 0.0059, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.597149133682251 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0345, 0.0024, 0.0188, 0.0129, 0.0317, 0.0068, 0.0039]) \n",
      "Test Loss tensor([0.0353, 0.0029, 0.0179, 0.0137, 0.0319, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6779022216796875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0033, 0.0182, 0.0120, 0.0321, 0.0063, 0.0034]) \n",
      "Test Loss tensor([0.0377, 0.0027, 0.0171, 0.0142, 0.0316, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6057064533233643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0033, 0.0187, 0.0157, 0.0336, 0.0067, 0.0039]) \n",
      "Test Loss tensor([0.0352, 0.0031, 0.0186, 0.0140, 0.0333, 0.0064, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.591545581817627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0403, 0.0022, 0.0173, 0.0129, 0.0311, 0.0051, 0.0030]) \n",
      "Test Loss tensor([0.0363, 0.0031, 0.0180, 0.0138, 0.0317, 0.0066, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.7059304714202881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0366, 0.0032, 0.0173, 0.0144, 0.0308, 0.0065, 0.0031]) \n",
      "Test Loss tensor([0.0355, 0.0030, 0.0181, 0.0138, 0.0318, 0.0063, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5783276557922363 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0371, 0.0026, 0.0178, 0.0145, 0.0305, 0.0070, 0.0032]) \n",
      "Test Loss tensor([0.0358, 0.0029, 0.0173, 0.0136, 0.0318, 0.0064, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5989348888397217 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0349, 0.0024, 0.0162, 0.0134, 0.0317, 0.0067, 0.0031]) \n",
      "Test Loss tensor([0.0361, 0.0029, 0.0179, 0.0136, 0.0321, 0.0063, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.592416524887085 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0040, 0.0194, 0.0138, 0.0314, 0.0078, 0.0029]) \n",
      "Test Loss tensor([0.0363, 0.0030, 0.0179, 0.0136, 0.0308, 0.0058, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5899002552032471 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0359, 0.0029, 0.0188, 0.0117, 0.0346, 0.0056, 0.0031]) \n",
      "Test Loss tensor([0.0364, 0.0030, 0.0175, 0.0137, 0.0318, 0.0064, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5807733535766602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0031, 0.0176, 0.0140, 0.0328, 0.0060, 0.0031]) \n",
      "Test Loss tensor([0.0349, 0.0030, 0.0182, 0.0143, 0.0314, 0.0062, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5797157287597656 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0395, 0.0031, 0.0159, 0.0136, 0.0311, 0.0060, 0.0034]) \n",
      "Test Loss tensor([0.0343, 0.0033, 0.0177, 0.0136, 0.0313, 0.0061, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6886186599731445 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0024, 0.0171, 0.0137, 0.0321, 0.0055, 0.0033]) \n",
      "Test Loss tensor([0.0357, 0.0030, 0.0179, 0.0136, 0.0319, 0.0061, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.7102205753326416 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0355, 0.0031, 0.0196, 0.0136, 0.0316, 0.0062, 0.0029]) \n",
      "Test Loss tensor([0.0361, 0.0031, 0.0180, 0.0139, 0.0311, 0.0062, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.634758472442627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0389, 0.0032, 0.0185, 0.0144, 0.0326, 0.0081, 0.0043]) \n",
      "Test Loss tensor([0.0354, 0.0029, 0.0177, 0.0139, 0.0319, 0.0059, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6080904006958008 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0036, 0.0162, 0.0136, 0.0281, 0.0055, 0.0025]) \n",
      "Test Loss tensor([0.0365, 0.0029, 0.0180, 0.0141, 0.0326, 0.0057, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5998027324676514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0028, 0.0173, 0.0136, 0.0313, 0.0059, 0.0027]) \n",
      "Test Loss tensor([0.0361, 0.0029, 0.0173, 0.0136, 0.0315, 0.0061, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.613872766494751 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0360, 0.0026, 0.0199, 0.0149, 0.0328, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0344, 0.0031, 0.0180, 0.0132, 0.0315, 0.0059, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6760632991790771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0035, 0.0161, 0.0143, 0.0318, 0.0046, 0.0041]) \n",
      "Test Loss tensor([0.0350, 0.0031, 0.0178, 0.0135, 0.0307, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5770556926727295 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0021, 0.0170, 0.0143, 0.0306, 0.0054, 0.0029]) \n",
      "Test Loss tensor([0.0359, 0.0027, 0.0183, 0.0138, 0.0324, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5766708850860596 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0028, 0.0183, 0.0144, 0.0294, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0358, 0.0030, 0.0183, 0.0139, 0.0309, 0.0059, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5785624980926514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0022, 0.0167, 0.0119, 0.0301, 0.0053, 0.0040]) \n",
      "Test Loss tensor([0.0366, 0.0027, 0.0179, 0.0138, 0.0315, 0.0063, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5746595859527588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0389, 0.0031, 0.0178, 0.0126, 0.0339, 0.0062, 0.0056]) \n",
      "Test Loss tensor([0.0349, 0.0030, 0.0183, 0.0138, 0.0319, 0.0060, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5783603191375732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0037, 0.0188, 0.0140, 0.0330, 0.0078, 0.0042]) \n",
      "Test Loss tensor([0.0353, 0.0029, 0.0182, 0.0140, 0.0318, 0.0060, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 672 in 0.5811862945556641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0348, 0.0027, 0.0177, 0.0123, 0.0385, 0.0067, 0.0026]) \n",
      "Test Loss tensor([0.0351, 0.0032, 0.0180, 0.0136, 0.0322, 0.0065, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5686047077178955 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0361, 0.0027, 0.0204, 0.0149, 0.0318, 0.0069, 0.0035]) \n",
      "Test Loss tensor([0.0350, 0.0029, 0.0176, 0.0138, 0.0309, 0.0063, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5727369785308838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0028, 0.0165, 0.0147, 0.0336, 0.0054, 0.0039]) \n",
      "Test Loss tensor([0.0359, 0.0030, 0.0176, 0.0138, 0.0315, 0.0061, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5745038986206055 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0375, 0.0021, 0.0183, 0.0134, 0.0301, 0.0067, 0.0029]) \n",
      "Test Loss tensor([0.0350, 0.0027, 0.0171, 0.0139, 0.0322, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5716831684112549 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0381, 0.0033, 0.0188, 0.0143, 0.0336, 0.0052, 0.0029]) \n",
      "Test Loss tensor([0.0353, 0.0031, 0.0180, 0.0140, 0.0308, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5669465065002441 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0367, 0.0034, 0.0189, 0.0146, 0.0353, 0.0055, 0.0039]) \n",
      "Test Loss tensor([0.0352, 0.0030, 0.0180, 0.0135, 0.0316, 0.0056, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5747227668762207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0397, 0.0029, 0.0177, 0.0133, 0.0306, 0.0043, 0.0039]) \n",
      "Test Loss tensor([0.0347, 0.0031, 0.0178, 0.0136, 0.0315, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5717477798461914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0367, 0.0037, 0.0202, 0.0140, 0.0355, 0.0049, 0.0029]) \n",
      "Test Loss tensor([0.0352, 0.0028, 0.0176, 0.0137, 0.0314, 0.0059, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5703516006469727 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0027, 0.0184, 0.0140, 0.0325, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0342, 0.0028, 0.0178, 0.0135, 0.0314, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5682592391967773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0030, 0.0186, 0.0147, 0.0296, 0.0054, 0.0028]) \n",
      "Test Loss tensor([0.0358, 0.0031, 0.0182, 0.0137, 0.0316, 0.0057, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5714356899261475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0330, 0.0029, 0.0160, 0.0145, 0.0291, 0.0054, 0.0035]) \n",
      "Test Loss tensor([0.0369, 0.0030, 0.0185, 0.0138, 0.0320, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.573408842086792 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0026, 0.0155, 0.0140, 0.0296, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0360, 0.0030, 0.0171, 0.0138, 0.0309, 0.0060, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.571009635925293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0023, 0.0191, 0.0148, 0.0309, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0333, 0.0029, 0.0174, 0.0136, 0.0320, 0.0059, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5704495906829834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0020, 0.0165, 0.0132, 0.0304, 0.0055, 0.0030]) \n",
      "Test Loss tensor([0.0348, 0.0029, 0.0174, 0.0137, 0.0304, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5717971324920654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0031, 0.0149, 0.0131, 0.0316, 0.0056, 0.0042]) \n",
      "Test Loss tensor([0.0342, 0.0032, 0.0179, 0.0134, 0.0305, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5699565410614014 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0035, 0.0182, 0.0132, 0.0271, 0.0066, 0.0038]) \n",
      "Test Loss tensor([0.0356, 0.0032, 0.0182, 0.0131, 0.0309, 0.0059, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5703411102294922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0030, 0.0165, 0.0128, 0.0258, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0353, 0.0029, 0.0172, 0.0134, 0.0317, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5698585510253906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0031, 0.0164, 0.0126, 0.0303, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0349, 0.0031, 0.0175, 0.0134, 0.0318, 0.0069, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5752294063568115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0038, 0.0148, 0.0117, 0.0307, 0.0052, 0.0031]) \n",
      "Test Loss tensor([0.0334, 0.0032, 0.0180, 0.0134, 0.0305, 0.0063, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5747883319854736 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0025, 0.0185, 0.0141, 0.0281, 0.0056, 0.0034]) \n",
      "Test Loss tensor([0.0345, 0.0029, 0.0181, 0.0140, 0.0307, 0.0061, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.581477165222168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0029, 0.0176, 0.0136, 0.0322, 0.0062, 0.0029]) \n",
      "Test Loss tensor([0.0353, 0.0030, 0.0178, 0.0136, 0.0306, 0.0064, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5724613666534424 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0027, 0.0183, 0.0166, 0.0317, 0.0051, 0.0039]) \n",
      "Test Loss tensor([0.0339, 0.0027, 0.0175, 0.0138, 0.0303, 0.0064, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5699689388275146 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0386, 0.0034, 0.0171, 0.0119, 0.0304, 0.0065, 0.0030]) \n",
      "Test Loss tensor([0.0351, 0.0030, 0.0172, 0.0137, 0.0300, 0.0061, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5734958648681641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0366, 0.0020, 0.0173, 0.0128, 0.0312, 0.0055, 0.0028]) \n",
      "Test Loss tensor([0.0343, 0.0028, 0.0173, 0.0137, 0.0304, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5738523006439209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0020, 0.0186, 0.0132, 0.0329, 0.0052, 0.0032]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0177, 0.0134, 0.0305, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5773463249206543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0371, 0.0030, 0.0182, 0.0137, 0.0316, 0.0054, 0.0037]) \n",
      "Test Loss tensor([0.0361, 0.0029, 0.0183, 0.0136, 0.0304, 0.0056, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5796926021575928 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0398, 0.0031, 0.0179, 0.0134, 0.0280, 0.0060, 0.0034]) \n",
      "Test Loss tensor([0.0355, 0.0031, 0.0176, 0.0136, 0.0313, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5727016925811768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0378, 0.0039, 0.0196, 0.0138, 0.0313, 0.0068, 0.0038]) \n",
      "Test Loss tensor([0.0339, 0.0031, 0.0176, 0.0136, 0.0318, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5711417198181152 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0352, 0.0033, 0.0165, 0.0125, 0.0357, 0.0050, 0.0032]) \n",
      "Test Loss tensor([0.0344, 0.0030, 0.0173, 0.0132, 0.0309, 0.0061, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5723457336425781 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0026, 0.0181, 0.0130, 0.0317, 0.0060, 0.0046]) \n",
      "Test Loss tensor([0.0347, 0.0030, 0.0169, 0.0134, 0.0306, 0.0059, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5729491710662842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0030, 0.0136, 0.0152, 0.0311, 0.0059, 0.0043]) \n",
      "Test Loss tensor([0.0336, 0.0029, 0.0176, 0.0140, 0.0303, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5732874870300293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0024, 0.0188, 0.0116, 0.0309, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0171, 0.0135, 0.0301, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5721814632415771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0366, 0.0029, 0.0162, 0.0133, 0.0310, 0.0065, 0.0049]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0171, 0.0129, 0.0308, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5725133419036865 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0030, 0.0179, 0.0123, 0.0324, 0.0059, 0.0037]) \n",
      "Test Loss tensor([0.0344, 0.0028, 0.0174, 0.0131, 0.0298, 0.0060, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5731685161590576 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0030, 0.0162, 0.0133, 0.0311, 0.0069, 0.0050]) \n",
      "Test Loss tensor([0.0355, 0.0030, 0.0169, 0.0132, 0.0303, 0.0060, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5709359645843506 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0359, 0.0028, 0.0185, 0.0130, 0.0333, 0.0052, 0.0042]) \n",
      "Test Loss tensor([0.0338, 0.0030, 0.0177, 0.0136, 0.0304, 0.0055, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 816 in 0.5748133659362793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0022, 0.0170, 0.0135, 0.0316, 0.0056, 0.0046]) \n",
      "Test Loss tensor([0.0344, 0.0029, 0.0180, 0.0137, 0.0303, 0.0058, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5734789371490479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0018, 0.0161, 0.0133, 0.0287, 0.0058, 0.0035]) \n",
      "Test Loss tensor([0.0346, 0.0029, 0.0177, 0.0135, 0.0299, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5707578659057617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0023, 0.0178, 0.0120, 0.0347, 0.0041, 0.0038]) \n",
      "Test Loss tensor([0.0344, 0.0029, 0.0169, 0.0134, 0.0310, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5727663040161133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0030, 0.0164, 0.0131, 0.0279, 0.0064, 0.0035]) \n",
      "Test Loss tensor([0.0346, 0.0030, 0.0176, 0.0134, 0.0293, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.576256513595581 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0047, 0.0185, 0.0138, 0.0283, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0339, 0.0031, 0.0170, 0.0132, 0.0296, 0.0060, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5728676319122314 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0032, 0.0175, 0.0123, 0.0291, 0.0067, 0.0037]) \n",
      "Test Loss tensor([0.0341, 0.0030, 0.0176, 0.0140, 0.0305, 0.0056, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5719048976898193 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0036, 0.0193, 0.0130, 0.0311, 0.0064, 0.0041]) \n",
      "Test Loss tensor([0.0360, 0.0031, 0.0174, 0.0135, 0.0290, 0.0058, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5685901641845703 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0024, 0.0159, 0.0126, 0.0254, 0.0046, 0.0035]) \n",
      "Test Loss tensor([0.0348, 0.0030, 0.0169, 0.0139, 0.0294, 0.0058, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5708141326904297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0026, 0.0164, 0.0135, 0.0262, 0.0056, 0.0032]) \n",
      "Test Loss tensor([0.0348, 0.0030, 0.0170, 0.0132, 0.0305, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.573002815246582 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0382, 0.0031, 0.0156, 0.0138, 0.0367, 0.0054, 0.0030]) \n",
      "Test Loss tensor([0.0345, 0.0029, 0.0172, 0.0137, 0.0309, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5773351192474365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0353, 0.0031, 0.0179, 0.0134, 0.0344, 0.0075, 0.0039]) \n",
      "Test Loss tensor([0.0343, 0.0030, 0.0177, 0.0133, 0.0303, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5707247257232666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0389, 0.0039, 0.0162, 0.0125, 0.0308, 0.0062, 0.0045]) \n",
      "Test Loss tensor([0.0344, 0.0028, 0.0179, 0.0135, 0.0307, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5711922645568848 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0028, 0.0155, 0.0120, 0.0322, 0.0053, 0.0033]) \n",
      "Test Loss tensor([0.0333, 0.0030, 0.0174, 0.0135, 0.0308, 0.0055, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5710999965667725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0349, 0.0036, 0.0170, 0.0130, 0.0334, 0.0053, 0.0039]) \n",
      "Test Loss tensor([0.0343, 0.0030, 0.0165, 0.0138, 0.0298, 0.0056, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.575467586517334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0026, 0.0195, 0.0143, 0.0286, 0.0055, 0.0041]) \n",
      "Test Loss tensor([0.0349, 0.0028, 0.0175, 0.0136, 0.0304, 0.0059, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5497474670410156 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0018, 0.0154, 0.0107, 0.0231, 0.0036, 0.0019]) \n",
      "Test Loss tensor([0.0336, 0.0029, 0.0162, 0.0136, 0.0304, 0.0058, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6177334785461426 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0360, 0.0034, 0.0172, 0.0146, 0.0317, 0.0069, 0.0041]) \n",
      "Test Loss tensor([0.0337, 0.0028, 0.0175, 0.0133, 0.0300, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5725796222686768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0352, 0.0026, 0.0157, 0.0124, 0.0308, 0.0063, 0.0028]) \n",
      "Test Loss tensor([0.0339, 0.0028, 0.0170, 0.0132, 0.0302, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5702805519104004 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0306, 0.0023, 0.0200, 0.0141, 0.0314, 0.0060, 0.0041]) \n",
      "Test Loss tensor([0.0339, 0.0030, 0.0175, 0.0133, 0.0293, 0.0062, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5760807991027832 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0028, 0.0170, 0.0123, 0.0294, 0.0063, 0.0031]) \n",
      "Test Loss tensor([0.0346, 0.0028, 0.0167, 0.0132, 0.0303, 0.0063, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5770714282989502 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0023, 0.0198, 0.0138, 0.0320, 0.0053, 0.0030]) \n",
      "Test Loss tensor([0.0338, 0.0031, 0.0173, 0.0138, 0.0296, 0.0059, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5689759254455566 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0024, 0.0157, 0.0142, 0.0285, 0.0062, 0.0028]) \n",
      "Test Loss tensor([0.0343, 0.0030, 0.0180, 0.0136, 0.0302, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5746176242828369 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0339, 0.0023, 0.0172, 0.0140, 0.0309, 0.0055, 0.0035]) \n",
      "Test Loss tensor([0.0339, 0.0029, 0.0172, 0.0137, 0.0295, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.574005126953125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0374, 0.0032, 0.0178, 0.0124, 0.0293, 0.0067, 0.0052]) \n",
      "Test Loss tensor([0.0325, 0.0026, 0.0166, 0.0128, 0.0313, 0.0059, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5725646018981934 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0034, 0.0192, 0.0145, 0.0277, 0.0053, 0.0027]) \n",
      "Test Loss tensor([0.0341, 0.0028, 0.0179, 0.0134, 0.0297, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5708262920379639 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0025, 0.0189, 0.0124, 0.0266, 0.0053, 0.0038]) \n",
      "Test Loss tensor([0.0330, 0.0030, 0.0177, 0.0134, 0.0297, 0.0059, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5714466571807861 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0329, 0.0025, 0.0164, 0.0128, 0.0302, 0.0058, 0.0042]) \n",
      "Test Loss tensor([0.0337, 0.0028, 0.0181, 0.0134, 0.0296, 0.0055, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5734949111938477 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0046, 0.0166, 0.0151, 0.0278, 0.0076, 0.0038]) \n",
      "Test Loss tensor([0.0337, 0.0029, 0.0174, 0.0135, 0.0308, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5698354244232178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0033, 0.0173, 0.0128, 0.0274, 0.0064, 0.0031]) \n",
      "Test Loss tensor([0.0341, 0.0032, 0.0177, 0.0136, 0.0305, 0.0061, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5850362777709961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0347, 0.0030, 0.0191, 0.0130, 0.0300, 0.0056, 0.0042]) \n",
      "Test Loss tensor([0.0331, 0.0030, 0.0177, 0.0134, 0.0307, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5721266269683838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0024, 0.0165, 0.0141, 0.0284, 0.0060, 0.0037]) \n",
      "Test Loss tensor([0.0331, 0.0031, 0.0169, 0.0133, 0.0292, 0.0056, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5701324939727783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0026, 0.0149, 0.0132, 0.0287, 0.0043, 0.0040]) \n",
      "Test Loss tensor([0.0353, 0.0032, 0.0174, 0.0133, 0.0298, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5704548358917236 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0030, 0.0151, 0.0143, 0.0301, 0.0060, 0.0027]) \n",
      "Test Loss tensor([0.0338, 0.0030, 0.0172, 0.0136, 0.0285, 0.0056, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5686488151550293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0030, 0.0148, 0.0125, 0.0288, 0.0060, 0.0036]) \n",
      "Test Loss tensor([0.0343, 0.0033, 0.0179, 0.0136, 0.0296, 0.0057, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5709638595581055 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0021, 0.0181, 0.0140, 0.0326, 0.0064, 0.0028]) \n",
      "Test Loss tensor([0.0334, 0.0026, 0.0172, 0.0136, 0.0301, 0.0058, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5675795078277588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0362, 0.0031, 0.0179, 0.0140, 0.0280, 0.0056, 0.0036]) \n",
      "Test Loss tensor([0.0346, 0.0028, 0.0177, 0.0135, 0.0306, 0.0059, 0.0036])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 80 in 0.5689654350280762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0034, 0.0178, 0.0118, 0.0294, 0.0042, 0.0037]) \n",
      "Test Loss tensor([0.0328, 0.0032, 0.0174, 0.0134, 0.0301, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5737411975860596 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0336, 0.0028, 0.0166, 0.0126, 0.0268, 0.0050, 0.0029]) \n",
      "Test Loss tensor([0.0339, 0.0030, 0.0170, 0.0137, 0.0308, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.57094407081604 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0024, 0.0170, 0.0129, 0.0283, 0.0057, 0.0032]) \n",
      "Test Loss tensor([0.0338, 0.0027, 0.0177, 0.0134, 0.0306, 0.0057, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5684897899627686 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0306, 0.0027, 0.0166, 0.0133, 0.0303, 0.0056, 0.0029]) \n",
      "Test Loss tensor([0.0355, 0.0029, 0.0168, 0.0134, 0.0296, 0.0058, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5668613910675049 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0019, 0.0175, 0.0138, 0.0329, 0.0062, 0.0034]) \n",
      "Test Loss tensor([0.0323, 0.0029, 0.0162, 0.0130, 0.0304, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5699234008789062 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0353, 0.0027, 0.0177, 0.0125, 0.0308, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0338, 0.0031, 0.0175, 0.0133, 0.0306, 0.0056, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5669863224029541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0033, 0.0184, 0.0130, 0.0279, 0.0048, 0.0029]) \n",
      "Test Loss tensor([0.0342, 0.0032, 0.0180, 0.0133, 0.0306, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5692856311798096 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0028, 0.0175, 0.0147, 0.0280, 0.0063, 0.0039]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0170, 0.0135, 0.0291, 0.0059, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5699033737182617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0029, 0.0168, 0.0135, 0.0343, 0.0064, 0.0034]) \n",
      "Test Loss tensor([0.0343, 0.0028, 0.0168, 0.0137, 0.0309, 0.0060, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5694248676300049 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0375, 0.0029, 0.0185, 0.0126, 0.0303, 0.0049, 0.0036]) \n",
      "Test Loss tensor([0.0341, 0.0029, 0.0173, 0.0134, 0.0284, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5701382160186768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0021, 0.0167, 0.0132, 0.0311, 0.0059, 0.0031]) \n",
      "Test Loss tensor([0.0343, 0.0028, 0.0167, 0.0133, 0.0306, 0.0060, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5807015895843506 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0028, 0.0172, 0.0127, 0.0320, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0339, 0.0027, 0.0176, 0.0134, 0.0289, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5715110301971436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0031, 0.0207, 0.0127, 0.0284, 0.0070, 0.0043]) \n",
      "Test Loss tensor([0.0340, 0.0030, 0.0170, 0.0130, 0.0293, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5723903179168701 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0019, 0.0155, 0.0126, 0.0287, 0.0064, 0.0032]) \n",
      "Test Loss tensor([0.0326, 0.0030, 0.0163, 0.0132, 0.0289, 0.0060, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6021378040313721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0024, 0.0160, 0.0145, 0.0249, 0.0053, 0.0024]) \n",
      "Test Loss tensor([0.0329, 0.0029, 0.0175, 0.0134, 0.0290, 0.0059, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5732972621917725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0361, 0.0042, 0.0153, 0.0133, 0.0279, 0.0053, 0.0028]) \n",
      "Test Loss tensor([0.0327, 0.0030, 0.0166, 0.0131, 0.0291, 0.0058, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5708084106445312 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0354, 0.0032, 0.0173, 0.0132, 0.0272, 0.0066, 0.0034]) \n",
      "Test Loss tensor([0.0348, 0.0030, 0.0170, 0.0131, 0.0292, 0.0060, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5706534385681152 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0372, 0.0030, 0.0147, 0.0137, 0.0288, 0.0045, 0.0033]) \n",
      "Test Loss tensor([0.0329, 0.0029, 0.0170, 0.0133, 0.0290, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.570122241973877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0036, 0.0162, 0.0133, 0.0325, 0.0091, 0.0046]) \n",
      "Test Loss tensor([0.0330, 0.0027, 0.0170, 0.0132, 0.0288, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5912113189697266 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0030, 0.0154, 0.0128, 0.0301, 0.0056, 0.0043]) \n",
      "Test Loss tensor([0.0330, 0.0027, 0.0176, 0.0138, 0.0287, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5738339424133301 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0027, 0.0179, 0.0138, 0.0313, 0.0050, 0.0028]) \n",
      "Test Loss tensor([0.0334, 0.0027, 0.0169, 0.0135, 0.0313, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5752854347229004 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0345, 0.0020, 0.0178, 0.0141, 0.0320, 0.0047, 0.0024]) \n",
      "Test Loss tensor([0.0336, 0.0028, 0.0169, 0.0130, 0.0301, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.57623291015625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0025, 0.0172, 0.0129, 0.0275, 0.0062, 0.0043]) \n",
      "Test Loss tensor([0.0337, 0.0028, 0.0169, 0.0133, 0.0297, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5767614841461182 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0027, 0.0178, 0.0152, 0.0301, 0.0043, 0.0040]) \n",
      "Test Loss tensor([0.0331, 0.0030, 0.0179, 0.0135, 0.0293, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.570868968963623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0036, 0.0168, 0.0146, 0.0287, 0.0043, 0.0026]) \n",
      "Test Loss tensor([0.0320, 0.0028, 0.0165, 0.0133, 0.0288, 0.0053, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5706276893615723 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0336, 0.0020, 0.0173, 0.0125, 0.0295, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0328, 0.0032, 0.0170, 0.0132, 0.0289, 0.0052, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5702099800109863 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0362, 0.0025, 0.0166, 0.0147, 0.0314, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0336, 0.0028, 0.0169, 0.0132, 0.0307, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5804042816162109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0369, 0.0037, 0.0159, 0.0130, 0.0322, 0.0059, 0.0043]) \n",
      "Test Loss tensor([0.0331, 0.0027, 0.0166, 0.0129, 0.0303, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5717184543609619 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0027, 0.0186, 0.0125, 0.0310, 0.0045, 0.0024]) \n",
      "Test Loss tensor([0.0339, 0.0033, 0.0170, 0.0130, 0.0294, 0.0057, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5716276168823242 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0031, 0.0191, 0.0130, 0.0291, 0.0057, 0.0042]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0165, 0.0135, 0.0288, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5738470554351807 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0330, 0.0030, 0.0153, 0.0122, 0.0295, 0.0063, 0.0045]) \n",
      "Test Loss tensor([0.0335, 0.0029, 0.0172, 0.0132, 0.0296, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5719692707061768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0353, 0.0023, 0.0146, 0.0129, 0.0309, 0.0055, 0.0039]) \n",
      "Test Loss tensor([0.0331, 0.0030, 0.0166, 0.0135, 0.0284, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5652694702148438 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0378, 0.0029, 0.0183, 0.0140, 0.0303, 0.0078, 0.0037]) \n",
      "Test Loss tensor([0.0316, 0.0032, 0.0176, 0.0137, 0.0287, 0.0058, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5733301639556885 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0027, 0.0162, 0.0136, 0.0308, 0.0066, 0.0031]) \n",
      "Test Loss tensor([0.0339, 0.0031, 0.0161, 0.0132, 0.0281, 0.0062, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5725677013397217 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0320, 0.0041, 0.0157, 0.0135, 0.0294, 0.0058, 0.0030]) \n",
      "Test Loss tensor([0.0329, 0.0028, 0.0170, 0.0131, 0.0289, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5745949745178223 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0384, 0.0029, 0.0169, 0.0137, 0.0263, 0.0066, 0.0047]) \n",
      "Test Loss tensor([0.0333, 0.0028, 0.0170, 0.0131, 0.0290, 0.0059, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 224 in 0.5738065242767334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0019, 0.0135, 0.0129, 0.0311, 0.0050, 0.0031]) \n",
      "Test Loss tensor([0.0329, 0.0029, 0.0174, 0.0135, 0.0287, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5772173404693604 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0033, 0.0168, 0.0126, 0.0293, 0.0050, 0.0024]) \n",
      "Test Loss tensor([0.0333, 0.0027, 0.0169, 0.0130, 0.0299, 0.0061, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5752649307250977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0032, 0.0196, 0.0143, 0.0291, 0.0056, 0.0036]) \n",
      "Test Loss tensor([0.0326, 0.0032, 0.0175, 0.0130, 0.0301, 0.0060, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5849654674530029 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0029, 0.0175, 0.0134, 0.0296, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0320, 0.0029, 0.0165, 0.0134, 0.0296, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5717315673828125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0028, 0.0153, 0.0129, 0.0309, 0.0047, 0.0034]) \n",
      "Test Loss tensor([0.0321, 0.0027, 0.0161, 0.0132, 0.0301, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5719509124755859 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0342, 0.0043, 0.0177, 0.0130, 0.0306, 0.0061, 0.0043]) \n",
      "Test Loss tensor([0.0334, 0.0025, 0.0175, 0.0135, 0.0304, 0.0052, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5710647106170654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0027, 0.0160, 0.0132, 0.0288, 0.0056, 0.0039]) \n",
      "Test Loss tensor([0.0332, 0.0026, 0.0171, 0.0132, 0.0299, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.570767879486084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0036, 0.0189, 0.0141, 0.0253, 0.0058, 0.0048]) \n",
      "Test Loss tensor([0.0338, 0.0030, 0.0166, 0.0133, 0.0285, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5698235034942627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0021, 0.0194, 0.0127, 0.0295, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0324, 0.0030, 0.0166, 0.0131, 0.0288, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5721373558044434 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0031, 0.0155, 0.0148, 0.0288, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0325, 0.0031, 0.0172, 0.0135, 0.0294, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5709378719329834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0029, 0.0179, 0.0129, 0.0301, 0.0057, 0.0031]) \n",
      "Test Loss tensor([0.0330, 0.0028, 0.0169, 0.0135, 0.0291, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5705933570861816 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0023, 0.0180, 0.0150, 0.0287, 0.0062, 0.0025]) \n",
      "Test Loss tensor([0.0330, 0.0029, 0.0171, 0.0136, 0.0286, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5715281963348389 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0027, 0.0165, 0.0127, 0.0289, 0.0058, 0.0036]) \n",
      "Test Loss tensor([0.0332, 0.0030, 0.0168, 0.0130, 0.0292, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5770137310028076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0360, 0.0022, 0.0178, 0.0125, 0.0289, 0.0058, 0.0046]) \n",
      "Test Loss tensor([0.0328, 0.0030, 0.0165, 0.0131, 0.0291, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5705790519714355 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0362, 0.0020, 0.0183, 0.0126, 0.0288, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0326, 0.0028, 0.0168, 0.0130, 0.0284, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5723092555999756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0368, 0.0032, 0.0152, 0.0120, 0.0268, 0.0047, 0.0046]) \n",
      "Test Loss tensor([0.0314, 0.0029, 0.0171, 0.0130, 0.0287, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5708534717559814 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0030, 0.0178, 0.0122, 0.0269, 0.0051, 0.0037]) \n",
      "Test Loss tensor([0.0329, 0.0032, 0.0169, 0.0130, 0.0281, 0.0059, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5692563056945801 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0346, 0.0022, 0.0187, 0.0116, 0.0297, 0.0054, 0.0040]) \n",
      "Test Loss tensor([0.0334, 0.0029, 0.0168, 0.0133, 0.0289, 0.0060, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5716357231140137 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0028, 0.0161, 0.0126, 0.0309, 0.0052, 0.0030]) \n",
      "Test Loss tensor([0.0332, 0.0029, 0.0164, 0.0129, 0.0287, 0.0056, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5714056491851807 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0345, 0.0022, 0.0183, 0.0129, 0.0290, 0.0057, 0.0046]) \n",
      "Test Loss tensor([0.0307, 0.0029, 0.0168, 0.0130, 0.0284, 0.0059, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5707416534423828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0020, 0.0170, 0.0133, 0.0348, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0331, 0.0030, 0.0172, 0.0134, 0.0282, 0.0058, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5725007057189941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0025, 0.0183, 0.0131, 0.0293, 0.0047, 0.0032]) \n",
      "Test Loss tensor([0.0318, 0.0030, 0.0164, 0.0130, 0.0280, 0.0056, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5704951286315918 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0028, 0.0140, 0.0106, 0.0338, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0326, 0.0031, 0.0168, 0.0132, 0.0289, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5763106346130371 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0319, 0.0021, 0.0169, 0.0124, 0.0293, 0.0049, 0.0024]) \n",
      "Test Loss tensor([0.0314, 0.0027, 0.0170, 0.0132, 0.0292, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5708167552947998 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0025, 0.0195, 0.0135, 0.0260, 0.0063, 0.0041]) \n",
      "Test Loss tensor([0.0323, 0.0027, 0.0166, 0.0131, 0.0297, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5709571838378906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0327, 0.0023, 0.0168, 0.0121, 0.0264, 0.0047, 0.0037]) \n",
      "Test Loss tensor([0.0336, 0.0029, 0.0174, 0.0129, 0.0289, 0.0055, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5710463523864746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0352, 0.0027, 0.0172, 0.0117, 0.0304, 0.0067, 0.0039]) \n",
      "Test Loss tensor([0.0331, 0.0029, 0.0168, 0.0129, 0.0300, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5694239139556885 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0361, 0.0030, 0.0159, 0.0121, 0.0315, 0.0059, 0.0040]) \n",
      "Test Loss tensor([0.0324, 0.0026, 0.0171, 0.0133, 0.0300, 0.0054, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5722005367279053 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0026, 0.0180, 0.0117, 0.0298, 0.0058, 0.0041]) \n",
      "Test Loss tensor([0.0342, 0.0029, 0.0168, 0.0137, 0.0287, 0.0052, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5725643634796143 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0033, 0.0158, 0.0136, 0.0281, 0.0053, 0.0038]) \n",
      "Test Loss tensor([0.0328, 0.0030, 0.0158, 0.0129, 0.0288, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5904414653778076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0027, 0.0150, 0.0139, 0.0299, 0.0049, 0.0037]) \n",
      "Test Loss tensor([0.0325, 0.0026, 0.0168, 0.0131, 0.0292, 0.0053, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6168522834777832 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0031, 0.0154, 0.0137, 0.0331, 0.0044, 0.0032]) \n",
      "Test Loss tensor([0.0325, 0.0028, 0.0160, 0.0135, 0.0286, 0.0057, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5748200416564941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0022, 0.0157, 0.0121, 0.0304, 0.0045, 0.0040]) \n",
      "Test Loss tensor([0.0329, 0.0028, 0.0165, 0.0131, 0.0294, 0.0056, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.5733442306518555 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0028, 0.0165, 0.0107, 0.0272, 0.0056, 0.0033]) \n",
      "Test Loss tensor([0.0320, 0.0030, 0.0173, 0.0131, 0.0281, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5832061767578125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0023, 0.0183, 0.0140, 0.0269, 0.0064, 0.0046]) \n",
      "Test Loss tensor([0.0321, 0.0029, 0.0165, 0.0131, 0.0277, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.608414888381958 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0333, 0.0025, 0.0182, 0.0122, 0.0261, 0.0039, 0.0037]) \n",
      "Test Loss tensor([0.0315, 0.0031, 0.0170, 0.0130, 0.0286, 0.0058, 0.0038])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 368 in 0.5885429382324219 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0030, 0.0185, 0.0152, 0.0275, 0.0044, 0.0028]) \n",
      "Test Loss tensor([0.0324, 0.0031, 0.0163, 0.0131, 0.0290, 0.0057, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.573962926864624 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0031, 0.0160, 0.0126, 0.0291, 0.0059, 0.0038]) \n",
      "Test Loss tensor([0.0321, 0.0030, 0.0163, 0.0133, 0.0279, 0.0056, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5730407238006592 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0032, 0.0179, 0.0120, 0.0274, 0.0053, 0.0039]) \n",
      "Test Loss tensor([0.0320, 0.0029, 0.0165, 0.0131, 0.0282, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5712499618530273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0359, 0.0033, 0.0174, 0.0125, 0.0297, 0.0051, 0.0038]) \n",
      "Test Loss tensor([0.0336, 0.0029, 0.0164, 0.0128, 0.0280, 0.0056, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5710160732269287 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0028, 0.0161, 0.0113, 0.0277, 0.0052, 0.0028]) \n",
      "Test Loss tensor([0.0328, 0.0032, 0.0161, 0.0130, 0.0284, 0.0060, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5745587348937988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0024, 0.0158, 0.0143, 0.0299, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0329, 0.0029, 0.0164, 0.0132, 0.0283, 0.0054, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5728697776794434 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0346, 0.0022, 0.0190, 0.0119, 0.0297, 0.0064, 0.0029]) \n",
      "Test Loss tensor([0.0316, 0.0033, 0.0170, 0.0129, 0.0271, 0.0052, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5714898109436035 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0024, 0.0167, 0.0140, 0.0279, 0.0046, 0.0043]) \n",
      "Test Loss tensor([0.0334, 0.0029, 0.0163, 0.0132, 0.0286, 0.0056, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5713250637054443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0028, 0.0161, 0.0135, 0.0287, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0327, 0.0029, 0.0166, 0.0131, 0.0284, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5714824199676514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0030, 0.0153, 0.0116, 0.0292, 0.0051, 0.0036]) \n",
      "Test Loss tensor([0.0316, 0.0027, 0.0167, 0.0131, 0.0281, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5678257942199707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0029, 0.0168, 0.0126, 0.0273, 0.0055, 0.0037]) \n",
      "Test Loss tensor([0.0343, 0.0026, 0.0166, 0.0133, 0.0282, 0.0054, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5716371536254883 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0348, 0.0030, 0.0165, 0.0135, 0.0317, 0.0055, 0.0037]) \n",
      "Test Loss tensor([0.0325, 0.0029, 0.0165, 0.0131, 0.0285, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5743587017059326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0028, 0.0159, 0.0132, 0.0278, 0.0057, 0.0047]) \n",
      "Test Loss tensor([0.0318, 0.0029, 0.0169, 0.0131, 0.0275, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5690100193023682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0026, 0.0153, 0.0141, 0.0290, 0.0046, 0.0031]) \n",
      "Test Loss tensor([0.0329, 0.0028, 0.0161, 0.0132, 0.0278, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.569371223449707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0330, 0.0026, 0.0158, 0.0143, 0.0300, 0.0076, 0.0032]) \n",
      "Test Loss tensor([0.0314, 0.0030, 0.0169, 0.0129, 0.0272, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5689232349395752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0028, 0.0189, 0.0130, 0.0300, 0.0062, 0.0055]) \n",
      "Test Loss tensor([0.0315, 0.0028, 0.0162, 0.0128, 0.0274, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5734350681304932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0035, 0.0190, 0.0139, 0.0287, 0.0054, 0.0039]) \n",
      "Test Loss tensor([0.0317, 0.0029, 0.0163, 0.0129, 0.0279, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5672850608825684 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0029, 0.0194, 0.0136, 0.0293, 0.0054, 0.0031]) \n",
      "Test Loss tensor([0.0312, 0.0028, 0.0165, 0.0131, 0.0281, 0.0055, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5668225288391113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0029, 0.0156, 0.0142, 0.0252, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0324, 0.0030, 0.0163, 0.0132, 0.0283, 0.0055, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5688807964324951 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0035, 0.0165, 0.0132, 0.0274, 0.0058, 0.0036]) \n",
      "Test Loss tensor([0.0332, 0.0027, 0.0163, 0.0130, 0.0289, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5716447830200195 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0308, 0.0024, 0.0151, 0.0138, 0.0250, 0.0056, 0.0031]) \n",
      "Test Loss tensor([0.0326, 0.0027, 0.0167, 0.0130, 0.0289, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5699656009674072 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0029, 0.0163, 0.0137, 0.0301, 0.0059, 0.0048]) \n",
      "Test Loss tensor([0.0319, 0.0030, 0.0166, 0.0130, 0.0295, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5680007934570312 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0030, 0.0170, 0.0142, 0.0260, 0.0045, 0.0039]) \n",
      "Test Loss tensor([0.0333, 0.0029, 0.0163, 0.0131, 0.0277, 0.0054, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5700857639312744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0349, 0.0028, 0.0156, 0.0122, 0.0319, 0.0069, 0.0034]) \n",
      "Test Loss tensor([0.0328, 0.0030, 0.0160, 0.0132, 0.0286, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5708858966827393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0020, 0.0170, 0.0137, 0.0281, 0.0051, 0.0051]) \n",
      "Test Loss tensor([0.0316, 0.0028, 0.0168, 0.0128, 0.0281, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5754363536834717 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0026, 0.0164, 0.0123, 0.0282, 0.0046, 0.0031]) \n",
      "Test Loss tensor([0.0318, 0.0032, 0.0168, 0.0133, 0.0295, 0.0055, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.574979305267334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0347, 0.0037, 0.0158, 0.0127, 0.0262, 0.0061, 0.0050]) \n",
      "Test Loss tensor([0.0320, 0.0030, 0.0166, 0.0132, 0.0289, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5697002410888672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0022, 0.0159, 0.0148, 0.0312, 0.0056, 0.0032]) \n",
      "Test Loss tensor([0.0313, 0.0029, 0.0163, 0.0130, 0.0282, 0.0055, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5735807418823242 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0022, 0.0174, 0.0133, 0.0290, 0.0048, 0.0031]) \n",
      "Test Loss tensor([0.0312, 0.0028, 0.0168, 0.0134, 0.0281, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5689065456390381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0329, 0.0029, 0.0167, 0.0140, 0.0293, 0.0069, 0.0037]) \n",
      "Test Loss tensor([0.0313, 0.0026, 0.0159, 0.0131, 0.0278, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5713889598846436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0339, 0.0040, 0.0174, 0.0121, 0.0289, 0.0049, 0.0042]) \n",
      "Test Loss tensor([0.0327, 0.0027, 0.0163, 0.0131, 0.0285, 0.0052, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5692288875579834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0363, 0.0021, 0.0164, 0.0138, 0.0241, 0.0042, 0.0038]) \n",
      "Test Loss tensor([0.0309, 0.0027, 0.0160, 0.0127, 0.0274, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.570059061050415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0022, 0.0177, 0.0124, 0.0292, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0320, 0.0028, 0.0157, 0.0130, 0.0275, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5694489479064941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0024, 0.0167, 0.0117, 0.0267, 0.0048, 0.0027]) \n",
      "Test Loss tensor([0.0316, 0.0026, 0.0162, 0.0136, 0.0283, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5710618495941162 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0034, 0.0170, 0.0129, 0.0259, 0.0048, 0.0038]) \n",
      "Test Loss tensor([0.0320, 0.0028, 0.0164, 0.0130, 0.0292, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5700831413269043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0019, 0.0151, 0.0133, 0.0284, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0322, 0.0031, 0.0164, 0.0130, 0.0282, 0.0057, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 512 in 0.5711109638214111 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0029, 0.0169, 0.0129, 0.0272, 0.0055, 0.0035]) \n",
      "Test Loss tensor([0.0312, 0.0031, 0.0162, 0.0131, 0.0281, 0.0058, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.571678876876831 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0032, 0.0163, 0.0129, 0.0264, 0.0045, 0.0034]) \n",
      "Test Loss tensor([0.0308, 0.0030, 0.0164, 0.0131, 0.0282, 0.0057, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5696539878845215 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0025, 0.0176, 0.0119, 0.0283, 0.0050, 0.0029]) \n",
      "Test Loss tensor([0.0312, 0.0026, 0.0169, 0.0133, 0.0270, 0.0055, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5693769454956055 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0030, 0.0182, 0.0135, 0.0279, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0325, 0.0028, 0.0166, 0.0132, 0.0275, 0.0059, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5706911087036133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0319, 0.0033, 0.0180, 0.0121, 0.0283, 0.0049, 0.0030]) \n",
      "Test Loss tensor([0.0336, 0.0028, 0.0163, 0.0131, 0.0268, 0.0057, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5693154335021973 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0034, 0.0160, 0.0133, 0.0292, 0.0068, 0.0025]) \n",
      "Test Loss tensor([0.0326, 0.0028, 0.0162, 0.0131, 0.0273, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.572911262512207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0022, 0.0155, 0.0123, 0.0309, 0.0067, 0.0046]) \n",
      "Test Loss tensor([0.0312, 0.0030, 0.0164, 0.0123, 0.0277, 0.0054, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5739243030548096 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0020, 0.0158, 0.0124, 0.0269, 0.0062, 0.0033]) \n",
      "Test Loss tensor([0.0317, 0.0030, 0.0164, 0.0127, 0.0275, 0.0058, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5740015506744385 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0038, 0.0194, 0.0133, 0.0265, 0.0065, 0.0034]) \n",
      "Test Loss tensor([0.0308, 0.0027, 0.0161, 0.0128, 0.0278, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5685114860534668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0341, 0.0033, 0.0171, 0.0149, 0.0270, 0.0064, 0.0050]) \n",
      "Test Loss tensor([0.0332, 0.0026, 0.0167, 0.0133, 0.0288, 0.0057, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5709853172302246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0354, 0.0032, 0.0153, 0.0133, 0.0305, 0.0062, 0.0040]) \n",
      "Test Loss tensor([0.0313, 0.0028, 0.0166, 0.0128, 0.0272, 0.0055, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5704832077026367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0018, 0.0173, 0.0128, 0.0320, 0.0041, 0.0035]) \n",
      "Test Loss tensor([0.0317, 0.0029, 0.0161, 0.0129, 0.0288, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5725829601287842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0024, 0.0172, 0.0142, 0.0286, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0319, 0.0028, 0.0166, 0.0130, 0.0284, 0.0056, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5691709518432617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0029, 0.0151, 0.0128, 0.0259, 0.0074, 0.0043]) \n",
      "Test Loss tensor([0.0331, 0.0026, 0.0169, 0.0128, 0.0292, 0.0052, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5694022178649902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0343, 0.0025, 0.0182, 0.0129, 0.0335, 0.0066, 0.0033]) \n",
      "Test Loss tensor([0.0328, 0.0029, 0.0158, 0.0124, 0.0278, 0.0054, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5696835517883301 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0023, 0.0164, 0.0127, 0.0282, 0.0058, 0.0034]) \n",
      "Test Loss tensor([0.0314, 0.0029, 0.0162, 0.0129, 0.0297, 0.0054, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5688459873199463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0339, 0.0031, 0.0180, 0.0140, 0.0300, 0.0054, 0.0030]) \n",
      "Test Loss tensor([0.0312, 0.0029, 0.0170, 0.0129, 0.0287, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5679786205291748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0030, 0.0147, 0.0134, 0.0303, 0.0047, 0.0023]) \n",
      "Test Loss tensor([0.0313, 0.0028, 0.0166, 0.0128, 0.0289, 0.0055, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6034376621246338 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0033, 0.0155, 0.0116, 0.0339, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0311, 0.0027, 0.0168, 0.0129, 0.0298, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5695726871490479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0347, 0.0028, 0.0170, 0.0141, 0.0299, 0.0052, 0.0035]) \n",
      "Test Loss tensor([0.0319, 0.0029, 0.0159, 0.0128, 0.0283, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5697164535522461 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0037, 0.0164, 0.0133, 0.0321, 0.0058, 0.0041]) \n",
      "Test Loss tensor([0.0318, 0.0030, 0.0170, 0.0130, 0.0282, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.572873592376709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0372, 0.0023, 0.0176, 0.0125, 0.0279, 0.0055, 0.0043]) \n",
      "Test Loss tensor([0.0310, 0.0031, 0.0167, 0.0128, 0.0277, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5708673000335693 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0023, 0.0161, 0.0133, 0.0266, 0.0057, 0.0029]) \n",
      "Test Loss tensor([0.0315, 0.0027, 0.0166, 0.0132, 0.0292, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5721471309661865 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0029, 0.0144, 0.0137, 0.0287, 0.0057, 0.0040]) \n",
      "Test Loss tensor([0.0308, 0.0030, 0.0169, 0.0129, 0.0269, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5744543075561523 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0358, 0.0037, 0.0157, 0.0146, 0.0285, 0.0054, 0.0030]) \n",
      "Test Loss tensor([0.0318, 0.0028, 0.0168, 0.0134, 0.0297, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5864870548248291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0024, 0.0136, 0.0121, 0.0268, 0.0056, 0.0040]) \n",
      "Test Loss tensor([0.0318, 0.0029, 0.0167, 0.0128, 0.0272, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5749242305755615 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0029, 0.0143, 0.0140, 0.0264, 0.0039, 0.0030]) \n",
      "Test Loss tensor([0.0320, 0.0029, 0.0161, 0.0129, 0.0284, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5710792541503906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0308, 0.0024, 0.0170, 0.0126, 0.0302, 0.0052, 0.0032]) \n",
      "Test Loss tensor([0.0319, 0.0027, 0.0160, 0.0130, 0.0275, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5718698501586914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0024, 0.0182, 0.0134, 0.0272, 0.0064, 0.0049]) \n",
      "Test Loss tensor([0.0327, 0.0026, 0.0160, 0.0127, 0.0291, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5713250637054443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0021, 0.0182, 0.0123, 0.0284, 0.0045, 0.0029]) \n",
      "Test Loss tensor([0.0317, 0.0030, 0.0161, 0.0131, 0.0274, 0.0050, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5691447257995605 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0032, 0.0170, 0.0119, 0.0263, 0.0063, 0.0045]) \n",
      "Test Loss tensor([0.0322, 0.0028, 0.0166, 0.0127, 0.0300, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5705254077911377 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0029, 0.0175, 0.0130, 0.0302, 0.0049, 0.0036]) \n",
      "Test Loss tensor([0.0314, 0.0028, 0.0164, 0.0128, 0.0278, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5702733993530273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0028, 0.0162, 0.0130, 0.0243, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0320, 0.0026, 0.0163, 0.0132, 0.0287, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5713939666748047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0026, 0.0146, 0.0125, 0.0286, 0.0051, 0.0030]) \n",
      "Test Loss tensor([0.0315, 0.0028, 0.0159, 0.0126, 0.0268, 0.0053, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5696597099304199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0026, 0.0173, 0.0132, 0.0244, 0.0065, 0.0046]) \n",
      "Test Loss tensor([0.0324, 0.0030, 0.0158, 0.0131, 0.0287, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5739865303039551 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0028, 0.0169, 0.0137, 0.0291, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0316, 0.0024, 0.0159, 0.0130, 0.0270, 0.0053, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 656 in 0.5746610164642334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0032, 0.0154, 0.0112, 0.0285, 0.0057, 0.0027]) \n",
      "Test Loss tensor([0.0306, 0.0026, 0.0164, 0.0132, 0.0273, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.571209192276001 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0303, 0.0027, 0.0173, 0.0128, 0.0288, 0.0050, 0.0035]) \n",
      "Test Loss tensor([0.0315, 0.0025, 0.0164, 0.0129, 0.0264, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5731546878814697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0020, 0.0163, 0.0130, 0.0305, 0.0062, 0.0038]) \n",
      "Test Loss tensor([0.0312, 0.0028, 0.0161, 0.0131, 0.0276, 0.0054, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5681490898132324 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0385, 0.0039, 0.0165, 0.0140, 0.0300, 0.0048, 0.0036]) \n",
      "Test Loss tensor([0.0331, 0.0027, 0.0157, 0.0128, 0.0265, 0.0057, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5700793266296387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0029, 0.0167, 0.0132, 0.0239, 0.0072, 0.0035]) \n",
      "Test Loss tensor([0.0315, 0.0028, 0.0161, 0.0127, 0.0268, 0.0058, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5684933662414551 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0026, 0.0186, 0.0127, 0.0256, 0.0062, 0.0035]) \n",
      "Test Loss tensor([0.0315, 0.0027, 0.0164, 0.0126, 0.0276, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5689127445220947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0024, 0.0154, 0.0119, 0.0248, 0.0052, 0.0035]) \n",
      "Test Loss tensor([0.0312, 0.0028, 0.0164, 0.0128, 0.0265, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5687623023986816 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0031, 0.0162, 0.0128, 0.0261, 0.0058, 0.0033]) \n",
      "Test Loss tensor([0.0304, 0.0026, 0.0161, 0.0129, 0.0274, 0.0054, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5681130886077881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0021, 0.0156, 0.0125, 0.0250, 0.0062, 0.0025]) \n",
      "Test Loss tensor([0.0311, 0.0029, 0.0166, 0.0127, 0.0262, 0.0054, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.571007251739502 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0022, 0.0154, 0.0132, 0.0282, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0325, 0.0026, 0.0164, 0.0129, 0.0277, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5751848220825195 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0031, 0.0171, 0.0128, 0.0286, 0.0042, 0.0043]) \n",
      "Test Loss tensor([0.0300, 0.0027, 0.0162, 0.0131, 0.0275, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5763006210327148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0331, 0.0024, 0.0178, 0.0127, 0.0279, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0320, 0.0027, 0.0162, 0.0130, 0.0266, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5752222537994385 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0020, 0.0160, 0.0115, 0.0281, 0.0051, 0.0031]) \n",
      "Test Loss tensor([0.0301, 0.0031, 0.0158, 0.0127, 0.0264, 0.0052, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.574439287185669 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0021, 0.0178, 0.0142, 0.0286, 0.0054, 0.0028]) \n",
      "Test Loss tensor([0.0308, 0.0029, 0.0164, 0.0131, 0.0273, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5759472846984863 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0021, 0.0168, 0.0118, 0.0311, 0.0058, 0.0041]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0164, 0.0126, 0.0264, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.576434850692749 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0040, 0.0157, 0.0130, 0.0291, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0316, 0.0028, 0.0163, 0.0123, 0.0272, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5769021511077881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0028, 0.0162, 0.0126, 0.0239, 0.0046, 0.0039]) \n",
      "Test Loss tensor([0.0315, 0.0028, 0.0161, 0.0126, 0.0270, 0.0054, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.573218822479248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0037, 0.0169, 0.0118, 0.0252, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0310, 0.0029, 0.0159, 0.0131, 0.0267, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5794486999511719 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0019, 0.0162, 0.0124, 0.0274, 0.0057, 0.0043]) \n",
      "Test Loss tensor([0.0309, 0.0025, 0.0161, 0.0131, 0.0271, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.575937032699585 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0029, 0.0156, 0.0123, 0.0282, 0.0057, 0.0040]) \n",
      "Test Loss tensor([0.0313, 0.0030, 0.0166, 0.0132, 0.0270, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5758213996887207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0027, 0.0191, 0.0126, 0.0254, 0.0053, 0.0033]) \n",
      "Test Loss tensor([0.0317, 0.0027, 0.0155, 0.0128, 0.0279, 0.0057, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5756561756134033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0027, 0.0168, 0.0121, 0.0254, 0.0055, 0.0038]) \n",
      "Test Loss tensor([0.0310, 0.0030, 0.0159, 0.0131, 0.0278, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5765700340270996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0023, 0.0157, 0.0126, 0.0266, 0.0052, 0.0042]) \n",
      "Test Loss tensor([0.0310, 0.0025, 0.0159, 0.0128, 0.0273, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.57460618019104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0365, 0.0026, 0.0168, 0.0112, 0.0266, 0.0053, 0.0043]) \n",
      "Test Loss tensor([0.0312, 0.0026, 0.0162, 0.0132, 0.0275, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5740017890930176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0364, 0.0022, 0.0162, 0.0114, 0.0294, 0.0051, 0.0036]) \n",
      "Test Loss tensor([0.0306, 0.0032, 0.0164, 0.0129, 0.0270, 0.0054, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5712707042694092 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0024, 0.0158, 0.0134, 0.0306, 0.0058, 0.0030]) \n",
      "Test Loss tensor([0.0306, 0.0030, 0.0165, 0.0132, 0.0274, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5758819580078125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0301, 0.0021, 0.0186, 0.0124, 0.0284, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0303, 0.0028, 0.0166, 0.0130, 0.0271, 0.0051, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5748405456542969 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0038, 0.0165, 0.0128, 0.0294, 0.0050, 0.0036]) \n",
      "Test Loss tensor([0.0309, 0.0029, 0.0162, 0.0126, 0.0273, 0.0056, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5754249095916748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0020, 0.0141, 0.0122, 0.0299, 0.0061, 0.0036]) \n",
      "Test Loss tensor([0.0315, 0.0027, 0.0152, 0.0129, 0.0270, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5756218433380127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0327, 0.0024, 0.0158, 0.0116, 0.0261, 0.0042, 0.0034]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0157, 0.0128, 0.0261, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5774426460266113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0329, 0.0032, 0.0169, 0.0121, 0.0277, 0.0062, 0.0036]) \n",
      "Test Loss tensor([0.0315, 0.0029, 0.0162, 0.0127, 0.0261, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5760772228240967 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0038, 0.0167, 0.0126, 0.0283, 0.0049, 0.0031]) \n",
      "Test Loss tensor([0.0310, 0.0028, 0.0160, 0.0130, 0.0267, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5777945518493652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0330, 0.0023, 0.0165, 0.0143, 0.0270, 0.0054, 0.0043]) \n",
      "Test Loss tensor([0.0310, 0.0029, 0.0169, 0.0130, 0.0266, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5774612426757812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0024, 0.0175, 0.0123, 0.0233, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0320, 0.0026, 0.0161, 0.0130, 0.0271, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.576974630355835 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0025, 0.0143, 0.0129, 0.0264, 0.0058, 0.0038]) \n",
      "Test Loss tensor([0.0312, 0.0026, 0.0159, 0.0130, 0.0266, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5752809047698975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0033, 0.0168, 0.0139, 0.0277, 0.0046, 0.0027]) \n",
      "Test Loss tensor([0.0313, 0.0028, 0.0153, 0.0129, 0.0265, 0.0053, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 800 in 0.5757479667663574 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0023, 0.0168, 0.0132, 0.0287, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0308, 0.0029, 0.0162, 0.0130, 0.0275, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5752513408660889 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0027, 0.0187, 0.0126, 0.0262, 0.0046, 0.0042]) \n",
      "Test Loss tensor([0.0314, 0.0029, 0.0161, 0.0127, 0.0261, 0.0054, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5763516426086426 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0026, 0.0161, 0.0130, 0.0269, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0308, 0.0026, 0.0156, 0.0131, 0.0267, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5769476890563965 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0333, 0.0034, 0.0160, 0.0135, 0.0293, 0.0063, 0.0035]) \n",
      "Test Loss tensor([0.0310, 0.0029, 0.0160, 0.0130, 0.0266, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5746676921844482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0306, 0.0027, 0.0163, 0.0121, 0.0246, 0.0047, 0.0025]) \n",
      "Test Loss tensor([0.0307, 0.0030, 0.0160, 0.0129, 0.0270, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.575253963470459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0025, 0.0152, 0.0122, 0.0268, 0.0038, 0.0033]) \n",
      "Test Loss tensor([0.0316, 0.0028, 0.0155, 0.0128, 0.0281, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5739271640777588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0037, 0.0186, 0.0131, 0.0293, 0.0053, 0.0034]) \n",
      "Test Loss tensor([0.0324, 0.0026, 0.0157, 0.0126, 0.0268, 0.0056, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5751693248748779 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0028, 0.0151, 0.0129, 0.0272, 0.0053, 0.0040]) \n",
      "Test Loss tensor([0.0304, 0.0030, 0.0161, 0.0128, 0.0258, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.5757339000701904 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0034, 0.0173, 0.0142, 0.0294, 0.0061, 0.0034]) \n",
      "Test Loss tensor([0.0301, 0.0030, 0.0163, 0.0127, 0.0260, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5813581943511963 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0301, 0.0027, 0.0182, 0.0127, 0.0268, 0.0051, 0.0024]) \n",
      "Test Loss tensor([0.0313, 0.0028, 0.0164, 0.0129, 0.0273, 0.0056, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5752873420715332 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0032, 0.0153, 0.0115, 0.0249, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0306, 0.0030, 0.0162, 0.0127, 0.0269, 0.0056, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.57568359375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0030, 0.0157, 0.0135, 0.0271, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0308, 0.0028, 0.0159, 0.0130, 0.0269, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5767080783843994 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0024, 0.0170, 0.0136, 0.0265, 0.0051, 0.0031]) \n",
      "Test Loss tensor([0.0313, 0.0031, 0.0157, 0.0127, 0.0266, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5812129974365234 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0024, 0.0149, 0.0126, 0.0254, 0.0052, 0.0039]) \n",
      "Test Loss tensor([0.0304, 0.0028, 0.0161, 0.0128, 0.0273, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5744366645812988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0024, 0.0171, 0.0124, 0.0290, 0.0072, 0.0040]) \n",
      "Test Loss tensor([0.0311, 0.0031, 0.0157, 0.0131, 0.0259, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5755796432495117 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0028, 0.0174, 0.0129, 0.0252, 0.0048, 0.0027]) \n",
      "Test Loss tensor([0.0312, 0.0031, 0.0162, 0.0127, 0.0275, 0.0054, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5792348384857178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0029, 0.0156, 0.0128, 0.0264, 0.0054, 0.0035]) \n",
      "Test Loss tensor([0.0319, 0.0029, 0.0163, 0.0129, 0.0263, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5801711082458496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0027, 0.0167, 0.0139, 0.0277, 0.0052, 0.0032]) \n",
      "Test Loss tensor([0.0312, 0.0027, 0.0159, 0.0128, 0.0259, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5741569995880127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0027, 0.0162, 0.0125, 0.0242, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0309, 0.0028, 0.0158, 0.0129, 0.0268, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5536508560180664 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0021, 0.0112, 0.0087, 0.0196, 0.0041, 0.0028]) \n",
      "Test Loss tensor([0.0292, 0.0029, 0.0159, 0.0127, 0.0266, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6131396293640137 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0028, 0.0167, 0.0121, 0.0322, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0305, 0.0030, 0.0161, 0.0128, 0.0264, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5732262134552002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0350, 0.0027, 0.0176, 0.0122, 0.0276, 0.0059, 0.0043]) \n",
      "Test Loss tensor([0.0305, 0.0026, 0.0162, 0.0130, 0.0272, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5741055011749268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0353, 0.0028, 0.0169, 0.0129, 0.0261, 0.0060, 0.0035]) \n",
      "Test Loss tensor([0.0314, 0.0031, 0.0160, 0.0127, 0.0258, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5790510177612305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0331, 0.0024, 0.0174, 0.0125, 0.0269, 0.0053, 0.0034]) \n",
      "Test Loss tensor([0.0308, 0.0028, 0.0163, 0.0126, 0.0262, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5734498500823975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0018, 0.0162, 0.0146, 0.0302, 0.0047, 0.0043]) \n",
      "Test Loss tensor([0.0313, 0.0029, 0.0157, 0.0127, 0.0254, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.574310302734375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0029, 0.0160, 0.0124, 0.0288, 0.0061, 0.0034]) \n",
      "Test Loss tensor([0.0309, 0.0029, 0.0163, 0.0129, 0.0267, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5735666751861572 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0026, 0.0140, 0.0127, 0.0269, 0.0056, 0.0027]) \n",
      "Test Loss tensor([0.0316, 0.0032, 0.0156, 0.0128, 0.0272, 0.0052, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5770494937896729 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0024, 0.0163, 0.0118, 0.0249, 0.0061, 0.0033]) \n",
      "Test Loss tensor([0.0309, 0.0032, 0.0162, 0.0126, 0.0268, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5751743316650391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0027, 0.0144, 0.0127, 0.0264, 0.0050, 0.0028]) \n",
      "Test Loss tensor([0.0297, 0.0029, 0.0159, 0.0124, 0.0267, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5764811038970947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0025, 0.0162, 0.0120, 0.0254, 0.0057, 0.0040]) \n",
      "Test Loss tensor([0.0315, 0.0029, 0.0157, 0.0124, 0.0265, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5801241397857666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0025, 0.0179, 0.0128, 0.0270, 0.0050, 0.0041]) \n",
      "Test Loss tensor([0.0310, 0.0028, 0.0154, 0.0125, 0.0267, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.576704740524292 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0021, 0.0181, 0.0130, 0.0260, 0.0047, 0.0025]) \n",
      "Test Loss tensor([0.0297, 0.0029, 0.0163, 0.0124, 0.0269, 0.0055, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5785961151123047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0308, 0.0029, 0.0163, 0.0122, 0.0291, 0.0057, 0.0038]) \n",
      "Test Loss tensor([0.0303, 0.0026, 0.0166, 0.0129, 0.0264, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.573258638381958 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0031, 0.0151, 0.0119, 0.0258, 0.0049, 0.0045]) \n",
      "Test Loss tensor([0.0311, 0.0028, 0.0163, 0.0128, 0.0259, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5751698017120361 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0032, 0.0169, 0.0126, 0.0254, 0.0051, 0.0035]) \n",
      "Test Loss tensor([0.0302, 0.0029, 0.0156, 0.0126, 0.0268, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5734457969665527 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0024, 0.0162, 0.0121, 0.0294, 0.0051, 0.0036]) \n",
      "Test Loss tensor([0.0310, 0.0032, 0.0164, 0.0128, 0.0270, 0.0053, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 64 in 0.5720658302307129 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0022, 0.0171, 0.0133, 0.0255, 0.0053, 0.0033]) \n",
      "Test Loss tensor([0.0301, 0.0027, 0.0162, 0.0128, 0.0260, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5750293731689453 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0022, 0.0155, 0.0123, 0.0252, 0.0051, 0.0055]) \n",
      "Test Loss tensor([0.0306, 0.0027, 0.0164, 0.0129, 0.0265, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5714335441589355 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0333, 0.0025, 0.0173, 0.0137, 0.0269, 0.0054, 0.0029]) \n",
      "Test Loss tensor([0.0308, 0.0030, 0.0162, 0.0126, 0.0266, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5744953155517578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0024, 0.0156, 0.0119, 0.0243, 0.0064, 0.0030]) \n",
      "Test Loss tensor([0.0307, 0.0028, 0.0159, 0.0128, 0.0278, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5747694969177246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0029, 0.0143, 0.0119, 0.0258, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0300, 0.0029, 0.0155, 0.0126, 0.0262, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5746026039123535 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0334, 0.0032, 0.0173, 0.0116, 0.0282, 0.0058, 0.0033]) \n",
      "Test Loss tensor([0.0307, 0.0026, 0.0161, 0.0129, 0.0270, 0.0055, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5728840827941895 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0023, 0.0192, 0.0127, 0.0290, 0.0062, 0.0042]) \n",
      "Test Loss tensor([0.0303, 0.0032, 0.0155, 0.0129, 0.0260, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5709447860717773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0021, 0.0157, 0.0127, 0.0282, 0.0045, 0.0034]) \n",
      "Test Loss tensor([0.0312, 0.0028, 0.0154, 0.0126, 0.0272, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.571768045425415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0021, 0.0171, 0.0126, 0.0281, 0.0051, 0.0028]) \n",
      "Test Loss tensor([0.0292, 0.0028, 0.0163, 0.0132, 0.0262, 0.0052, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5695209503173828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0320, 0.0019, 0.0165, 0.0122, 0.0308, 0.0044, 0.0041]) \n",
      "Test Loss tensor([0.0304, 0.0027, 0.0162, 0.0128, 0.0273, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5701735019683838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0038, 0.0162, 0.0124, 0.0276, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0292, 0.0026, 0.0159, 0.0122, 0.0265, 0.0050, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5686204433441162 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0032, 0.0157, 0.0116, 0.0254, 0.0048, 0.0029]) \n",
      "Test Loss tensor([0.0301, 0.0030, 0.0158, 0.0128, 0.0271, 0.0052, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5711274147033691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0021, 0.0157, 0.0133, 0.0304, 0.0053, 0.0041]) \n",
      "Test Loss tensor([0.0297, 0.0028, 0.0155, 0.0130, 0.0278, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5692095756530762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0025, 0.0154, 0.0110, 0.0269, 0.0050, 0.0043]) \n",
      "Test Loss tensor([0.0312, 0.0027, 0.0161, 0.0127, 0.0258, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5713996887207031 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0033, 0.0158, 0.0132, 0.0282, 0.0042, 0.0038]) \n",
      "Test Loss tensor([0.0299, 0.0026, 0.0162, 0.0128, 0.0272, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5700066089630127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0026, 0.0157, 0.0136, 0.0292, 0.0045, 0.0033]) \n",
      "Test Loss tensor([0.0300, 0.0028, 0.0156, 0.0123, 0.0261, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5682535171508789 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0030, 0.0151, 0.0121, 0.0276, 0.0049, 0.0043]) \n",
      "Test Loss tensor([0.0307, 0.0027, 0.0158, 0.0128, 0.0260, 0.0054, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5713605880737305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0022, 0.0154, 0.0124, 0.0289, 0.0051, 0.0040]) \n",
      "Test Loss tensor([0.0309, 0.0031, 0.0156, 0.0124, 0.0264, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.571847677230835 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0036, 0.0138, 0.0134, 0.0257, 0.0065, 0.0044]) \n",
      "Test Loss tensor([0.0301, 0.0029, 0.0160, 0.0126, 0.0256, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5682003498077393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0026, 0.0144, 0.0136, 0.0257, 0.0060, 0.0031]) \n",
      "Test Loss tensor([0.0297, 0.0030, 0.0161, 0.0127, 0.0259, 0.0052, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.575514554977417 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0027, 0.0144, 0.0137, 0.0247, 0.0051, 0.0032]) \n",
      "Test Loss tensor([0.0291, 0.0026, 0.0153, 0.0128, 0.0257, 0.0050, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5692803859710693 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0024, 0.0173, 0.0131, 0.0282, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0297, 0.0028, 0.0163, 0.0126, 0.0262, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6010265350341797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0022, 0.0170, 0.0128, 0.0229, 0.0045, 0.0028]) \n",
      "Test Loss tensor([0.0309, 0.0029, 0.0157, 0.0129, 0.0259, 0.0054, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5746252536773682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0018, 0.0174, 0.0125, 0.0263, 0.0042, 0.0037]) \n",
      "Test Loss tensor([0.0300, 0.0027, 0.0158, 0.0127, 0.0260, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.570056676864624 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0026, 0.0147, 0.0122, 0.0242, 0.0047, 0.0035]) \n",
      "Test Loss tensor([0.0295, 0.0028, 0.0158, 0.0127, 0.0266, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5678162574768066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0327, 0.0022, 0.0164, 0.0136, 0.0250, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0302, 0.0029, 0.0152, 0.0125, 0.0254, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5697410106658936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0023, 0.0155, 0.0116, 0.0260, 0.0052, 0.0041]) \n",
      "Test Loss tensor([0.0316, 0.0029, 0.0153, 0.0128, 0.0262, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5729937553405762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0022, 0.0149, 0.0139, 0.0256, 0.0064, 0.0036]) \n",
      "Test Loss tensor([0.0287, 0.0026, 0.0158, 0.0129, 0.0260, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5690877437591553 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0026, 0.0148, 0.0111, 0.0254, 0.0052, 0.0034]) \n",
      "Test Loss tensor([0.0303, 0.0027, 0.0157, 0.0130, 0.0261, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5863323211669922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0043, 0.0141, 0.0132, 0.0251, 0.0044, 0.0026]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0160, 0.0123, 0.0264, 0.0051, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5708627700805664 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0035, 0.0169, 0.0130, 0.0270, 0.0044, 0.0035]) \n",
      "Test Loss tensor([0.0301, 0.0029, 0.0160, 0.0124, 0.0261, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5727472305297852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0029, 0.0162, 0.0126, 0.0247, 0.0047, 0.0034]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0155, 0.0123, 0.0262, 0.0056, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.57071852684021 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0023, 0.0172, 0.0136, 0.0256, 0.0056, 0.0030]) \n",
      "Test Loss tensor([0.0310, 0.0028, 0.0159, 0.0125, 0.0262, 0.0053, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5684702396392822 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0027, 0.0155, 0.0138, 0.0262, 0.0041, 0.0028]) \n",
      "Test Loss tensor([0.0300, 0.0029, 0.0159, 0.0125, 0.0259, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5675897598266602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0357, 0.0020, 0.0153, 0.0114, 0.0251, 0.0048, 0.0032]) \n",
      "Test Loss tensor([0.0308, 0.0028, 0.0156, 0.0126, 0.0250, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5692238807678223 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0033, 0.0174, 0.0129, 0.0271, 0.0052, 0.0042]) \n",
      "Test Loss tensor([0.0301, 0.0026, 0.0151, 0.0124, 0.0261, 0.0051, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 208 in 0.5749015808105469 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0024, 0.0146, 0.0123, 0.0260, 0.0055, 0.0032]) \n",
      "Test Loss tensor([0.0301, 0.0025, 0.0163, 0.0127, 0.0259, 0.0051, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5707440376281738 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0025, 0.0192, 0.0134, 0.0251, 0.0052, 0.0025]) \n",
      "Test Loss tensor([0.0302, 0.0027, 0.0164, 0.0126, 0.0256, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5690467357635498 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0027, 0.0164, 0.0132, 0.0279, 0.0047, 0.0030]) \n",
      "Test Loss tensor([0.0292, 0.0026, 0.0159, 0.0131, 0.0260, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5689339637756348 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0027, 0.0163, 0.0126, 0.0238, 0.0041, 0.0036]) \n",
      "Test Loss tensor([0.0302, 0.0026, 0.0159, 0.0126, 0.0260, 0.0054, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.569263219833374 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0021, 0.0139, 0.0122, 0.0286, 0.0039, 0.0033]) \n",
      "Test Loss tensor([0.0310, 0.0025, 0.0157, 0.0128, 0.0253, 0.0050, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.5778517723083496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0023, 0.0149, 0.0115, 0.0289, 0.0038, 0.0035]) \n",
      "Test Loss tensor([0.0295, 0.0028, 0.0163, 0.0127, 0.0260, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5688667297363281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0032, 0.0140, 0.0126, 0.0272, 0.0052, 0.0034]) \n",
      "Test Loss tensor([0.0308, 0.0027, 0.0155, 0.0124, 0.0261, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5710773468017578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0025, 0.0158, 0.0116, 0.0258, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0301, 0.0026, 0.0157, 0.0124, 0.0258, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5698192119598389 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0032, 0.0148, 0.0124, 0.0233, 0.0066, 0.0045]) \n",
      "Test Loss tensor([0.0307, 0.0028, 0.0153, 0.0125, 0.0270, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5701565742492676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0018, 0.0154, 0.0125, 0.0246, 0.0041, 0.0034]) \n",
      "Test Loss tensor([0.0311, 0.0029, 0.0157, 0.0127, 0.0264, 0.0053, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5715541839599609 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0025, 0.0162, 0.0127, 0.0281, 0.0054, 0.0032]) \n",
      "Test Loss tensor([0.0285, 0.0027, 0.0163, 0.0126, 0.0247, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5679931640625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0026, 0.0165, 0.0117, 0.0248, 0.0045, 0.0040]) \n",
      "Test Loss tensor([0.0306, 0.0027, 0.0154, 0.0127, 0.0266, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5689122676849365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0023, 0.0153, 0.0118, 0.0306, 0.0052, 0.0048]) \n",
      "Test Loss tensor([0.0302, 0.0026, 0.0156, 0.0128, 0.0256, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5714609622955322 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0025, 0.0159, 0.0130, 0.0252, 0.0046, 0.0026]) \n",
      "Test Loss tensor([0.0293, 0.0028, 0.0158, 0.0127, 0.0262, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5717489719390869 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0028, 0.0162, 0.0127, 0.0253, 0.0048, 0.0029]) \n",
      "Test Loss tensor([0.0301, 0.0026, 0.0158, 0.0125, 0.0261, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5683126449584961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0025, 0.0174, 0.0121, 0.0283, 0.0054, 0.0025]) \n",
      "Test Loss tensor([0.0292, 0.0028, 0.0153, 0.0123, 0.0267, 0.0051, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5726706981658936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0301, 0.0022, 0.0159, 0.0129, 0.0250, 0.0047, 0.0040]) \n",
      "Test Loss tensor([0.0297, 0.0026, 0.0157, 0.0130, 0.0263, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.5666487216949463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0032, 0.0168, 0.0137, 0.0250, 0.0051, 0.0038]) \n",
      "Test Loss tensor([0.0308, 0.0030, 0.0154, 0.0124, 0.0266, 0.0053, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5699326992034912 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0025, 0.0170, 0.0129, 0.0250, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0294, 0.0028, 0.0154, 0.0127, 0.0261, 0.0051, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5677814483642578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0023, 0.0158, 0.0142, 0.0261, 0.0047, 0.0035]) \n",
      "Test Loss tensor([0.0296, 0.0026, 0.0159, 0.0128, 0.0248, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5691101551055908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0031, 0.0185, 0.0114, 0.0277, 0.0048, 0.0041]) \n",
      "Test Loss tensor([0.0308, 0.0029, 0.0158, 0.0128, 0.0252, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5716061592102051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0029, 0.0124, 0.0133, 0.0272, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0297, 0.0029, 0.0155, 0.0127, 0.0247, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.573096752166748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0031, 0.0162, 0.0137, 0.0253, 0.0059, 0.0037]) \n",
      "Test Loss tensor([0.0303, 0.0027, 0.0154, 0.0131, 0.0260, 0.0053, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6046774387359619 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0028, 0.0132, 0.0125, 0.0273, 0.0054, 0.0032]) \n",
      "Test Loss tensor([0.0299, 0.0028, 0.0157, 0.0127, 0.0254, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.613018274307251 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0029, 0.0139, 0.0121, 0.0253, 0.0050, 0.0027]) \n",
      "Test Loss tensor([0.0309, 0.0029, 0.0154, 0.0126, 0.0261, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5724759101867676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0023, 0.0157, 0.0116, 0.0243, 0.0042, 0.0026]) \n",
      "Test Loss tensor([0.0318, 0.0023, 0.0154, 0.0126, 0.0263, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5719475746154785 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0340, 0.0034, 0.0173, 0.0131, 0.0270, 0.0055, 0.0036]) \n",
      "Test Loss tensor([0.0297, 0.0026, 0.0161, 0.0127, 0.0250, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6059579849243164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0344, 0.0022, 0.0158, 0.0131, 0.0281, 0.0052, 0.0032]) \n",
      "Test Loss tensor([0.0303, 0.0026, 0.0154, 0.0124, 0.0261, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5736062526702881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0029, 0.0169, 0.0123, 0.0253, 0.0063, 0.0034]) \n",
      "Test Loss tensor([0.0299, 0.0027, 0.0157, 0.0126, 0.0258, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6051383018493652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0021, 0.0160, 0.0125, 0.0262, 0.0064, 0.0026]) \n",
      "Test Loss tensor([0.0296, 0.0028, 0.0153, 0.0126, 0.0267, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5883541107177734 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0021, 0.0178, 0.0133, 0.0245, 0.0067, 0.0034]) \n",
      "Test Loss tensor([0.0300, 0.0027, 0.0153, 0.0127, 0.0260, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.581043004989624 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0331, 0.0029, 0.0159, 0.0108, 0.0254, 0.0061, 0.0038]) \n",
      "Test Loss tensor([0.0296, 0.0027, 0.0154, 0.0125, 0.0251, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5822665691375732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0325, 0.0027, 0.0162, 0.0128, 0.0254, 0.0043, 0.0044]) \n",
      "Test Loss tensor([0.0299, 0.0027, 0.0157, 0.0128, 0.0259, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5872988700866699 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0036, 0.0154, 0.0134, 0.0275, 0.0038, 0.0026]) \n",
      "Test Loss tensor([0.0298, 0.0026, 0.0152, 0.0126, 0.0255, 0.0052, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5823321342468262 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0019, 0.0152, 0.0113, 0.0229, 0.0036, 0.0024]) \n",
      "Test Loss tensor([0.0289, 0.0028, 0.0155, 0.0127, 0.0263, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.580197811126709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0027, 0.0168, 0.0132, 0.0274, 0.0054, 0.0043]) \n",
      "Test Loss tensor([0.0291, 0.0026, 0.0160, 0.0124, 0.0253, 0.0051, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 352 in 0.581524133682251 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0040, 0.0166, 0.0136, 0.0234, 0.0052, 0.0027]) \n",
      "Test Loss tensor([0.0303, 0.0027, 0.0155, 0.0127, 0.0265, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.581028938293457 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0027, 0.0168, 0.0123, 0.0244, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0293, 0.0026, 0.0158, 0.0129, 0.0243, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5817196369171143 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0319, 0.0034, 0.0181, 0.0119, 0.0244, 0.0040, 0.0038]) \n",
      "Test Loss tensor([0.0291, 0.0029, 0.0159, 0.0126, 0.0253, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5798735618591309 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0329, 0.0025, 0.0166, 0.0126, 0.0254, 0.0056, 0.0029]) \n",
      "Test Loss tensor([0.0299, 0.0026, 0.0153, 0.0123, 0.0261, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5828309059143066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0022, 0.0147, 0.0117, 0.0296, 0.0059, 0.0040]) \n",
      "Test Loss tensor([0.0301, 0.0027, 0.0157, 0.0126, 0.0248, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5801651477813721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0303, 0.0022, 0.0162, 0.0127, 0.0249, 0.0048, 0.0029]) \n",
      "Test Loss tensor([0.0288, 0.0029, 0.0148, 0.0128, 0.0260, 0.0051, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5806427001953125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0028, 0.0152, 0.0142, 0.0274, 0.0040, 0.0028]) \n",
      "Test Loss tensor([0.0296, 0.0028, 0.0157, 0.0126, 0.0249, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5794312953948975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0326, 0.0026, 0.0139, 0.0120, 0.0238, 0.0050, 0.0037]) \n",
      "Test Loss tensor([0.0305, 0.0024, 0.0153, 0.0129, 0.0265, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5829858779907227 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0351, 0.0025, 0.0136, 0.0130, 0.0285, 0.0064, 0.0039]) \n",
      "Test Loss tensor([0.0286, 0.0027, 0.0152, 0.0127, 0.0255, 0.0055, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.5798718929290771 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0021, 0.0146, 0.0126, 0.0247, 0.0047, 0.0030]) \n",
      "Test Loss tensor([0.0295, 0.0031, 0.0160, 0.0127, 0.0270, 0.0057, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5802104473114014 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0023, 0.0145, 0.0117, 0.0273, 0.0042, 0.0032]) \n",
      "Test Loss tensor([0.0311, 0.0026, 0.0153, 0.0123, 0.0257, 0.0055, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5779862403869629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0031, 0.0130, 0.0133, 0.0243, 0.0060, 0.0028]) \n",
      "Test Loss tensor([0.0302, 0.0026, 0.0158, 0.0124, 0.0264, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5806686878204346 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0029, 0.0159, 0.0124, 0.0260, 0.0048, 0.0038]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0159, 0.0124, 0.0249, 0.0052, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5827398300170898 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0338, 0.0031, 0.0153, 0.0129, 0.0234, 0.0056, 0.0038]) \n",
      "Test Loss tensor([0.0302, 0.0028, 0.0158, 0.0125, 0.0252, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5791516304016113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0025, 0.0160, 0.0138, 0.0240, 0.0046, 0.0035]) \n",
      "Test Loss tensor([0.0287, 0.0028, 0.0157, 0.0125, 0.0251, 0.0050, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5790853500366211 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0028, 0.0177, 0.0143, 0.0263, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0292, 0.0029, 0.0160, 0.0126, 0.0250, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5836615562438965 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0320, 0.0027, 0.0153, 0.0116, 0.0242, 0.0049, 0.0039]) \n",
      "Test Loss tensor([0.0292, 0.0025, 0.0155, 0.0126, 0.0248, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5858421325683594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0019, 0.0138, 0.0125, 0.0264, 0.0052, 0.0037]) \n",
      "Test Loss tensor([0.0294, 0.0027, 0.0157, 0.0126, 0.0268, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5851287841796875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0031, 0.0164, 0.0125, 0.0251, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0298, 0.0026, 0.0155, 0.0129, 0.0251, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5849134922027588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0019, 0.0168, 0.0144, 0.0223, 0.0054, 0.0033]) \n",
      "Test Loss tensor([0.0306, 0.0024, 0.0155, 0.0127, 0.0253, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.583526611328125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0306, 0.0019, 0.0158, 0.0123, 0.0267, 0.0047, 0.0025]) \n",
      "Test Loss tensor([0.0295, 0.0026, 0.0161, 0.0130, 0.0253, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5850181579589844 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0027, 0.0169, 0.0143, 0.0266, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0291, 0.0028, 0.0154, 0.0127, 0.0257, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5828835964202881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0320, 0.0032, 0.0136, 0.0115, 0.0255, 0.0051, 0.0031]) \n",
      "Test Loss tensor([0.0311, 0.0025, 0.0157, 0.0125, 0.0245, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5839359760284424 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0030, 0.0175, 0.0130, 0.0241, 0.0040, 0.0032]) \n",
      "Test Loss tensor([0.0297, 0.0029, 0.0153, 0.0126, 0.0246, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.585094690322876 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0018, 0.0159, 0.0135, 0.0210, 0.0059, 0.0036]) \n",
      "Test Loss tensor([0.0289, 0.0027, 0.0162, 0.0122, 0.0247, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5881218910217285 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0319, 0.0028, 0.0153, 0.0128, 0.0254, 0.0053, 0.0027]) \n",
      "Test Loss tensor([0.0294, 0.0026, 0.0160, 0.0124, 0.0248, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5828745365142822 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0035, 0.0171, 0.0133, 0.0274, 0.0066, 0.0029]) \n",
      "Test Loss tensor([0.0304, 0.0029, 0.0154, 0.0125, 0.0253, 0.0052, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5810906887054443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0023, 0.0158, 0.0123, 0.0248, 0.0048, 0.0040]) \n",
      "Test Loss tensor([0.0307, 0.0029, 0.0153, 0.0126, 0.0246, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5903110504150391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0032, 0.0186, 0.0124, 0.0255, 0.0060, 0.0036]) \n",
      "Test Loss tensor([0.0302, 0.0027, 0.0154, 0.0128, 0.0240, 0.0050, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5813260078430176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0023, 0.0161, 0.0122, 0.0241, 0.0064, 0.0034]) \n",
      "Test Loss tensor([0.0291, 0.0025, 0.0158, 0.0128, 0.0252, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5810105800628662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0023, 0.0153, 0.0129, 0.0219, 0.0055, 0.0042]) \n",
      "Test Loss tensor([0.0278, 0.0029, 0.0152, 0.0124, 0.0253, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5804977416992188 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0339, 0.0031, 0.0166, 0.0121, 0.0285, 0.0060, 0.0040]) \n",
      "Test Loss tensor([0.0286, 0.0027, 0.0156, 0.0127, 0.0249, 0.0054, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5788543224334717 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0029, 0.0167, 0.0118, 0.0275, 0.0074, 0.0043]) \n",
      "Test Loss tensor([0.0286, 0.0027, 0.0156, 0.0126, 0.0247, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5821821689605713 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0034, 0.0159, 0.0130, 0.0237, 0.0052, 0.0033]) \n",
      "Test Loss tensor([0.0301, 0.0026, 0.0151, 0.0124, 0.0246, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5814085006713867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0018, 0.0143, 0.0138, 0.0273, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0281, 0.0025, 0.0155, 0.0124, 0.0257, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5806012153625488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0027, 0.0164, 0.0148, 0.0249, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0290, 0.0028, 0.0157, 0.0129, 0.0259, 0.0051, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 496 in 0.579200029373169 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0024, 0.0144, 0.0128, 0.0252, 0.0044, 0.0032]) \n",
      "Test Loss tensor([0.0294, 0.0026, 0.0158, 0.0126, 0.0251, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5859041213989258 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0025, 0.0150, 0.0133, 0.0252, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0297, 0.0027, 0.0158, 0.0121, 0.0249, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5850117206573486 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0023, 0.0175, 0.0118, 0.0236, 0.0050, 0.0040]) \n",
      "Test Loss tensor([0.0298, 0.0026, 0.0145, 0.0124, 0.0251, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5802710056304932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0018, 0.0164, 0.0114, 0.0255, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0292, 0.0028, 0.0158, 0.0125, 0.0244, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5812523365020752 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0373, 0.0023, 0.0147, 0.0125, 0.0221, 0.0042, 0.0039]) \n",
      "Test Loss tensor([0.0284, 0.0027, 0.0154, 0.0127, 0.0244, 0.0051, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5829172134399414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0025, 0.0156, 0.0139, 0.0255, 0.0044, 0.0051]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0157, 0.0129, 0.0250, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5832135677337646 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0025, 0.0157, 0.0123, 0.0276, 0.0058, 0.0029]) \n",
      "Test Loss tensor([0.0296, 0.0027, 0.0161, 0.0126, 0.0251, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5826971530914307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0023, 0.0155, 0.0146, 0.0244, 0.0044, 0.0035]) \n",
      "Test Loss tensor([0.0288, 0.0027, 0.0156, 0.0127, 0.0249, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.5819439888000488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0028, 0.0158, 0.0142, 0.0237, 0.0043, 0.0042]) \n",
      "Test Loss tensor([0.0290, 0.0027, 0.0157, 0.0125, 0.0252, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5822160243988037 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0021, 0.0142, 0.0122, 0.0266, 0.0057, 0.0051]) \n",
      "Test Loss tensor([0.0282, 0.0028, 0.0160, 0.0124, 0.0255, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5804221630096436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0034, 0.0136, 0.0129, 0.0256, 0.0050, 0.0043]) \n",
      "Test Loss tensor([0.0277, 0.0028, 0.0154, 0.0127, 0.0245, 0.0053, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5829517841339111 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0025, 0.0176, 0.0135, 0.0270, 0.0043, 0.0034]) \n",
      "Test Loss tensor([0.0295, 0.0028, 0.0151, 0.0128, 0.0243, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5818068981170654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0025, 0.0168, 0.0128, 0.0227, 0.0045, 0.0037]) \n",
      "Test Loss tensor([0.0290, 0.0027, 0.0154, 0.0125, 0.0250, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5818064212799072 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0331, 0.0031, 0.0148, 0.0133, 0.0249, 0.0067, 0.0036]) \n",
      "Test Loss tensor([0.0295, 0.0026, 0.0157, 0.0125, 0.0248, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5846447944641113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0023, 0.0149, 0.0128, 0.0256, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0293, 0.0025, 0.0157, 0.0125, 0.0247, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5860960483551025 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0031, 0.0151, 0.0118, 0.0282, 0.0055, 0.0044]) \n",
      "Test Loss tensor([0.0298, 0.0029, 0.0160, 0.0124, 0.0246, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5807948112487793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0028, 0.0153, 0.0131, 0.0250, 0.0056, 0.0039]) \n",
      "Test Loss tensor([0.0297, 0.0026, 0.0152, 0.0123, 0.0253, 0.0051, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5798490047454834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0029, 0.0165, 0.0138, 0.0221, 0.0041, 0.0037]) \n",
      "Test Loss tensor([0.0301, 0.0026, 0.0150, 0.0124, 0.0249, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5811982154846191 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0027, 0.0149, 0.0125, 0.0262, 0.0042, 0.0028]) \n",
      "Test Loss tensor([0.0288, 0.0028, 0.0152, 0.0123, 0.0249, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.579974889755249 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0025, 0.0162, 0.0134, 0.0256, 0.0051, 0.0036]) \n",
      "Test Loss tensor([0.0290, 0.0028, 0.0154, 0.0128, 0.0254, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5806148052215576 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0027, 0.0140, 0.0119, 0.0229, 0.0059, 0.0051]) \n",
      "Test Loss tensor([0.0312, 0.0027, 0.0153, 0.0129, 0.0252, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5866446495056152 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0324, 0.0028, 0.0182, 0.0135, 0.0267, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0289, 0.0029, 0.0154, 0.0124, 0.0250, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5867886543273926 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0035, 0.0162, 0.0119, 0.0254, 0.0057, 0.0043]) \n",
      "Test Loss tensor([0.0276, 0.0026, 0.0153, 0.0126, 0.0243, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5862691402435303 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0020, 0.0144, 0.0113, 0.0269, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0148, 0.0126, 0.0244, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5879373550415039 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0037, 0.0162, 0.0129, 0.0241, 0.0047, 0.0030]) \n",
      "Test Loss tensor([0.0299, 0.0027, 0.0155, 0.0126, 0.0247, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6055161952972412 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0339, 0.0023, 0.0182, 0.0115, 0.0247, 0.0055, 0.0038]) \n",
      "Test Loss tensor([0.0299, 0.0026, 0.0150, 0.0125, 0.0261, 0.0051, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5830233097076416 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0027, 0.0146, 0.0109, 0.0261, 0.0049, 0.0036]) \n",
      "Test Loss tensor([0.0293, 0.0027, 0.0153, 0.0123, 0.0241, 0.0052, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5842945575714111 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0030, 0.0158, 0.0127, 0.0243, 0.0043, 0.0043]) \n",
      "Test Loss tensor([0.0290, 0.0023, 0.0150, 0.0122, 0.0257, 0.0046, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5826854705810547 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0020, 0.0167, 0.0110, 0.0236, 0.0052, 0.0032]) \n",
      "Test Loss tensor([0.0288, 0.0029, 0.0157, 0.0125, 0.0259, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5833353996276855 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0024, 0.0172, 0.0125, 0.0272, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0282, 0.0029, 0.0149, 0.0121, 0.0251, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5812032222747803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0021, 0.0155, 0.0117, 0.0234, 0.0053, 0.0029]) \n",
      "Test Loss tensor([0.0299, 0.0025, 0.0146, 0.0129, 0.0245, 0.0051, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5847945213317871 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0021, 0.0135, 0.0137, 0.0287, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0293, 0.0025, 0.0159, 0.0125, 0.0245, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.598121166229248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0023, 0.0159, 0.0120, 0.0231, 0.0041, 0.0026]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0155, 0.0123, 0.0239, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5858242511749268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0026, 0.0176, 0.0118, 0.0231, 0.0039, 0.0026]) \n",
      "Test Loss tensor([0.0282, 0.0028, 0.0156, 0.0124, 0.0250, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5823113918304443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0022, 0.0150, 0.0130, 0.0259, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0290, 0.0030, 0.0156, 0.0125, 0.0244, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5845439434051514 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0022, 0.0155, 0.0131, 0.0270, 0.0058, 0.0030]) \n",
      "Test Loss tensor([0.0282, 0.0026, 0.0161, 0.0127, 0.0253, 0.0046, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 640 in 0.5910837650299072 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0337, 0.0025, 0.0146, 0.0128, 0.0288, 0.0046, 0.0031]) \n",
      "Test Loss tensor([0.0293, 0.0027, 0.0149, 0.0127, 0.0245, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.587512731552124 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0021, 0.0156, 0.0120, 0.0221, 0.0044, 0.0029]) \n",
      "Test Loss tensor([0.0293, 0.0028, 0.0153, 0.0128, 0.0248, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5866563320159912 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0026, 0.0165, 0.0119, 0.0267, 0.0039, 0.0029]) \n",
      "Test Loss tensor([0.0294, 0.0027, 0.0153, 0.0123, 0.0239, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5851435661315918 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0022, 0.0137, 0.0123, 0.0253, 0.0061, 0.0034]) \n",
      "Test Loss tensor([0.0291, 0.0029, 0.0148, 0.0124, 0.0237, 0.0049, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5969226360321045 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0020, 0.0181, 0.0126, 0.0256, 0.0042, 0.0035]) \n",
      "Test Loss tensor([0.0291, 0.0028, 0.0153, 0.0123, 0.0256, 0.0049, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5850687026977539 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0026, 0.0154, 0.0108, 0.0244, 0.0059, 0.0045]) \n",
      "Test Loss tensor([0.0290, 0.0025, 0.0154, 0.0120, 0.0250, 0.0053, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5872070789337158 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0030, 0.0167, 0.0117, 0.0276, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0302, 0.0026, 0.0156, 0.0124, 0.0254, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5844886302947998 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0027, 0.0150, 0.0126, 0.0254, 0.0049, 0.0032]) \n",
      "Test Loss tensor([0.0281, 0.0026, 0.0154, 0.0128, 0.0252, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5880751609802246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0023, 0.0158, 0.0142, 0.0265, 0.0052, 0.0033]) \n",
      "Test Loss tensor([0.0287, 0.0028, 0.0151, 0.0126, 0.0235, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5841226577758789 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0031, 0.0151, 0.0129, 0.0248, 0.0038, 0.0031]) \n",
      "Test Loss tensor([0.0292, 0.0026, 0.0155, 0.0122, 0.0254, 0.0055, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5889902114868164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0027, 0.0164, 0.0123, 0.0305, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0282, 0.0026, 0.0155, 0.0128, 0.0241, 0.0049, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5845518112182617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0026, 0.0150, 0.0137, 0.0233, 0.0032, 0.0033]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0158, 0.0121, 0.0258, 0.0051, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5813858509063721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0035, 0.0152, 0.0116, 0.0250, 0.0046, 0.0041]) \n",
      "Test Loss tensor([0.0288, 0.0028, 0.0147, 0.0124, 0.0244, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5853722095489502 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0025, 0.0146, 0.0117, 0.0232, 0.0044, 0.0032]) \n",
      "Test Loss tensor([0.0285, 0.0026, 0.0157, 0.0125, 0.0259, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5820820331573486 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0024, 0.0158, 0.0126, 0.0241, 0.0061, 0.0033]) \n",
      "Test Loss tensor([0.0294, 0.0026, 0.0149, 0.0125, 0.0246, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.581101655960083 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0026, 0.0176, 0.0120, 0.0232, 0.0051, 0.0038]) \n",
      "Test Loss tensor([0.0296, 0.0027, 0.0152, 0.0123, 0.0251, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5874943733215332 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0319, 0.0032, 0.0142, 0.0125, 0.0239, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0287, 0.0024, 0.0153, 0.0124, 0.0259, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5878140926361084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0021, 0.0162, 0.0122, 0.0235, 0.0048, 0.0040]) \n",
      "Test Loss tensor([0.0297, 0.0025, 0.0156, 0.0122, 0.0248, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5893292427062988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0021, 0.0156, 0.0119, 0.0250, 0.0038, 0.0034]) \n",
      "Test Loss tensor([0.0280, 0.0028, 0.0150, 0.0123, 0.0256, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.581026554107666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0028, 0.0148, 0.0128, 0.0244, 0.0068, 0.0032]) \n",
      "Test Loss tensor([0.0282, 0.0027, 0.0154, 0.0125, 0.0242, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5786685943603516 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0312, 0.0020, 0.0142, 0.0111, 0.0234, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0294, 0.0028, 0.0150, 0.0126, 0.0246, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5823805332183838 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0025, 0.0145, 0.0134, 0.0253, 0.0035, 0.0029]) \n",
      "Test Loss tensor([0.0296, 0.0026, 0.0149, 0.0120, 0.0247, 0.0050, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5833361148834229 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0032, 0.0142, 0.0117, 0.0252, 0.0048, 0.0051]) \n",
      "Test Loss tensor([0.0279, 0.0028, 0.0156, 0.0126, 0.0246, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5878229141235352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0032, 0.0139, 0.0139, 0.0222, 0.0056, 0.0034]) \n",
      "Test Loss tensor([0.0286, 0.0029, 0.0153, 0.0123, 0.0249, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.5787923336029053 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0308, 0.0034, 0.0162, 0.0113, 0.0202, 0.0052, 0.0036]) \n",
      "Test Loss tensor([0.0292, 0.0025, 0.0150, 0.0126, 0.0244, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5823497772216797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0033, 0.0153, 0.0124, 0.0249, 0.0046, 0.0025]) \n",
      "Test Loss tensor([0.0281, 0.0027, 0.0155, 0.0127, 0.0244, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5833749771118164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0309, 0.0031, 0.0174, 0.0122, 0.0240, 0.0064, 0.0045]) \n",
      "Test Loss tensor([0.0278, 0.0028, 0.0159, 0.0124, 0.0254, 0.0052, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5808172225952148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0032, 0.0151, 0.0125, 0.0257, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0282, 0.0026, 0.0155, 0.0122, 0.0236, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5841293334960938 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0028, 0.0150, 0.0112, 0.0256, 0.0051, 0.0047]) \n",
      "Test Loss tensor([0.0285, 0.0024, 0.0151, 0.0130, 0.0247, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5816977024078369 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0018, 0.0162, 0.0126, 0.0240, 0.0042, 0.0032]) \n",
      "Test Loss tensor([0.0273, 0.0027, 0.0152, 0.0124, 0.0251, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5847623348236084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0026, 0.0152, 0.0122, 0.0233, 0.0043, 0.0040]) \n",
      "Test Loss tensor([0.0290, 0.0027, 0.0153, 0.0123, 0.0252, 0.0051, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5836453437805176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0021, 0.0159, 0.0126, 0.0231, 0.0054, 0.0045]) \n",
      "Test Loss tensor([0.0296, 0.0027, 0.0157, 0.0125, 0.0247, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.584836483001709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0025, 0.0143, 0.0114, 0.0235, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0280, 0.0028, 0.0159, 0.0122, 0.0236, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5835442543029785 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0024, 0.0178, 0.0128, 0.0247, 0.0041, 0.0038]) \n",
      "Test Loss tensor([0.0282, 0.0026, 0.0155, 0.0122, 0.0242, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5808932781219482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0029, 0.0144, 0.0126, 0.0256, 0.0050, 0.0036]) \n",
      "Test Loss tensor([0.0295, 0.0025, 0.0152, 0.0122, 0.0244, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5813112258911133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0030, 0.0152, 0.0128, 0.0253, 0.0043, 0.0034]) \n",
      "Test Loss tensor([0.0298, 0.0024, 0.0153, 0.0123, 0.0246, 0.0047, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 784 in 0.5840833187103271 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0022, 0.0175, 0.0141, 0.0248, 0.0041, 0.0032]) \n",
      "Test Loss tensor([0.0287, 0.0026, 0.0149, 0.0120, 0.0240, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.580474853515625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0028, 0.0148, 0.0117, 0.0254, 0.0042, 0.0032]) \n",
      "Test Loss tensor([0.0286, 0.0026, 0.0158, 0.0123, 0.0241, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5829033851623535 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0020, 0.0137, 0.0115, 0.0243, 0.0052, 0.0036]) \n",
      "Test Loss tensor([0.0286, 0.0026, 0.0152, 0.0120, 0.0247, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5815548896789551 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0311, 0.0027, 0.0172, 0.0108, 0.0218, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0292, 0.0026, 0.0154, 0.0123, 0.0248, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6111388206481934 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0024, 0.0146, 0.0129, 0.0290, 0.0054, 0.0037]) \n",
      "Test Loss tensor([0.0279, 0.0026, 0.0154, 0.0127, 0.0244, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5890865325927734 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0024, 0.0144, 0.0120, 0.0231, 0.0055, 0.0032]) \n",
      "Test Loss tensor([0.0279, 0.0025, 0.0156, 0.0124, 0.0245, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5808115005493164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0027, 0.0144, 0.0124, 0.0235, 0.0034, 0.0037]) \n",
      "Test Loss tensor([0.0277, 0.0025, 0.0154, 0.0123, 0.0249, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5836002826690674 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0345, 0.0021, 0.0149, 0.0103, 0.0253, 0.0039, 0.0030]) \n",
      "Test Loss tensor([0.0276, 0.0027, 0.0153, 0.0122, 0.0245, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5836231708526611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0020, 0.0138, 0.0124, 0.0234, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0278, 0.0025, 0.0155, 0.0123, 0.0249, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5838642120361328 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0028, 0.0138, 0.0115, 0.0208, 0.0048, 0.0036]) \n",
      "Test Loss tensor([0.0280, 0.0029, 0.0151, 0.0121, 0.0245, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.582587480545044 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0038, 0.0140, 0.0115, 0.0247, 0.0048, 0.0040]) \n",
      "Test Loss tensor([0.0278, 0.0026, 0.0148, 0.0122, 0.0257, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5804202556610107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0020, 0.0164, 0.0115, 0.0269, 0.0032, 0.0039]) \n",
      "Test Loss tensor([0.0278, 0.0029, 0.0148, 0.0121, 0.0243, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.584496259689331 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0022, 0.0154, 0.0124, 0.0245, 0.0064, 0.0053]) \n",
      "Test Loss tensor([0.0285, 0.0026, 0.0153, 0.0122, 0.0249, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5789294242858887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0025, 0.0157, 0.0122, 0.0246, 0.0048, 0.0033]) \n",
      "Test Loss tensor([0.0288, 0.0025, 0.0151, 0.0124, 0.0237, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5907459259033203 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0023, 0.0155, 0.0104, 0.0210, 0.0056, 0.0042]) \n",
      "Test Loss tensor([0.0300, 0.0026, 0.0151, 0.0125, 0.0249, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5822854042053223 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0031, 0.0148, 0.0126, 0.0250, 0.0042, 0.0041]) \n",
      "Test Loss tensor([0.0281, 0.0025, 0.0151, 0.0122, 0.0245, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5824460983276367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0029, 0.0149, 0.0113, 0.0281, 0.0041, 0.0033]) \n",
      "Test Loss tensor([0.0282, 0.0030, 0.0153, 0.0121, 0.0253, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.5811116695404053 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0303, 0.0022, 0.0151, 0.0123, 0.0233, 0.0044, 0.0028]) \n",
      "Test Loss tensor([0.0274, 0.0027, 0.0159, 0.0126, 0.0238, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5813636779785156 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0019, 0.0157, 0.0125, 0.0226, 0.0055, 0.0040]) \n",
      "Test Loss tensor([0.0283, 0.0029, 0.0154, 0.0125, 0.0253, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5827019214630127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0021, 0.0149, 0.0132, 0.0248, 0.0041, 0.0032]) \n",
      "Test Loss tensor([0.0291, 0.0025, 0.0157, 0.0129, 0.0255, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5825767517089844 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0028, 0.0164, 0.0112, 0.0260, 0.0046, 0.0027]) \n",
      "Test Loss tensor([0.0285, 0.0029, 0.0154, 0.0121, 0.0242, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5831279754638672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0024, 0.0143, 0.0123, 0.0278, 0.0036, 0.0030]) \n",
      "Test Loss tensor([0.0288, 0.0025, 0.0155, 0.0125, 0.0280, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5857207775115967 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0028, 0.0154, 0.0121, 0.0286, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0288, 0.0027, 0.0151, 0.0121, 0.0242, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5575087070465088 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0014, 0.0101, 0.0095, 0.0184, 0.0036, 0.0031]) \n",
      "Test Loss tensor([0.0285, 0.0026, 0.0154, 0.0124, 0.0248, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6177961826324463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0037, 0.0140, 0.0122, 0.0272, 0.0047, 0.0034]) \n",
      "Test Loss tensor([0.0279, 0.0027, 0.0151, 0.0124, 0.0237, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5771548748016357 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0020, 0.0141, 0.0129, 0.0226, 0.0055, 0.0036]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0150, 0.0123, 0.0250, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5806946754455566 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0026, 0.0141, 0.0126, 0.0242, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0293, 0.0024, 0.0152, 0.0125, 0.0236, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.579948902130127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0287, 0.0026, 0.0165, 0.0113, 0.0236, 0.0048, 0.0032]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0146, 0.0122, 0.0247, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5821847915649414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0018, 0.0140, 0.0137, 0.0257, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0282, 0.0027, 0.0151, 0.0126, 0.0243, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5816926956176758 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0329, 0.0031, 0.0145, 0.0113, 0.0228, 0.0049, 0.0030]) \n",
      "Test Loss tensor([0.0290, 0.0025, 0.0150, 0.0126, 0.0249, 0.0051, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5817852020263672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0321, 0.0023, 0.0149, 0.0120, 0.0286, 0.0050, 0.0028]) \n",
      "Test Loss tensor([0.0284, 0.0027, 0.0154, 0.0121, 0.0242, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5830247402191162 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0027, 0.0144, 0.0142, 0.0243, 0.0052, 0.0048]) \n",
      "Test Loss tensor([0.0281, 0.0028, 0.0158, 0.0125, 0.0260, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5805225372314453 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0024, 0.0126, 0.0124, 0.0268, 0.0043, 0.0043]) \n",
      "Test Loss tensor([0.0290, 0.0027, 0.0149, 0.0126, 0.0241, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5794661045074463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0024, 0.0143, 0.0116, 0.0211, 0.0031, 0.0032]) \n",
      "Test Loss tensor([0.0290, 0.0024, 0.0158, 0.0125, 0.0260, 0.0052, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5830821990966797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0021, 0.0147, 0.0115, 0.0247, 0.0043, 0.0035]) \n",
      "Test Loss tensor([0.0279, 0.0025, 0.0152, 0.0123, 0.0235, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5801894664764404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0026, 0.0170, 0.0117, 0.0240, 0.0045, 0.0050]) \n",
      "Test Loss tensor([0.0283, 0.0027, 0.0148, 0.0120, 0.0244, 0.0050, 0.0038])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 48 in 0.5836832523345947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0019, 0.0155, 0.0133, 0.0259, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0275, 0.0028, 0.0150, 0.0121, 0.0239, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6066112518310547 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0025, 0.0160, 0.0122, 0.0218, 0.0057, 0.0036]) \n",
      "Test Loss tensor([0.0294, 0.0026, 0.0155, 0.0123, 0.0250, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5857789516448975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0026, 0.0158, 0.0123, 0.0255, 0.0049, 0.0028]) \n",
      "Test Loss tensor([0.0283, 0.0025, 0.0155, 0.0124, 0.0243, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5876038074493408 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0018, 0.0122, 0.0116, 0.0242, 0.0047, 0.0042]) \n",
      "Test Loss tensor([0.0281, 0.0027, 0.0152, 0.0122, 0.0241, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5853559970855713 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0026, 0.0164, 0.0128, 0.0270, 0.0040, 0.0041]) \n",
      "Test Loss tensor([0.0283, 0.0025, 0.0155, 0.0124, 0.0236, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5799238681793213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0024, 0.0146, 0.0130, 0.0245, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0290, 0.0026, 0.0152, 0.0123, 0.0248, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5802288055419922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0021, 0.0161, 0.0123, 0.0235, 0.0041, 0.0032]) \n",
      "Test Loss tensor([0.0272, 0.0026, 0.0153, 0.0120, 0.0245, 0.0052, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.603968620300293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0025, 0.0150, 0.0121, 0.0248, 0.0056, 0.0049]) \n",
      "Test Loss tensor([0.0285, 0.0028, 0.0149, 0.0125, 0.0247, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6223912239074707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0323, 0.0023, 0.0153, 0.0109, 0.0266, 0.0054, 0.0023]) \n",
      "Test Loss tensor([0.0276, 0.0027, 0.0154, 0.0125, 0.0250, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6428849697113037 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0024, 0.0158, 0.0134, 0.0252, 0.0039, 0.0026]) \n",
      "Test Loss tensor([0.0277, 0.0027, 0.0152, 0.0124, 0.0244, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6315324306488037 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0033, 0.0153, 0.0121, 0.0256, 0.0065, 0.0041]) \n",
      "Test Loss tensor([0.0272, 0.0024, 0.0150, 0.0125, 0.0245, 0.0050, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.615424394607544 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0026, 0.0172, 0.0116, 0.0255, 0.0051, 0.0023]) \n",
      "Test Loss tensor([0.0280, 0.0027, 0.0150, 0.0124, 0.0247, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6177716255187988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0021, 0.0150, 0.0119, 0.0234, 0.0056, 0.0038]) \n",
      "Test Loss tensor([0.0277, 0.0028, 0.0149, 0.0122, 0.0237, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6347723007202148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0024, 0.0158, 0.0116, 0.0241, 0.0063, 0.0033]) \n",
      "Test Loss tensor([0.0279, 0.0027, 0.0151, 0.0119, 0.0232, 0.0048, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.610426664352417 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0023, 0.0157, 0.0143, 0.0248, 0.0046, 0.0030]) \n",
      "Test Loss tensor([0.0282, 0.0027, 0.0152, 0.0124, 0.0244, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6112685203552246 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0310, 0.0025, 0.0144, 0.0123, 0.0240, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0280, 0.0027, 0.0153, 0.0122, 0.0229, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6053555011749268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0028, 0.0154, 0.0114, 0.0220, 0.0045, 0.0042]) \n",
      "Test Loss tensor([0.0289, 0.0026, 0.0152, 0.0123, 0.0238, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.608569860458374 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0025, 0.0137, 0.0139, 0.0216, 0.0053, 0.0037]) \n",
      "Test Loss tensor([0.0287, 0.0028, 0.0150, 0.0124, 0.0245, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6037638187408447 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0023, 0.0147, 0.0110, 0.0221, 0.0047, 0.0039]) \n",
      "Test Loss tensor([0.0263, 0.0030, 0.0152, 0.0124, 0.0243, 0.0047, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6049675941467285 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0335, 0.0031, 0.0153, 0.0147, 0.0247, 0.0051, 0.0049]) \n",
      "Test Loss tensor([0.0277, 0.0028, 0.0154, 0.0118, 0.0236, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6127662658691406 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0018, 0.0158, 0.0129, 0.0249, 0.0055, 0.0030]) \n",
      "Test Loss tensor([0.0291, 0.0026, 0.0145, 0.0124, 0.0244, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5974977016448975 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0025, 0.0161, 0.0142, 0.0255, 0.0039, 0.0028]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0150, 0.0123, 0.0235, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5946016311645508 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0026, 0.0151, 0.0125, 0.0237, 0.0051, 0.0028]) \n",
      "Test Loss tensor([0.0267, 0.0025, 0.0150, 0.0125, 0.0240, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6000139713287354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0025, 0.0164, 0.0118, 0.0222, 0.0056, 0.0025]) \n",
      "Test Loss tensor([0.0286, 0.0026, 0.0153, 0.0126, 0.0232, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5997827053070068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0018, 0.0136, 0.0123, 0.0257, 0.0051, 0.0025]) \n",
      "Test Loss tensor([0.0296, 0.0025, 0.0153, 0.0124, 0.0242, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7213389873504639 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0022, 0.0151, 0.0125, 0.0226, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0288, 0.0025, 0.0148, 0.0122, 0.0238, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5904390811920166 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0304, 0.0027, 0.0158, 0.0124, 0.0250, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0278, 0.0025, 0.0154, 0.0123, 0.0237, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6244215965270996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0028, 0.0138, 0.0120, 0.0236, 0.0047, 0.0034]) \n",
      "Test Loss tensor([0.0287, 0.0025, 0.0152, 0.0128, 0.0239, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5921947956085205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0035, 0.0137, 0.0105, 0.0254, 0.0051, 0.0046]) \n",
      "Test Loss tensor([0.0278, 0.0026, 0.0152, 0.0127, 0.0239, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5894861221313477 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0030, 0.0161, 0.0117, 0.0246, 0.0054, 0.0037]) \n",
      "Test Loss tensor([0.0274, 0.0027, 0.0150, 0.0123, 0.0236, 0.0051, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.5942866802215576 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0031, 0.0158, 0.0124, 0.0248, 0.0047, 0.0032]) \n",
      "Test Loss tensor([0.0271, 0.0027, 0.0153, 0.0118, 0.0226, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5923197269439697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0028, 0.0179, 0.0131, 0.0250, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0284, 0.0027, 0.0151, 0.0122, 0.0226, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5908021926879883 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0023, 0.0140, 0.0127, 0.0221, 0.0054, 0.0039]) \n",
      "Test Loss tensor([0.0277, 0.0027, 0.0152, 0.0123, 0.0240, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6045713424682617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0027, 0.0153, 0.0127, 0.0238, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0285, 0.0025, 0.0149, 0.0122, 0.0245, 0.0051, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5945005416870117 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0032, 0.0159, 0.0116, 0.0253, 0.0051, 0.0039]) \n",
      "Test Loss tensor([0.0277, 0.0025, 0.0148, 0.0125, 0.0234, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5926105976104736 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0023, 0.0146, 0.0123, 0.0259, 0.0039, 0.0038]) \n",
      "Test Loss tensor([0.0281, 0.0026, 0.0149, 0.0118, 0.0235, 0.0048, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 192 in 0.5927293300628662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0026, 0.0149, 0.0132, 0.0218, 0.0037, 0.0032]) \n",
      "Test Loss tensor([0.0274, 0.0028, 0.0154, 0.0122, 0.0236, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5973153114318848 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0028, 0.0150, 0.0122, 0.0243, 0.0060, 0.0049]) \n",
      "Test Loss tensor([0.0291, 0.0027, 0.0153, 0.0125, 0.0234, 0.0050, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5943715572357178 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0023, 0.0164, 0.0136, 0.0285, 0.0056, 0.0035]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0155, 0.0125, 0.0230, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5914211273193359 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0028, 0.0141, 0.0133, 0.0211, 0.0054, 0.0038]) \n",
      "Test Loss tensor([0.0276, 0.0025, 0.0152, 0.0125, 0.0238, 0.0047, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5933740139007568 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0024, 0.0163, 0.0133, 0.0219, 0.0047, 0.0032]) \n",
      "Test Loss tensor([0.0286, 0.0025, 0.0150, 0.0120, 0.0244, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5924205780029297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0030, 0.0153, 0.0129, 0.0215, 0.0049, 0.0028]) \n",
      "Test Loss tensor([0.0279, 0.0031, 0.0144, 0.0122, 0.0236, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5961086750030518 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0025, 0.0151, 0.0118, 0.0251, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0285, 0.0026, 0.0147, 0.0122, 0.0232, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5965442657470703 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0301, 0.0018, 0.0147, 0.0110, 0.0226, 0.0054, 0.0030]) \n",
      "Test Loss tensor([0.0287, 0.0026, 0.0146, 0.0119, 0.0231, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5943551063537598 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0318, 0.0019, 0.0150, 0.0112, 0.0251, 0.0045, 0.0034]) \n",
      "Test Loss tensor([0.0283, 0.0025, 0.0148, 0.0126, 0.0239, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.67582106590271 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0028, 0.0144, 0.0129, 0.0214, 0.0059, 0.0045]) \n",
      "Test Loss tensor([0.0276, 0.0028, 0.0147, 0.0124, 0.0237, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6316146850585938 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0018, 0.0154, 0.0125, 0.0212, 0.0046, 0.0031]) \n",
      "Test Loss tensor([0.0272, 0.0027, 0.0151, 0.0121, 0.0229, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6539547443389893 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0024, 0.0145, 0.0119, 0.0217, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0274, 0.0027, 0.0148, 0.0122, 0.0235, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6162073612213135 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0023, 0.0159, 0.0116, 0.0271, 0.0057, 0.0041]) \n",
      "Test Loss tensor([0.0281, 0.0027, 0.0148, 0.0121, 0.0231, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6074132919311523 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0026, 0.0151, 0.0126, 0.0261, 0.0057, 0.0039]) \n",
      "Test Loss tensor([0.0273, 0.0026, 0.0155, 0.0122, 0.0237, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7794022560119629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0027, 0.0159, 0.0115, 0.0230, 0.0053, 0.0028]) \n",
      "Test Loss tensor([0.0282, 0.0024, 0.0147, 0.0122, 0.0234, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7772266864776611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0023, 0.0169, 0.0123, 0.0222, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0154, 0.0127, 0.0238, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7079918384552002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0314, 0.0022, 0.0137, 0.0128, 0.0234, 0.0046, 0.0030]) \n",
      "Test Loss tensor([0.0282, 0.0025, 0.0151, 0.0122, 0.0242, 0.0049, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7469949722290039 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0025, 0.0165, 0.0124, 0.0199, 0.0049, 0.0031]) \n",
      "Test Loss tensor([0.0272, 0.0024, 0.0154, 0.0121, 0.0243, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.7312297821044922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0021, 0.0144, 0.0113, 0.0255, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0151, 0.0122, 0.0234, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.7511956691741943 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0018, 0.0169, 0.0115, 0.0229, 0.0047, 0.0040]) \n",
      "Test Loss tensor([0.0282, 0.0025, 0.0147, 0.0121, 0.0231, 0.0049, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6482479572296143 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0328, 0.0027, 0.0138, 0.0125, 0.0243, 0.0047, 0.0035]) \n",
      "Test Loss tensor([0.0274, 0.0028, 0.0152, 0.0124, 0.0242, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.655322790145874 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0029, 0.0172, 0.0122, 0.0247, 0.0053, 0.0036]) \n",
      "Test Loss tensor([0.0278, 0.0027, 0.0146, 0.0122, 0.0234, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6927061080932617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0021, 0.0166, 0.0127, 0.0209, 0.0044, 0.0033]) \n",
      "Test Loss tensor([0.0275, 0.0027, 0.0154, 0.0126, 0.0256, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6355493068695068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0031, 0.0146, 0.0119, 0.0246, 0.0051, 0.0028]) \n",
      "Test Loss tensor([0.0274, 0.0025, 0.0149, 0.0125, 0.0236, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6307690143585205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0021, 0.0155, 0.0127, 0.0264, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0291, 0.0025, 0.0152, 0.0122, 0.0255, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6572694778442383 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0355, 0.0020, 0.0156, 0.0131, 0.0238, 0.0049, 0.0041]) \n",
      "Test Loss tensor([0.0277, 0.0026, 0.0152, 0.0123, 0.0248, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6596775054931641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0346, 0.0030, 0.0181, 0.0123, 0.0248, 0.0044, 0.0050]) \n",
      "Test Loss tensor([0.0273, 0.0027, 0.0151, 0.0122, 0.0238, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6395246982574463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0022, 0.0140, 0.0121, 0.0226, 0.0057, 0.0028]) \n",
      "Test Loss tensor([0.0284, 0.0025, 0.0148, 0.0123, 0.0246, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.63627028465271 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0023, 0.0139, 0.0139, 0.0277, 0.0052, 0.0042]) \n",
      "Test Loss tensor([0.0262, 0.0026, 0.0145, 0.0124, 0.0231, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.651447057723999 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0026, 0.0139, 0.0115, 0.0260, 0.0046, 0.0035]) \n",
      "Test Loss tensor([0.0280, 0.0029, 0.0146, 0.0121, 0.0223, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6652536392211914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0028, 0.0133, 0.0128, 0.0232, 0.0050, 0.0025]) \n",
      "Test Loss tensor([0.0271, 0.0028, 0.0148, 0.0122, 0.0239, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7107200622558594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0018, 0.0141, 0.0121, 0.0217, 0.0042, 0.0038]) \n",
      "Test Loss tensor([0.0283, 0.0026, 0.0153, 0.0125, 0.0243, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6834609508514404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0023, 0.0147, 0.0117, 0.0241, 0.0051, 0.0029]) \n",
      "Test Loss tensor([0.0272, 0.0028, 0.0150, 0.0123, 0.0237, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6797616481781006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0027, 0.0152, 0.0112, 0.0227, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0271, 0.0028, 0.0154, 0.0122, 0.0237, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6432132720947266 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0023, 0.0130, 0.0120, 0.0250, 0.0037, 0.0038]) \n",
      "Test Loss tensor([0.0275, 0.0026, 0.0152, 0.0121, 0.0231, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.628821611404419 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0037, 0.0162, 0.0121, 0.0254, 0.0044, 0.0036]) \n",
      "Test Loss tensor([0.0269, 0.0027, 0.0151, 0.0123, 0.0238, 0.0048, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 336 in 0.7470095157623291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0020, 0.0154, 0.0127, 0.0219, 0.0035, 0.0030]) \n",
      "Test Loss tensor([0.0276, 0.0023, 0.0144, 0.0122, 0.0237, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6477489471435547 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0023, 0.0131, 0.0132, 0.0208, 0.0049, 0.0041]) \n",
      "Test Loss tensor([0.0283, 0.0027, 0.0152, 0.0125, 0.0238, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6755192279815674 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0025, 0.0157, 0.0127, 0.0217, 0.0053, 0.0030]) \n",
      "Test Loss tensor([0.0273, 0.0025, 0.0149, 0.0122, 0.0234, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6624877452850342 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0025, 0.0162, 0.0123, 0.0209, 0.0043, 0.0026]) \n",
      "Test Loss tensor([0.0276, 0.0026, 0.0146, 0.0121, 0.0236, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.647479772567749 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0022, 0.0156, 0.0121, 0.0272, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0279, 0.0026, 0.0142, 0.0122, 0.0231, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.664010763168335 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0030, 0.0149, 0.0132, 0.0232, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0274, 0.0028, 0.0145, 0.0121, 0.0230, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.615515947341919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0028, 0.0146, 0.0118, 0.0234, 0.0057, 0.0036]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0149, 0.0119, 0.0232, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6373462677001953 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0031, 0.0143, 0.0115, 0.0226, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0285, 0.0027, 0.0144, 0.0125, 0.0236, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6596322059631348 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0021, 0.0128, 0.0129, 0.0222, 0.0046, 0.0030]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0156, 0.0123, 0.0231, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.661823034286499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0020, 0.0153, 0.0121, 0.0234, 0.0053, 0.0038]) \n",
      "Test Loss tensor([0.0276, 0.0026, 0.0152, 0.0122, 0.0240, 0.0048, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6461009979248047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0024, 0.0167, 0.0120, 0.0195, 0.0048, 0.0033]) \n",
      "Test Loss tensor([0.0276, 0.0024, 0.0149, 0.0124, 0.0242, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6357455253601074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0023, 0.0160, 0.0107, 0.0215, 0.0061, 0.0036]) \n",
      "Test Loss tensor([0.0277, 0.0024, 0.0144, 0.0122, 0.0237, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.600266695022583 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0022, 0.0166, 0.0124, 0.0236, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0269, 0.0028, 0.0157, 0.0126, 0.0228, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6074230670928955 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0029, 0.0145, 0.0132, 0.0230, 0.0044, 0.0034]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0150, 0.0124, 0.0235, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6261498928070068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0028, 0.0160, 0.0113, 0.0220, 0.0041, 0.0029]) \n",
      "Test Loss tensor([0.0276, 0.0027, 0.0147, 0.0123, 0.0233, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6607258319854736 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0026, 0.0158, 0.0122, 0.0244, 0.0038, 0.0042]) \n",
      "Test Loss tensor([0.0268, 0.0029, 0.0146, 0.0123, 0.0228, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.7066738605499268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0313, 0.0028, 0.0139, 0.0115, 0.0261, 0.0056, 0.0043]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0152, 0.0127, 0.0247, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6593904495239258 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0030, 0.0156, 0.0126, 0.0222, 0.0044, 0.0034]) \n",
      "Test Loss tensor([0.0285, 0.0027, 0.0148, 0.0126, 0.0236, 0.0048, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6408853530883789 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0032, 0.0150, 0.0127, 0.0251, 0.0049, 0.0038]) \n",
      "Test Loss tensor([0.0284, 0.0024, 0.0145, 0.0120, 0.0234, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6565768718719482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0026, 0.0136, 0.0106, 0.0225, 0.0043, 0.0045]) \n",
      "Test Loss tensor([0.0265, 0.0027, 0.0150, 0.0124, 0.0229, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.616396427154541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0045, 0.0133, 0.0118, 0.0211, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0278, 0.0025, 0.0149, 0.0122, 0.0228, 0.0046, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6715240478515625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0019, 0.0153, 0.0123, 0.0219, 0.0037, 0.0031]) \n",
      "Test Loss tensor([0.0264, 0.0027, 0.0152, 0.0121, 0.0229, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6585483551025391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0018, 0.0135, 0.0124, 0.0202, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0278, 0.0026, 0.0148, 0.0123, 0.0233, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5965847969055176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0023, 0.0171, 0.0115, 0.0237, 0.0039, 0.0034]) \n",
      "Test Loss tensor([0.0279, 0.0024, 0.0143, 0.0123, 0.0233, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6345314979553223 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0028, 0.0175, 0.0116, 0.0231, 0.0033, 0.0038]) \n",
      "Test Loss tensor([0.0273, 0.0024, 0.0152, 0.0124, 0.0232, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6447992324829102 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0021, 0.0159, 0.0123, 0.0242, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0276, 0.0026, 0.0143, 0.0126, 0.0238, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6795775890350342 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0025, 0.0149, 0.0123, 0.0273, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0275, 0.0025, 0.0148, 0.0121, 0.0237, 0.0049, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.651249885559082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0029, 0.0133, 0.0118, 0.0238, 0.0065, 0.0036]) \n",
      "Test Loss tensor([0.0277, 0.0024, 0.0154, 0.0123, 0.0231, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.638308048248291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0019, 0.0139, 0.0132, 0.0217, 0.0035, 0.0030]) \n",
      "Test Loss tensor([0.0262, 0.0026, 0.0152, 0.0121, 0.0230, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6946592330932617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0023, 0.0146, 0.0123, 0.0228, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0278, 0.0028, 0.0143, 0.0124, 0.0226, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6905791759490967 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0025, 0.0133, 0.0114, 0.0243, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0271, 0.0026, 0.0149, 0.0125, 0.0227, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6819493770599365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0022, 0.0139, 0.0108, 0.0243, 0.0058, 0.0024]) \n",
      "Test Loss tensor([0.0270, 0.0028, 0.0146, 0.0121, 0.0228, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.640190601348877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0020, 0.0136, 0.0100, 0.0229, 0.0056, 0.0029]) \n",
      "Test Loss tensor([0.0276, 0.0025, 0.0143, 0.0121, 0.0229, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6450378894805908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0030, 0.0139, 0.0118, 0.0240, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0272, 0.0025, 0.0146, 0.0120, 0.0232, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7722873687744141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0030, 0.0137, 0.0105, 0.0204, 0.0038, 0.0037]) \n",
      "Test Loss tensor([0.0262, 0.0025, 0.0148, 0.0126, 0.0227, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.7171485424041748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0022, 0.0168, 0.0110, 0.0226, 0.0036, 0.0036]) \n",
      "Test Loss tensor([0.0282, 0.0025, 0.0146, 0.0126, 0.0229, 0.0049, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 480 in 0.627805233001709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0021, 0.0134, 0.0116, 0.0240, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0281, 0.0027, 0.0148, 0.0122, 0.0227, 0.0048, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.631309986114502 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0020, 0.0149, 0.0123, 0.0245, 0.0066, 0.0045]) \n",
      "Test Loss tensor([0.0267, 0.0026, 0.0146, 0.0120, 0.0235, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.734576940536499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0030, 0.0161, 0.0120, 0.0214, 0.0040, 0.0035]) \n",
      "Test Loss tensor([0.0262, 0.0024, 0.0145, 0.0122, 0.0228, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6862678527832031 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0026, 0.0160, 0.0130, 0.0246, 0.0054, 0.0036]) \n",
      "Test Loss tensor([0.0265, 0.0025, 0.0150, 0.0123, 0.0241, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7674834728240967 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0025, 0.0128, 0.0128, 0.0211, 0.0055, 0.0031]) \n",
      "Test Loss tensor([0.0263, 0.0026, 0.0148, 0.0122, 0.0234, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.7422971725463867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0303, 0.0029, 0.0154, 0.0115, 0.0259, 0.0053, 0.0026]) \n",
      "Test Loss tensor([0.0267, 0.0026, 0.0145, 0.0126, 0.0226, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7173845767974854 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0028, 0.0151, 0.0123, 0.0245, 0.0042, 0.0035]) \n",
      "Test Loss tensor([0.0267, 0.0025, 0.0149, 0.0122, 0.0229, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6972334384918213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0030, 0.0129, 0.0125, 0.0250, 0.0044, 0.0026]) \n",
      "Test Loss tensor([0.0270, 0.0024, 0.0145, 0.0121, 0.0225, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.7596755027770996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0027, 0.0166, 0.0138, 0.0225, 0.0037, 0.0026]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0146, 0.0119, 0.0225, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6657226085662842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0029, 0.0148, 0.0127, 0.0216, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0272, 0.0024, 0.0147, 0.0119, 0.0231, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6453821659088135 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0033, 0.0149, 0.0125, 0.0263, 0.0046, 0.0036]) \n",
      "Test Loss tensor([0.0268, 0.0026, 0.0149, 0.0125, 0.0225, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.648888349533081 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0322, 0.0023, 0.0149, 0.0127, 0.0245, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0278, 0.0025, 0.0149, 0.0120, 0.0223, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6558761596679688 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0316, 0.0020, 0.0162, 0.0119, 0.0198, 0.0047, 0.0039]) \n",
      "Test Loss tensor([0.0271, 0.0024, 0.0149, 0.0123, 0.0234, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6930439472198486 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0026, 0.0155, 0.0131, 0.0249, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0275, 0.0024, 0.0152, 0.0119, 0.0227, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6162688732147217 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0021, 0.0166, 0.0119, 0.0224, 0.0038, 0.0038]) \n",
      "Test Loss tensor([0.0260, 0.0022, 0.0150, 0.0122, 0.0232, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6497981548309326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0023, 0.0150, 0.0117, 0.0225, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0152, 0.0123, 0.0226, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.7439613342285156 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0024, 0.0164, 0.0113, 0.0225, 0.0037, 0.0039]) \n",
      "Test Loss tensor([0.0275, 0.0026, 0.0146, 0.0126, 0.0234, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.8071386814117432 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0028, 0.0153, 0.0123, 0.0196, 0.0034, 0.0035]) \n",
      "Test Loss tensor([0.0278, 0.0027, 0.0144, 0.0124, 0.0236, 0.0050, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.649651050567627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0023, 0.0131, 0.0128, 0.0219, 0.0053, 0.0036]) \n",
      "Test Loss tensor([0.0267, 0.0025, 0.0145, 0.0122, 0.0233, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6746933460235596 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0027, 0.0145, 0.0123, 0.0207, 0.0040, 0.0031]) \n",
      "Test Loss tensor([0.0269, 0.0027, 0.0149, 0.0122, 0.0235, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.7704160213470459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0025, 0.0120, 0.0119, 0.0267, 0.0038, 0.0033]) \n",
      "Test Loss tensor([0.0267, 0.0026, 0.0150, 0.0120, 0.0226, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6831696033477783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0021, 0.0149, 0.0123, 0.0254, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0148, 0.0124, 0.0226, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6923618316650391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0039, 0.0138, 0.0138, 0.0226, 0.0039, 0.0025]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0149, 0.0122, 0.0231, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6503291130065918 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0021, 0.0161, 0.0134, 0.0248, 0.0056, 0.0026]) \n",
      "Test Loss tensor([0.0277, 0.0024, 0.0145, 0.0123, 0.0232, 0.0045, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.643296480178833 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0018, 0.0168, 0.0136, 0.0227, 0.0037, 0.0026]) \n",
      "Test Loss tensor([0.0264, 0.0025, 0.0141, 0.0126, 0.0230, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.644942045211792 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0020, 0.0167, 0.0124, 0.0203, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0145, 0.0123, 0.0233, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6873123645782471 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0025, 0.0140, 0.0123, 0.0251, 0.0042, 0.0035]) \n",
      "Test Loss tensor([0.0266, 0.0028, 0.0146, 0.0119, 0.0239, 0.0045, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.7357912063598633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0022, 0.0150, 0.0119, 0.0238, 0.0041, 0.0035]) \n",
      "Test Loss tensor([0.0266, 0.0026, 0.0149, 0.0121, 0.0237, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.652785062789917 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0021, 0.0127, 0.0131, 0.0260, 0.0044, 0.0035]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0147, 0.0122, 0.0222, 0.0043, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6159427165985107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0021, 0.0172, 0.0118, 0.0218, 0.0040, 0.0045]) \n",
      "Test Loss tensor([0.0266, 0.0024, 0.0150, 0.0123, 0.0229, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6661813259124756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0020, 0.0158, 0.0128, 0.0232, 0.0032, 0.0042]) \n",
      "Test Loss tensor([0.0267, 0.0023, 0.0145, 0.0120, 0.0234, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7868049144744873 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0021, 0.0146, 0.0129, 0.0234, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0277, 0.0025, 0.0150, 0.0123, 0.0232, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.7595336437225342 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0024, 0.0129, 0.0122, 0.0242, 0.0046, 0.0041]) \n",
      "Test Loss tensor([0.0261, 0.0027, 0.0151, 0.0123, 0.0236, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.7399101257324219 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0027, 0.0150, 0.0129, 0.0233, 0.0053, 0.0026]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0148, 0.0124, 0.0228, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.677156925201416 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0018, 0.0148, 0.0125, 0.0241, 0.0059, 0.0035]) \n",
      "Test Loss tensor([0.0270, 0.0024, 0.0153, 0.0123, 0.0229, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6184062957763672 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0022, 0.0156, 0.0123, 0.0230, 0.0037, 0.0038]) \n",
      "Test Loss tensor([0.0270, 0.0025, 0.0148, 0.0123, 0.0234, 0.0045, 0.0036])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 624 in 0.6287481784820557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0024, 0.0149, 0.0129, 0.0265, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0277, 0.0027, 0.0147, 0.0123, 0.0229, 0.0049, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6576998233795166 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0019, 0.0140, 0.0126, 0.0251, 0.0041, 0.0031]) \n",
      "Test Loss tensor([0.0277, 0.0023, 0.0144, 0.0119, 0.0232, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6208810806274414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0287, 0.0028, 0.0151, 0.0124, 0.0253, 0.0040, 0.0032]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0144, 0.0125, 0.0236, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6285419464111328 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0030, 0.0134, 0.0114, 0.0237, 0.0045, 0.0033]) \n",
      "Test Loss tensor([0.0280, 0.0026, 0.0144, 0.0127, 0.0248, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6663544178009033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0027, 0.0155, 0.0132, 0.0261, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0276, 0.0025, 0.0150, 0.0122, 0.0226, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6818170547485352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0028, 0.0156, 0.0125, 0.0244, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0275, 0.0026, 0.0146, 0.0121, 0.0239, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6292903423309326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0019, 0.0126, 0.0118, 0.0239, 0.0043, 0.0039]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0142, 0.0121, 0.0232, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6310181617736816 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0025, 0.0163, 0.0138, 0.0249, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0263, 0.0025, 0.0146, 0.0121, 0.0233, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.7190170288085938 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0034, 0.0156, 0.0121, 0.0253, 0.0035, 0.0036]) \n",
      "Test Loss tensor([0.0268, 0.0026, 0.0147, 0.0120, 0.0236, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6529345512390137 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0024, 0.0161, 0.0136, 0.0251, 0.0052, 0.0034]) \n",
      "Test Loss tensor([0.0269, 0.0026, 0.0155, 0.0123, 0.0227, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6400148868560791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0027, 0.0155, 0.0125, 0.0218, 0.0053, 0.0031]) \n",
      "Test Loss tensor([0.0271, 0.0026, 0.0148, 0.0121, 0.0230, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6279716491699219 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0023, 0.0155, 0.0121, 0.0222, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0271, 0.0025, 0.0149, 0.0121, 0.0229, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6419155597686768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0030, 0.0141, 0.0118, 0.0253, 0.0035, 0.0040]) \n",
      "Test Loss tensor([0.0263, 0.0026, 0.0148, 0.0121, 0.0230, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6267738342285156 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0028, 0.0131, 0.0117, 0.0226, 0.0037, 0.0030]) \n",
      "Test Loss tensor([0.0275, 0.0026, 0.0147, 0.0121, 0.0225, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.618887186050415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0033, 0.0150, 0.0114, 0.0226, 0.0050, 0.0037]) \n",
      "Test Loss tensor([0.0268, 0.0026, 0.0146, 0.0121, 0.0228, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6264674663543701 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0021, 0.0143, 0.0128, 0.0229, 0.0042, 0.0028]) \n",
      "Test Loss tensor([0.0256, 0.0026, 0.0149, 0.0121, 0.0229, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.619124174118042 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0022, 0.0143, 0.0123, 0.0213, 0.0046, 0.0039]) \n",
      "Test Loss tensor([0.0269, 0.0024, 0.0147, 0.0123, 0.0233, 0.0050, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6376466751098633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0029, 0.0173, 0.0132, 0.0213, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0269, 0.0026, 0.0142, 0.0119, 0.0221, 0.0050, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6274785995483398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0021, 0.0133, 0.0117, 0.0230, 0.0045, 0.0029]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0151, 0.0122, 0.0226, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6354875564575195 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0019, 0.0139, 0.0114, 0.0243, 0.0052, 0.0041]) \n",
      "Test Loss tensor([0.0268, 0.0025, 0.0144, 0.0120, 0.0227, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.7711913585662842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0018, 0.0140, 0.0126, 0.0222, 0.0046, 0.0029]) \n",
      "Test Loss tensor([0.0261, 0.0027, 0.0144, 0.0121, 0.0224, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6178584098815918 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0027, 0.0152, 0.0117, 0.0226, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0274, 0.0025, 0.0146, 0.0120, 0.0229, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.7070407867431641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0020, 0.0155, 0.0124, 0.0219, 0.0041, 0.0029]) \n",
      "Test Loss tensor([0.0262, 0.0024, 0.0144, 0.0123, 0.0229, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6352365016937256 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0027, 0.0167, 0.0129, 0.0195, 0.0052, 0.0049]) \n",
      "Test Loss tensor([0.0266, 0.0026, 0.0147, 0.0123, 0.0222, 0.0045, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6610844135284424 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0022, 0.0138, 0.0126, 0.0211, 0.0040, 0.0038]) \n",
      "Test Loss tensor([0.0270, 0.0027, 0.0147, 0.0121, 0.0221, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6233494281768799 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0025, 0.0125, 0.0116, 0.0228, 0.0040, 0.0036]) \n",
      "Test Loss tensor([0.0257, 0.0026, 0.0145, 0.0117, 0.0227, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6387064456939697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0287, 0.0034, 0.0161, 0.0119, 0.0225, 0.0058, 0.0045]) \n",
      "Test Loss tensor([0.0259, 0.0027, 0.0142, 0.0121, 0.0223, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6787142753601074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0026, 0.0157, 0.0117, 0.0212, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0265, 0.0025, 0.0141, 0.0122, 0.0224, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6966872215270996 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0023, 0.0157, 0.0131, 0.0211, 0.0054, 0.0038]) \n",
      "Test Loss tensor([0.0271, 0.0025, 0.0145, 0.0117, 0.0221, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6243829727172852 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0033, 0.0165, 0.0118, 0.0248, 0.0049, 0.0031]) \n",
      "Test Loss tensor([0.0268, 0.0027, 0.0148, 0.0122, 0.0224, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6577243804931641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0028, 0.0138, 0.0115, 0.0232, 0.0058, 0.0035]) \n",
      "Test Loss tensor([0.0268, 0.0028, 0.0155, 0.0120, 0.0220, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6367530822753906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0027, 0.0135, 0.0116, 0.0223, 0.0032, 0.0034]) \n",
      "Test Loss tensor([0.0275, 0.0027, 0.0148, 0.0123, 0.0219, 0.0050, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6580343246459961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0021, 0.0143, 0.0114, 0.0199, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0272, 0.0026, 0.0140, 0.0122, 0.0226, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6382994651794434 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0019, 0.0136, 0.0127, 0.0225, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0265, 0.0027, 0.0149, 0.0122, 0.0221, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6314847469329834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0023, 0.0161, 0.0112, 0.0216, 0.0044, 0.0034]) \n",
      "Test Loss tensor([0.0270, 0.0027, 0.0146, 0.0124, 0.0227, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7670791149139404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0022, 0.0162, 0.0129, 0.0250, 0.0044, 0.0035]) \n",
      "Test Loss tensor([0.0263, 0.0024, 0.0145, 0.0121, 0.0233, 0.0047, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 768 in 0.7798364162445068 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0305, 0.0022, 0.0171, 0.0121, 0.0228, 0.0055, 0.0035]) \n",
      "Test Loss tensor([0.0277, 0.0026, 0.0146, 0.0120, 0.0225, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6422762870788574 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0023, 0.0171, 0.0138, 0.0242, 0.0046, 0.0035]) \n",
      "Test Loss tensor([0.0270, 0.0024, 0.0146, 0.0121, 0.0225, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.721874475479126 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0023, 0.0162, 0.0121, 0.0237, 0.0041, 0.0036]) \n",
      "Test Loss tensor([0.0264, 0.0024, 0.0145, 0.0120, 0.0235, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.8225095272064209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0017, 0.0151, 0.0123, 0.0237, 0.0040, 0.0039]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0149, 0.0126, 0.0221, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6280550956726074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0030, 0.0140, 0.0134, 0.0232, 0.0059, 0.0042]) \n",
      "Test Loss tensor([0.0271, 0.0025, 0.0141, 0.0121, 0.0232, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.723229169845581 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0030, 0.0155, 0.0117, 0.0226, 0.0043, 0.0036]) \n",
      "Test Loss tensor([0.0278, 0.0028, 0.0149, 0.0125, 0.0219, 0.0048, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.7593419551849365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0026, 0.0136, 0.0123, 0.0219, 0.0048, 0.0044]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0147, 0.0124, 0.0224, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.649925947189331 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0036, 0.0153, 0.0123, 0.0224, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0266, 0.0027, 0.0149, 0.0121, 0.0242, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.630333662033081 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0021, 0.0141, 0.0119, 0.0258, 0.0040, 0.0030]) \n",
      "Test Loss tensor([0.0267, 0.0028, 0.0146, 0.0122, 0.0224, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6240067481994629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0025, 0.0157, 0.0102, 0.0203, 0.0044, 0.0028]) \n",
      "Test Loss tensor([0.0259, 0.0024, 0.0150, 0.0124, 0.0229, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7022333145141602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0021, 0.0148, 0.0125, 0.0238, 0.0043, 0.0027]) \n",
      "Test Loss tensor([0.0260, 0.0025, 0.0142, 0.0123, 0.0233, 0.0050, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6722404956817627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0020, 0.0136, 0.0123, 0.0267, 0.0034, 0.0040]) \n",
      "Test Loss tensor([0.0269, 0.0024, 0.0141, 0.0124, 0.0237, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.7847115993499756 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0029, 0.0159, 0.0111, 0.0235, 0.0050, 0.0031]) \n",
      "Test Loss tensor([0.0261, 0.0027, 0.0143, 0.0116, 0.0224, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7586276531219482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0022, 0.0167, 0.0125, 0.0257, 0.0052, 0.0036]) \n",
      "Test Loss tensor([0.0264, 0.0024, 0.0149, 0.0125, 0.0234, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.7230305671691895 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0287, 0.0019, 0.0150, 0.0125, 0.0231, 0.0049, 0.0040]) \n",
      "Test Loss tensor([0.0262, 0.0029, 0.0144, 0.0118, 0.0234, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.7222316265106201 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0296, 0.0035, 0.0142, 0.0129, 0.0225, 0.0047, 0.0026]) \n",
      "Test Loss tensor([0.0267, 0.0024, 0.0143, 0.0120, 0.0232, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7095644474029541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0024, 0.0144, 0.0125, 0.0272, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0276, 0.0023, 0.0145, 0.0124, 0.0238, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6449024677276611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0028, 0.0156, 0.0111, 0.0228, 0.0041, 0.0033]) \n",
      "Test Loss tensor([0.0268, 0.0026, 0.0143, 0.0122, 0.0222, 0.0043, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6512854099273682 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0023, 0.0163, 0.0136, 0.0221, 0.0040, 0.0030]) \n",
      "Test Loss tensor([0.0267, 0.0025, 0.0148, 0.0124, 0.0233, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6293253898620605 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0023, 0.0133, 0.0123, 0.0237, 0.0039, 0.0025]) \n",
      "Test Loss tensor([0.0263, 0.0026, 0.0145, 0.0120, 0.0241, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6138064861297607 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0022, 0.0152, 0.0110, 0.0252, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0268, 0.0025, 0.0142, 0.0120, 0.0240, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6357369422912598 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0302, 0.0022, 0.0149, 0.0117, 0.0231, 0.0045, 0.0037]) \n",
      "Test Loss tensor([0.0269, 0.0028, 0.0147, 0.0123, 0.0237, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.7961301803588867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0315, 0.0035, 0.0128, 0.0122, 0.0250, 0.0032, 0.0043]) \n",
      "Test Loss tensor([0.0262, 0.0025, 0.0146, 0.0121, 0.0227, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.594407320022583 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0019, 0.0133, 0.0109, 0.0233, 0.0049, 0.0039]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0145, 0.0120, 0.0239, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.5777745246887207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0031, 0.0147, 0.0112, 0.0262, 0.0040, 0.0033]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0146, 0.0122, 0.0237, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6129486560821533 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0019, 0.0130, 0.0122, 0.0230, 0.0052, 0.0025]) \n",
      "Test Loss tensor([0.0269, 0.0026, 0.0140, 0.0122, 0.0230, 0.0049, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5750527381896973 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0026, 0.0145, 0.0117, 0.0253, 0.0039, 0.0028]) \n",
      "Test Loss tensor([0.0264, 0.0025, 0.0147, 0.0121, 0.0239, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.56050705909729 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0196, 0.0016, 0.0110, 0.0082, 0.0175, 0.0034, 0.0025]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0149, 0.0121, 0.0227, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6056127548217773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0308, 0.0027, 0.0145, 0.0137, 0.0247, 0.0052, 0.0045]) \n",
      "Test Loss tensor([0.0270, 0.0028, 0.0152, 0.0123, 0.0253, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.5721511840820312 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0021, 0.0157, 0.0111, 0.0254, 0.0045, 0.0030]) \n",
      "Test Loss tensor([0.0262, 0.0026, 0.0145, 0.0120, 0.0226, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5759055614471436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0031, 0.0137, 0.0117, 0.0237, 0.0040, 0.0037]) \n",
      "Test Loss tensor([0.0266, 0.0024, 0.0147, 0.0121, 0.0258, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5869960784912109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0025, 0.0134, 0.0133, 0.0290, 0.0043, 0.0026]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0140, 0.0122, 0.0229, 0.0048, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5840957164764404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0027, 0.0126, 0.0125, 0.0233, 0.0036, 0.0036]) \n",
      "Test Loss tensor([0.0271, 0.0026, 0.0144, 0.0122, 0.0250, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5901401042938232 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0023, 0.0164, 0.0131, 0.0246, 0.0041, 0.0027]) \n",
      "Test Loss tensor([0.0257, 0.0026, 0.0141, 0.0123, 0.0236, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6078791618347168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0018, 0.0141, 0.0120, 0.0232, 0.0043, 0.0031]) \n",
      "Test Loss tensor([0.0261, 0.0025, 0.0148, 0.0125, 0.0233, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5966217517852783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0024, 0.0150, 0.0135, 0.0249, 0.0036, 0.0030]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0147, 0.0123, 0.0233, 0.0047, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 32 in 0.6018209457397461 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0028, 0.0128, 0.0117, 0.0227, 0.0060, 0.0038]) \n",
      "Test Loss tensor([0.0260, 0.0026, 0.0143, 0.0117, 0.0217, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5910804271697998 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0300, 0.0025, 0.0163, 0.0130, 0.0227, 0.0054, 0.0031]) \n",
      "Test Loss tensor([0.0270, 0.0025, 0.0140, 0.0125, 0.0239, 0.0047, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5899825096130371 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0023, 0.0145, 0.0127, 0.0247, 0.0048, 0.0033]) \n",
      "Test Loss tensor([0.0270, 0.0025, 0.0144, 0.0119, 0.0220, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5839240550994873 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0021, 0.0161, 0.0129, 0.0230, 0.0051, 0.0038]) \n",
      "Test Loss tensor([0.0270, 0.0027, 0.0146, 0.0124, 0.0245, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.5853631496429443 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0020, 0.0160, 0.0113, 0.0239, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0268, 0.0027, 0.0146, 0.0122, 0.0223, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5910894870758057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0020, 0.0154, 0.0126, 0.0232, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0263, 0.0026, 0.0143, 0.0122, 0.0222, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5850334167480469 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0031, 0.0161, 0.0122, 0.0216, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0250, 0.0026, 0.0149, 0.0119, 0.0223, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5865850448608398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0027, 0.0111, 0.0118, 0.0241, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0262, 0.0025, 0.0149, 0.0119, 0.0212, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5807156562805176 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0025, 0.0140, 0.0121, 0.0212, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0262, 0.0025, 0.0146, 0.0121, 0.0234, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5790908336639404 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0022, 0.0135, 0.0122, 0.0229, 0.0047, 0.0039]) \n",
      "Test Loss tensor([0.0264, 0.0025, 0.0143, 0.0124, 0.0219, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5719432830810547 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0025, 0.0151, 0.0117, 0.0204, 0.0040, 0.0050]) \n",
      "Test Loss tensor([0.0267, 0.0026, 0.0144, 0.0122, 0.0232, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6016354560852051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0021, 0.0134, 0.0119, 0.0244, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0263, 0.0028, 0.0141, 0.0121, 0.0221, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6740903854370117 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0018, 0.0135, 0.0113, 0.0231, 0.0044, 0.0038]) \n",
      "Test Loss tensor([0.0282, 0.0025, 0.0144, 0.0124, 0.0235, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6038448810577393 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0022, 0.0161, 0.0126, 0.0202, 0.0039, 0.0031]) \n",
      "Test Loss tensor([0.0264, 0.0026, 0.0146, 0.0122, 0.0230, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5944602489471436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0022, 0.0133, 0.0111, 0.0211, 0.0037, 0.0034]) \n",
      "Test Loss tensor([0.0259, 0.0027, 0.0144, 0.0120, 0.0217, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5994324684143066 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0026, 0.0140, 0.0136, 0.0237, 0.0031, 0.0041]) \n",
      "Test Loss tensor([0.0271, 0.0024, 0.0143, 0.0122, 0.0228, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6159243583679199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0022, 0.0133, 0.0133, 0.0225, 0.0056, 0.0024]) \n",
      "Test Loss tensor([0.0265, 0.0027, 0.0145, 0.0122, 0.0222, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7794125080108643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0030, 0.0141, 0.0112, 0.0208, 0.0032, 0.0029]) \n",
      "Test Loss tensor([0.0260, 0.0027, 0.0146, 0.0122, 0.0222, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6268925666809082 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0020, 0.0143, 0.0116, 0.0223, 0.0050, 0.0042]) \n",
      "Test Loss tensor([0.0267, 0.0027, 0.0148, 0.0119, 0.0219, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6004416942596436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0022, 0.0141, 0.0114, 0.0235, 0.0051, 0.0024]) \n",
      "Test Loss tensor([0.0261, 0.0026, 0.0145, 0.0121, 0.0224, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6160073280334473 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0030, 0.0135, 0.0140, 0.0211, 0.0041, 0.0028]) \n",
      "Test Loss tensor([0.0261, 0.0026, 0.0142, 0.0124, 0.0226, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6075832843780518 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0031, 0.0150, 0.0129, 0.0219, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0274, 0.0028, 0.0143, 0.0118, 0.0218, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.591317892074585 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0020, 0.0123, 0.0119, 0.0241, 0.0046, 0.0046]) \n",
      "Test Loss tensor([0.0267, 0.0024, 0.0145, 0.0120, 0.0232, 0.0047, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5908944606781006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0022, 0.0135, 0.0116, 0.0238, 0.0038, 0.0030]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0144, 0.0119, 0.0224, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.588306188583374 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0028, 0.0142, 0.0120, 0.0206, 0.0031, 0.0029]) \n",
      "Test Loss tensor([0.0248, 0.0024, 0.0150, 0.0124, 0.0231, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5925736427307129 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0025, 0.0149, 0.0116, 0.0210, 0.0047, 0.0039]) \n",
      "Test Loss tensor([0.0263, 0.0024, 0.0142, 0.0122, 0.0221, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5889673233032227 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0298, 0.0042, 0.0145, 0.0113, 0.0242, 0.0051, 0.0027]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0143, 0.0120, 0.0223, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5872912406921387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0026, 0.0149, 0.0129, 0.0223, 0.0050, 0.0035]) \n",
      "Test Loss tensor([0.0260, 0.0025, 0.0142, 0.0122, 0.0212, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5851898193359375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0027, 0.0133, 0.0124, 0.0225, 0.0045, 0.0024]) \n",
      "Test Loss tensor([0.0265, 0.0025, 0.0143, 0.0123, 0.0221, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5829558372497559 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0019, 0.0135, 0.0130, 0.0211, 0.0034, 0.0038]) \n",
      "Test Loss tensor([0.0268, 0.0024, 0.0144, 0.0121, 0.0220, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5942122936248779 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0307, 0.0024, 0.0162, 0.0129, 0.0185, 0.0043, 0.0045]) \n",
      "Test Loss tensor([0.0255, 0.0026, 0.0141, 0.0121, 0.0222, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.610114336013794 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0022, 0.0130, 0.0123, 0.0208, 0.0036, 0.0049]) \n",
      "Test Loss tensor([0.0265, 0.0024, 0.0144, 0.0123, 0.0226, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6188101768493652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0025, 0.0136, 0.0121, 0.0230, 0.0048, 0.0037]) \n",
      "Test Loss tensor([0.0265, 0.0025, 0.0147, 0.0120, 0.0222, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5992119312286377 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0023, 0.0154, 0.0122, 0.0230, 0.0055, 0.0046]) \n",
      "Test Loss tensor([0.0269, 0.0022, 0.0144, 0.0122, 0.0215, 0.0043, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6038777828216553 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0024, 0.0155, 0.0131, 0.0212, 0.0034, 0.0027]) \n",
      "Test Loss tensor([0.0261, 0.0023, 0.0144, 0.0122, 0.0219, 0.0042, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5938246250152588 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0022, 0.0160, 0.0131, 0.0230, 0.0032, 0.0032]) \n",
      "Test Loss tensor([0.0269, 0.0025, 0.0142, 0.0118, 0.0218, 0.0045, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 176 in 0.6014220714569092 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0024, 0.0146, 0.0125, 0.0190, 0.0039, 0.0031]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0147, 0.0121, 0.0224, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5978567600250244 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0024, 0.0143, 0.0121, 0.0235, 0.0053, 0.0027]) \n",
      "Test Loss tensor([0.0272, 0.0024, 0.0146, 0.0120, 0.0227, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6007027626037598 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0022, 0.0133, 0.0122, 0.0243, 0.0052, 0.0043]) \n",
      "Test Loss tensor([0.0258, 0.0026, 0.0141, 0.0122, 0.0225, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6352028846740723 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0303, 0.0019, 0.0154, 0.0129, 0.0252, 0.0056, 0.0046]) \n",
      "Test Loss tensor([0.0260, 0.0029, 0.0147, 0.0120, 0.0217, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6159493923187256 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0022, 0.0144, 0.0111, 0.0227, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0138, 0.0121, 0.0222, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6117141246795654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0022, 0.0145, 0.0132, 0.0212, 0.0045, 0.0039]) \n",
      "Test Loss tensor([0.0257, 0.0025, 0.0142, 0.0126, 0.0223, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6285641193389893 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0023, 0.0163, 0.0121, 0.0243, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0262, 0.0025, 0.0142, 0.0119, 0.0220, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6338577270507812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0032, 0.0154, 0.0125, 0.0239, 0.0051, 0.0040]) \n",
      "Test Loss tensor([0.0264, 0.0024, 0.0137, 0.0121, 0.0210, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.621739387512207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0295, 0.0024, 0.0156, 0.0127, 0.0233, 0.0045, 0.0041]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0139, 0.0122, 0.0222, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6152141094207764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0032, 0.0140, 0.0113, 0.0224, 0.0038, 0.0031]) \n",
      "Test Loss tensor([0.0264, 0.0027, 0.0142, 0.0124, 0.0214, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5880937576293945 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0032, 0.0153, 0.0114, 0.0198, 0.0031, 0.0033]) \n",
      "Test Loss tensor([0.0259, 0.0028, 0.0148, 0.0123, 0.0215, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5844383239746094 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0017, 0.0165, 0.0122, 0.0223, 0.0043, 0.0035]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0148, 0.0124, 0.0219, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5841619968414307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0023, 0.0130, 0.0109, 0.0230, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0260, 0.0025, 0.0142, 0.0121, 0.0231, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6186132431030273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0023, 0.0141, 0.0129, 0.0232, 0.0039, 0.0029]) \n",
      "Test Loss tensor([0.0255, 0.0027, 0.0139, 0.0121, 0.0218, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6264364719390869 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0029, 0.0165, 0.0119, 0.0229, 0.0051, 0.0028]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0141, 0.0121, 0.0217, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6782424449920654 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0023, 0.0148, 0.0122, 0.0213, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0273, 0.0027, 0.0141, 0.0120, 0.0219, 0.0048, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6030735969543457 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0020, 0.0155, 0.0117, 0.0205, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0267, 0.0024, 0.0146, 0.0122, 0.0216, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6270327568054199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0024, 0.0157, 0.0116, 0.0236, 0.0037, 0.0037]) \n",
      "Test Loss tensor([0.0261, 0.0024, 0.0140, 0.0123, 0.0224, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.757850170135498 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0029, 0.0145, 0.0116, 0.0211, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0266, 0.0027, 0.0141, 0.0124, 0.0226, 0.0047, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6270401477813721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0027, 0.0142, 0.0127, 0.0197, 0.0040, 0.0028]) \n",
      "Test Loss tensor([0.0267, 0.0023, 0.0142, 0.0122, 0.0222, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6487407684326172 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0021, 0.0144, 0.0119, 0.0205, 0.0039, 0.0038]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0140, 0.0121, 0.0226, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6294069290161133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0019, 0.0134, 0.0114, 0.0235, 0.0045, 0.0045]) \n",
      "Test Loss tensor([0.0273, 0.0024, 0.0143, 0.0122, 0.0229, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6422383785247803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0025, 0.0154, 0.0127, 0.0252, 0.0042, 0.0041]) \n",
      "Test Loss tensor([0.0251, 0.0027, 0.0146, 0.0121, 0.0211, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6144778728485107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0022, 0.0146, 0.0135, 0.0233, 0.0066, 0.0033]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0143, 0.0120, 0.0223, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6216626167297363 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0332, 0.0025, 0.0142, 0.0123, 0.0237, 0.0058, 0.0029]) \n",
      "Test Loss tensor([0.0255, 0.0026, 0.0141, 0.0122, 0.0209, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6313574314117432 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0021, 0.0146, 0.0119, 0.0211, 0.0043, 0.0037]) \n",
      "Test Loss tensor([0.0263, 0.0025, 0.0140, 0.0124, 0.0227, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6059722900390625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0026, 0.0144, 0.0134, 0.0231, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0266, 0.0024, 0.0142, 0.0121, 0.0225, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.610954999923706 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0022, 0.0164, 0.0124, 0.0238, 0.0037, 0.0027]) \n",
      "Test Loss tensor([0.0266, 0.0026, 0.0142, 0.0120, 0.0221, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6186122894287109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0292, 0.0034, 0.0144, 0.0112, 0.0230, 0.0048, 0.0026]) \n",
      "Test Loss tensor([0.0256, 0.0027, 0.0143, 0.0120, 0.0219, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6020922660827637 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0024, 0.0144, 0.0115, 0.0209, 0.0047, 0.0035]) \n",
      "Test Loss tensor([0.0257, 0.0024, 0.0146, 0.0119, 0.0228, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.591423749923706 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0026, 0.0136, 0.0108, 0.0202, 0.0032, 0.0034]) \n",
      "Test Loss tensor([0.0255, 0.0027, 0.0141, 0.0123, 0.0217, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.585651159286499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0022, 0.0145, 0.0119, 0.0210, 0.0059, 0.0033]) \n",
      "Test Loss tensor([0.0263, 0.0027, 0.0143, 0.0121, 0.0221, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.595937967300415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0028, 0.0156, 0.0132, 0.0219, 0.0045, 0.0043]) \n",
      "Test Loss tensor([0.0253, 0.0024, 0.0147, 0.0121, 0.0222, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6324357986450195 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0025, 0.0120, 0.0115, 0.0234, 0.0032, 0.0036]) \n",
      "Test Loss tensor([0.0264, 0.0025, 0.0145, 0.0122, 0.0225, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6004030704498291 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0023, 0.0161, 0.0133, 0.0204, 0.0041, 0.0026]) \n",
      "Test Loss tensor([0.0258, 0.0025, 0.0141, 0.0118, 0.0218, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5786924362182617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0021, 0.0139, 0.0121, 0.0262, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0258, 0.0025, 0.0145, 0.0123, 0.0216, 0.0046, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 320 in 0.6376044750213623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0022, 0.0122, 0.0120, 0.0206, 0.0059, 0.0026]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0143, 0.0119, 0.0214, 0.0047, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5926229953765869 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0025, 0.0150, 0.0131, 0.0212, 0.0032, 0.0031]) \n",
      "Test Loss tensor([0.0252, 0.0025, 0.0147, 0.0124, 0.0213, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6492760181427002 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0028, 0.0134, 0.0120, 0.0225, 0.0042, 0.0033]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0140, 0.0117, 0.0216, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6906435489654541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0026, 0.0135, 0.0132, 0.0186, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0258, 0.0027, 0.0140, 0.0124, 0.0222, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6270401477813721 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0025, 0.0158, 0.0116, 0.0219, 0.0042, 0.0040]) \n",
      "Test Loss tensor([0.0258, 0.0026, 0.0145, 0.0120, 0.0209, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.7619626522064209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0031, 0.0147, 0.0124, 0.0220, 0.0051, 0.0025]) \n",
      "Test Loss tensor([0.0253, 0.0026, 0.0138, 0.0119, 0.0212, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6272811889648438 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0019, 0.0141, 0.0118, 0.0216, 0.0040, 0.0024]) \n",
      "Test Loss tensor([0.0261, 0.0025, 0.0135, 0.0122, 0.0218, 0.0044, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6053993701934814 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0026, 0.0152, 0.0118, 0.0202, 0.0041, 0.0036]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0148, 0.0122, 0.0220, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.5965461730957031 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0024, 0.0141, 0.0125, 0.0224, 0.0045, 0.0045]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0142, 0.0123, 0.0221, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6107912063598633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0026, 0.0145, 0.0117, 0.0222, 0.0045, 0.0022]) \n",
      "Test Loss tensor([0.0257, 0.0026, 0.0140, 0.0119, 0.0213, 0.0041, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6327731609344482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0025, 0.0159, 0.0117, 0.0218, 0.0044, 0.0036]) \n",
      "Test Loss tensor([0.0255, 0.0025, 0.0147, 0.0118, 0.0216, 0.0042, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6024951934814453 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0287, 0.0025, 0.0127, 0.0116, 0.0215, 0.0040, 0.0047]) \n",
      "Test Loss tensor([0.0265, 0.0023, 0.0141, 0.0121, 0.0217, 0.0043, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5974025726318359 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0021, 0.0127, 0.0118, 0.0195, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0255, 0.0027, 0.0141, 0.0122, 0.0217, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5955252647399902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0019, 0.0144, 0.0122, 0.0219, 0.0048, 0.0038]) \n",
      "Test Loss tensor([0.0261, 0.0025, 0.0142, 0.0123, 0.0213, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5966894626617432 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0026, 0.0144, 0.0113, 0.0204, 0.0040, 0.0026]) \n",
      "Test Loss tensor([0.0261, 0.0023, 0.0139, 0.0120, 0.0225, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.642777681350708 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0027, 0.0132, 0.0122, 0.0203, 0.0033, 0.0028]) \n",
      "Test Loss tensor([0.0245, 0.0026, 0.0142, 0.0122, 0.0214, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6072995662689209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0301, 0.0043, 0.0150, 0.0133, 0.0230, 0.0041, 0.0036]) \n",
      "Test Loss tensor([0.0265, 0.0025, 0.0146, 0.0120, 0.0209, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6120665073394775 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0299, 0.0020, 0.0133, 0.0123, 0.0232, 0.0050, 0.0041]) \n",
      "Test Loss tensor([0.0263, 0.0025, 0.0142, 0.0123, 0.0223, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6222865581512451 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0025, 0.0148, 0.0122, 0.0220, 0.0040, 0.0031]) \n",
      "Test Loss tensor([0.0273, 0.0024, 0.0142, 0.0122, 0.0223, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.610609769821167 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0025, 0.0149, 0.0132, 0.0204, 0.0038, 0.0030]) \n",
      "Test Loss tensor([0.0250, 0.0026, 0.0146, 0.0118, 0.0225, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6113321781158447 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0019, 0.0139, 0.0114, 0.0222, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0256, 0.0028, 0.0142, 0.0122, 0.0215, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.636702299118042 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0022, 0.0131, 0.0112, 0.0234, 0.0051, 0.0036]) \n",
      "Test Loss tensor([0.0262, 0.0027, 0.0145, 0.0122, 0.0225, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6085529327392578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0020, 0.0149, 0.0121, 0.0221, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0257, 0.0027, 0.0139, 0.0120, 0.0217, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6249420642852783 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0024, 0.0167, 0.0130, 0.0209, 0.0046, 0.0043]) \n",
      "Test Loss tensor([0.0253, 0.0027, 0.0147, 0.0121, 0.0233, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5976629257202148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0023, 0.0158, 0.0129, 0.0247, 0.0054, 0.0028]) \n",
      "Test Loss tensor([0.0254, 0.0028, 0.0147, 0.0123, 0.0218, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6149508953094482 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0022, 0.0132, 0.0107, 0.0225, 0.0040, 0.0026]) \n",
      "Test Loss tensor([0.0267, 0.0025, 0.0139, 0.0120, 0.0230, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6902420520782471 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0024, 0.0165, 0.0115, 0.0233, 0.0048, 0.0037]) \n",
      "Test Loss tensor([0.0257, 0.0025, 0.0138, 0.0122, 0.0238, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.7464029788970947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0297, 0.0035, 0.0140, 0.0109, 0.0249, 0.0043, 0.0039]) \n",
      "Test Loss tensor([0.0260, 0.0024, 0.0137, 0.0118, 0.0221, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6918010711669922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0027, 0.0156, 0.0127, 0.0230, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0267, 0.0026, 0.0142, 0.0119, 0.0232, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.7572920322418213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0030, 0.0173, 0.0129, 0.0242, 0.0038, 0.0032]) \n",
      "Test Loss tensor([0.0262, 0.0024, 0.0139, 0.0123, 0.0220, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.752711296081543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0027, 0.0128, 0.0108, 0.0225, 0.0045, 0.0039]) \n",
      "Test Loss tensor([0.0251, 0.0025, 0.0139, 0.0118, 0.0227, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.7382287979125977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0025, 0.0142, 0.0129, 0.0235, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0260, 0.0027, 0.0140, 0.0123, 0.0209, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.7669329643249512 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0019, 0.0144, 0.0125, 0.0216, 0.0061, 0.0026]) \n",
      "Test Loss tensor([0.0265, 0.0024, 0.0143, 0.0121, 0.0223, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.7717921733856201 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0021, 0.0157, 0.0122, 0.0241, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0143, 0.0118, 0.0214, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6367545127868652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0021, 0.0162, 0.0119, 0.0216, 0.0033, 0.0028]) \n",
      "Test Loss tensor([0.0245, 0.0024, 0.0141, 0.0119, 0.0225, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7274377346038818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0020, 0.0142, 0.0125, 0.0193, 0.0038, 0.0037]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0145, 0.0120, 0.0217, 0.0046, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 464 in 0.8668618202209473 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0025, 0.0128, 0.0127, 0.0210, 0.0050, 0.0043]) \n",
      "Test Loss tensor([0.0249, 0.0023, 0.0138, 0.0118, 0.0219, 0.0048, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.9242773056030273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0293, 0.0022, 0.0131, 0.0117, 0.0199, 0.0033, 0.0023]) \n",
      "Test Loss tensor([0.0261, 0.0026, 0.0140, 0.0119, 0.0226, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7596654891967773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0022, 0.0138, 0.0112, 0.0231, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0258, 0.0024, 0.0141, 0.0122, 0.0223, 0.0048, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6021103858947754 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0025, 0.0139, 0.0127, 0.0212, 0.0042, 0.0038]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0144, 0.0119, 0.0213, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6583414077758789 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0021, 0.0144, 0.0115, 0.0212, 0.0050, 0.0030]) \n",
      "Test Loss tensor([0.0250, 0.0029, 0.0140, 0.0121, 0.0214, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.685513973236084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0021, 0.0132, 0.0112, 0.0203, 0.0045, 0.0031]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0140, 0.0121, 0.0210, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.7918300628662109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0026, 0.0151, 0.0122, 0.0213, 0.0045, 0.0038]) \n",
      "Test Loss tensor([0.0258, 0.0024, 0.0139, 0.0124, 0.0212, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.722271203994751 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0024, 0.0157, 0.0120, 0.0235, 0.0036, 0.0033]) \n",
      "Test Loss tensor([0.0255, 0.0025, 0.0141, 0.0118, 0.0208, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7234117984771729 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0023, 0.0152, 0.0118, 0.0207, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0258, 0.0026, 0.0141, 0.0117, 0.0228, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.7690815925598145 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0283, 0.0027, 0.0147, 0.0113, 0.0251, 0.0046, 0.0031]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0143, 0.0123, 0.0201, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7115073204040527 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0031, 0.0138, 0.0110, 0.0227, 0.0052, 0.0044]) \n",
      "Test Loss tensor([0.0245, 0.0027, 0.0141, 0.0118, 0.0222, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6555883884429932 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0018, 0.0119, 0.0113, 0.0221, 0.0052, 0.0030]) \n",
      "Test Loss tensor([0.0244, 0.0028, 0.0140, 0.0118, 0.0216, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6823053359985352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0019, 0.0154, 0.0118, 0.0182, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0237, 0.0026, 0.0142, 0.0118, 0.0209, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6644251346588135 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0024, 0.0152, 0.0114, 0.0188, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0256, 0.0024, 0.0143, 0.0119, 0.0232, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.7147367000579834 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0032, 0.0143, 0.0118, 0.0228, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0141, 0.0121, 0.0204, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6220214366912842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0027, 0.0147, 0.0117, 0.0221, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0142, 0.0122, 0.0225, 0.0048, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.594271183013916 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0025, 0.0159, 0.0118, 0.0244, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0248, 0.0028, 0.0146, 0.0120, 0.0206, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5870211124420166 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0026, 0.0147, 0.0119, 0.0238, 0.0037, 0.0029]) \n",
      "Test Loss tensor([0.0260, 0.0026, 0.0153, 0.0123, 0.0221, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6147854328155518 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0018, 0.0135, 0.0123, 0.0201, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0253, 0.0027, 0.0138, 0.0122, 0.0208, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6033508777618408 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0028, 0.0156, 0.0117, 0.0199, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0144, 0.0121, 0.0223, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5888016223907471 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0025, 0.0148, 0.0126, 0.0234, 0.0051, 0.0032]) \n",
      "Test Loss tensor([0.0253, 0.0027, 0.0145, 0.0121, 0.0212, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5795407295227051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0025, 0.0136, 0.0129, 0.0214, 0.0038, 0.0027]) \n",
      "Test Loss tensor([0.0248, 0.0023, 0.0137, 0.0119, 0.0215, 0.0047, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5810089111328125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0032, 0.0137, 0.0108, 0.0205, 0.0054, 0.0028]) \n",
      "Test Loss tensor([0.0260, 0.0026, 0.0137, 0.0120, 0.0229, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5789456367492676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0285, 0.0025, 0.0130, 0.0119, 0.0208, 0.0034, 0.0029]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0148, 0.0121, 0.0214, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5819897651672363 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0029, 0.0127, 0.0126, 0.0193, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0256, 0.0024, 0.0140, 0.0119, 0.0229, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.582240104675293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0025, 0.0154, 0.0137, 0.0249, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0253, 0.0027, 0.0142, 0.0121, 0.0210, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5856747627258301 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0026, 0.0141, 0.0116, 0.0212, 0.0048, 0.0037]) \n",
      "Test Loss tensor([0.0250, 0.0029, 0.0134, 0.0118, 0.0208, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5837433338165283 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0018, 0.0129, 0.0128, 0.0209, 0.0043, 0.0041]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0142, 0.0121, 0.0211, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6407394409179688 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0024, 0.0131, 0.0120, 0.0195, 0.0044, 0.0027]) \n",
      "Test Loss tensor([0.0256, 0.0024, 0.0144, 0.0121, 0.0221, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6063048839569092 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0023, 0.0144, 0.0134, 0.0235, 0.0050, 0.0046]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0138, 0.0117, 0.0214, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6474606990814209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0029, 0.0145, 0.0115, 0.0203, 0.0054, 0.0043]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0142, 0.0121, 0.0223, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6426875591278076 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0022, 0.0134, 0.0124, 0.0213, 0.0038, 0.0028]) \n",
      "Test Loss tensor([0.0256, 0.0024, 0.0145, 0.0118, 0.0217, 0.0044, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6274552345275879 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0028, 0.0139, 0.0115, 0.0214, 0.0052, 0.0036]) \n",
      "Test Loss tensor([0.0248, 0.0023, 0.0139, 0.0125, 0.0215, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6154961585998535 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0023, 0.0160, 0.0117, 0.0231, 0.0037, 0.0032]) \n",
      "Test Loss tensor([0.0252, 0.0026, 0.0138, 0.0118, 0.0227, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.8312761783599854 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0020, 0.0128, 0.0116, 0.0236, 0.0043, 0.0031]) \n",
      "Test Loss tensor([0.0260, 0.0026, 0.0134, 0.0122, 0.0209, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.8429412841796875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0020, 0.0110, 0.0106, 0.0227, 0.0044, 0.0042]) \n",
      "Test Loss tensor([0.0255, 0.0024, 0.0148, 0.0120, 0.0235, 0.0042, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 608 in 0.6611461639404297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0024, 0.0129, 0.0129, 0.0211, 0.0040, 0.0021]) \n",
      "Test Loss tensor([0.0257, 0.0024, 0.0141, 0.0122, 0.0211, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6999027729034424 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0024, 0.0152, 0.0131, 0.0196, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0256, 0.0023, 0.0142, 0.0124, 0.0223, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.789820671081543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0029, 0.0133, 0.0113, 0.0246, 0.0055, 0.0030]) \n",
      "Test Loss tensor([0.0251, 0.0027, 0.0142, 0.0118, 0.0212, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.7330942153930664 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0021, 0.0128, 0.0123, 0.0248, 0.0063, 0.0039]) \n",
      "Test Loss tensor([0.0251, 0.0023, 0.0146, 0.0120, 0.0212, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6212165355682373 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0025, 0.0128, 0.0119, 0.0221, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0238, 0.0023, 0.0136, 0.0119, 0.0214, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6499688625335693 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0021, 0.0144, 0.0118, 0.0211, 0.0046, 0.0027]) \n",
      "Test Loss tensor([0.0257, 0.0025, 0.0138, 0.0120, 0.0208, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6007301807403564 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0027, 0.0138, 0.0120, 0.0200, 0.0043, 0.0035]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0141, 0.0120, 0.0215, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6212911605834961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0026, 0.0145, 0.0109, 0.0206, 0.0040, 0.0031]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0137, 0.0117, 0.0207, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5928068161010742 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0031, 0.0142, 0.0111, 0.0196, 0.0041, 0.0031]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0140, 0.0117, 0.0215, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6808686256408691 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0027, 0.0138, 0.0113, 0.0221, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0246, 0.0026, 0.0139, 0.0118, 0.0207, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6744351387023926 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0035, 0.0157, 0.0111, 0.0208, 0.0045, 0.0025]) \n",
      "Test Loss tensor([0.0254, 0.0025, 0.0135, 0.0123, 0.0215, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5987813472747803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0021, 0.0134, 0.0126, 0.0197, 0.0041, 0.0040]) \n",
      "Test Loss tensor([0.0259, 0.0024, 0.0143, 0.0122, 0.0205, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.7108888626098633 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0209, 0.0026, 0.0135, 0.0118, 0.0232, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0137, 0.0123, 0.0206, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6776924133300781 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0023, 0.0158, 0.0124, 0.0206, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0250, 0.0027, 0.0141, 0.0120, 0.0203, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6253626346588135 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0022, 0.0147, 0.0115, 0.0242, 0.0038, 0.0031]) \n",
      "Test Loss tensor([0.0266, 0.0026, 0.0138, 0.0121, 0.0201, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.61669921875 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0025, 0.0140, 0.0137, 0.0209, 0.0050, 0.0029]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0143, 0.0114, 0.0212, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6150374412536621 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0021, 0.0147, 0.0128, 0.0214, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0262, 0.0026, 0.0139, 0.0120, 0.0213, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.61763596534729 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0282, 0.0030, 0.0128, 0.0110, 0.0212, 0.0050, 0.0039]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0141, 0.0118, 0.0211, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6564126014709473 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0019, 0.0132, 0.0115, 0.0225, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0248, 0.0023, 0.0143, 0.0122, 0.0204, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6247854232788086 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0019, 0.0130, 0.0119, 0.0224, 0.0058, 0.0040]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0141, 0.0119, 0.0223, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5791411399841309 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0022, 0.0158, 0.0126, 0.0212, 0.0052, 0.0036]) \n",
      "Test Loss tensor([0.0257, 0.0024, 0.0145, 0.0120, 0.0206, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6449332237243652 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0028, 0.0158, 0.0125, 0.0218, 0.0035, 0.0029]) \n",
      "Test Loss tensor([0.0248, 0.0024, 0.0145, 0.0121, 0.0218, 0.0044, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7730295658111572 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0021, 0.0170, 0.0130, 0.0222, 0.0037, 0.0026]) \n",
      "Test Loss tensor([0.0242, 0.0027, 0.0143, 0.0118, 0.0218, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.7473189830780029 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0026, 0.0131, 0.0125, 0.0234, 0.0045, 0.0040]) \n",
      "Test Loss tensor([0.0261, 0.0025, 0.0137, 0.0120, 0.0209, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5854020118713379 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0028, 0.0141, 0.0118, 0.0196, 0.0047, 0.0028]) \n",
      "Test Loss tensor([0.0261, 0.0024, 0.0143, 0.0124, 0.0228, 0.0048, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6201572418212891 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0023, 0.0157, 0.0115, 0.0242, 0.0038, 0.0041]) \n",
      "Test Loss tensor([0.0228, 0.0024, 0.0137, 0.0120, 0.0214, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6247844696044922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0021, 0.0140, 0.0124, 0.0180, 0.0041, 0.0029]) \n",
      "Test Loss tensor([0.0255, 0.0026, 0.0141, 0.0121, 0.0219, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6882412433624268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0027, 0.0133, 0.0121, 0.0226, 0.0042, 0.0034]) \n",
      "Test Loss tensor([0.0253, 0.0027, 0.0139, 0.0123, 0.0204, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5977566242218018 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0017, 0.0139, 0.0112, 0.0186, 0.0056, 0.0042]) \n",
      "Test Loss tensor([0.0259, 0.0025, 0.0138, 0.0121, 0.0228, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6467888355255127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0018, 0.0150, 0.0108, 0.0238, 0.0042, 0.0033]) \n",
      "Test Loss tensor([0.0248, 0.0025, 0.0141, 0.0119, 0.0207, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6693761348724365 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0033, 0.0153, 0.0115, 0.0210, 0.0037, 0.0036]) \n",
      "Test Loss tensor([0.0249, 0.0024, 0.0136, 0.0120, 0.0227, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.7117307186126709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0028, 0.0158, 0.0112, 0.0235, 0.0043, 0.0035]) \n",
      "Test Loss tensor([0.0251, 0.0024, 0.0141, 0.0121, 0.0209, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.8698627948760986 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0227, 0.0035, 0.0143, 0.0130, 0.0207, 0.0050, 0.0035]) \n",
      "Test Loss tensor([0.0250, 0.0025, 0.0146, 0.0124, 0.0217, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.8729526996612549 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0290, 0.0025, 0.0138, 0.0118, 0.0185, 0.0039, 0.0030]) \n",
      "Test Loss tensor([0.0270, 0.0026, 0.0139, 0.0124, 0.0217, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.787839412689209 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0026, 0.0152, 0.0123, 0.0221, 0.0037, 0.0039]) \n",
      "Test Loss tensor([0.0245, 0.0026, 0.0138, 0.0119, 0.0209, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6507360935211182 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0019, 0.0144, 0.0115, 0.0183, 0.0053, 0.0036]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0145, 0.0120, 0.0225, 0.0045, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 752 in 0.6526200771331787 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0019, 0.0132, 0.0122, 0.0219, 0.0043, 0.0034]) \n",
      "Test Loss tensor([0.0256, 0.0023, 0.0135, 0.0122, 0.0212, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6383371353149414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0022, 0.0141, 0.0125, 0.0229, 0.0038, 0.0035]) \n",
      "Test Loss tensor([0.0253, 0.0026, 0.0140, 0.0119, 0.0208, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6287088394165039 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0031, 0.0137, 0.0120, 0.0195, 0.0039, 0.0024]) \n",
      "Test Loss tensor([0.0252, 0.0023, 0.0141, 0.0118, 0.0212, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6266608238220215 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0027, 0.0151, 0.0138, 0.0194, 0.0047, 0.0043]) \n",
      "Test Loss tensor([0.0252, 0.0024, 0.0139, 0.0120, 0.0213, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6094558238983154 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0023, 0.0157, 0.0115, 0.0193, 0.0051, 0.0041]) \n",
      "Test Loss tensor([0.0257, 0.0024, 0.0137, 0.0119, 0.0210, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.578585147857666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0277, 0.0037, 0.0150, 0.0129, 0.0223, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0243, 0.0025, 0.0140, 0.0117, 0.0208, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.582531213760376 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0025, 0.0142, 0.0115, 0.0211, 0.0049, 0.0028]) \n",
      "Test Loss tensor([0.0251, 0.0024, 0.0145, 0.0119, 0.0209, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5892152786254883 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0027, 0.0135, 0.0111, 0.0210, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0250, 0.0027, 0.0145, 0.0120, 0.0206, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5950734615325928 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0288, 0.0023, 0.0142, 0.0122, 0.0221, 0.0052, 0.0047]) \n",
      "Test Loss tensor([0.0250, 0.0025, 0.0140, 0.0116, 0.0219, 0.0047, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5974748134613037 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0020, 0.0123, 0.0123, 0.0241, 0.0043, 0.0038]) \n",
      "Test Loss tensor([0.0265, 0.0023, 0.0138, 0.0119, 0.0210, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5851037502288818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0021, 0.0132, 0.0132, 0.0199, 0.0058, 0.0029]) \n",
      "Test Loss tensor([0.0257, 0.0026, 0.0139, 0.0120, 0.0215, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.5893607139587402 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0020, 0.0134, 0.0116, 0.0201, 0.0035, 0.0034]) \n",
      "Test Loss tensor([0.0236, 0.0026, 0.0139, 0.0122, 0.0209, 0.0046, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.719008207321167 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0022, 0.0156, 0.0120, 0.0230, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0246, 0.0028, 0.0141, 0.0122, 0.0204, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6515107154846191 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0018, 0.0134, 0.0128, 0.0221, 0.0051, 0.0035]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0139, 0.0123, 0.0212, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6878769397735596 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0018, 0.0124, 0.0129, 0.0166, 0.0046, 0.0026]) \n",
      "Test Loss tensor([0.0247, 0.0024, 0.0138, 0.0123, 0.0204, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.644538402557373 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0024, 0.0141, 0.0122, 0.0205, 0.0049, 0.0032]) \n",
      "Test Loss tensor([0.0258, 0.0026, 0.0138, 0.0122, 0.0208, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.9225594997406006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0018, 0.0120, 0.0106, 0.0218, 0.0039, 0.0041]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0138, 0.0121, 0.0204, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.962216854095459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0017, 0.0145, 0.0111, 0.0215, 0.0049, 0.0035]) \n",
      "Test Loss tensor([0.0261, 0.0024, 0.0141, 0.0122, 0.0213, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.8422896862030029 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0222, 0.0023, 0.0141, 0.0115, 0.0191, 0.0034, 0.0032]) \n",
      "Test Loss tensor([0.0248, 0.0025, 0.0139, 0.0119, 0.0205, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.7558290958404541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0291, 0.0025, 0.0165, 0.0140, 0.0217, 0.0035, 0.0031]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0144, 0.0121, 0.0210, 0.0042, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.73866868019104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0020, 0.0139, 0.0131, 0.0223, 0.0034, 0.0034]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0142, 0.0124, 0.0213, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7035086154937744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0018, 0.0131, 0.0113, 0.0203, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0141, 0.0122, 0.0212, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7612769603729248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0021, 0.0136, 0.0122, 0.0214, 0.0042, 0.0024]) \n",
      "Test Loss tensor([0.0243, 0.0023, 0.0142, 0.0120, 0.0211, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6511008739471436 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0023, 0.0143, 0.0104, 0.0232, 0.0058, 0.0040]) \n",
      "Test Loss tensor([0.0241, 0.0024, 0.0141, 0.0118, 0.0207, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6849198341369629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0023, 0.0139, 0.0118, 0.0209, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0144, 0.0118, 0.0204, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.693894624710083 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0017, 0.0150, 0.0119, 0.0205, 0.0032, 0.0027]) \n",
      "Test Loss tensor([0.0233, 0.0027, 0.0140, 0.0119, 0.0200, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.678647518157959 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0020, 0.0166, 0.0117, 0.0208, 0.0034, 0.0035]) \n",
      "Test Loss tensor([0.0256, 0.0025, 0.0138, 0.0120, 0.0207, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6403079032897949 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0220, 0.0020, 0.0140, 0.0115, 0.0237, 0.0050, 0.0033]) \n",
      "Test Loss tensor([0.0246, 0.0026, 0.0136, 0.0121, 0.0199, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6006288528442383 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0018, 0.0141, 0.0118, 0.0193, 0.0049, 0.0046]) \n",
      "Test Loss tensor([0.0255, 0.0024, 0.0139, 0.0117, 0.0204, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6402297019958496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0018, 0.0147, 0.0107, 0.0236, 0.0047, 0.0024]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0143, 0.0120, 0.0199, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.5966882705688477 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0030, 0.0124, 0.0114, 0.0160, 0.0037, 0.0034]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0138, 0.0120, 0.0206, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5655951499938965 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0172, 0.0017, 0.0100, 0.0089, 0.0141, 0.0038, 0.0024]) \n",
      "Test Loss tensor([0.0260, 0.0029, 0.0139, 0.0120, 0.0203, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6600217819213867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0018, 0.0144, 0.0118, 0.0219, 0.0033, 0.0032]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0143, 0.0121, 0.0203, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6033265590667725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0021, 0.0135, 0.0122, 0.0171, 0.0050, 0.0056]) \n",
      "Test Loss tensor([0.0246, 0.0026, 0.0144, 0.0120, 0.0198, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5942933559417725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0023, 0.0120, 0.0121, 0.0176, 0.0057, 0.0029]) \n",
      "Test Loss tensor([0.0243, 0.0024, 0.0138, 0.0120, 0.0200, 0.0046, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6077380180358887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0021, 0.0139, 0.0122, 0.0188, 0.0037, 0.0046]) \n",
      "Test Loss tensor([0.0251, 0.0025, 0.0137, 0.0121, 0.0201, 0.0046, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 16 in 0.5928239822387695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0021, 0.0144, 0.0120, 0.0214, 0.0039, 0.0024]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0142, 0.0121, 0.0198, 0.0044, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5950024127960205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0021, 0.0144, 0.0128, 0.0199, 0.0035, 0.0026]) \n",
      "Test Loss tensor([0.0237, 0.0026, 0.0138, 0.0115, 0.0194, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6068432331085205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0017, 0.0144, 0.0108, 0.0191, 0.0040, 0.0028]) \n",
      "Test Loss tensor([0.0237, 0.0028, 0.0134, 0.0117, 0.0199, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5983870029449463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0265, 0.0025, 0.0133, 0.0116, 0.0214, 0.0049, 0.0039]) \n",
      "Test Loss tensor([0.0250, 0.0024, 0.0142, 0.0119, 0.0201, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6053376197814941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0019, 0.0136, 0.0121, 0.0195, 0.0035, 0.0023]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0138, 0.0118, 0.0201, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5931804180145264 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0023, 0.0135, 0.0122, 0.0205, 0.0050, 0.0032]) \n",
      "Test Loss tensor([0.0249, 0.0024, 0.0139, 0.0121, 0.0204, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6515588760375977 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0023, 0.0138, 0.0117, 0.0205, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0246, 0.0024, 0.0138, 0.0117, 0.0201, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6819164752960205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0018, 0.0143, 0.0105, 0.0193, 0.0038, 0.0038]) \n",
      "Test Loss tensor([0.0253, 0.0025, 0.0140, 0.0120, 0.0205, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6068964004516602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0019, 0.0135, 0.0116, 0.0200, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0249, 0.0026, 0.0133, 0.0122, 0.0207, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.5918416976928711 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0023, 0.0133, 0.0124, 0.0205, 0.0051, 0.0030]) \n",
      "Test Loss tensor([0.0242, 0.0025, 0.0143, 0.0119, 0.0204, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6980478763580322 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0030, 0.0135, 0.0119, 0.0216, 0.0052, 0.0040]) \n",
      "Test Loss tensor([0.0252, 0.0027, 0.0145, 0.0121, 0.0202, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6379637718200684 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0025, 0.0119, 0.0128, 0.0175, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0248, 0.0023, 0.0138, 0.0117, 0.0196, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5804393291473389 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0227, 0.0029, 0.0156, 0.0125, 0.0215, 0.0040, 0.0032]) \n",
      "Test Loss tensor([0.0246, 0.0024, 0.0142, 0.0120, 0.0199, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5791158676147461 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0286, 0.0025, 0.0143, 0.0118, 0.0213, 0.0040, 0.0031]) \n",
      "Test Loss tensor([0.0254, 0.0023, 0.0142, 0.0121, 0.0205, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6008038520812988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0271, 0.0027, 0.0164, 0.0105, 0.0226, 0.0047, 0.0026]) \n",
      "Test Loss tensor([0.0246, 0.0026, 0.0142, 0.0123, 0.0192, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6369106769561768 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0026, 0.0135, 0.0121, 0.0196, 0.0045, 0.0034]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0139, 0.0121, 0.0205, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.5767931938171387 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0030, 0.0108, 0.0111, 0.0218, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0137, 0.0120, 0.0202, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6091680526733398 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0220, 0.0019, 0.0144, 0.0122, 0.0205, 0.0046, 0.0028]) \n",
      "Test Loss tensor([0.0245, 0.0026, 0.0137, 0.0117, 0.0199, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6208734512329102 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0024, 0.0135, 0.0123, 0.0216, 0.0042, 0.0034]) \n",
      "Test Loss tensor([0.0246, 0.0024, 0.0138, 0.0118, 0.0197, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6130685806274414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0284, 0.0033, 0.0128, 0.0136, 0.0206, 0.0052, 0.0030]) \n",
      "Test Loss tensor([0.0251, 0.0026, 0.0141, 0.0123, 0.0198, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6017675399780273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0021, 0.0152, 0.0122, 0.0183, 0.0043, 0.0036]) \n",
      "Test Loss tensor([0.0248, 0.0025, 0.0138, 0.0116, 0.0199, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6070313453674316 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0027, 0.0145, 0.0120, 0.0201, 0.0035, 0.0040]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0137, 0.0122, 0.0202, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6214778423309326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0019, 0.0134, 0.0123, 0.0187, 0.0042, 0.0027]) \n",
      "Test Loss tensor([0.0243, 0.0025, 0.0136, 0.0120, 0.0205, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6020810604095459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0026, 0.0143, 0.0120, 0.0209, 0.0052, 0.0026]) \n",
      "Test Loss tensor([0.0243, 0.0024, 0.0138, 0.0121, 0.0192, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.608222246170044 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0019, 0.0146, 0.0128, 0.0211, 0.0053, 0.0029]) \n",
      "Test Loss tensor([0.0247, 0.0024, 0.0137, 0.0122, 0.0203, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6159961223602295 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0022, 0.0139, 0.0116, 0.0189, 0.0036, 0.0030]) \n",
      "Test Loss tensor([0.0245, 0.0024, 0.0132, 0.0125, 0.0204, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6109907627105713 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0034, 0.0129, 0.0128, 0.0202, 0.0042, 0.0027]) \n",
      "Test Loss tensor([0.0242, 0.0025, 0.0138, 0.0121, 0.0191, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.624060869216919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0021, 0.0126, 0.0112, 0.0173, 0.0042, 0.0034]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0140, 0.0122, 0.0203, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6289722919464111 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0024, 0.0133, 0.0110, 0.0213, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0252, 0.0025, 0.0140, 0.0123, 0.0197, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.7522447109222412 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0021, 0.0150, 0.0144, 0.0201, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0134, 0.0118, 0.0195, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6556224822998047 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0022, 0.0131, 0.0131, 0.0193, 0.0048, 0.0028]) \n",
      "Test Loss tensor([0.0229, 0.0027, 0.0145, 0.0118, 0.0197, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.765411376953125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0025, 0.0134, 0.0117, 0.0214, 0.0035, 0.0030]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0140, 0.0120, 0.0198, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.9906272888183594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0022, 0.0152, 0.0115, 0.0196, 0.0038, 0.0031]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0136, 0.0116, 0.0193, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.8784406185150146 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0023, 0.0129, 0.0118, 0.0221, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0253, 0.0024, 0.0143, 0.0121, 0.0218, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6740448474884033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0021, 0.0160, 0.0122, 0.0192, 0.0045, 0.0039]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0142, 0.0118, 0.0204, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7392761707305908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0023, 0.0151, 0.0116, 0.0203, 0.0042, 0.0031]) \n",
      "Test Loss tensor([0.0238, 0.0024, 0.0143, 0.0118, 0.0209, 0.0045, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 160 in 0.6226339340209961 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0022, 0.0141, 0.0118, 0.0192, 0.0051, 0.0028]) \n",
      "Test Loss tensor([0.0244, 0.0026, 0.0142, 0.0122, 0.0212, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6111173629760742 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0269, 0.0024, 0.0150, 0.0121, 0.0233, 0.0047, 0.0029]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0135, 0.0116, 0.0202, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6410908699035645 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0031, 0.0143, 0.0121, 0.0183, 0.0045, 0.0025]) \n",
      "Test Loss tensor([0.0250, 0.0026, 0.0139, 0.0118, 0.0214, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.647871732711792 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0024, 0.0135, 0.0135, 0.0232, 0.0044, 0.0026]) \n",
      "Test Loss tensor([0.0247, 0.0026, 0.0145, 0.0119, 0.0204, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6958966255187988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0030, 0.0150, 0.0105, 0.0200, 0.0055, 0.0037]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0140, 0.0119, 0.0207, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6351807117462158 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0023, 0.0146, 0.0125, 0.0210, 0.0046, 0.0029]) \n",
      "Test Loss tensor([0.0238, 0.0027, 0.0137, 0.0119, 0.0218, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6624493598937988 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0021, 0.0148, 0.0110, 0.0214, 0.0044, 0.0029]) \n",
      "Test Loss tensor([0.0239, 0.0027, 0.0135, 0.0119, 0.0204, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6554641723632812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0023, 0.0123, 0.0126, 0.0196, 0.0053, 0.0034]) \n",
      "Test Loss tensor([0.0259, 0.0026, 0.0139, 0.0119, 0.0223, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.926835298538208 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0022, 0.0145, 0.0126, 0.0244, 0.0046, 0.0030]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0140, 0.0117, 0.0197, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.8189835548400879 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0021, 0.0131, 0.0112, 0.0213, 0.0033, 0.0042]) \n",
      "Test Loss tensor([0.0257, 0.0027, 0.0141, 0.0122, 0.0235, 0.0043, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6004629135131836 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0294, 0.0026, 0.0159, 0.0108, 0.0247, 0.0049, 0.0049]) \n",
      "Test Loss tensor([0.0241, 0.0026, 0.0141, 0.0119, 0.0206, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5861968994140625 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0027, 0.0158, 0.0120, 0.0204, 0.0043, 0.0038]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0142, 0.0119, 0.0215, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5927941799163818 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0026, 0.0144, 0.0125, 0.0204, 0.0041, 0.0028]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0134, 0.0117, 0.0199, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.7309272289276123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0027, 0.0154, 0.0126, 0.0206, 0.0040, 0.0025]) \n",
      "Test Loss tensor([0.0250, 0.0026, 0.0137, 0.0122, 0.0202, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7512845993041992 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0023, 0.0144, 0.0117, 0.0207, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0252, 0.0024, 0.0144, 0.0120, 0.0214, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.612602710723877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0018, 0.0150, 0.0119, 0.0207, 0.0044, 0.0027]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0137, 0.0119, 0.0198, 0.0043, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7303810119628906 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0026, 0.0152, 0.0114, 0.0194, 0.0055, 0.0037]) \n",
      "Test Loss tensor([0.0241, 0.0023, 0.0137, 0.0120, 0.0215, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.7156858444213867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0017, 0.0135, 0.0127, 0.0219, 0.0042, 0.0035]) \n",
      "Test Loss tensor([0.0249, 0.0023, 0.0142, 0.0119, 0.0201, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.7186319828033447 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0032, 0.0158, 0.0120, 0.0201, 0.0038, 0.0037]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0136, 0.0122, 0.0202, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6072261333465576 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0030, 0.0144, 0.0133, 0.0209, 0.0049, 0.0040]) \n",
      "Test Loss tensor([0.0244, 0.0024, 0.0141, 0.0119, 0.0191, 0.0041, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6464569568634033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0019, 0.0162, 0.0127, 0.0180, 0.0041, 0.0027]) \n",
      "Test Loss tensor([0.0234, 0.0023, 0.0140, 0.0123, 0.0197, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7558352947235107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0021, 0.0128, 0.0123, 0.0193, 0.0034, 0.0031]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0141, 0.0120, 0.0201, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.8408236503601074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0027, 0.0130, 0.0126, 0.0212, 0.0050, 0.0040]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0134, 0.0120, 0.0196, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7497467994689941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0031, 0.0130, 0.0129, 0.0206, 0.0040, 0.0033]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0142, 0.0123, 0.0201, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6222739219665527 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0022, 0.0122, 0.0121, 0.0176, 0.0031, 0.0027]) \n",
      "Test Loss tensor([0.0243, 0.0022, 0.0139, 0.0119, 0.0193, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6366801261901855 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0218, 0.0020, 0.0140, 0.0129, 0.0179, 0.0041, 0.0036]) \n",
      "Test Loss tensor([0.0247, 0.0023, 0.0136, 0.0121, 0.0197, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6490015983581543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0023, 0.0129, 0.0123, 0.0197, 0.0033, 0.0032]) \n",
      "Test Loss tensor([0.0242, 0.0024, 0.0141, 0.0118, 0.0190, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6914358139038086 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0213, 0.0028, 0.0146, 0.0108, 0.0199, 0.0044, 0.0032]) \n",
      "Test Loss tensor([0.0245, 0.0024, 0.0143, 0.0119, 0.0197, 0.0040, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6585638523101807 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0289, 0.0022, 0.0150, 0.0130, 0.0182, 0.0060, 0.0033]) \n",
      "Test Loss tensor([0.0246, 0.0028, 0.0141, 0.0119, 0.0198, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6135804653167725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0020, 0.0143, 0.0133, 0.0187, 0.0031, 0.0024]) \n",
      "Test Loss tensor([0.0248, 0.0025, 0.0139, 0.0117, 0.0193, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6435174942016602 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0018, 0.0118, 0.0119, 0.0188, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0138, 0.0116, 0.0195, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6173052787780762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0029, 0.0143, 0.0116, 0.0178, 0.0050, 0.0038]) \n",
      "Test Loss tensor([0.0244, 0.0026, 0.0134, 0.0123, 0.0189, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.91929030418396 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0025, 0.0144, 0.0116, 0.0200, 0.0051, 0.0033]) \n",
      "Test Loss tensor([0.0244, 0.0025, 0.0137, 0.0120, 0.0199, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.750708818435669 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0028, 0.0145, 0.0121, 0.0188, 0.0042, 0.0027]) \n",
      "Test Loss tensor([0.0232, 0.0024, 0.0135, 0.0119, 0.0194, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7883059978485107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0027, 0.0143, 0.0122, 0.0196, 0.0049, 0.0034]) \n",
      "Test Loss tensor([0.0254, 0.0027, 0.0139, 0.0124, 0.0204, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.8276107311248779 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0023, 0.0125, 0.0110, 0.0195, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0240, 0.0023, 0.0136, 0.0119, 0.0200, 0.0043, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 304 in 0.6531622409820557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0020, 0.0138, 0.0121, 0.0220, 0.0037, 0.0037]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0135, 0.0122, 0.0201, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6317815780639648 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0020, 0.0127, 0.0113, 0.0197, 0.0037, 0.0031]) \n",
      "Test Loss tensor([0.0247, 0.0023, 0.0133, 0.0118, 0.0202, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6383624076843262 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0026, 0.0141, 0.0124, 0.0209, 0.0041, 0.0035]) \n",
      "Test Loss tensor([0.0247, 0.0025, 0.0140, 0.0123, 0.0194, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6132266521453857 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0025, 0.0121, 0.0129, 0.0204, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0237, 0.0025, 0.0135, 0.0118, 0.0204, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6230988502502441 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0022, 0.0136, 0.0113, 0.0209, 0.0043, 0.0027]) \n",
      "Test Loss tensor([0.0249, 0.0024, 0.0134, 0.0119, 0.0195, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6554934978485107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0023, 0.0161, 0.0119, 0.0188, 0.0044, 0.0023]) \n",
      "Test Loss tensor([0.0246, 0.0027, 0.0134, 0.0119, 0.0199, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6582164764404297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0022, 0.0141, 0.0122, 0.0191, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0237, 0.0023, 0.0135, 0.0116, 0.0199, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7905547618865967 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0020, 0.0165, 0.0124, 0.0200, 0.0044, 0.0039]) \n",
      "Test Loss tensor([0.0241, 0.0023, 0.0134, 0.0120, 0.0195, 0.0045, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6976876258850098 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0317, 0.0027, 0.0143, 0.0128, 0.0184, 0.0032, 0.0038]) \n",
      "Test Loss tensor([0.0250, 0.0024, 0.0133, 0.0119, 0.0196, 0.0047, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6027090549468994 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0022, 0.0126, 0.0125, 0.0192, 0.0040, 0.0026]) \n",
      "Test Loss tensor([0.0251, 0.0027, 0.0137, 0.0122, 0.0189, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.641352653503418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0224, 0.0021, 0.0149, 0.0125, 0.0203, 0.0050, 0.0032]) \n",
      "Test Loss tensor([0.0254, 0.0026, 0.0139, 0.0121, 0.0191, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6398279666900635 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0022, 0.0131, 0.0115, 0.0201, 0.0051, 0.0050]) \n",
      "Test Loss tensor([0.0244, 0.0023, 0.0134, 0.0121, 0.0194, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7170722484588623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0025, 0.0160, 0.0114, 0.0187, 0.0035, 0.0042]) \n",
      "Test Loss tensor([0.0245, 0.0025, 0.0141, 0.0121, 0.0197, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.611283540725708 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0029, 0.0137, 0.0119, 0.0204, 0.0037, 0.0035]) \n",
      "Test Loss tensor([0.0237, 0.0024, 0.0136, 0.0119, 0.0195, 0.0045, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6463792324066162 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0018, 0.0135, 0.0131, 0.0209, 0.0064, 0.0033]) \n",
      "Test Loss tensor([0.0237, 0.0026, 0.0137, 0.0120, 0.0196, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6395671367645264 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0020, 0.0129, 0.0113, 0.0204, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0231, 0.0024, 0.0140, 0.0118, 0.0197, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.637000322341919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0023, 0.0134, 0.0123, 0.0205, 0.0043, 0.0046]) \n",
      "Test Loss tensor([0.0255, 0.0027, 0.0130, 0.0122, 0.0198, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6404950618743896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0023, 0.0131, 0.0124, 0.0206, 0.0032, 0.0028]) \n",
      "Test Loss tensor([0.0234, 0.0026, 0.0139, 0.0119, 0.0190, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7099285125732422 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0026, 0.0130, 0.0124, 0.0192, 0.0038, 0.0038]) \n",
      "Test Loss tensor([0.0243, 0.0026, 0.0138, 0.0118, 0.0191, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6080622673034668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0213, 0.0022, 0.0115, 0.0114, 0.0189, 0.0035, 0.0033]) \n",
      "Test Loss tensor([0.0245, 0.0022, 0.0132, 0.0120, 0.0194, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6713576316833496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0026, 0.0131, 0.0119, 0.0191, 0.0037, 0.0026]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0138, 0.0120, 0.0202, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6071298122406006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0019, 0.0127, 0.0116, 0.0200, 0.0058, 0.0036]) \n",
      "Test Loss tensor([0.0233, 0.0027, 0.0139, 0.0120, 0.0190, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.643622875213623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0023, 0.0137, 0.0125, 0.0224, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0138, 0.0120, 0.0197, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6152133941650391 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0023, 0.0135, 0.0122, 0.0206, 0.0038, 0.0022]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0137, 0.0121, 0.0197, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.605161190032959 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0017, 0.0139, 0.0125, 0.0212, 0.0046, 0.0050]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0131, 0.0117, 0.0192, 0.0048, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6356568336486816 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0022, 0.0144, 0.0107, 0.0175, 0.0048, 0.0026]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0137, 0.0118, 0.0192, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6443400382995605 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0023, 0.0133, 0.0123, 0.0221, 0.0041, 0.0033]) \n",
      "Test Loss tensor([0.0240, 0.0027, 0.0136, 0.0120, 0.0188, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.613419771194458 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0019, 0.0157, 0.0123, 0.0191, 0.0042, 0.0025]) \n",
      "Test Loss tensor([0.0231, 0.0026, 0.0134, 0.0116, 0.0191, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5965232849121094 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0024, 0.0145, 0.0119, 0.0206, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0246, 0.0025, 0.0132, 0.0121, 0.0200, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.686997652053833 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0024, 0.0119, 0.0120, 0.0181, 0.0047, 0.0030]) \n",
      "Test Loss tensor([0.0229, 0.0025, 0.0138, 0.0123, 0.0191, 0.0040, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.619497537612915 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0262, 0.0029, 0.0129, 0.0110, 0.0174, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0244, 0.0026, 0.0138, 0.0124, 0.0191, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6673338413238525 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0024, 0.0137, 0.0126, 0.0203, 0.0044, 0.0041]) \n",
      "Test Loss tensor([0.0244, 0.0026, 0.0139, 0.0119, 0.0193, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.601987361907959 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0197, 0.0020, 0.0140, 0.0125, 0.0193, 0.0045, 0.0036]) \n",
      "Test Loss tensor([0.0239, 0.0026, 0.0137, 0.0119, 0.0199, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5866200923919678 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0020, 0.0121, 0.0115, 0.0205, 0.0034, 0.0030]) \n",
      "Test Loss tensor([0.0241, 0.0027, 0.0137, 0.0121, 0.0189, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5852768421173096 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0275, 0.0022, 0.0136, 0.0131, 0.0188, 0.0043, 0.0034]) \n",
      "Test Loss tensor([0.0246, 0.0023, 0.0140, 0.0122, 0.0200, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6775784492492676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0021, 0.0131, 0.0119, 0.0206, 0.0038, 0.0030]) \n",
      "Test Loss tensor([0.0242, 0.0025, 0.0142, 0.0120, 0.0195, 0.0045, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 448 in 0.6340756416320801 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0027, 0.0123, 0.0106, 0.0187, 0.0032, 0.0034]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0143, 0.0118, 0.0191, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6105542182922363 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0023, 0.0131, 0.0127, 0.0211, 0.0042, 0.0032]) \n",
      "Test Loss tensor([0.0241, 0.0026, 0.0138, 0.0118, 0.0200, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6183638572692871 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0020, 0.0154, 0.0122, 0.0195, 0.0034, 0.0031]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0135, 0.0121, 0.0195, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6258502006530762 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0031, 0.0140, 0.0108, 0.0219, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0232, 0.0027, 0.0140, 0.0120, 0.0201, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7019252777099609 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0018, 0.0146, 0.0123, 0.0210, 0.0045, 0.0038]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0137, 0.0118, 0.0191, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6761975288391113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0019, 0.0135, 0.0126, 0.0219, 0.0050, 0.0042]) \n",
      "Test Loss tensor([0.0241, 0.0026, 0.0137, 0.0118, 0.0203, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7171986103057861 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0222, 0.0021, 0.0150, 0.0127, 0.0183, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0133, 0.0119, 0.0202, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.7278561592102051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0023, 0.0127, 0.0132, 0.0224, 0.0042, 0.0023]) \n",
      "Test Loss tensor([0.0233, 0.0026, 0.0136, 0.0117, 0.0199, 0.0040, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5927486419677734 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0022, 0.0130, 0.0120, 0.0200, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0255, 0.0025, 0.0136, 0.0120, 0.0206, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5998187065124512 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0019, 0.0132, 0.0112, 0.0207, 0.0040, 0.0028]) \n",
      "Test Loss tensor([0.0244, 0.0025, 0.0135, 0.0118, 0.0195, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5931706428527832 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0018, 0.0146, 0.0118, 0.0188, 0.0043, 0.0035]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0134, 0.0121, 0.0200, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5852835178375244 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0028, 0.0153, 0.0120, 0.0203, 0.0042, 0.0032]) \n",
      "Test Loss tensor([0.0242, 0.0025, 0.0137, 0.0120, 0.0192, 0.0045, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5839569568634033 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0032, 0.0133, 0.0124, 0.0212, 0.0035, 0.0043]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0133, 0.0120, 0.0197, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.5829389095306396 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0026, 0.0134, 0.0103, 0.0192, 0.0045, 0.0037]) \n",
      "Test Loss tensor([0.0237, 0.0026, 0.0133, 0.0119, 0.0194, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5844595432281494 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0028, 0.0145, 0.0127, 0.0218, 0.0032, 0.0041]) \n",
      "Test Loss tensor([0.0242, 0.0023, 0.0134, 0.0123, 0.0187, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5862035751342773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0205, 0.0022, 0.0132, 0.0129, 0.0200, 0.0045, 0.0031]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0132, 0.0116, 0.0188, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5840191841125488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0024, 0.0125, 0.0120, 0.0185, 0.0039, 0.0033]) \n",
      "Test Loss tensor([0.0226, 0.0025, 0.0134, 0.0115, 0.0189, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5778028964996338 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0020, 0.0129, 0.0132, 0.0200, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0137, 0.0119, 0.0196, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5780258178710938 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0218, 0.0020, 0.0142, 0.0121, 0.0208, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0230, 0.0024, 0.0133, 0.0123, 0.0188, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5975630283355713 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0025, 0.0148, 0.0127, 0.0190, 0.0036, 0.0035]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0133, 0.0118, 0.0192, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6327958106994629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0263, 0.0025, 0.0127, 0.0105, 0.0196, 0.0034, 0.0037]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0135, 0.0122, 0.0194, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6079668998718262 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0272, 0.0022, 0.0155, 0.0115, 0.0187, 0.0042, 0.0037]) \n",
      "Test Loss tensor([0.0230, 0.0024, 0.0134, 0.0119, 0.0197, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6358740329742432 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0021, 0.0114, 0.0122, 0.0201, 0.0043, 0.0031]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0133, 0.0119, 0.0197, 0.0046, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6033833026885986 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0210, 0.0026, 0.0148, 0.0107, 0.0194, 0.0043, 0.0027]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0135, 0.0121, 0.0192, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5978167057037354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0029, 0.0145, 0.0129, 0.0188, 0.0043, 0.0026]) \n",
      "Test Loss tensor([0.0243, 0.0024, 0.0134, 0.0120, 0.0199, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6162497997283936 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0024, 0.0138, 0.0119, 0.0215, 0.0041, 0.0039]) \n",
      "Test Loss tensor([0.0231, 0.0024, 0.0133, 0.0118, 0.0192, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6178545951843262 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0209, 0.0024, 0.0153, 0.0108, 0.0173, 0.0040, 0.0036]) \n",
      "Test Loss tensor([0.0231, 0.0026, 0.0136, 0.0120, 0.0185, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.595534086227417 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0219, 0.0029, 0.0143, 0.0122, 0.0172, 0.0038, 0.0035]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0136, 0.0122, 0.0193, 0.0039, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6425685882568359 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0027, 0.0139, 0.0118, 0.0169, 0.0029, 0.0029]) \n",
      "Test Loss tensor([0.0235, 0.0027, 0.0133, 0.0120, 0.0194, 0.0039, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6076416969299316 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0027, 0.0135, 0.0129, 0.0179, 0.0053, 0.0031]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0135, 0.0119, 0.0195, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.615412712097168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0027, 0.0127, 0.0119, 0.0194, 0.0051, 0.0041]) \n",
      "Test Loss tensor([0.0235, 0.0023, 0.0135, 0.0122, 0.0189, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.608858585357666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0021, 0.0128, 0.0110, 0.0217, 0.0046, 0.0042]) \n",
      "Test Loss tensor([0.0231, 0.0025, 0.0135, 0.0118, 0.0191, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.634380578994751 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0222, 0.0022, 0.0136, 0.0101, 0.0195, 0.0035, 0.0028]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0135, 0.0121, 0.0187, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6194503307342529 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0026, 0.0135, 0.0122, 0.0180, 0.0055, 0.0034]) \n",
      "Test Loss tensor([0.0245, 0.0023, 0.0134, 0.0123, 0.0194, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6201720237731934 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0218, 0.0025, 0.0158, 0.0130, 0.0169, 0.0045, 0.0033]) \n",
      "Test Loss tensor([0.0239, 0.0022, 0.0133, 0.0121, 0.0189, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6379473209381104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0023, 0.0141, 0.0105, 0.0181, 0.0044, 0.0027]) \n",
      "Test Loss tensor([0.0247, 0.0024, 0.0134, 0.0120, 0.0193, 0.0041, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 592 in 0.6216862201690674 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0018, 0.0138, 0.0111, 0.0211, 0.0060, 0.0029]) \n",
      "Test Loss tensor([0.0237, 0.0024, 0.0132, 0.0119, 0.0188, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6177694797515869 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0022, 0.0147, 0.0127, 0.0200, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0241, 0.0026, 0.0137, 0.0121, 0.0193, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6031057834625244 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0022, 0.0136, 0.0127, 0.0166, 0.0039, 0.0039]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0133, 0.0120, 0.0186, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6119921207427979 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0024, 0.0128, 0.0112, 0.0176, 0.0035, 0.0037]) \n",
      "Test Loss tensor([0.0237, 0.0025, 0.0136, 0.0115, 0.0188, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5993902683258057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0027, 0.0129, 0.0113, 0.0181, 0.0029, 0.0030]) \n",
      "Test Loss tensor([0.0243, 0.0025, 0.0138, 0.0118, 0.0186, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6101324558258057 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0024, 0.0136, 0.0119, 0.0194, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0137, 0.0118, 0.0197, 0.0039, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5945549011230469 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0027, 0.0138, 0.0110, 0.0198, 0.0045, 0.0031]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0132, 0.0120, 0.0195, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6107652187347412 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0209, 0.0019, 0.0117, 0.0114, 0.0212, 0.0033, 0.0028]) \n",
      "Test Loss tensor([0.0231, 0.0023, 0.0136, 0.0118, 0.0189, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6004254817962646 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0018, 0.0136, 0.0114, 0.0178, 0.0034, 0.0032]) \n",
      "Test Loss tensor([0.0240, 0.0022, 0.0139, 0.0121, 0.0195, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6125838756561279 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0023, 0.0133, 0.0126, 0.0178, 0.0040, 0.0036]) \n",
      "Test Loss tensor([0.0246, 0.0027, 0.0139, 0.0119, 0.0193, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6244692802429199 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0019, 0.0138, 0.0114, 0.0173, 0.0030, 0.0034]) \n",
      "Test Loss tensor([0.0235, 0.0023, 0.0137, 0.0118, 0.0188, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5993998050689697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0022, 0.0119, 0.0105, 0.0178, 0.0046, 0.0038]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0137, 0.0117, 0.0185, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6113770008087158 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0024, 0.0145, 0.0122, 0.0193, 0.0039, 0.0027]) \n",
      "Test Loss tensor([0.0243, 0.0024, 0.0135, 0.0117, 0.0184, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6268482208251953 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0021, 0.0141, 0.0122, 0.0184, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0138, 0.0118, 0.0191, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6313564777374268 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0219, 0.0021, 0.0131, 0.0123, 0.0193, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0241, 0.0024, 0.0133, 0.0120, 0.0193, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.605783224105835 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0213, 0.0027, 0.0118, 0.0131, 0.0177, 0.0035, 0.0031]) \n",
      "Test Loss tensor([0.0228, 0.0026, 0.0138, 0.0119, 0.0182, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6380462646484375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0030, 0.0127, 0.0113, 0.0202, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0229, 0.0023, 0.0136, 0.0121, 0.0197, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5999798774719238 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0024, 0.0136, 0.0123, 0.0194, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0236, 0.0026, 0.0135, 0.0117, 0.0188, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5997865200042725 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0020, 0.0152, 0.0125, 0.0208, 0.0037, 0.0036]) \n",
      "Test Loss tensor([0.0239, 0.0024, 0.0131, 0.0118, 0.0191, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6360793113708496 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0024, 0.0128, 0.0123, 0.0176, 0.0036, 0.0027]) \n",
      "Test Loss tensor([0.0240, 0.0026, 0.0137, 0.0119, 0.0200, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5937299728393555 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0025, 0.0131, 0.0119, 0.0168, 0.0038, 0.0037]) \n",
      "Test Loss tensor([0.0238, 0.0025, 0.0137, 0.0122, 0.0187, 0.0046, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.620642900466919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0222, 0.0026, 0.0126, 0.0122, 0.0194, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0144, 0.0119, 0.0195, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6694557666778564 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0025, 0.0126, 0.0128, 0.0212, 0.0039, 0.0026]) \n",
      "Test Loss tensor([0.0232, 0.0023, 0.0136, 0.0119, 0.0193, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6018223762512207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0236, 0.0025, 0.0135, 0.0114, 0.0195, 0.0042, 0.0034]) \n",
      "Test Loss tensor([0.0234, 0.0024, 0.0139, 0.0122, 0.0195, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6320290565490723 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0019, 0.0124, 0.0133, 0.0205, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0222, 0.0029, 0.0135, 0.0116, 0.0188, 0.0040, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6546871662139893 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0274, 0.0030, 0.0154, 0.0121, 0.0167, 0.0053, 0.0042]) \n",
      "Test Loss tensor([0.0233, 0.0024, 0.0131, 0.0118, 0.0189, 0.0043, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6272814273834229 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0026, 0.0144, 0.0123, 0.0196, 0.0043, 0.0031]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0134, 0.0118, 0.0189, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6154153347015381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0021, 0.0127, 0.0117, 0.0186, 0.0040, 0.0026]) \n",
      "Test Loss tensor([0.0232, 0.0025, 0.0136, 0.0121, 0.0188, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6164150238037109 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0033, 0.0134, 0.0108, 0.0180, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0234, 0.0022, 0.0131, 0.0123, 0.0190, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6274845600128174 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0025, 0.0129, 0.0113, 0.0193, 0.0036, 0.0023]) \n",
      "Test Loss tensor([0.0240, 0.0023, 0.0131, 0.0123, 0.0191, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6078028678894043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0031, 0.0125, 0.0124, 0.0190, 0.0034, 0.0034]) \n",
      "Test Loss tensor([0.0236, 0.0024, 0.0132, 0.0120, 0.0186, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6043624877929688 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0279, 0.0027, 0.0138, 0.0122, 0.0185, 0.0034, 0.0034]) \n",
      "Test Loss tensor([0.0235, 0.0027, 0.0135, 0.0118, 0.0191, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6233375072479248 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0267, 0.0029, 0.0146, 0.0115, 0.0185, 0.0048, 0.0034]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0135, 0.0123, 0.0181, 0.0040, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6010129451751709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0028, 0.0125, 0.0121, 0.0209, 0.0040, 0.0040]) \n",
      "Test Loss tensor([0.0236, 0.0024, 0.0134, 0.0119, 0.0191, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5910983085632324 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0020, 0.0119, 0.0121, 0.0191, 0.0035, 0.0030]) \n",
      "Test Loss tensor([0.0237, 0.0024, 0.0130, 0.0119, 0.0183, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5953788757324219 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0251, 0.0023, 0.0125, 0.0106, 0.0214, 0.0050, 0.0033]) \n",
      "Test Loss tensor([0.0230, 0.0026, 0.0131, 0.0120, 0.0186, 0.0046, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 736 in 0.6050400733947754 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0017, 0.0115, 0.0106, 0.0176, 0.0035, 0.0047]) \n",
      "Test Loss tensor([0.0232, 0.0025, 0.0135, 0.0118, 0.0185, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5937070846557617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0026, 0.0132, 0.0123, 0.0195, 0.0050, 0.0036]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0135, 0.0120, 0.0198, 0.0045, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6132700443267822 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0024, 0.0132, 0.0118, 0.0196, 0.0035, 0.0032]) \n",
      "Test Loss tensor([0.0230, 0.0023, 0.0131, 0.0116, 0.0184, 0.0042, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6304609775543213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0027, 0.0154, 0.0111, 0.0164, 0.0047, 0.0034]) \n",
      "Test Loss tensor([0.0240, 0.0025, 0.0138, 0.0116, 0.0187, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6011714935302734 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0022, 0.0150, 0.0126, 0.0185, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0225, 0.0026, 0.0134, 0.0118, 0.0183, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6181988716125488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0026, 0.0133, 0.0125, 0.0184, 0.0044, 0.0043]) \n",
      "Test Loss tensor([0.0240, 0.0023, 0.0137, 0.0123, 0.0192, 0.0037, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6814684867858887 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0203, 0.0019, 0.0127, 0.0118, 0.0222, 0.0049, 0.0033]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0135, 0.0121, 0.0193, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6088409423828125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0025, 0.0111, 0.0117, 0.0202, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0228, 0.0027, 0.0133, 0.0119, 0.0186, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6233272552490234 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0273, 0.0021, 0.0156, 0.0112, 0.0195, 0.0034, 0.0024]) \n",
      "Test Loss tensor([0.0235, 0.0023, 0.0133, 0.0120, 0.0200, 0.0042, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6279537677764893 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0023, 0.0136, 0.0113, 0.0182, 0.0035, 0.0024]) \n",
      "Test Loss tensor([0.0242, 0.0025, 0.0136, 0.0118, 0.0191, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6435914039611816 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0216, 0.0021, 0.0143, 0.0123, 0.0205, 0.0044, 0.0025]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0134, 0.0123, 0.0190, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6263442039489746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0024, 0.0129, 0.0115, 0.0217, 0.0033, 0.0038]) \n",
      "Test Loss tensor([0.0234, 0.0026, 0.0137, 0.0119, 0.0203, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6164543628692627 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0209, 0.0020, 0.0135, 0.0120, 0.0210, 0.0053, 0.0030]) \n",
      "Test Loss tensor([0.0234, 0.0027, 0.0134, 0.0119, 0.0192, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6301190853118896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0020, 0.0126, 0.0110, 0.0188, 0.0038, 0.0029]) \n",
      "Test Loss tensor([0.0230, 0.0025, 0.0132, 0.0119, 0.0201, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6350696086883545 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0278, 0.0029, 0.0156, 0.0118, 0.0192, 0.0036, 0.0036]) \n",
      "Test Loss tensor([0.0237, 0.0023, 0.0137, 0.0120, 0.0198, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6295619010925293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0023, 0.0152, 0.0121, 0.0194, 0.0043, 0.0037]) \n",
      "Test Loss tensor([0.0239, 0.0023, 0.0133, 0.0117, 0.0199, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6280646324157715 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0020, 0.0144, 0.0120, 0.0203, 0.0036, 0.0033]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0137, 0.0120, 0.0192, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6160109043121338 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0024, 0.0129, 0.0099, 0.0195, 0.0039, 0.0031]) \n",
      "Test Loss tensor([0.0236, 0.0023, 0.0137, 0.0118, 0.0189, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6320648193359375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0022, 0.0149, 0.0110, 0.0217, 0.0064, 0.0034]) \n",
      "Test Loss tensor([0.0239, 0.0025, 0.0134, 0.0120, 0.0194, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6245577335357666 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0027, 0.0162, 0.0116, 0.0196, 0.0039, 0.0029]) \n",
      "Test Loss tensor([0.0234, 0.0022, 0.0137, 0.0120, 0.0192, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5970385074615479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0022, 0.0141, 0.0122, 0.0193, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0134, 0.0120, 0.0215, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6205582618713379 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0024, 0.0135, 0.0113, 0.0217, 0.0045, 0.0027]) \n",
      "Test Loss tensor([0.0241, 0.0023, 0.0129, 0.0118, 0.0190, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6419198513031006 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0017, 0.0145, 0.0123, 0.0177, 0.0051, 0.0024]) \n",
      "Test Loss tensor([0.0227, 0.0026, 0.0135, 0.0121, 0.0206, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6080441474914551 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0022, 0.0137, 0.0111, 0.0189, 0.0053, 0.0046]) \n",
      "Test Loss tensor([0.0230, 0.0025, 0.0127, 0.0117, 0.0198, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6243698596954346 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0022, 0.0119, 0.0116, 0.0167, 0.0043, 0.0023]) \n",
      "Test Loss tensor([0.0231, 0.0025, 0.0135, 0.0118, 0.0192, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.614931583404541 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0030, 0.0139, 0.0108, 0.0205, 0.0053, 0.0032]) \n",
      "Test Loss tensor([0.0232, 0.0026, 0.0136, 0.0121, 0.0200, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6235666275024414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0206, 0.0026, 0.0130, 0.0094, 0.0183, 0.0048, 0.0034]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0138, 0.0121, 0.0194, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6333551406860352 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0220, 0.0026, 0.0156, 0.0129, 0.0204, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0242, 0.0023, 0.0126, 0.0118, 0.0215, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6055922508239746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0032, 0.0142, 0.0125, 0.0209, 0.0047, 0.0038]) \n",
      "Test Loss tensor([0.0238, 0.0024, 0.0133, 0.0119, 0.0182, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6029367446899414 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0023, 0.0132, 0.0124, 0.0190, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0141, 0.0120, 0.0215, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6139001846313477 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0281, 0.0024, 0.0148, 0.0116, 0.0202, 0.0045, 0.0025]) \n",
      "Test Loss tensor([0.0231, 0.0023, 0.0132, 0.0121, 0.0188, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6233251094818115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0021, 0.0142, 0.0118, 0.0213, 0.0041, 0.0037]) \n",
      "Test Loss tensor([0.0243, 0.0024, 0.0138, 0.0118, 0.0201, 0.0040, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6301400661468506 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0026, 0.0149, 0.0129, 0.0211, 0.0043, 0.0039]) \n",
      "Test Loss tensor([0.0231, 0.0024, 0.0134, 0.0119, 0.0193, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6202006340026855 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0021, 0.0132, 0.0121, 0.0194, 0.0048, 0.0035]) \n",
      "Test Loss tensor([0.0236, 0.0024, 0.0136, 0.0118, 0.0196, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6020455360412598 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0032, 0.0132, 0.0114, 0.0200, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0230, 0.0023, 0.0134, 0.0116, 0.0188, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5719752311706543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0187, 0.0017, 0.0089, 0.0080, 0.0129, 0.0041, 0.0031]) \n",
      "Test Loss tensor([0.0232, 0.0023, 0.0132, 0.0119, 0.0193, 0.0047, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.6701793670654297 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0025, 0.0138, 0.0124, 0.0175, 0.0040, 0.0038]) \n",
      "Test Loss tensor([0.0239, 0.0024, 0.0134, 0.0116, 0.0193, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6151421070098877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0246, 0.0021, 0.0133, 0.0121, 0.0206, 0.0038, 0.0036]) \n",
      "Test Loss tensor([0.0228, 0.0023, 0.0132, 0.0116, 0.0184, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6320090293884277 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0023, 0.0127, 0.0111, 0.0178, 0.0036, 0.0037]) \n",
      "Test Loss tensor([0.0225, 0.0026, 0.0132, 0.0118, 0.0192, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6259686946868896 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0029, 0.0146, 0.0126, 0.0180, 0.0037, 0.0035]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0133, 0.0118, 0.0185, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5997579097747803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0022, 0.0132, 0.0117, 0.0177, 0.0045, 0.0027]) \n",
      "Test Loss tensor([0.0244, 0.0023, 0.0131, 0.0121, 0.0188, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5990498065948486 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0026, 0.0150, 0.0111, 0.0208, 0.0041, 0.0028]) \n",
      "Test Loss tensor([0.0232, 0.0025, 0.0131, 0.0117, 0.0184, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6008360385894775 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0025, 0.0125, 0.0134, 0.0176, 0.0043, 0.0026]) \n",
      "Test Loss tensor([0.0237, 0.0025, 0.0134, 0.0117, 0.0187, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6238839626312256 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0210, 0.0018, 0.0131, 0.0116, 0.0157, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0137, 0.0118, 0.0178, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6218430995941162 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0024, 0.0134, 0.0109, 0.0196, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0136, 0.0117, 0.0187, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6053545475006104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0020, 0.0135, 0.0116, 0.0187, 0.0035, 0.0037]) \n",
      "Test Loss tensor([0.0234, 0.0025, 0.0133, 0.0116, 0.0183, 0.0046, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6148617267608643 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0023, 0.0128, 0.0121, 0.0199, 0.0035, 0.0032]) \n",
      "Test Loss tensor([0.0235, 0.0026, 0.0136, 0.0119, 0.0188, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6058018207550049 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0193, 0.0025, 0.0133, 0.0106, 0.0165, 0.0040, 0.0030]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0130, 0.0122, 0.0188, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6409590244293213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0021, 0.0119, 0.0124, 0.0178, 0.0042, 0.0025]) \n",
      "Test Loss tensor([0.0234, 0.0026, 0.0136, 0.0118, 0.0190, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6118528842926025 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0018, 0.0156, 0.0114, 0.0169, 0.0040, 0.0035]) \n",
      "Test Loss tensor([0.0241, 0.0025, 0.0129, 0.0115, 0.0186, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6195363998413086 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0021, 0.0120, 0.0113, 0.0205, 0.0035, 0.0040]) \n",
      "Test Loss tensor([0.0226, 0.0024, 0.0136, 0.0120, 0.0181, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6077704429626465 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0018, 0.0124, 0.0111, 0.0180, 0.0047, 0.0031]) \n",
      "Test Loss tensor([0.0242, 0.0026, 0.0136, 0.0117, 0.0182, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6262850761413574 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0216, 0.0026, 0.0119, 0.0106, 0.0175, 0.0048, 0.0030]) \n",
      "Test Loss tensor([0.0230, 0.0025, 0.0136, 0.0117, 0.0180, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.5990157127380371 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0224, 0.0025, 0.0134, 0.0109, 0.0189, 0.0040, 0.0024]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0132, 0.0116, 0.0186, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6135165691375732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0029, 0.0141, 0.0102, 0.0189, 0.0045, 0.0045]) \n",
      "Test Loss tensor([0.0231, 0.0026, 0.0134, 0.0116, 0.0182, 0.0046, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6077170372009277 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0260, 0.0026, 0.0137, 0.0111, 0.0170, 0.0040, 0.0044]) \n",
      "Test Loss tensor([0.0230, 0.0024, 0.0130, 0.0121, 0.0189, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6096885204315186 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0266, 0.0024, 0.0142, 0.0113, 0.0194, 0.0040, 0.0024]) \n",
      "Test Loss tensor([0.0226, 0.0025, 0.0135, 0.0118, 0.0190, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6078524589538574 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0020, 0.0142, 0.0123, 0.0201, 0.0042, 0.0031]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0128, 0.0118, 0.0189, 0.0038, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6212067604064941 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0022, 0.0146, 0.0128, 0.0187, 0.0032, 0.0037]) \n",
      "Test Loss tensor([0.0232, 0.0026, 0.0136, 0.0119, 0.0187, 0.0045, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6124992370605469 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0025, 0.0127, 0.0123, 0.0197, 0.0050, 0.0043]) \n",
      "Test Loss tensor([0.0232, 0.0026, 0.0133, 0.0118, 0.0182, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6237301826477051 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0020, 0.0134, 0.0114, 0.0183, 0.0039, 0.0025]) \n",
      "Test Loss tensor([0.0233, 0.0026, 0.0132, 0.0117, 0.0189, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6092400550842285 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0022, 0.0131, 0.0114, 0.0180, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0229, 0.0027, 0.0134, 0.0119, 0.0182, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.605083703994751 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0030, 0.0123, 0.0128, 0.0207, 0.0036, 0.0025]) \n",
      "Test Loss tensor([0.0226, 0.0024, 0.0131, 0.0114, 0.0186, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6091487407684326 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0024, 0.0136, 0.0116, 0.0183, 0.0041, 0.0027]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0135, 0.0119, 0.0190, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6012911796569824 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0028, 0.0135, 0.0137, 0.0176, 0.0037, 0.0039]) \n",
      "Test Loss tensor([0.0211, 0.0026, 0.0138, 0.0114, 0.0183, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6223936080932617 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0022, 0.0131, 0.0136, 0.0192, 0.0042, 0.0039]) \n",
      "Test Loss tensor([0.0235, 0.0026, 0.0132, 0.0118, 0.0185, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6321296691894531 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0025, 0.0140, 0.0118, 0.0194, 0.0043, 0.0033]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0140, 0.0121, 0.0189, 0.0042, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6583597660064697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0270, 0.0024, 0.0141, 0.0118, 0.0178, 0.0049, 0.0029]) \n",
      "Test Loss tensor([0.0229, 0.0026, 0.0128, 0.0117, 0.0190, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6329336166381836 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0021, 0.0163, 0.0132, 0.0177, 0.0036, 0.0029]) \n",
      "Test Loss tensor([0.0226, 0.0024, 0.0133, 0.0117, 0.0185, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6681044101715088 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0022, 0.0130, 0.0110, 0.0206, 0.0047, 0.0033]) \n",
      "Test Loss tensor([0.0224, 0.0027, 0.0133, 0.0117, 0.0187, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.605750322341919 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0024, 0.0135, 0.0111, 0.0178, 0.0041, 0.0037]) \n",
      "Test Loss tensor([0.0239, 0.0024, 0.0135, 0.0117, 0.0186, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7732231616973877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0029, 0.0138, 0.0120, 0.0190, 0.0039, 0.0033]) \n",
      "Test Loss tensor([0.0230, 0.0027, 0.0135, 0.0119, 0.0190, 0.0043, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 144 in 0.7200789451599121 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0027, 0.0143, 0.0127, 0.0195, 0.0055, 0.0028]) \n",
      "Test Loss tensor([0.0240, 0.0027, 0.0136, 0.0122, 0.0188, 0.0046, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6600124835968018 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0264, 0.0026, 0.0161, 0.0118, 0.0191, 0.0046, 0.0036]) \n",
      "Test Loss tensor([0.0231, 0.0027, 0.0131, 0.0118, 0.0199, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6389725208282471 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0201, 0.0024, 0.0144, 0.0115, 0.0198, 0.0035, 0.0029]) \n",
      "Test Loss tensor([0.0240, 0.0024, 0.0133, 0.0121, 0.0185, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6780378818511963 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0199, 0.0020, 0.0127, 0.0107, 0.0169, 0.0044, 0.0035]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0131, 0.0120, 0.0191, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6407690048217773 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0022, 0.0139, 0.0118, 0.0182, 0.0038, 0.0030]) \n",
      "Test Loss tensor([0.0226, 0.0026, 0.0135, 0.0117, 0.0188, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6441173553466797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0025, 0.0118, 0.0118, 0.0192, 0.0036, 0.0028]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0132, 0.0118, 0.0191, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7225668430328369 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0020, 0.0122, 0.0126, 0.0205, 0.0042, 0.0038]) \n",
      "Test Loss tensor([0.0234, 0.0027, 0.0134, 0.0122, 0.0189, 0.0047, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6612203121185303 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0019, 0.0131, 0.0110, 0.0197, 0.0035, 0.0027]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0134, 0.0121, 0.0185, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6942856311798096 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0219, 0.0024, 0.0121, 0.0107, 0.0211, 0.0045, 0.0025]) \n",
      "Test Loss tensor([0.0238, 0.0025, 0.0134, 0.0122, 0.0183, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6667826175689697 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0022, 0.0122, 0.0122, 0.0196, 0.0050, 0.0032]) \n",
      "Test Loss tensor([0.0228, 0.0026, 0.0134, 0.0120, 0.0189, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6226041316986084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0021, 0.0131, 0.0120, 0.0187, 0.0050, 0.0046]) \n",
      "Test Loss tensor([0.0224, 0.0025, 0.0138, 0.0121, 0.0187, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6657538414001465 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0021, 0.0137, 0.0118, 0.0191, 0.0036, 0.0026]) \n",
      "Test Loss tensor([0.0227, 0.0026, 0.0137, 0.0116, 0.0195, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6302053928375244 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0019, 0.0122, 0.0123, 0.0195, 0.0047, 0.0041]) \n",
      "Test Loss tensor([0.0229, 0.0025, 0.0134, 0.0117, 0.0185, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7027184963226318 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0257, 0.0018, 0.0133, 0.0122, 0.0172, 0.0044, 0.0033]) \n",
      "Test Loss tensor([0.0230, 0.0024, 0.0136, 0.0118, 0.0191, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6103782653808594 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0029, 0.0114, 0.0123, 0.0185, 0.0037, 0.0031]) \n",
      "Test Loss tensor([0.0233, 0.0023, 0.0137, 0.0121, 0.0192, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6058022975921631 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0023, 0.0144, 0.0116, 0.0181, 0.0037, 0.0033]) \n",
      "Test Loss tensor([0.0232, 0.0023, 0.0136, 0.0119, 0.0188, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6263866424560547 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0216, 0.0027, 0.0126, 0.0112, 0.0188, 0.0035, 0.0029]) \n",
      "Test Loss tensor([0.0226, 0.0025, 0.0134, 0.0120, 0.0191, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.607499361038208 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0017, 0.0119, 0.0118, 0.0194, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0135, 0.0120, 0.0184, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6006259918212891 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0022, 0.0142, 0.0121, 0.0177, 0.0035, 0.0033]) \n",
      "Test Loss tensor([0.0237, 0.0023, 0.0131, 0.0115, 0.0190, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6328389644622803 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0017, 0.0146, 0.0113, 0.0209, 0.0044, 0.0032]) \n",
      "Test Loss tensor([0.0229, 0.0026, 0.0129, 0.0119, 0.0188, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.636040210723877 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0201, 0.0022, 0.0134, 0.0123, 0.0159, 0.0042, 0.0023]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0133, 0.0118, 0.0186, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.583035945892334 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0200, 0.0021, 0.0141, 0.0132, 0.0192, 0.0036, 0.0029]) \n",
      "Test Loss tensor([0.0226, 0.0022, 0.0131, 0.0123, 0.0178, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5910792350769043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0029, 0.0116, 0.0122, 0.0156, 0.0039, 0.0026]) \n",
      "Test Loss tensor([0.0232, 0.0024, 0.0130, 0.0117, 0.0184, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5870535373687744 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0019, 0.0124, 0.0116, 0.0191, 0.0039, 0.0036]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0131, 0.0118, 0.0184, 0.0047, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5871362686157227 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0018, 0.0140, 0.0122, 0.0185, 0.0040, 0.0038]) \n",
      "Test Loss tensor([0.0234, 0.0026, 0.0134, 0.0120, 0.0181, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.584315299987793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0018, 0.0142, 0.0107, 0.0204, 0.0039, 0.0023]) \n",
      "Test Loss tensor([0.0219, 0.0025, 0.0130, 0.0118, 0.0196, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6062774658203125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0020, 0.0107, 0.0117, 0.0217, 0.0048, 0.0031]) \n",
      "Test Loss tensor([0.0226, 0.0026, 0.0133, 0.0118, 0.0186, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5863373279571533 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0268, 0.0019, 0.0124, 0.0119, 0.0179, 0.0047, 0.0028]) \n",
      "Test Loss tensor([0.0227, 0.0024, 0.0132, 0.0117, 0.0184, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5862987041473389 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0232, 0.0017, 0.0142, 0.0126, 0.0181, 0.0037, 0.0028]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0130, 0.0125, 0.0188, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5842409133911133 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0023, 0.0143, 0.0116, 0.0159, 0.0050, 0.0034]) \n",
      "Test Loss tensor([0.0220, 0.0026, 0.0134, 0.0118, 0.0188, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5869426727294922 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0207, 0.0025, 0.0135, 0.0114, 0.0171, 0.0040, 0.0035]) \n",
      "Test Loss tensor([0.0225, 0.0027, 0.0131, 0.0118, 0.0179, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5852680206298828 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0022, 0.0127, 0.0117, 0.0185, 0.0034, 0.0028]) \n",
      "Test Loss tensor([0.0229, 0.0023, 0.0136, 0.0120, 0.0181, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5875077247619629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0029, 0.0159, 0.0118, 0.0179, 0.0038, 0.0028]) \n",
      "Test Loss tensor([0.0221, 0.0024, 0.0133, 0.0115, 0.0187, 0.0040, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.585479736328125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0022, 0.0130, 0.0120, 0.0206, 0.0043, 0.0048]) \n",
      "Test Loss tensor([0.0231, 0.0022, 0.0127, 0.0121, 0.0183, 0.0045, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5847325325012207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0021, 0.0118, 0.0107, 0.0184, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0227, 0.0026, 0.0130, 0.0119, 0.0181, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.584010124206543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0021, 0.0147, 0.0130, 0.0183, 0.0039, 0.0028]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0133, 0.0121, 0.0186, 0.0043, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 288 in 0.5824322700500488 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0280, 0.0022, 0.0131, 0.0127, 0.0179, 0.0050, 0.0027]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0135, 0.0116, 0.0192, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5808489322662354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0201, 0.0018, 0.0136, 0.0117, 0.0189, 0.0047, 0.0036]) \n",
      "Test Loss tensor([0.0228, 0.0024, 0.0127, 0.0118, 0.0186, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5833225250244141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0031, 0.0131, 0.0131, 0.0182, 0.0037, 0.0032]) \n",
      "Test Loss tensor([0.0235, 0.0023, 0.0132, 0.0119, 0.0198, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5816233158111572 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0029, 0.0137, 0.0118, 0.0203, 0.0032, 0.0035]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0129, 0.0117, 0.0181, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5872836112976074 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0026, 0.0123, 0.0131, 0.0172, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0131, 0.0118, 0.0194, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5848543643951416 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0018, 0.0143, 0.0114, 0.0180, 0.0038, 0.0024]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0128, 0.0115, 0.0183, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5830063819885254 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0022, 0.0118, 0.0128, 0.0172, 0.0051, 0.0047]) \n",
      "Test Loss tensor([0.0234, 0.0022, 0.0130, 0.0120, 0.0184, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.592487096786499 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0032, 0.0115, 0.0116, 0.0184, 0.0048, 0.0036]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0134, 0.0118, 0.0189, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5846271514892578 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0025, 0.0131, 0.0131, 0.0196, 0.0039, 0.0030]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0133, 0.0115, 0.0180, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.619387149810791 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0222, 0.0021, 0.0125, 0.0111, 0.0191, 0.0041, 0.0029]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0130, 0.0118, 0.0184, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.606013298034668 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0029, 0.0138, 0.0120, 0.0184, 0.0050, 0.0033]) \n",
      "Test Loss tensor([0.0223, 0.0026, 0.0127, 0.0120, 0.0185, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7006845474243164 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0020, 0.0145, 0.0110, 0.0205, 0.0040, 0.0038]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0132, 0.0121, 0.0185, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6140997409820557 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0023, 0.0138, 0.0113, 0.0173, 0.0037, 0.0029]) \n",
      "Test Loss tensor([0.0233, 0.0023, 0.0131, 0.0117, 0.0184, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6245534420013428 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0205, 0.0021, 0.0122, 0.0114, 0.0184, 0.0041, 0.0037]) \n",
      "Test Loss tensor([0.0231, 0.0025, 0.0138, 0.0116, 0.0179, 0.0043, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5998029708862305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0034, 0.0136, 0.0120, 0.0181, 0.0047, 0.0028]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0133, 0.0123, 0.0186, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5965554714202881 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0023, 0.0139, 0.0113, 0.0182, 0.0046, 0.0037]) \n",
      "Test Loss tensor([0.0228, 0.0024, 0.0134, 0.0119, 0.0196, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.616809606552124 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0191, 0.0027, 0.0124, 0.0117, 0.0212, 0.0050, 0.0024]) \n",
      "Test Loss tensor([0.0222, 0.0022, 0.0127, 0.0117, 0.0182, 0.0043, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6098222732543945 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0224, 0.0019, 0.0141, 0.0116, 0.0174, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0221, 0.0024, 0.0129, 0.0116, 0.0187, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6049723625183105 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0030, 0.0130, 0.0123, 0.0194, 0.0038, 0.0035]) \n",
      "Test Loss tensor([0.0227, 0.0025, 0.0131, 0.0118, 0.0185, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6023635864257812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0021, 0.0140, 0.0118, 0.0185, 0.0042, 0.0031]) \n",
      "Test Loss tensor([0.0230, 0.0024, 0.0135, 0.0117, 0.0188, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6218507289886475 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0021, 0.0145, 0.0132, 0.0207, 0.0044, 0.0029]) \n",
      "Test Loss tensor([0.0225, 0.0023, 0.0131, 0.0118, 0.0185, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6341748237609863 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0025, 0.0120, 0.0112, 0.0191, 0.0057, 0.0036]) \n",
      "Test Loss tensor([0.0231, 0.0026, 0.0134, 0.0117, 0.0191, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6423935890197754 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0035, 0.0152, 0.0137, 0.0204, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0224, 0.0025, 0.0131, 0.0115, 0.0178, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6370923519134521 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0018, 0.0117, 0.0119, 0.0182, 0.0030, 0.0023]) \n",
      "Test Loss tensor([0.0227, 0.0025, 0.0130, 0.0121, 0.0183, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6385202407836914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0203, 0.0020, 0.0136, 0.0111, 0.0188, 0.0037, 0.0019]) \n",
      "Test Loss tensor([0.0232, 0.0022, 0.0128, 0.0117, 0.0178, 0.0043, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6325480937957764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0026, 0.0126, 0.0114, 0.0176, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0128, 0.0114, 0.0181, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6450047492980957 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0020, 0.0152, 0.0114, 0.0180, 0.0039, 0.0038]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0128, 0.0117, 0.0183, 0.0042, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.629265546798706 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0022, 0.0135, 0.0116, 0.0180, 0.0034, 0.0032]) \n",
      "Test Loss tensor([0.0231, 0.0026, 0.0129, 0.0117, 0.0182, 0.0041, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.608729362487793 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0254, 0.0022, 0.0132, 0.0108, 0.0196, 0.0034, 0.0036]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0131, 0.0121, 0.0184, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5983188152313232 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0227, 0.0026, 0.0125, 0.0121, 0.0194, 0.0046, 0.0027]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0133, 0.0114, 0.0184, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5968585014343262 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0019, 0.0124, 0.0131, 0.0219, 0.0040, 0.0031]) \n",
      "Test Loss tensor([0.0225, 0.0026, 0.0130, 0.0117, 0.0192, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5979094505310059 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0220, 0.0022, 0.0129, 0.0123, 0.0198, 0.0038, 0.0037]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0134, 0.0121, 0.0182, 0.0039, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6016960144042969 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0022, 0.0129, 0.0122, 0.0159, 0.0033, 0.0027]) \n",
      "Test Loss tensor([0.0233, 0.0024, 0.0131, 0.0120, 0.0185, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.63197922706604 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0220, 0.0021, 0.0142, 0.0125, 0.0187, 0.0037, 0.0033]) \n",
      "Test Loss tensor([0.0233, 0.0024, 0.0134, 0.0118, 0.0180, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6210289001464844 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0022, 0.0124, 0.0106, 0.0162, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0221, 0.0023, 0.0126, 0.0118, 0.0181, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6239993572235107 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0019, 0.0149, 0.0111, 0.0163, 0.0048, 0.0033]) \n",
      "Test Loss tensor([0.0226, 0.0025, 0.0135, 0.0120, 0.0179, 0.0042, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.6206610202789307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0023, 0.0148, 0.0131, 0.0181, 0.0044, 0.0034]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0127, 0.0116, 0.0174, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6292262077331543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0020, 0.0125, 0.0125, 0.0170, 0.0038, 0.0029]) \n",
      "Test Loss tensor([0.0230, 0.0026, 0.0132, 0.0119, 0.0183, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6340756416320801 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0213, 0.0019, 0.0130, 0.0116, 0.0198, 0.0035, 0.0031]) \n",
      "Test Loss tensor([0.0227, 0.0025, 0.0132, 0.0117, 0.0180, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6323986053466797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0028, 0.0109, 0.0116, 0.0180, 0.0040, 0.0034]) \n",
      "Test Loss tensor([0.0227, 0.0024, 0.0136, 0.0120, 0.0181, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.644221305847168 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0023, 0.0120, 0.0120, 0.0168, 0.0035, 0.0041]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0133, 0.0120, 0.0175, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6410031318664551 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0025, 0.0131, 0.0120, 0.0199, 0.0043, 0.0030]) \n",
      "Test Loss tensor([0.0219, 0.0023, 0.0129, 0.0117, 0.0201, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.624039888381958 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0225, 0.0020, 0.0137, 0.0121, 0.0172, 0.0041, 0.0035]) \n",
      "Test Loss tensor([0.0225, 0.0026, 0.0136, 0.0120, 0.0182, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6342475414276123 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0030, 0.0135, 0.0130, 0.0167, 0.0040, 0.0036]) \n",
      "Test Loss tensor([0.0230, 0.0023, 0.0128, 0.0118, 0.0204, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6256613731384277 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0023, 0.0138, 0.0126, 0.0226, 0.0039, 0.0031]) \n",
      "Test Loss tensor([0.0233, 0.0026, 0.0133, 0.0118, 0.0186, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6389472484588623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0256, 0.0024, 0.0145, 0.0114, 0.0158, 0.0048, 0.0031]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0128, 0.0118, 0.0183, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.631338357925415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0022, 0.0135, 0.0128, 0.0190, 0.0037, 0.0033]) \n",
      "Test Loss tensor([0.0230, 0.0026, 0.0131, 0.0118, 0.0192, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6188740730285645 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0029, 0.0125, 0.0124, 0.0177, 0.0044, 0.0036]) \n",
      "Test Loss tensor([0.0222, 0.0022, 0.0128, 0.0117, 0.0179, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6192550659179688 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0216, 0.0021, 0.0130, 0.0124, 0.0191, 0.0034, 0.0042]) \n",
      "Test Loss tensor([0.0225, 0.0025, 0.0127, 0.0117, 0.0187, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6338343620300293 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0259, 0.0021, 0.0138, 0.0107, 0.0193, 0.0030, 0.0028]) \n",
      "Test Loss tensor([0.0236, 0.0024, 0.0129, 0.0120, 0.0177, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6439812183380127 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0231, 0.0028, 0.0131, 0.0101, 0.0181, 0.0037, 0.0033]) \n",
      "Test Loss tensor([0.0215, 0.0025, 0.0131, 0.0118, 0.0176, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6419029235839844 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0022, 0.0120, 0.0130, 0.0156, 0.0038, 0.0034]) \n",
      "Test Loss tensor([0.0224, 0.0026, 0.0130, 0.0118, 0.0181, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6365525722503662 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0025, 0.0130, 0.0113, 0.0188, 0.0054, 0.0036]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0124, 0.0120, 0.0184, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6303279399871826 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0020, 0.0146, 0.0127, 0.0193, 0.0040, 0.0029]) \n",
      "Test Loss tensor([0.0231, 0.0024, 0.0131, 0.0119, 0.0184, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6242649555206299 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0024, 0.0135, 0.0112, 0.0188, 0.0050, 0.0029]) \n",
      "Test Loss tensor([0.0232, 0.0024, 0.0128, 0.0119, 0.0179, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6350255012512207 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0017, 0.0120, 0.0118, 0.0182, 0.0050, 0.0041]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0132, 0.0119, 0.0182, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6495552062988281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0227, 0.0026, 0.0134, 0.0107, 0.0173, 0.0049, 0.0032]) \n",
      "Test Loss tensor([0.0221, 0.0025, 0.0131, 0.0116, 0.0181, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6364021301269531 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0022, 0.0145, 0.0121, 0.0181, 0.0039, 0.0038]) \n",
      "Test Loss tensor([0.0229, 0.0023, 0.0134, 0.0118, 0.0181, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6087987422943115 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0261, 0.0017, 0.0140, 0.0106, 0.0190, 0.0040, 0.0033]) \n",
      "Test Loss tensor([0.0222, 0.0025, 0.0127, 0.0117, 0.0182, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5990808010101318 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0021, 0.0134, 0.0123, 0.0196, 0.0051, 0.0026]) \n",
      "Test Loss tensor([0.0222, 0.0025, 0.0131, 0.0114, 0.0174, 0.0040, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6012403964996338 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0206, 0.0027, 0.0138, 0.0114, 0.0193, 0.0037, 0.0027]) \n",
      "Test Loss tensor([0.0234, 0.0024, 0.0132, 0.0119, 0.0182, 0.0045, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.597681999206543 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0198, 0.0022, 0.0129, 0.0129, 0.0145, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0220, 0.0023, 0.0130, 0.0120, 0.0185, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6011760234832764 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0021, 0.0131, 0.0123, 0.0156, 0.0039, 0.0029]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0131, 0.0116, 0.0176, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5957193374633789 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0023, 0.0128, 0.0115, 0.0192, 0.0037, 0.0034]) \n",
      "Test Loss tensor([0.0224, 0.0024, 0.0132, 0.0121, 0.0178, 0.0043, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.59368896484375 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0248, 0.0025, 0.0122, 0.0114, 0.0182, 0.0055, 0.0029]) \n",
      "Test Loss tensor([0.0225, 0.0022, 0.0130, 0.0116, 0.0180, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5911791324615479 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0021, 0.0140, 0.0127, 0.0186, 0.0039, 0.0039]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0129, 0.0115, 0.0181, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5929548740386963 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0199, 0.0023, 0.0139, 0.0114, 0.0191, 0.0039, 0.0030]) \n",
      "Test Loss tensor([0.0222, 0.0024, 0.0130, 0.0117, 0.0185, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.597174882888794 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0018, 0.0136, 0.0110, 0.0191, 0.0045, 0.0032]) \n",
      "Test Loss tensor([0.0233, 0.0025, 0.0129, 0.0118, 0.0182, 0.0040, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5966458320617676 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0025, 0.0120, 0.0117, 0.0185, 0.0059, 0.0038]) \n",
      "Test Loss tensor([0.0222, 0.0024, 0.0132, 0.0123, 0.0178, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5962886810302734 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0025, 0.0119, 0.0123, 0.0180, 0.0035, 0.0037]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0130, 0.0116, 0.0185, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5970714092254639 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0022, 0.0137, 0.0108, 0.0201, 0.0051, 0.0034]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0130, 0.0117, 0.0182, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5959973335266113 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0027, 0.0133, 0.0103, 0.0174, 0.0067, 0.0031]) \n",
      "Test Loss tensor([0.0218, 0.0025, 0.0134, 0.0118, 0.0184, 0.0042, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 576 in 0.5957775115966797 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0245, 0.0019, 0.0130, 0.0112, 0.0172, 0.0046, 0.0033]) \n",
      "Test Loss tensor([0.0227, 0.0024, 0.0128, 0.0120, 0.0181, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6073315143585205 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0238, 0.0024, 0.0137, 0.0110, 0.0179, 0.0053, 0.0035]) \n",
      "Test Loss tensor([0.0229, 0.0026, 0.0128, 0.0114, 0.0186, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6494970321655273 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0226, 0.0025, 0.0138, 0.0113, 0.0176, 0.0034, 0.0027]) \n",
      "Test Loss tensor([0.0224, 0.0026, 0.0129, 0.0117, 0.0184, 0.0044, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5944309234619141 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0213, 0.0021, 0.0125, 0.0122, 0.0189, 0.0049, 0.0034]) \n",
      "Test Loss tensor([0.0235, 0.0024, 0.0132, 0.0118, 0.0177, 0.0043, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5912888050079346 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0276, 0.0026, 0.0117, 0.0115, 0.0188, 0.0045, 0.0042]) \n",
      "Test Loss tensor([0.0222, 0.0025, 0.0127, 0.0116, 0.0186, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5919716358184814 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0022, 0.0137, 0.0106, 0.0182, 0.0041, 0.0030]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0129, 0.0119, 0.0186, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5939161777496338 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0018, 0.0119, 0.0133, 0.0179, 0.0031, 0.0031]) \n",
      "Test Loss tensor([0.0226, 0.0026, 0.0134, 0.0118, 0.0182, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6123359203338623 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0023, 0.0151, 0.0118, 0.0181, 0.0036, 0.0035]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0134, 0.0116, 0.0186, 0.0039, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5983686447143555 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0018, 0.0136, 0.0109, 0.0194, 0.0050, 0.0038]) \n",
      "Test Loss tensor([0.0217, 0.0025, 0.0127, 0.0118, 0.0178, 0.0042, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5921816825866699 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0029, 0.0126, 0.0126, 0.0182, 0.0040, 0.0036]) \n",
      "Test Loss tensor([0.0223, 0.0025, 0.0132, 0.0118, 0.0175, 0.0039, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5909268856048584 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0021, 0.0122, 0.0121, 0.0171, 0.0037, 0.0035]) \n",
      "Test Loss tensor([0.0225, 0.0023, 0.0129, 0.0118, 0.0184, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.595360279083252 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0022, 0.0124, 0.0116, 0.0175, 0.0031, 0.0044]) \n",
      "Test Loss tensor([0.0229, 0.0025, 0.0133, 0.0118, 0.0178, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5950689315795898 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0024, 0.0136, 0.0129, 0.0212, 0.0043, 0.0029]) \n",
      "Test Loss tensor([0.0224, 0.0027, 0.0132, 0.0116, 0.0186, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6220290660858154 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0025, 0.0138, 0.0134, 0.0156, 0.0046, 0.0034]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0124, 0.0116, 0.0182, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 632 in 1.010887622833252 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0023, 0.0143, 0.0125, 0.0220, 0.0039, 0.0033]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0129, 0.0118, 0.0178, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6759765148162842 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0205, 0.0022, 0.0131, 0.0126, 0.0186, 0.0035, 0.0035]) \n",
      "Test Loss tensor([0.0230, 0.0025, 0.0131, 0.0118, 0.0179, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6616697311401367 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0242, 0.0026, 0.0137, 0.0120, 0.0167, 0.0050, 0.0038]) \n",
      "Test Loss tensor([0.0215, 0.0025, 0.0132, 0.0118, 0.0179, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6254317760467529 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0258, 0.0020, 0.0138, 0.0115, 0.0185, 0.0056, 0.0028]) \n",
      "Test Loss tensor([0.0226, 0.0023, 0.0125, 0.0121, 0.0182, 0.0039, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6230771541595459 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0206, 0.0028, 0.0125, 0.0123, 0.0206, 0.0035, 0.0034]) \n",
      "Test Loss tensor([0.0215, 0.0025, 0.0130, 0.0118, 0.0181, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.704458475112915 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0018, 0.0141, 0.0109, 0.0181, 0.0033, 0.0034]) \n",
      "Test Loss tensor([0.0236, 0.0025, 0.0130, 0.0115, 0.0183, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6034619808197021 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0230, 0.0020, 0.0129, 0.0115, 0.0161, 0.0038, 0.0035]) \n",
      "Test Loss tensor([0.0232, 0.0023, 0.0128, 0.0117, 0.0186, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6114616394042969 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0025, 0.0119, 0.0118, 0.0179, 0.0035, 0.0036]) \n",
      "Test Loss tensor([0.0221, 0.0025, 0.0127, 0.0116, 0.0181, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6117448806762695 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0249, 0.0028, 0.0144, 0.0109, 0.0179, 0.0042, 0.0030]) \n",
      "Test Loss tensor([0.0237, 0.0024, 0.0125, 0.0119, 0.0188, 0.0045, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6125509738922119 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0017, 0.0132, 0.0126, 0.0190, 0.0037, 0.0029]) \n",
      "Test Loss tensor([0.0225, 0.0023, 0.0126, 0.0119, 0.0178, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6027977466583252 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0020, 0.0135, 0.0117, 0.0184, 0.0039, 0.0034]) \n",
      "Test Loss tensor([0.0220, 0.0026, 0.0126, 0.0118, 0.0186, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.5985198020935059 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0207, 0.0021, 0.0128, 0.0125, 0.0209, 0.0052, 0.0025]) \n",
      "Test Loss tensor([0.0224, 0.0022, 0.0130, 0.0119, 0.0189, 0.0041, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5966343879699707 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0018, 0.0130, 0.0108, 0.0186, 0.0045, 0.0037]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0126, 0.0118, 0.0177, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6053144931793213 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0018, 0.0125, 0.0114, 0.0203, 0.0046, 0.0035]) \n",
      "Test Loss tensor([0.0218, 0.0026, 0.0129, 0.0118, 0.0202, 0.0040, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5992505550384521 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0020, 0.0137, 0.0112, 0.0194, 0.0041, 0.0029]) \n",
      "Test Loss tensor([0.0224, 0.0026, 0.0128, 0.0115, 0.0179, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6013946533203125 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0198, 0.0024, 0.0145, 0.0124, 0.0169, 0.0032, 0.0029]) \n",
      "Test Loss tensor([0.0223, 0.0026, 0.0129, 0.0116, 0.0191, 0.0043, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.60978102684021 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0218, 0.0022, 0.0132, 0.0138, 0.0185, 0.0032, 0.0032]) \n",
      "Test Loss tensor([0.0228, 0.0025, 0.0132, 0.0121, 0.0180, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6071827411651611 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0207, 0.0020, 0.0126, 0.0111, 0.0173, 0.0039, 0.0045]) \n",
      "Test Loss tensor([0.0226, 0.0022, 0.0130, 0.0123, 0.0179, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5978446006774902 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0024, 0.0139, 0.0120, 0.0194, 0.0042, 0.0029]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0129, 0.0117, 0.0193, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5957770347595215 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0021, 0.0127, 0.0123, 0.0189, 0.0039, 0.0024]) \n",
      "Test Loss tensor([0.0228, 0.0023, 0.0128, 0.0117, 0.0176, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5980880260467529 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0023, 0.0126, 0.0099, 0.0169, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0230, 0.0025, 0.0134, 0.0118, 0.0195, 0.0039, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5969071388244629 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0227, 0.0026, 0.0141, 0.0115, 0.0195, 0.0044, 0.0029]) \n",
      "Test Loss tensor([0.0229, 0.0024, 0.0135, 0.0118, 0.0184, 0.0044, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.5950043201446533 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0025, 0.0127, 0.0128, 0.0178, 0.0044, 0.0031]) \n",
      "Test Loss tensor([0.0222, 0.0027, 0.0132, 0.0116, 0.0178, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5931363105773926 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0026, 0.0132, 0.0111, 0.0195, 0.0039, 0.0035]) \n",
      "Test Loss tensor([0.0232, 0.0023, 0.0133, 0.0118, 0.0202, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5955290794372559 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0216, 0.0028, 0.0113, 0.0116, 0.0207, 0.0038, 0.0029]) \n",
      "Test Loss tensor([0.0228, 0.0023, 0.0135, 0.0120, 0.0172, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.596083402633667 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0023, 0.0144, 0.0117, 0.0184, 0.0049, 0.0037]) \n",
      "Test Loss tensor([0.0235, 0.0025, 0.0129, 0.0118, 0.0189, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.596184492111206 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0018, 0.0154, 0.0125, 0.0190, 0.0036, 0.0033]) \n",
      "Test Loss tensor([0.0227, 0.0023, 0.0125, 0.0120, 0.0185, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5945146083831787 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0219, 0.0022, 0.0116, 0.0128, 0.0184, 0.0039, 0.0026]) \n",
      "Test Loss tensor([0.0226, 0.0023, 0.0127, 0.0115, 0.0184, 0.0043, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5978391170501709 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0026, 0.0139, 0.0116, 0.0179, 0.0036, 0.0027]) \n",
      "Test Loss tensor([0.0223, 0.0026, 0.0124, 0.0115, 0.0184, 0.0045, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5947721004486084 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0025, 0.0138, 0.0121, 0.0175, 0.0042, 0.0026]) \n",
      "Test Loss tensor([0.0219, 0.0025, 0.0127, 0.0114, 0.0175, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5976753234863281 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0219, 0.0032, 0.0131, 0.0110, 0.0175, 0.0034, 0.0025]) \n",
      "Test Loss tensor([0.0223, 0.0025, 0.0125, 0.0116, 0.0184, 0.0041, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5923027992248535 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0247, 0.0018, 0.0132, 0.0109, 0.0187, 0.0037, 0.0033]) \n",
      "Test Loss tensor([0.0226, 0.0024, 0.0129, 0.0117, 0.0177, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5912454128265381 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0244, 0.0031, 0.0132, 0.0115, 0.0212, 0.0046, 0.0029]) \n",
      "Test Loss tensor([0.0221, 0.0026, 0.0129, 0.0117, 0.0175, 0.0044, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.595205545425415 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0212, 0.0022, 0.0131, 0.0117, 0.0184, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0125, 0.0117, 0.0178, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.5931410789489746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0214, 0.0018, 0.0111, 0.0116, 0.0172, 0.0048, 0.0036]) \n",
      "Test Loss tensor([0.0223, 0.0024, 0.0127, 0.0121, 0.0177, 0.0042, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5957956314086914 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0252, 0.0021, 0.0130, 0.0114, 0.0184, 0.0052, 0.0034]) \n",
      "Test Loss tensor([0.0230, 0.0026, 0.0128, 0.0119, 0.0179, 0.0044, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5963213443756104 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0239, 0.0026, 0.0133, 0.0113, 0.0187, 0.0045, 0.0043]) \n",
      "Test Loss tensor([0.0222, 0.0023, 0.0128, 0.0117, 0.0180, 0.0038, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6010386943817139 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0253, 0.0021, 0.0125, 0.0126, 0.0210, 0.0056, 0.0036]) \n",
      "Test Loss tensor([0.0211, 0.0025, 0.0132, 0.0119, 0.0183, 0.0039, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6066889762878418 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0235, 0.0026, 0.0123, 0.0116, 0.0208, 0.0039, 0.0028]) \n",
      "Test Loss tensor([0.0228, 0.0026, 0.0130, 0.0122, 0.0181, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6023044586181641 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0021, 0.0143, 0.0108, 0.0171, 0.0034, 0.0025]) \n",
      "Test Loss tensor([0.0219, 0.0027, 0.0128, 0.0115, 0.0182, 0.0042, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5998897552490234 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0243, 0.0022, 0.0140, 0.0125, 0.0203, 0.0054, 0.0034]) \n",
      "Test Loss tensor([0.0234, 0.0024, 0.0126, 0.0119, 0.0188, 0.0039, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6046156883239746 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0223, 0.0022, 0.0115, 0.0107, 0.0192, 0.0039, 0.0032]) \n",
      "Test Loss tensor([0.0226, 0.0022, 0.0128, 0.0116, 0.0185, 0.0040, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5955793857574463 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0233, 0.0025, 0.0126, 0.0109, 0.0199, 0.0047, 0.0027]) \n",
      "Test Loss tensor([0.0217, 0.0025, 0.0130, 0.0115, 0.0174, 0.0042, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5974938869476318 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0215, 0.0030, 0.0125, 0.0124, 0.0193, 0.0056, 0.0029]) \n",
      "Test Loss tensor([0.0230, 0.0023, 0.0131, 0.0115, 0.0199, 0.0040, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.596872091293335 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0217, 0.0028, 0.0139, 0.0121, 0.0214, 0.0044, 0.0030]) \n",
      "Test Loss tensor([0.0216, 0.0024, 0.0128, 0.0113, 0.0184, 0.0040, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.5954201221466064 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0250, 0.0019, 0.0126, 0.0117, 0.0165, 0.0041, 0.0032]) \n",
      "Test Loss tensor([0.0225, 0.0022, 0.0134, 0.0116, 0.0191, 0.0040, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5924139022827148 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0221, 0.0018, 0.0137, 0.0114, 0.0171, 0.0039, 0.0037]) \n",
      "Test Loss tensor([0.0215, 0.0023, 0.0131, 0.0117, 0.0186, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5926382541656494 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0234, 0.0024, 0.0129, 0.0115, 0.0180, 0.0041, 0.0031]) \n",
      "Test Loss tensor([0.0219, 0.0024, 0.0126, 0.0118, 0.0184, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.5988624095916748 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0237, 0.0025, 0.0120, 0.0108, 0.0183, 0.0043, 0.0032]) \n",
      "Test Loss tensor([0.0213, 0.0026, 0.0130, 0.0112, 0.0184, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.5938186645507812 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0210, 0.0023, 0.0111, 0.0117, 0.0175, 0.0051, 0.0035]) \n",
      "Test Loss tensor([0.0228, 0.0023, 0.0127, 0.0119, 0.0180, 0.0042, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6207926273345947 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0191, 0.0024, 0.0117, 0.0121, 0.0166, 0.0056, 0.0023]) \n",
      "Test Loss tensor([0.0222, 0.0024, 0.0124, 0.0122, 0.0187, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6153948307037354 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0211, 0.0029, 0.0122, 0.0116, 0.0183, 0.0033, 0.0027]) \n",
      "Test Loss tensor([0.0224, 0.0022, 0.0125, 0.0118, 0.0172, 0.0041, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6099765300750732 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0021, 0.0110, 0.0108, 0.0186, 0.0036, 0.0025]) \n",
      "Test Loss tensor([0.0223, 0.0026, 0.0129, 0.0117, 0.0181, 0.0039, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6079816818237305 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0024, 0.0126, 0.0116, 0.0193, 0.0041, 0.0043]) \n",
      "Test Loss tensor([0.0220, 0.0025, 0.0129, 0.0118, 0.0183, 0.0042, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6082098484039307 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0240, 0.0023, 0.0134, 0.0113, 0.0172, 0.0045, 0.0035]) \n",
      "Test Loss tensor([0.0221, 0.0025, 0.0124, 0.0116, 0.0184, 0.0044, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6844227313995361 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0208, 0.0029, 0.0137, 0.0123, 0.0176, 0.0046, 0.0032]) \n",
      "Test Loss tensor([0.0223, 0.0023, 0.0130, 0.0114, 0.0172, 0.0042, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.7734863758087158 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0255, 0.0026, 0.0126, 0.0114, 0.0202, 0.0036, 0.0032]) \n",
      "Test Loss tensor([0.0225, 0.0024, 0.0127, 0.0116, 0.0182, 0.0043, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6513838768005371 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0228, 0.0024, 0.0148, 0.0114, 0.0199, 0.0033, 0.0026]) \n",
      "Test Loss tensor([0.0218, 0.0025, 0.0131, 0.0116, 0.0186, 0.0042, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.6770203113555908 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0229, 0.0036, 0.0130, 0.0112, 0.0195, 0.0042, 0.0025]) \n",
      "Test Loss tensor([0.0225, 0.0026, 0.0132, 0.0118, 0.0178, 0.0044, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6490626335144043 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0241, 0.0017, 0.0127, 0.0125, 0.0165, 0.0036, 0.0026]) \n",
      "Test Loss tensor([0.0221, 0.0023, 0.0131, 0.0119, 0.0188, 0.0041, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.7926678657531738 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0207, 0.0025, 0.0112, 0.0102, 0.0164, 0.0038, 0.0032]) \n",
      "Test Loss tensor([0.0218, 0.0026, 0.0130, 0.0117, 0.0176, 0.0041, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6332883834838867 **************\n",
      "\n",
      "Training Idx 4 \n",
      "Train Loss tensor([0.0184, 0.0021, 0.0088, 0.0088, 0.0113, 0.0037, 0.0027]) \n",
      "Test Loss tensor([0.0227, 0.0026, 0.0128, 0.0118, 0.0187, 0.0041, 0.0032])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.6741514205932617 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3793, 0.4733, 0.3819, 0.3850, 0.4442, 0.4876, 0.5393]) \n",
      "Test Loss tensor([0.3776, 0.4736, 0.3813, 0.3838, 0.4434, 0.4891, 0.5408])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6224839687347412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3775, 0.4714, 0.3807, 0.3830, 0.4429, 0.4883, 0.5424]) \n",
      "Test Loss tensor([0.3763, 0.4753, 0.3797, 0.3827, 0.4434, 0.4893, 0.5424])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6222541332244873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3769, 0.4786, 0.3785, 0.3808, 0.4426, 0.4875, 0.5427]) \n",
      "Test Loss tensor([0.3754, 0.4742, 0.3786, 0.3809, 0.4442, 0.4913, 0.5431])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6793527603149414 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3750, 0.4792, 0.3770, 0.3810, 0.4415, 0.4898, 0.5447]) \n",
      "Test Loss tensor([0.3734, 0.4774, 0.3775, 0.3798, 0.4436, 0.4924, 0.5445])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6443796157836914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3728, 0.4762, 0.3784, 0.3802, 0.4426, 0.4910, 0.5456]) \n",
      "Test Loss tensor([0.3727, 0.4769, 0.3760, 0.3791, 0.4441, 0.4925, 0.5466])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.636486291885376 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3724, 0.4793, 0.3765, 0.3778, 0.4448, 0.4907, 0.5468]) \n",
      "Test Loss tensor([0.3709, 0.4787, 0.3754, 0.3780, 0.4457, 0.4939, 0.5470])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6531450748443604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3715, 0.4808, 0.3744, 0.3772, 0.4469, 0.4931, 0.5473]) \n",
      "Test Loss tensor([0.3695, 0.4791, 0.3737, 0.3772, 0.4452, 0.4950, 0.5486])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6381721496582031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3690, 0.4762, 0.3719, 0.3777, 0.4484, 0.4935, 0.5502]) \n",
      "Test Loss tensor([0.3687, 0.4806, 0.3725, 0.3761, 0.4460, 0.4947, 0.5503])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6107151508331299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3689, 0.4800, 0.3715, 0.3761, 0.4460, 0.4953, 0.5487]) \n",
      "Test Loss tensor([0.3678, 0.4815, 0.3715, 0.3749, 0.4467, 0.4959, 0.5511])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.609605073928833 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3686, 0.4833, 0.3701, 0.3746, 0.4443, 0.4975, 0.5507]) \n",
      "Test Loss tensor([0.3667, 0.4823, 0.3709, 0.3740, 0.4462, 0.4975, 0.5515])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6485559940338135 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3655, 0.4777, 0.3708, 0.3732, 0.4488, 0.4983, 0.5528]) \n",
      "Test Loss tensor([0.3658, 0.4832, 0.3696, 0.3731, 0.4472, 0.4977, 0.5530])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6914277076721191 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3664, 0.4851, 0.3688, 0.3744, 0.4444, 0.4956, 0.5537]) \n",
      "Test Loss tensor([0.3650, 0.4832, 0.3692, 0.3728, 0.4469, 0.4964, 0.5538])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.720649003982544 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3646, 0.4827, 0.3700, 0.3740, 0.4418, 0.4984, 0.5522]) \n",
      "Test Loss tensor([0.3641, 0.4828, 0.3685, 0.3718, 0.4474, 0.5004, 0.5543])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.698859691619873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3629, 0.4814, 0.3683, 0.3706, 0.4446, 0.4990, 0.5548]) \n",
      "Test Loss tensor([0.3634, 0.4844, 0.3680, 0.3714, 0.4470, 0.4991, 0.5549])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6278870105743408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3639, 0.4864, 0.3681, 0.3705, 0.4492, 0.5002, 0.5570]) \n",
      "Test Loss tensor([0.3627, 0.4839, 0.3672, 0.3710, 0.4473, 0.4996, 0.5563])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6868855953216553 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3625, 0.4841, 0.3663, 0.3690, 0.4464, 0.5018, 0.5564]) \n",
      "Test Loss tensor([0.3620, 0.4850, 0.3665, 0.3705, 0.4478, 0.5001, 0.5571])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7413091659545898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3632, 0.4809, 0.3671, 0.3695, 0.4493, 0.4972, 0.5578]) \n",
      "Test Loss tensor([0.3614, 0.4860, 0.3654, 0.3697, 0.4473, 0.5003, 0.5578])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7222812175750732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3614, 0.4883, 0.3658, 0.3710, 0.4473, 0.4988, 0.5568]) \n",
      "Test Loss tensor([0.3611, 0.4862, 0.3660, 0.3691, 0.4480, 0.5012, 0.5569])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6980998516082764 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3613, 0.4879, 0.3652, 0.3699, 0.4448, 0.5015, 0.5581]) \n",
      "Test Loss tensor([0.3608, 0.4866, 0.3654, 0.3693, 0.4479, 0.5008, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7025113105773926 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3623, 0.4837, 0.3666, 0.3695, 0.4506, 0.4960, 0.5561]) \n",
      "Test Loss tensor([0.3607, 0.4854, 0.3653, 0.3689, 0.4473, 0.5008, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6955702304840088 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3618, 0.4887, 0.3640, 0.3680, 0.4486, 0.5040, 0.5578]) \n",
      "Test Loss tensor([0.3601, 0.4871, 0.3652, 0.3684, 0.4488, 0.5010, 0.5576])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6519742012023926 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3601, 0.4894, 0.3646, 0.3707, 0.4492, 0.5050, 0.5593]) \n",
      "Test Loss tensor([0.3603, 0.4868, 0.3646, 0.3682, 0.4475, 0.5002, 0.5587])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.75003981590271 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3608, 0.4835, 0.3656, 0.3693, 0.4530, 0.5016, 0.5588]) \n",
      "Test Loss tensor([0.3603, 0.4862, 0.3652, 0.3684, 0.4480, 0.5015, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7727828025817871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3582, 0.4838, 0.3652, 0.3682, 0.4488, 0.4994, 0.5569]) \n",
      "Test Loss tensor([0.3597, 0.4865, 0.3653, 0.3684, 0.4480, 0.5013, 0.5586])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.776681661605835 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3605, 0.4860, 0.3659, 0.3683, 0.4466, 0.5023, 0.5598]) \n",
      "Test Loss tensor([0.3602, 0.4868, 0.3651, 0.3683, 0.4486, 0.5014, 0.5586])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7748332023620605 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3597, 0.4908, 0.3639, 0.3681, 0.4477, 0.5046, 0.5599]) \n",
      "Test Loss tensor([0.3597, 0.4866, 0.3646, 0.3687, 0.4471, 0.5017, 0.5587])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6291801929473877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3592, 0.4862, 0.3647, 0.3668, 0.4486, 0.4999, 0.5588]) \n",
      "Test Loss tensor([0.3596, 0.4862, 0.3648, 0.3680, 0.4490, 0.5014, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6291608810424805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3594, 0.4858, 0.3641, 0.3718, 0.4477, 0.5053, 0.5583]) \n",
      "Test Loss tensor([0.3600, 0.4868, 0.3645, 0.3684, 0.4487, 0.5016, 0.5587])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6305677890777588 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3600, 0.4856, 0.3652, 0.3684, 0.4508, 0.4995, 0.5572]) \n",
      "Test Loss tensor([0.3598, 0.4869, 0.3645, 0.3683, 0.4475, 0.5012, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6544647216796875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3606, 0.4894, 0.3637, 0.3670, 0.4487, 0.5029, 0.5607]) \n",
      "Test Loss tensor([0.3600, 0.4862, 0.3647, 0.3684, 0.4487, 0.5007, 0.5581])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6537177562713623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3591, 0.4860, 0.3644, 0.3698, 0.4512, 0.5015, 0.5583]) \n",
      "Test Loss tensor([0.3599, 0.4865, 0.3647, 0.3682, 0.4487, 0.5029, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6502089500427246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3605, 0.4888, 0.3641, 0.3691, 0.4508, 0.5001, 0.5578]) \n",
      "Test Loss tensor([0.3600, 0.4866, 0.3649, 0.3683, 0.4488, 0.5007, 0.5586])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6257181167602539 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3600, 0.4808, 0.3651, 0.3677, 0.4469, 0.5031, 0.5594]) \n",
      "Test Loss tensor([0.3597, 0.4869, 0.3644, 0.3682, 0.4484, 0.5013, 0.5581])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.614980936050415 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3605, 0.4867, 0.3646, 0.3686, 0.4494, 0.4988, 0.5581]) \n",
      "Test Loss tensor([0.3599, 0.4877, 0.3651, 0.3691, 0.4493, 0.5016, 0.5586])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6103236675262451 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3595, 0.4889, 0.3647, 0.3673, 0.4532, 0.5007, 0.5586]) \n",
      "Test Loss tensor([0.3596, 0.4876, 0.3645, 0.3689, 0.4494, 0.5013, 0.5588])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6375443935394287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3607, 0.4830, 0.3648, 0.3706, 0.4420, 0.5026, 0.5600]) \n",
      "Test Loss tensor([0.3598, 0.4867, 0.3647, 0.3686, 0.4489, 0.5003, 0.5585])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 144 in 0.6778066158294678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3589, 0.4843, 0.3650, 0.3697, 0.4479, 0.4969, 0.5583]) \n",
      "Test Loss tensor([0.3599, 0.4870, 0.3648, 0.3685, 0.4473, 0.5012, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.830371618270874 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3588, 0.4827, 0.3657, 0.3692, 0.4463, 0.5069, 0.5591]) \n",
      "Test Loss tensor([0.3596, 0.4862, 0.3650, 0.3683, 0.4492, 0.5009, 0.5586])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.647775411605835 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3600, 0.4849, 0.3644, 0.3679, 0.4473, 0.5015, 0.5599]) \n",
      "Test Loss tensor([0.3594, 0.4862, 0.3647, 0.3681, 0.4473, 0.5023, 0.5585])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6185531616210938 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3606, 0.4844, 0.3632, 0.3704, 0.4505, 0.5021, 0.5594]) \n",
      "Test Loss tensor([0.3595, 0.4870, 0.3644, 0.3687, 0.4487, 0.5014, 0.5585])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6532251834869385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3589, 0.4862, 0.3644, 0.3686, 0.4448, 0.5017, 0.5606]) \n",
      "Test Loss tensor([0.3594, 0.4869, 0.3651, 0.3685, 0.4484, 0.5015, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6592178344726562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3586, 0.4830, 0.3647, 0.3691, 0.4453, 0.5035, 0.5595]) \n",
      "Test Loss tensor([0.3594, 0.4877, 0.3651, 0.3688, 0.4486, 0.5006, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6082282066345215 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3586, 0.4898, 0.3656, 0.3705, 0.4490, 0.4988, 0.5581]) \n",
      "Test Loss tensor([0.3597, 0.4860, 0.3653, 0.3687, 0.4482, 0.5011, 0.5574])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6187355518341064 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3593, 0.4864, 0.3647, 0.3678, 0.4462, 0.4995, 0.5566]) \n",
      "Test Loss tensor([0.3599, 0.4853, 0.3655, 0.3686, 0.4481, 0.4999, 0.5578])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6217994689941406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3598, 0.4843, 0.3647, 0.3692, 0.4511, 0.5003, 0.5587]) \n",
      "Test Loss tensor([0.3598, 0.4861, 0.3655, 0.3694, 0.4477, 0.5017, 0.5579])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6262598037719727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3599, 0.4841, 0.3653, 0.3681, 0.4469, 0.5006, 0.5588]) \n",
      "Test Loss tensor([0.3600, 0.4867, 0.3656, 0.3690, 0.4473, 0.4996, 0.5575])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6307709217071533 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3593, 0.4845, 0.3657, 0.3718, 0.4551, 0.5020, 0.5582]) \n",
      "Test Loss tensor([0.3599, 0.4862, 0.3665, 0.3693, 0.4474, 0.5006, 0.5570])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6508116722106934 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3600, 0.4818, 0.3670, 0.3688, 0.4442, 0.5051, 0.5578]) \n",
      "Test Loss tensor([0.3602, 0.4867, 0.3659, 0.3697, 0.4492, 0.4996, 0.5569])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6360831260681152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3602, 0.4869, 0.3645, 0.3694, 0.4439, 0.4993, 0.5575]) \n",
      "Test Loss tensor([0.3600, 0.4858, 0.3665, 0.3691, 0.4491, 0.4998, 0.5565])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6306092739105225 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3608, 0.4843, 0.3665, 0.3686, 0.4432, 0.4998, 0.5597]) \n",
      "Test Loss tensor([0.3595, 0.4861, 0.3659, 0.3694, 0.4469, 0.5016, 0.5573])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6261639595031738 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3596, 0.4817, 0.3638, 0.3689, 0.4516, 0.4979, 0.5573]) \n",
      "Test Loss tensor([0.3596, 0.4857, 0.3667, 0.3691, 0.4490, 0.4996, 0.5570])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6264026165008545 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3591, 0.4866, 0.3652, 0.3719, 0.4484, 0.4991, 0.5579]) \n",
      "Test Loss tensor([0.3588, 0.4862, 0.3654, 0.3692, 0.4476, 0.5013, 0.5584])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6223964691162109 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3585, 0.4880, 0.3652, 0.3704, 0.4492, 0.4992, 0.5587]) \n",
      "Test Loss tensor([0.3590, 0.4871, 0.3657, 0.3698, 0.4489, 0.5005, 0.5573])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6275503635406494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3593, 0.4848, 0.3657, 0.3698, 0.4442, 0.5009, 0.5576]) \n",
      "Test Loss tensor([0.3589, 0.4855, 0.3655, 0.3689, 0.4486, 0.5004, 0.5576])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.616891622543335 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3579, 0.4892, 0.3667, 0.3692, 0.4483, 0.5031, 0.5558]) \n",
      "Test Loss tensor([0.3584, 0.4854, 0.3655, 0.3693, 0.4479, 0.5008, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6585478782653809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3583, 0.4845, 0.3666, 0.3717, 0.4461, 0.4991, 0.5550]) \n",
      "Test Loss tensor([0.3577, 0.4873, 0.3649, 0.3690, 0.4482, 0.5004, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6487612724304199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3588, 0.4858, 0.3656, 0.3694, 0.4486, 0.5025, 0.5572]) \n",
      "Test Loss tensor([0.3574, 0.4853, 0.3651, 0.3686, 0.4481, 0.5013, 0.5582])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6786792278289795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3565, 0.4813, 0.3644, 0.3677, 0.4455, 0.4990, 0.5583]) \n",
      "Test Loss tensor([0.3576, 0.4861, 0.3658, 0.3686, 0.4477, 0.5015, 0.5581])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.651970624923706 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3569, 0.4889, 0.3664, 0.3688, 0.4453, 0.4972, 0.5559]) \n",
      "Test Loss tensor([0.3566, 0.4874, 0.3652, 0.3685, 0.4493, 0.5019, 0.5575])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6751766204833984 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3573, 0.4899, 0.3648, 0.3686, 0.4482, 0.5018, 0.5610]) \n",
      "Test Loss tensor([0.3565, 0.4875, 0.3649, 0.3682, 0.4475, 0.5012, 0.5587])\n",
      "\n",
      "\n",
      "************** Batch 240 in 1.0120680332183838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3559, 0.4816, 0.3656, 0.3677, 0.4435, 0.5029, 0.5583]) \n",
      "Test Loss tensor([0.3561, 0.4871, 0.3650, 0.3689, 0.4469, 0.5023, 0.5583])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.8031232357025146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3568, 0.4861, 0.3655, 0.3693, 0.4458, 0.5029, 0.5589]) \n",
      "Test Loss tensor([0.3558, 0.4870, 0.3649, 0.3690, 0.4485, 0.5005, 0.5583])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6906321048736572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3576, 0.4822, 0.3665, 0.3689, 0.4509, 0.4996, 0.5568]) \n",
      "Test Loss tensor([0.3559, 0.4871, 0.3658, 0.3685, 0.4486, 0.4998, 0.5579])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6527252197265625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3565, 0.4831, 0.3665, 0.3690, 0.4488, 0.5040, 0.5582]) \n",
      "Test Loss tensor([0.3558, 0.4858, 0.3659, 0.3686, 0.4480, 0.5011, 0.5569])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6108884811401367 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3560, 0.4857, 0.3642, 0.3693, 0.4449, 0.4984, 0.5588]) \n",
      "Test Loss tensor([0.3555, 0.4856, 0.3658, 0.3688, 0.4475, 0.5011, 0.5573])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6150741577148438 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3567, 0.4831, 0.3658, 0.3688, 0.4436, 0.4976, 0.5567]) \n",
      "Test Loss tensor([0.3557, 0.4851, 0.3658, 0.3685, 0.4484, 0.5005, 0.5577])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6918518543243408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3552, 0.4844, 0.3656, 0.3691, 0.4440, 0.4988, 0.5578]) \n",
      "Test Loss tensor([0.3548, 0.4869, 0.3662, 0.3694, 0.4486, 0.5011, 0.5569])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.7728867530822754 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3544, 0.4875, 0.3659, 0.3701, 0.4446, 0.5020, 0.5578]) \n",
      "Test Loss tensor([0.3544, 0.4863, 0.3660, 0.3691, 0.4496, 0.5014, 0.5566])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7259032726287842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3546, 0.4869, 0.3652, 0.3697, 0.4474, 0.5010, 0.5556]) \n",
      "Test Loss tensor([0.3538, 0.4871, 0.3659, 0.3688, 0.4482, 0.5010, 0.5572])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7422573566436768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3536, 0.4854, 0.3647, 0.3689, 0.4534, 0.5002, 0.5563]) \n",
      "Test Loss tensor([0.3538, 0.4855, 0.3660, 0.3686, 0.4484, 0.5013, 0.5570])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.670090913772583 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3543, 0.4847, 0.3666, 0.3678, 0.4465, 0.5018, 0.5563]) \n",
      "Test Loss tensor([0.3535, 0.4858, 0.3666, 0.3695, 0.4492, 0.5006, 0.5569])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.8424272537231445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3531, 0.4838, 0.3651, 0.3680, 0.4420, 0.5002, 0.5577]) \n",
      "Test Loss tensor([0.3527, 0.4872, 0.3662, 0.3694, 0.4482, 0.5002, 0.5563])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 288 in 0.9305102825164795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3529, 0.4858, 0.3663, 0.3696, 0.4490, 0.5017, 0.5567]) \n",
      "Test Loss tensor([0.3521, 0.4865, 0.3663, 0.3690, 0.4482, 0.5011, 0.5570])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6539285182952881 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3509, 0.4872, 0.3657, 0.3701, 0.4472, 0.5004, 0.5572]) \n",
      "Test Loss tensor([0.3515, 0.4866, 0.3664, 0.3693, 0.4478, 0.5000, 0.5570])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6378393173217773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3520, 0.4854, 0.3659, 0.3695, 0.4498, 0.4995, 0.5569]) \n",
      "Test Loss tensor([0.3512, 0.4868, 0.3668, 0.3687, 0.4476, 0.4999, 0.5571])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6657640933990479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3508, 0.4865, 0.3661, 0.3692, 0.4480, 0.5010, 0.5569]) \n",
      "Test Loss tensor([0.3506, 0.4858, 0.3672, 0.3694, 0.4483, 0.4995, 0.5565])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6363897323608398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3504, 0.4834, 0.3671, 0.3701, 0.4456, 0.4985, 0.5557]) \n",
      "Test Loss tensor([0.3506, 0.4866, 0.3675, 0.3700, 0.4479, 0.5005, 0.5553])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6418392658233643 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3510, 0.4861, 0.3681, 0.3710, 0.4444, 0.4984, 0.5541]) \n",
      "Test Loss tensor([0.3501, 0.4844, 0.3681, 0.3699, 0.4476, 0.5001, 0.5553])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6821749210357666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3507, 0.4833, 0.3666, 0.3706, 0.4500, 0.4984, 0.5544]) \n",
      "Test Loss tensor([0.3497, 0.4854, 0.3684, 0.3705, 0.4481, 0.4990, 0.5546])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6559023857116699 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3508, 0.4820, 0.3672, 0.3698, 0.4417, 0.5038, 0.5551]) \n",
      "Test Loss tensor([0.3488, 0.4842, 0.3688, 0.3706, 0.4474, 0.4980, 0.5545])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6563370227813721 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3481, 0.4820, 0.3683, 0.3709, 0.4445, 0.4994, 0.5547]) \n",
      "Test Loss tensor([0.3481, 0.4844, 0.3689, 0.3705, 0.4465, 0.4999, 0.5537])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6489205360412598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3488, 0.4816, 0.3695, 0.3709, 0.4488, 0.4983, 0.5528]) \n",
      "Test Loss tensor([0.3472, 0.4845, 0.3694, 0.3714, 0.4470, 0.4991, 0.5538])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.9806969165802002 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3479, 0.4846, 0.3679, 0.3701, 0.4482, 0.5007, 0.5553]) \n",
      "Test Loss tensor([0.3467, 0.4837, 0.3695, 0.3714, 0.4480, 0.4988, 0.5535])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7244341373443604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3464, 0.4832, 0.3691, 0.3710, 0.4500, 0.4972, 0.5548]) \n",
      "Test Loss tensor([0.3462, 0.4839, 0.3699, 0.3718, 0.4469, 0.4975, 0.5527])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7747616767883301 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3475, 0.4844, 0.3708, 0.3730, 0.4491, 0.4963, 0.5518]) \n",
      "Test Loss tensor([0.3459, 0.4831, 0.3713, 0.3727, 0.4459, 0.4966, 0.5525])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6229124069213867 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3464, 0.4847, 0.3711, 0.3738, 0.4454, 0.4944, 0.5532]) \n",
      "Test Loss tensor([0.3452, 0.4830, 0.3721, 0.3735, 0.4470, 0.4967, 0.5501])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.652449369430542 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3465, 0.4803, 0.3712, 0.3731, 0.4469, 0.4987, 0.5509]) \n",
      "Test Loss tensor([0.3445, 0.4802, 0.3726, 0.3742, 0.4468, 0.4962, 0.5499])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6488556861877441 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3453, 0.4815, 0.3725, 0.3750, 0.4455, 0.4946, 0.5511]) \n",
      "Test Loss tensor([0.3439, 0.4815, 0.3740, 0.3750, 0.4465, 0.4959, 0.5484])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6398794651031494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3439, 0.4803, 0.3731, 0.3754, 0.4419, 0.4945, 0.5508]) \n",
      "Test Loss tensor([0.3433, 0.4797, 0.3743, 0.3757, 0.4453, 0.4952, 0.5475])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6127970218658447 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3426, 0.4799, 0.3757, 0.3752, 0.4427, 0.4968, 0.5477]) \n",
      "Test Loss tensor([0.3425, 0.4789, 0.3757, 0.3763, 0.4449, 0.4942, 0.5464])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6120998859405518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3422, 0.4773, 0.3751, 0.3780, 0.4453, 0.4953, 0.5463]) \n",
      "Test Loss tensor([0.3413, 0.4781, 0.3764, 0.3771, 0.4448, 0.4937, 0.5459])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6633553504943848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3416, 0.4818, 0.3763, 0.3770, 0.4456, 0.4930, 0.5455]) \n",
      "Test Loss tensor([0.3403, 0.4784, 0.3775, 0.3781, 0.4450, 0.4934, 0.5445])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6702451705932617 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3400, 0.4763, 0.3766, 0.3788, 0.4417, 0.4929, 0.5449]) \n",
      "Test Loss tensor([0.3390, 0.4769, 0.3786, 0.3791, 0.4438, 0.4938, 0.5435])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6298389434814453 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3400, 0.4793, 0.3772, 0.3789, 0.4450, 0.4938, 0.5446]) \n",
      "Test Loss tensor([0.3381, 0.4771, 0.3798, 0.3800, 0.4440, 0.4917, 0.5423])\n",
      "\n",
      "\n",
      "************** Batch 376 in 1.0750205516815186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3385, 0.4711, 0.3805, 0.3795, 0.4411, 0.4887, 0.5425]) \n",
      "Test Loss tensor([0.3371, 0.4755, 0.3808, 0.3809, 0.4441, 0.4906, 0.5407])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.699765682220459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3372, 0.4776, 0.3812, 0.3804, 0.4460, 0.4904, 0.5400]) \n",
      "Test Loss tensor([0.3356, 0.4761, 0.3822, 0.3815, 0.4439, 0.4898, 0.5395])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.7463648319244385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3357, 0.4792, 0.3830, 0.3814, 0.4405, 0.4882, 0.5398]) \n",
      "Test Loss tensor([0.3344, 0.4760, 0.3826, 0.3824, 0.4427, 0.4889, 0.5386])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6122779846191406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3354, 0.4772, 0.3828, 0.3807, 0.4459, 0.4899, 0.5392]) \n",
      "Test Loss tensor([0.3336, 0.4731, 0.3849, 0.3844, 0.4424, 0.4866, 0.5372])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6234633922576904 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3333, 0.4715, 0.3840, 0.3828, 0.4420, 0.4873, 0.5374]) \n",
      "Test Loss tensor([0.3320, 0.4715, 0.3863, 0.3853, 0.4419, 0.4873, 0.5357])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6028790473937988 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3321, 0.4697, 0.3869, 0.3827, 0.4384, 0.4859, 0.5360]) \n",
      "Test Loss tensor([0.3305, 0.4713, 0.3879, 0.3863, 0.4426, 0.4859, 0.5335])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6480560302734375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3295, 0.4754, 0.3875, 0.3854, 0.4417, 0.4859, 0.5360]) \n",
      "Test Loss tensor([0.3287, 0.4712, 0.3893, 0.3873, 0.4409, 0.4844, 0.5327])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6370255947113037 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3296, 0.4698, 0.3888, 0.3867, 0.4380, 0.4807, 0.5323]) \n",
      "Test Loss tensor([0.3261, 0.4712, 0.3898, 0.3881, 0.4408, 0.4838, 0.5313])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6522748470306396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3263, 0.4680, 0.3911, 0.3886, 0.4427, 0.4847, 0.5304]) \n",
      "Test Loss tensor([0.3244, 0.4695, 0.3916, 0.3887, 0.4409, 0.4830, 0.5298])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7149040699005127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3239, 0.4697, 0.3922, 0.3904, 0.4395, 0.4809, 0.5301]) \n",
      "Test Loss tensor([0.3225, 0.4687, 0.3937, 0.3902, 0.4391, 0.4819, 0.5275])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.8635931015014648 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3232, 0.4665, 0.3911, 0.3880, 0.4354, 0.4838, 0.5291]) \n",
      "Test Loss tensor([0.3206, 0.4678, 0.3952, 0.3914, 0.4398, 0.4797, 0.5264])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7383928298950195 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3212, 0.4647, 0.3963, 0.3930, 0.4373, 0.4796, 0.5267]) \n",
      "Test Loss tensor([0.3176, 0.4677, 0.3964, 0.3926, 0.4384, 0.4785, 0.5247])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.7205154895782471 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3177, 0.4698, 0.3970, 0.3921, 0.4356, 0.4758, 0.5256]) \n",
      "Test Loss tensor([0.3152, 0.4664, 0.3985, 0.3936, 0.4378, 0.4781, 0.5227])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6631383895874023 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3158, 0.4671, 0.3986, 0.3944, 0.4351, 0.4762, 0.5230]) \n",
      "Test Loss tensor([0.3126, 0.4655, 0.4000, 0.3946, 0.4379, 0.4772, 0.5213])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.6456224918365479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3129, 0.4650, 0.4004, 0.3947, 0.4375, 0.4759, 0.5227]) \n",
      "Test Loss tensor([0.3099, 0.4629, 0.4020, 0.3955, 0.4377, 0.4757, 0.5194])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6978840827941895 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3103, 0.4616, 0.4020, 0.3959, 0.4393, 0.4763, 0.5182]) \n",
      "Test Loss tensor([0.3067, 0.4626, 0.4038, 0.3971, 0.4372, 0.4741, 0.5173])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6273097991943359 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3065, 0.4641, 0.4042, 0.3961, 0.4323, 0.4717, 0.5180]) \n",
      "Test Loss tensor([0.3040, 0.4616, 0.4060, 0.3976, 0.4367, 0.4718, 0.5147])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.611168622970581 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3033, 0.4638, 0.4054, 0.3972, 0.4350, 0.4721, 0.5137]) \n",
      "Test Loss tensor([0.3003, 0.4615, 0.4080, 0.3988, 0.4349, 0.4710, 0.5130])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6144380569458008 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.3001, 0.4630, 0.4081, 0.3982, 0.4343, 0.4688, 0.5140]) \n",
      "Test Loss tensor([0.2978, 0.4594, 0.4098, 0.4002, 0.4341, 0.4690, 0.5106])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6488440036773682 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2985, 0.4597, 0.4100, 0.4010, 0.4369, 0.4689, 0.5112]) \n",
      "Test Loss tensor([0.2948, 0.4593, 0.4130, 0.4017, 0.4338, 0.4676, 0.5078])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.66225266456604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2952, 0.4606, 0.4129, 0.4019, 0.4346, 0.4676, 0.5063]) \n",
      "Test Loss tensor([0.2921, 0.4588, 0.4152, 0.4024, 0.4332, 0.4656, 0.5058])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6706149578094482 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2919, 0.4528, 0.4146, 0.4035, 0.4314, 0.4682, 0.5066]) \n",
      "Test Loss tensor([0.2885, 0.4568, 0.4168, 0.4029, 0.4322, 0.4650, 0.5032])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6557238101959229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2881, 0.4576, 0.4164, 0.4037, 0.4315, 0.4638, 0.5033]) \n",
      "Test Loss tensor([0.2849, 0.4584, 0.4191, 0.4029, 0.4326, 0.4627, 0.5015])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6679730415344238 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2868, 0.4529, 0.4173, 0.4040, 0.4279, 0.4629, 0.4996]) \n",
      "Test Loss tensor([0.2816, 0.4579, 0.4216, 0.4034, 0.4301, 0.4616, 0.4980])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6691117286682129 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2817, 0.4575, 0.4201, 0.4038, 0.4301, 0.4609, 0.4993]) \n",
      "Test Loss tensor([0.2780, 0.4566, 0.4238, 0.4042, 0.4312, 0.4582, 0.4957])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6605701446533203 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2778, 0.4581, 0.4252, 0.4026, 0.4282, 0.4568, 0.4949]) \n",
      "Test Loss tensor([0.2748, 0.4563, 0.4266, 0.4043, 0.4301, 0.4577, 0.4931])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.9674856662750244 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2743, 0.4578, 0.4277, 0.4029, 0.4336, 0.4565, 0.4929]) \n",
      "Test Loss tensor([0.2709, 0.4553, 0.4295, 0.4041, 0.4283, 0.4544, 0.4892])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.7592144012451172 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2711, 0.4556, 0.4289, 0.4050, 0.4279, 0.4559, 0.4898]) \n",
      "Test Loss tensor([0.2673, 0.4570, 0.4321, 0.4044, 0.4288, 0.4522, 0.4869])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.7634761333465576 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2665, 0.4557, 0.4341, 0.4038, 0.4293, 0.4522, 0.4866]) \n",
      "Test Loss tensor([0.2637, 0.4558, 0.4354, 0.4030, 0.4282, 0.4494, 0.4840])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.678685188293457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2633, 0.4608, 0.4355, 0.4040, 0.4285, 0.4498, 0.4836]) \n",
      "Test Loss tensor([0.2599, 0.4569, 0.4383, 0.4018, 0.4267, 0.4485, 0.4803])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6552238464355469 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2594, 0.4557, 0.4379, 0.4022, 0.4257, 0.4481, 0.4806]) \n",
      "Test Loss tensor([0.2556, 0.4595, 0.4411, 0.3998, 0.4262, 0.4455, 0.4773])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6657302379608154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2553, 0.4564, 0.4417, 0.3992, 0.4235, 0.4461, 0.4779]) \n",
      "Test Loss tensor([0.2513, 0.4599, 0.4438, 0.3974, 0.4252, 0.4447, 0.4738])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7090563774108887 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2513, 0.4599, 0.4434, 0.3975, 0.4275, 0.4422, 0.4737]) \n",
      "Test Loss tensor([0.2465, 0.4631, 0.4464, 0.3942, 0.4238, 0.4415, 0.4709])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6116971969604492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2460, 0.4612, 0.4462, 0.3953, 0.4258, 0.4404, 0.4717]) \n",
      "Test Loss tensor([0.2421, 0.4656, 0.4492, 0.3900, 0.4237, 0.4384, 0.4671])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6092555522918701 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2413, 0.4688, 0.4492, 0.3905, 0.4220, 0.4390, 0.4665]) \n",
      "Test Loss tensor([0.2375, 0.4684, 0.4519, 0.3851, 0.4225, 0.4370, 0.4634])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6388485431671143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2371, 0.4703, 0.4507, 0.3848, 0.4231, 0.4351, 0.4624]) \n",
      "Test Loss tensor([0.2323, 0.4731, 0.4544, 0.3792, 0.4228, 0.4340, 0.4605])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6635527610778809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2325, 0.4728, 0.4548, 0.3789, 0.4225, 0.4316, 0.4612]) \n",
      "Test Loss tensor([0.2270, 0.4784, 0.4565, 0.3720, 0.4218, 0.4323, 0.4554])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.675865888595581 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2269, 0.4811, 0.4555, 0.3722, 0.4232, 0.4312, 0.4559]) \n",
      "Test Loss tensor([0.2220, 0.4858, 0.4578, 0.3625, 0.4205, 0.4285, 0.4523])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7528641223907471 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2202, 0.4867, 0.4579, 0.3623, 0.4221, 0.4281, 0.4507]) \n",
      "Test Loss tensor([0.2163, 0.4943, 0.4583, 0.3512, 0.4205, 0.4286, 0.4480])\n",
      "\n",
      "\n",
      "************** Batch 532 in 1.0029425621032715 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2168, 0.4929, 0.4600, 0.3503, 0.4193, 0.4295, 0.4478]) \n",
      "Test Loss tensor([0.2105, 0.5037, 0.4566, 0.3366, 0.4204, 0.4270, 0.4450])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.7176811695098877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2111, 0.5030, 0.4565, 0.3359, 0.4192, 0.4264, 0.4448]) \n",
      "Test Loss tensor([0.2046, 0.5203, 0.4518, 0.3203, 0.4208, 0.4253, 0.4412])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6342709064483643 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.2040, 0.5219, 0.4508, 0.3212, 0.4210, 0.4229, 0.4419]) \n",
      "Test Loss tensor([0.1984, 0.5379, 0.4432, 0.3015, 0.4213, 0.4253, 0.4379])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6242072582244873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1979, 0.5353, 0.4437, 0.3026, 0.4180, 0.4228, 0.4378]) \n",
      "Test Loss tensor([0.1922, 0.5559, 0.4295, 0.2817, 0.4239, 0.4274, 0.4346])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6568441390991211 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1927, 0.5599, 0.4286, 0.2819, 0.4219, 0.4249, 0.4348]) \n",
      "Test Loss tensor([0.1858, 0.5744, 0.4139, 0.2645, 0.4261, 0.4276, 0.4309])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6353988647460938 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1863, 0.5762, 0.4144, 0.2656, 0.4280, 0.4265, 0.4294]) \n",
      "Test Loss tensor([0.1795, 0.5874, 0.4001, 0.2536, 0.4281, 0.4273, 0.4260])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.8552389144897461 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1793, 0.5859, 0.3967, 0.2525, 0.4234, 0.4249, 0.4273]) \n",
      "Test Loss tensor([0.1732, 0.6011, 0.3904, 0.2432, 0.4269, 0.4246, 0.4203])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6973867416381836 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1734, 0.5969, 0.3888, 0.2437, 0.4266, 0.4243, 0.4184]) \n",
      "Test Loss tensor([0.1671, 0.6108, 0.3825, 0.2365, 0.4281, 0.4187, 0.4127])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.7150015830993652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1669, 0.6102, 0.3828, 0.2371, 0.4244, 0.4201, 0.4112]) \n",
      "Test Loss tensor([0.1609, 0.6227, 0.3720, 0.2292, 0.4290, 0.4164, 0.4058])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6054389476776123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1610, 0.6169, 0.3704, 0.2308, 0.4290, 0.4171, 0.4060]) \n",
      "Test Loss tensor([0.1541, 0.6331, 0.3590, 0.2211, 0.4301, 0.4123, 0.3985])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6713297367095947 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1540, 0.6350, 0.3614, 0.2198, 0.4292, 0.4122, 0.3995]) \n",
      "Test Loss tensor([0.1473, 0.6448, 0.3441, 0.2122, 0.4343, 0.4089, 0.3920])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 576 in 0.7554893493652344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1476, 0.6420, 0.3417, 0.2130, 0.4304, 0.4071, 0.3916]) \n",
      "Test Loss tensor([0.1401, 0.6573, 0.3255, 0.2050, 0.4402, 0.4070, 0.3851])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6868698596954346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1398, 0.6525, 0.3228, 0.2037, 0.4381, 0.4080, 0.3857]) \n",
      "Test Loss tensor([0.1327, 0.6659, 0.3074, 0.1961, 0.4443, 0.4048, 0.3786])\n",
      "\n",
      "\n",
      "************** Batch 584 in 1.0606448650360107 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1327, 0.6743, 0.3083, 0.1960, 0.4427, 0.4053, 0.3781]) \n",
      "Test Loss tensor([0.1251, 0.6793, 0.2949, 0.1899, 0.4468, 0.3986, 0.3715])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.946385383605957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1258, 0.6727, 0.2928, 0.1866, 0.4388, 0.3970, 0.3725]) \n",
      "Test Loss tensor([0.1179, 0.6908, 0.2837, 0.1820, 0.4490, 0.3913, 0.3642])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.710974931716919 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1183, 0.6822, 0.2842, 0.1858, 0.4502, 0.3946, 0.3652]) \n",
      "Test Loss tensor([0.1104, 0.7000, 0.2689, 0.1756, 0.4542, 0.3869, 0.3582])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6706228256225586 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1108, 0.7021, 0.2727, 0.1784, 0.4474, 0.3836, 0.3578]) \n",
      "Test Loss tensor([0.1028, 0.7140, 0.2548, 0.1700, 0.4585, 0.3807, 0.3530])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6353507041931152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.1026, 0.7092, 0.2559, 0.1664, 0.4553, 0.3764, 0.3500]) \n",
      "Test Loss tensor([0.0955, 0.7253, 0.2439, 0.1630, 0.4581, 0.3731, 0.3462])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6685671806335449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0959, 0.7240, 0.2451, 0.1598, 0.4564, 0.3713, 0.3478]) \n",
      "Test Loss tensor([0.0880, 0.7354, 0.2277, 0.1566, 0.4605, 0.3676, 0.3408])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.8808190822601318 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0881, 0.7279, 0.2290, 0.1540, 0.4537, 0.3675, 0.3405]) \n",
      "Test Loss tensor([0.0806, 0.7478, 0.2110, 0.1516, 0.4619, 0.3629, 0.3344])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6579859256744385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0805, 0.7465, 0.2095, 0.1528, 0.4545, 0.3616, 0.3348]) \n",
      "Test Loss tensor([0.0740, 0.7597, 0.2016, 0.1483, 0.4566, 0.3563, 0.3285])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6353662014007568 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0745, 0.7595, 0.2035, 0.1497, 0.4589, 0.3586, 0.3243]) \n",
      "Test Loss tensor([0.0681, 0.7683, 0.1959, 0.1429, 0.4442, 0.3490, 0.3214])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6560142040252686 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0686, 0.7659, 0.1959, 0.1426, 0.4434, 0.3522, 0.3222]) \n",
      "Test Loss tensor([0.0630, 0.7786, 0.1902, 0.1407, 0.4272, 0.3447, 0.3141])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.7217040061950684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0633, 0.7830, 0.1958, 0.1462, 0.4292, 0.3456, 0.3133]) \n",
      "Test Loss tensor([0.0575, 0.7929, 0.1800, 0.1394, 0.4139, 0.3389, 0.3060])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.7316277027130127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0574, 0.7961, 0.1828, 0.1363, 0.4154, 0.3418, 0.3097]) \n",
      "Test Loss tensor([0.0517, 0.8034, 0.1640, 0.1354, 0.4036, 0.3353, 0.2996])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6458144187927246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0516, 0.7944, 0.1594, 0.1376, 0.4093, 0.3363, 0.2987]) \n",
      "Test Loss tensor([0.0459, 0.8208, 0.1417, 0.1318, 0.3962, 0.3303, 0.2919])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6304693222045898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0460, 0.8250, 0.1407, 0.1318, 0.3907, 0.3299, 0.2912]) \n",
      "Test Loss tensor([0.0401, 0.8421, 0.1212, 0.1288, 0.3878, 0.3245, 0.2837])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6496834754943848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0400, 0.8490, 0.1195, 0.1288, 0.3881, 0.3231, 0.2836]) \n",
      "Test Loss tensor([0.0355, 0.8595, 0.1092, 0.1252, 0.3765, 0.3205, 0.2764])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.620525598526001 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0354, 0.8524, 0.1084, 0.1305, 0.3800, 0.3222, 0.2765]) \n",
      "Test Loss tensor([0.0312, 0.8746, 0.0972, 0.1247, 0.3712, 0.3156, 0.2671])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6539552211761475 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0312, 0.8720, 0.0961, 0.1259, 0.3684, 0.3083, 0.2659]) \n",
      "Test Loss tensor([0.0263, 0.8994, 0.0830, 0.1178, 0.3672, 0.3115, 0.2591])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6471834182739258 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0264, 0.9002, 0.0836, 0.1215, 0.3673, 0.3083, 0.2613]) \n",
      "Test Loss tensor([0.0221, 0.9176, 0.0731, 0.1107, 0.3642, 0.3058, 0.2512])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.644467830657959 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0221, 0.9185, 0.0727, 0.1073, 0.3619, 0.3088, 0.2506]) \n",
      "Test Loss tensor([0.0192, 0.9294, 0.0663, 0.1050, 0.3578, 0.2991, 0.2435])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6399486064910889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0194, 0.9408, 0.0658, 0.1058, 0.3625, 0.2946, 0.2415]) \n",
      "Test Loss tensor([0.0175, 0.9406, 0.0635, 0.1058, 0.3495, 0.2960, 0.2345])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6424553394317627 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0177, 0.9559, 0.0570, 0.1045, 0.3452, 0.3003, 0.2312]) \n",
      "Test Loss tensor([0.0163, 0.9471, 0.0603, 0.1058, 0.3403, 0.2899, 0.2255])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.9706220626831055 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0162, 0.9559, 0.0594, 0.1106, 0.3508, 0.2859, 0.2267]) \n",
      "Test Loss tensor([0.0151, 0.9543, 0.0584, 0.1058, 0.3329, 0.2856, 0.2187])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.7138450145721436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0150, 0.9423, 0.0587, 0.1046, 0.3332, 0.2917, 0.2171]) \n",
      "Test Loss tensor([0.0144, 0.9555, 0.0560, 0.1067, 0.3267, 0.2814, 0.2120])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.8238444328308105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0145, 0.9745, 0.0542, 0.1020, 0.3335, 0.2791, 0.2105]) \n",
      "Test Loss tensor([0.0143, 0.9600, 0.0581, 0.1102, 0.3226, 0.2765, 0.2022])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.7152681350708008 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0146, 0.9668, 0.0551, 0.1185, 0.3202, 0.2718, 0.2018]) \n",
      "Test Loss tensor([0.0140, 0.9613, 0.0568, 0.1096, 0.3150, 0.2726, 0.1951])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.784083366394043 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0141, 0.9611, 0.0573, 0.1159, 0.3065, 0.2683, 0.1917]) \n",
      "Test Loss tensor([0.0137, 0.9632, 0.0562, 0.1090, 0.3098, 0.2685, 0.1905])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.7165408134460449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0135, 0.9592, 0.0561, 0.1108, 0.3078, 0.2735, 0.1874]) \n",
      "Test Loss tensor([0.0139, 0.9629, 0.0568, 0.1091, 0.3075, 0.2632, 0.1824])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6642575263977051 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0139, 0.9717, 0.0529, 0.1133, 0.3169, 0.2622, 0.1798]) \n",
      "Test Loss tensor([0.0143, 0.9591, 0.0579, 0.1106, 0.2959, 0.2572, 0.1722])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6572976112365723 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0141, 0.9494, 0.0592, 0.1101, 0.2947, 0.2627, 0.1752]) \n",
      "Test Loss tensor([0.0146, 0.9553, 0.0574, 0.1084, 0.2945, 0.2518, 0.1654])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6922872066497803 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0145, 0.9581, 0.0606, 0.1103, 0.2956, 0.2462, 0.1643]) \n",
      "Test Loss tensor([0.0148, 0.9590, 0.0586, 0.1042, 0.2887, 0.2472, 0.1579])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.7397058010101318 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0147, 0.9615, 0.0552, 0.1070, 0.2907, 0.2433, 0.1552]) \n",
      "Test Loss tensor([0.0156, 0.9534, 0.0600, 0.1067, 0.2826, 0.2422, 0.1507])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6640985012054443 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0157, 0.9396, 0.0622, 0.1097, 0.2773, 0.2416, 0.1486]) \n",
      "Test Loss tensor([0.0161, 0.9471, 0.0592, 0.1051, 0.2819, 0.2409, 0.1447])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6162292957305908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0162, 0.9509, 0.0552, 0.1112, 0.2841, 0.2402, 0.1386]) \n",
      "Test Loss tensor([0.0170, 0.9489, 0.0609, 0.1059, 0.2782, 0.2349, 0.1363])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6786072254180908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0170, 0.9365, 0.0643, 0.1060, 0.2792, 0.2419, 0.1318]) \n",
      "Test Loss tensor([0.0177, 0.9428, 0.0626, 0.1040, 0.2731, 0.2354, 0.1309])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.6989903450012207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0179, 0.9420, 0.0598, 0.1055, 0.2767, 0.2295, 0.1235]) \n",
      "Test Loss tensor([0.0187, 0.9397, 0.0643, 0.1051, 0.2647, 0.2290, 0.1225])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6227478981018066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0187, 0.9351, 0.0626, 0.1130, 0.2760, 0.2367, 0.1217]) \n",
      "Test Loss tensor([0.0200, 0.9311, 0.0665, 0.1075, 0.2631, 0.2305, 0.1173])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6498730182647705 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0203, 0.9479, 0.0674, 0.1179, 0.2593, 0.2333, 0.1216]) \n",
      "Test Loss tensor([0.0208, 0.9262, 0.0678, 0.1063, 0.2572, 0.2282, 0.1134])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6247484683990479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0209, 0.9273, 0.0660, 0.1109, 0.2611, 0.2310, 0.1176]) \n",
      "Test Loss tensor([0.0217, 0.9225, 0.0677, 0.1069, 0.2545, 0.2226, 0.1080])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6183450222015381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0217, 0.9109, 0.0689, 0.1059, 0.2567, 0.2239, 0.1126]) \n",
      "Test Loss tensor([0.0228, 0.9169, 0.0704, 0.1071, 0.2447, 0.2228, 0.1034])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6915931701660156 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0231, 0.9097, 0.0689, 0.1129, 0.2536, 0.2228, 0.1032]) \n",
      "Test Loss tensor([0.0245, 0.9055, 0.0766, 0.1134, 0.2425, 0.2196, 0.0958])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.697385311126709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0246, 0.9132, 0.0812, 0.1111, 0.2429, 0.2270, 0.0957]) \n",
      "Test Loss tensor([0.0248, 0.9083, 0.0739, 0.1083, 0.2387, 0.2187, 0.0952])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6665055751800537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0247, 0.9103, 0.0768, 0.1084, 0.2402, 0.2190, 0.0978]) \n",
      "Test Loss tensor([0.0258, 0.9049, 0.0770, 0.1088, 0.2314, 0.2187, 0.0914])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6232657432556152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0257, 0.9045, 0.0788, 0.1098, 0.2422, 0.2123, 0.0911]) \n",
      "Test Loss tensor([0.0270, 0.8985, 0.0813, 0.1133, 0.2277, 0.2170, 0.0869])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.607011079788208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0270, 0.8997, 0.0826, 0.1132, 0.2345, 0.2118, 0.0846]) \n",
      "Test Loss tensor([0.0273, 0.9010, 0.0789, 0.1094, 0.2248, 0.2159, 0.0856])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6070773601531982 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0274, 0.8974, 0.0839, 0.1075, 0.2290, 0.2101, 0.0843]) \n",
      "Test Loss tensor([0.0279, 0.8974, 0.0790, 0.1084, 0.2228, 0.2151, 0.0842])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6060066223144531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0278, 0.8965, 0.0838, 0.1107, 0.2325, 0.2286, 0.0908]) \n",
      "Test Loss tensor([0.0293, 0.8914, 0.0834, 0.1162, 0.2176, 0.2105, 0.0771])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6596617698669434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0294, 0.8915, 0.0863, 0.1150, 0.2154, 0.2101, 0.0764]) \n",
      "Test Loss tensor([0.0294, 0.8904, 0.0836, 0.1114, 0.2158, 0.2110, 0.0775])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6023881435394287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0291, 0.8945, 0.0804, 0.1113, 0.2162, 0.2142, 0.0791]) \n",
      "Test Loss tensor([0.0291, 0.8919, 0.0794, 0.1086, 0.2196, 0.2113, 0.0776])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6001224517822266 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0293, 0.8914, 0.0824, 0.1142, 0.2242, 0.2087, 0.0793]) \n",
      "Test Loss tensor([0.0301, 0.8896, 0.0840, 0.1130, 0.2101, 0.2104, 0.0729])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6006369590759277 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8843, 0.0850, 0.1099, 0.2098, 0.2130, 0.0678]) \n",
      "Test Loss tensor([0.0308, 0.8857, 0.0851, 0.1173, 0.2081, 0.2134, 0.0706])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6040651798248291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0310, 0.8827, 0.0905, 0.1176, 0.2214, 0.2122, 0.0723]) \n",
      "Test Loss tensor([0.0303, 0.8887, 0.0833, 0.1105, 0.2093, 0.2085, 0.0740])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6212196350097656 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8796, 0.0851, 0.1118, 0.2081, 0.1947, 0.0727]) \n",
      "Test Loss tensor([0.0305, 0.8899, 0.0827, 0.1117, 0.2061, 0.2046, 0.0723])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6097524166107178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8737, 0.0868, 0.1156, 0.2059, 0.2074, 0.0748]) \n",
      "Test Loss tensor([0.0316, 0.8824, 0.0879, 0.1195, 0.2011, 0.2119, 0.0663])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6096584796905518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0315, 0.8781, 0.0871, 0.1156, 0.2003, 0.2138, 0.0619]) \n",
      "Test Loss tensor([0.0312, 0.8853, 0.0859, 0.1152, 0.1995, 0.2081, 0.0678])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.5990314483642578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0310, 0.8841, 0.0863, 0.1176, 0.2007, 0.2083, 0.0683]) \n",
      "Test Loss tensor([0.0302, 0.8894, 0.0811, 0.1093, 0.2087, 0.2046, 0.0722])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5952877998352051 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8783, 0.0960, 0.1085, 0.2059, 0.2064, 0.0707]) \n",
      "Test Loss tensor([0.0300, 0.8882, 0.0817, 0.1077, 0.2062, 0.2041, 0.0726])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.5994746685028076 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0301, 0.9006, 0.0857, 0.1069, 0.2029, 0.2001, 0.0687]) \n",
      "Test Loss tensor([0.0312, 0.8807, 0.0871, 0.1153, 0.1909, 0.2085, 0.0641])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6148302555084229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0312, 0.8920, 0.0915, 0.1133, 0.1981, 0.2237, 0.0607]) \n",
      "Test Loss tensor([0.0310, 0.8856, 0.0868, 0.1140, 0.1901, 0.2087, 0.0671])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6537067890167236 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0309, 0.8812, 0.0844, 0.1145, 0.1892, 0.1991, 0.0636]) \n",
      "Test Loss tensor([0.0300, 0.8899, 0.0821, 0.1092, 0.1944, 0.2016, 0.0709])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6472511291503906 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0304, 0.8995, 0.0779, 0.1145, 0.1983, 0.1986, 0.0648]) \n",
      "Test Loss tensor([0.0301, 0.8880, 0.0817, 0.1084, 0.1940, 0.2022, 0.0694])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.7395358085632324 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0298, 0.8878, 0.0764, 0.1130, 0.2000, 0.2057, 0.0627]) \n",
      "Test Loss tensor([0.0308, 0.8870, 0.0854, 0.1120, 0.1845, 0.2078, 0.0645])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6617529392242432 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0306, 0.8834, 0.0875, 0.1113, 0.1783, 0.2093, 0.0660]) \n",
      "Test Loss tensor([0.0310, 0.8828, 0.0888, 0.1142, 0.1832, 0.2095, 0.0635])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6267344951629639 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0308, 0.8849, 0.0868, 0.1149, 0.1900, 0.2041, 0.0607]) \n",
      "Test Loss tensor([0.0302, 0.8865, 0.0833, 0.1079, 0.1836, 0.2049, 0.0668])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6393887996673584 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0306, 0.8828, 0.0835, 0.1058, 0.1892, 0.1990, 0.0685]) \n",
      "Test Loss tensor([0.0297, 0.8892, 0.0815, 0.1062, 0.1904, 0.1994, 0.0677])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.722663164138794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0300, 0.8903, 0.0813, 0.1027, 0.2002, 0.1918, 0.0652]) \n",
      "Test Loss tensor([0.0302, 0.8899, 0.0849, 0.1095, 0.1817, 0.2049, 0.0662])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.7100486755371094 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0303, 0.8897, 0.0858, 0.1043, 0.1847, 0.2070, 0.0658]) \n",
      "Test Loss tensor([0.0307, 0.8868, 0.0862, 0.1122, 0.1770, 0.2065, 0.0638])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.710299015045166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8868, 0.0887, 0.1136, 0.1799, 0.2051, 0.0611]) \n",
      "Test Loss tensor([0.0301, 0.8860, 0.0859, 0.1095, 0.1790, 0.2010, 0.0653])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6014230251312256 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0297, 0.8915, 0.0824, 0.1115, 0.1813, 0.2035, 0.0549]) \n",
      "Test Loss tensor([0.0295, 0.8881, 0.0830, 0.1068, 0.1862, 0.1987, 0.0687])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.7305233478546143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0296, 0.8848, 0.0861, 0.1069, 0.1854, 0.1920, 0.0693]) \n",
      "Test Loss tensor([0.0300, 0.8865, 0.0832, 0.1091, 0.1780, 0.2025, 0.0645])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7612252235412598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8856, 0.0815, 0.1135, 0.1800, 0.1925, 0.0562]) \n",
      "Test Loss tensor([0.0304, 0.8865, 0.0867, 0.1109, 0.1729, 0.2039, 0.0612])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.679718017578125 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0303, 0.8830, 0.0875, 0.1056, 0.1738, 0.2134, 0.0666]) \n",
      "Test Loss tensor([0.0298, 0.8907, 0.0819, 0.1091, 0.1772, 0.2007, 0.0656])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.7013940811157227 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0297, 0.8829, 0.0789, 0.1106, 0.1821, 0.2132, 0.0622]) \n",
      "Test Loss tensor([0.0295, 0.8877, 0.0820, 0.1061, 0.1813, 0.1993, 0.0648])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6934986114501953 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0295, 0.8913, 0.0877, 0.1030, 0.1821, 0.1986, 0.0691]) \n",
      "Test Loss tensor([0.0298, 0.8920, 0.0816, 0.1077, 0.1755, 0.1986, 0.0647])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.681490421295166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0223, 0.6706, 0.0616, 0.0871, 0.1428, 0.1598, 0.0565]) \n",
      "Test Loss tensor([0.0302, 0.8876, 0.0856, 0.1113, 0.1687, 0.2038, 0.0606])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7303938865661621 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0306, 0.9027, 0.0830, 0.1081, 0.1816, 0.2039, 0.0550]) \n",
      "Test Loss tensor([0.0301, 0.8862, 0.0861, 0.1082, 0.1686, 0.1993, 0.0649])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.7090799808502197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8829, 0.0858, 0.1089, 0.1766, 0.2046, 0.0640]) \n",
      "Test Loss tensor([0.0297, 0.8910, 0.0818, 0.1066, 0.1745, 0.1979, 0.0641])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7809033393859863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0298, 0.8973, 0.0808, 0.1114, 0.1760, 0.1921, 0.0596]) \n",
      "Test Loss tensor([0.0297, 0.8891, 0.0825, 0.1076, 0.1772, 0.1991, 0.0647])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7489702701568604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0298, 0.8848, 0.0813, 0.1143, 0.1759, 0.2007, 0.0604]) \n",
      "Test Loss tensor([0.0303, 0.8873, 0.0835, 0.1104, 0.1684, 0.2025, 0.0617])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6463625431060791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8913, 0.0805, 0.1134, 0.1689, 0.2001, 0.0546]) \n",
      "Test Loss tensor([0.0305, 0.8874, 0.0843, 0.1115, 0.1657, 0.2039, 0.0614])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6429836750030518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8883, 0.0806, 0.1105, 0.1578, 0.2117, 0.0512]) \n",
      "Test Loss tensor([0.0302, 0.8875, 0.0819, 0.1083, 0.1682, 0.1982, 0.0620])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.7631418704986572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0303, 0.8934, 0.0805, 0.1100, 0.1747, 0.2032, 0.0514]) \n",
      "Test Loss tensor([0.0298, 0.8909, 0.0811, 0.1061, 0.1752, 0.1992, 0.0624])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.7604241371154785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0300, 0.8948, 0.0773, 0.1011, 0.1831, 0.2054, 0.0652]) \n",
      "Test Loss tensor([0.0302, 0.8857, 0.0820, 0.1086, 0.1721, 0.2030, 0.0638])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.69915771484375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0304, 0.8812, 0.0846, 0.1096, 0.1706, 0.1985, 0.0664]) \n",
      "Test Loss tensor([0.0306, 0.8876, 0.0836, 0.1084, 0.1652, 0.1987, 0.0616])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6724770069122314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0304, 0.8834, 0.0851, 0.1051, 0.1663, 0.2020, 0.0605]) \n",
      "Test Loss tensor([0.0306, 0.8855, 0.0818, 0.1088, 0.1654, 0.2007, 0.0602])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6317648887634277 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8784, 0.0830, 0.1121, 0.1650, 0.2101, 0.0654]) \n",
      "Test Loss tensor([0.0305, 0.8870, 0.0831, 0.1077, 0.1661, 0.2044, 0.0608])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6359798908233643 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8963, 0.0791, 0.1138, 0.1676, 0.2059, 0.0580]) \n",
      "Test Loss tensor([0.0305, 0.8867, 0.0816, 0.1093, 0.1655, 0.1996, 0.0607])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6481184959411621 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8873, 0.0857, 0.0996, 0.1660, 0.2073, 0.0585]) \n",
      "Test Loss tensor([0.0307, 0.8864, 0.0827, 0.1062, 0.1637, 0.1997, 0.0604])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.66701340675354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0308, 0.8758, 0.0888, 0.1076, 0.1624, 0.1830, 0.0532]) \n",
      "Test Loss tensor([0.0306, 0.8832, 0.0838, 0.1104, 0.1639, 0.1992, 0.0603])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6272330284118652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0308, 0.8769, 0.0869, 0.1046, 0.1647, 0.2042, 0.0584]) \n",
      "Test Loss tensor([0.0304, 0.8872, 0.0818, 0.1068, 0.1654, 0.1943, 0.0598])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6287562847137451 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8880, 0.0818, 0.1086, 0.1649, 0.1979, 0.0568]) \n",
      "Test Loss tensor([0.0306, 0.8864, 0.0809, 0.1085, 0.1653, 0.2001, 0.0587])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6650536060333252 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0303, 0.8872, 0.0815, 0.1082, 0.1706, 0.1974, 0.0620]) \n",
      "Test Loss tensor([0.0310, 0.8849, 0.0833, 0.1091, 0.1609, 0.2044, 0.0574])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6426763534545898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0310, 0.8667, 0.0848, 0.1103, 0.1609, 0.2044, 0.0563]) \n",
      "Test Loss tensor([0.0307, 0.8847, 0.0833, 0.1073, 0.1616, 0.1997, 0.0571])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.629929780960083 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0308, 0.8807, 0.0889, 0.1074, 0.1619, 0.1823, 0.0585]) \n",
      "Test Loss tensor([0.0301, 0.8875, 0.0814, 0.1044, 0.1703, 0.1923, 0.0601])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6285450458526611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8859, 0.0819, 0.1034, 0.1702, 0.1978, 0.0569]) \n",
      "Test Loss tensor([0.0303, 0.8868, 0.0819, 0.1051, 0.1680, 0.1913, 0.0608])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6440095901489258 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0305, 0.8759, 0.0850, 0.1095, 0.1716, 0.1886, 0.0593]) \n",
      "Test Loss tensor([0.0309, 0.8807, 0.0847, 0.1071, 0.1593, 0.2012, 0.0563])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.654710054397583 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8756, 0.0859, 0.1048, 0.1602, 0.1954, 0.0509]) \n",
      "Test Loss tensor([0.0308, 0.8837, 0.0835, 0.1081, 0.1580, 0.2016, 0.0570])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6266560554504395 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0311, 0.8745, 0.0849, 0.1090, 0.1609, 0.1974, 0.0531]) \n",
      "Test Loss tensor([0.0302, 0.8819, 0.0817, 0.1042, 0.1641, 0.1915, 0.0587])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6478853225708008 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0303, 0.8764, 0.0843, 0.1042, 0.1729, 0.1946, 0.0657]) \n",
      "Test Loss tensor([0.0302, 0.8842, 0.0812, 0.1049, 0.1669, 0.1921, 0.0574])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6474409103393555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8925, 0.0831, 0.1072, 0.1648, 0.1858, 0.0536]) \n",
      "Test Loss tensor([0.0306, 0.8821, 0.0847, 0.1076, 0.1574, 0.1985, 0.0548])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6248502731323242 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8843, 0.0864, 0.1058, 0.1539, 0.2058, 0.0519]) \n",
      "Test Loss tensor([0.0307, 0.8799, 0.0860, 0.1072, 0.1545, 0.1949, 0.0541])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.629730224609375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8826, 0.0785, 0.1107, 0.1478, 0.2057, 0.0469]) \n",
      "Test Loss tensor([0.0300, 0.8818, 0.0838, 0.1037, 0.1603, 0.1913, 0.0564])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6598787307739258 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8847, 0.0805, 0.1060, 0.1606, 0.1974, 0.0486]) \n",
      "Test Loss tensor([0.0298, 0.8821, 0.0811, 0.1026, 0.1644, 0.1852, 0.0562])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6279830932617188 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0297, 0.8830, 0.0767, 0.1073, 0.1668, 0.1918, 0.0532]) \n",
      "Test Loss tensor([0.0304, 0.8781, 0.0846, 0.1079, 0.1532, 0.1912, 0.0552])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.638563871383667 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0307, 0.8916, 0.0818, 0.1047, 0.1561, 0.1908, 0.0447]) \n",
      "Test Loss tensor([0.0307, 0.8757, 0.0866, 0.1092, 0.1520, 0.1956, 0.0534])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6448276042938232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0306, 0.8823, 0.0849, 0.1105, 0.1514, 0.1962, 0.0491]) \n",
      "Test Loss tensor([0.0301, 0.8841, 0.0831, 0.1067, 0.1585, 0.1900, 0.0534])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6528761386871338 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0301, 0.8843, 0.0828, 0.1067, 0.1518, 0.1878, 0.0546]) \n",
      "Test Loss tensor([0.0295, 0.8872, 0.0808, 0.1037, 0.1662, 0.1808, 0.0539])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 128 in 0.6220786571502686 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0293, 0.8860, 0.0799, 0.1015, 0.1670, 0.1727, 0.0521]) \n",
      "Test Loss tensor([0.0298, 0.8813, 0.0825, 0.1043, 0.1588, 0.1869, 0.0544])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6604609489440918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0298, 0.8820, 0.0830, 0.1137, 0.1578, 0.1955, 0.0530]) \n",
      "Test Loss tensor([0.0300, 0.8842, 0.0825, 0.1068, 0.1546, 0.1902, 0.0505])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6452114582061768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0299, 0.8748, 0.0820, 0.1110, 0.1526, 0.1877, 0.0467]) \n",
      "Test Loss tensor([0.0301, 0.8792, 0.0843, 0.1062, 0.1566, 0.1889, 0.0518])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6332311630249023 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0302, 0.8786, 0.0811, 0.1105, 0.1540, 0.1870, 0.0507]) \n",
      "Test Loss tensor([0.0295, 0.8779, 0.0813, 0.1024, 0.1555, 0.1786, 0.0486])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6345586776733398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0292, 0.8800, 0.0856, 0.1084, 0.1653, 0.1788, 0.0504]) \n",
      "Test Loss tensor([0.0291, 0.8820, 0.0804, 0.1021, 0.1680, 0.1743, 0.0518])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6497066020965576 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0290, 0.8710, 0.0845, 0.1050, 0.1648, 0.1766, 0.0559]) \n",
      "Test Loss tensor([0.0293, 0.8796, 0.0812, 0.1037, 0.1597, 0.1720, 0.0495])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6328887939453125 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0295, 0.8794, 0.0917, 0.1059, 0.1650, 0.1740, 0.0489]) \n",
      "Test Loss tensor([0.0297, 0.8794, 0.0824, 0.1048, 0.1534, 0.1769, 0.0479])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6314013004302979 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0300, 0.8746, 0.0827, 0.1009, 0.1532, 0.1829, 0.0475]) \n",
      "Test Loss tensor([0.0297, 0.8734, 0.0824, 0.1053, 0.1542, 0.1732, 0.0470])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6377608776092529 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0296, 0.8793, 0.0832, 0.1056, 0.1532, 0.1792, 0.0432]) \n",
      "Test Loss tensor([0.0292, 0.8808, 0.0810, 0.1031, 0.1538, 0.1646, 0.0479])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6265957355499268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0292, 0.8785, 0.0805, 0.1047, 0.1643, 0.1567, 0.0453]) \n",
      "Test Loss tensor([0.0290, 0.8771, 0.0789, 0.1042, 0.1596, 0.1612, 0.0479])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7361044883728027 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0290, 0.8735, 0.0806, 0.1046, 0.1573, 0.1567, 0.0450]) \n",
      "Test Loss tensor([0.0290, 0.8734, 0.0812, 0.1029, 0.1563, 0.1561, 0.0464])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.8363006114959717 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0289, 0.8680, 0.0803, 0.1091, 0.1639, 0.1628, 0.0467]) \n",
      "Test Loss tensor([0.0291, 0.8721, 0.0802, 0.1044, 0.1546, 0.1535, 0.0442])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7741193771362305 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0292, 0.8730, 0.0742, 0.0988, 0.1527, 0.1564, 0.0445]) \n",
      "Test Loss tensor([0.0290, 0.8680, 0.0800, 0.1045, 0.1531, 0.1470, 0.0419])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6681663990020752 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0291, 0.8677, 0.0760, 0.1095, 0.1573, 0.1488, 0.0460]) \n",
      "Test Loss tensor([0.0290, 0.8616, 0.0795, 0.1026, 0.1532, 0.1399, 0.0414])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6220555305480957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0289, 0.8695, 0.0759, 0.1046, 0.1539, 0.1439, 0.0433]) \n",
      "Test Loss tensor([0.0290, 0.8533, 0.0788, 0.1043, 0.1510, 0.1388, 0.0391])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6476671695709229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0291, 0.8648, 0.0801, 0.1004, 0.1471, 0.1359, 0.0389]) \n",
      "Test Loss tensor([0.0287, 0.8535, 0.0771, 0.1049, 0.1519, 0.1254, 0.0367])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6546883583068848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0285, 0.8566, 0.0777, 0.1051, 0.1641, 0.1198, 0.0441]) \n",
      "Test Loss tensor([0.0283, 0.8440, 0.0760, 0.1057, 0.1543, 0.1185, 0.0363])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6278078556060791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0285, 0.8461, 0.0750, 0.1018, 0.1501, 0.1126, 0.0342]) \n",
      "Test Loss tensor([0.0286, 0.8298, 0.0773, 0.1093, 0.1487, 0.1167, 0.0344])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6460800170898438 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0284, 0.8369, 0.0766, 0.1086, 0.1482, 0.1226, 0.0383]) \n",
      "Test Loss tensor([0.0284, 0.8232, 0.0749, 0.1107, 0.1518, 0.1144, 0.0304])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6120107173919678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0286, 0.8292, 0.0730, 0.1184, 0.1509, 0.1087, 0.0286]) \n",
      "Test Loss tensor([0.0280, 0.8138, 0.0731, 0.1153, 0.1536, 0.1072, 0.0292])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6099991798400879 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0280, 0.8058, 0.0770, 0.1224, 0.1466, 0.1070, 0.0295]) \n",
      "Test Loss tensor([0.0273, 0.8106, 0.0720, 0.1148, 0.1524, 0.1001, 0.0270])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.617264986038208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0270, 0.8003, 0.0735, 0.1205, 0.1531, 0.0954, 0.0273]) \n",
      "Test Loss tensor([0.0268, 0.8048, 0.0708, 0.1191, 0.1563, 0.0940, 0.0255])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6030635833740234 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0270, 0.7999, 0.0751, 0.1187, 0.1596, 0.0912, 0.0248]) \n",
      "Test Loss tensor([0.0265, 0.7925, 0.0691, 0.1292, 0.1527, 0.0954, 0.0224])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6070687770843506 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0266, 0.7933, 0.0658, 0.1356, 0.1487, 0.1007, 0.0217]) \n",
      "Test Loss tensor([0.0258, 0.7833, 0.0676, 0.1302, 0.1585, 0.0890, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6003804206848145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0264, 0.7844, 0.0647, 0.1353, 0.1588, 0.0918, 0.0213]) \n",
      "Test Loss tensor([0.0249, 0.7813, 0.0667, 0.1353, 0.1573, 0.0866, 0.0207])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6054422855377197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0250, 0.7717, 0.0643, 0.1309, 0.1592, 0.0861, 0.0211]) \n",
      "Test Loss tensor([0.0239, 0.7748, 0.0635, 0.1356, 0.1600, 0.0825, 0.0203])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6087007522583008 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0239, 0.7831, 0.0648, 0.1317, 0.1625, 0.0784, 0.0200]) \n",
      "Test Loss tensor([0.0233, 0.7666, 0.0623, 0.1435, 0.1587, 0.0795, 0.0168])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6365642547607422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0234, 0.7631, 0.0625, 0.1439, 0.1635, 0.0782, 0.0164]) \n",
      "Test Loss tensor([0.0226, 0.7470, 0.0606, 0.1570, 0.1584, 0.0808, 0.0151])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6614108085632324 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0226, 0.7438, 0.0618, 0.1578, 0.1711, 0.0773, 0.0136]) \n",
      "Test Loss tensor([0.0219, 0.7284, 0.0600, 0.1650, 0.1612, 0.0783, 0.0135])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6853876113891602 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0217, 0.7315, 0.0614, 0.1669, 0.1528, 0.0741, 0.0139]) \n",
      "Test Loss tensor([0.0211, 0.7035, 0.0583, 0.1736, 0.1605, 0.0745, 0.0128])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6391119956970215 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0210, 0.7151, 0.0609, 0.1856, 0.1581, 0.0760, 0.0131]) \n",
      "Test Loss tensor([0.0204, 0.6591, 0.0568, 0.1914, 0.1637, 0.0761, 0.0118])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.64105224609375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0206, 0.6566, 0.0573, 0.1941, 0.1621, 0.0767, 0.0137]) \n",
      "Test Loss tensor([0.0200, 0.5567, 0.0601, 0.2266, 0.1696, 0.0742, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6077184677124023 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0202, 0.5447, 0.0579, 0.2287, 0.1795, 0.0770, 0.0152]) \n",
      "Test Loss tensor([0.0198, 0.4000, 0.0666, 0.2878, 0.1882, 0.0786, 0.0127])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.630739688873291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0197, 0.4096, 0.0689, 0.2949, 0.1885, 0.0851, 0.0137]) \n",
      "Test Loss tensor([0.0191, 0.2877, 0.0687, 0.3278, 0.1997, 0.0808, 0.0126])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6696417331695557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0193, 0.2833, 0.0682, 0.3265, 0.1968, 0.0761, 0.0128]) \n",
      "Test Loss tensor([0.0176, 0.2530, 0.0577, 0.3192, 0.1882, 0.0732, 0.0120])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6368348598480225 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0174, 0.2613, 0.0581, 0.3160, 0.1972, 0.0725, 0.0143]) \n",
      "Test Loss tensor([0.0159, 0.2481, 0.0489, 0.2871, 0.1752, 0.0752, 0.0144])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 272 in 0.782719612121582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0160, 0.2463, 0.0460, 0.2919, 0.1814, 0.0716, 0.0119]) \n",
      "Test Loss tensor([0.0145, 0.2152, 0.0454, 0.2844, 0.1770, 0.0804, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6802265644073486 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0143, 0.2216, 0.0437, 0.2901, 0.1768, 0.0855, 0.0197]) \n",
      "Test Loss tensor([0.0133, 0.1660, 0.0431, 0.3064, 0.1786, 0.0824, 0.0219])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.760023832321167 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0133, 0.1511, 0.0459, 0.3033, 0.1767, 0.0813, 0.0225]) \n",
      "Test Loss tensor([0.0124, 0.1245, 0.0414, 0.3277, 0.1797, 0.0789, 0.0208])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.8016681671142578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0120, 0.1197, 0.0386, 0.3274, 0.1670, 0.0691, 0.0199]) \n",
      "Test Loss tensor([0.0110, 0.1175, 0.0384, 0.3194, 0.1807, 0.0804, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6738181114196777 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0108, 0.1143, 0.0409, 0.3245, 0.1850, 0.0800, 0.0211]) \n",
      "Test Loss tensor([0.0096, 0.1210, 0.0372, 0.2840, 0.1818, 0.0860, 0.0233])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.9083905220031738 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0096, 0.1237, 0.0360, 0.2820, 0.1835, 0.0881, 0.0261]) \n",
      "Test Loss tensor([0.0085, 0.1185, 0.0328, 0.2719, 0.1810, 0.0850, 0.0202])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7552673816680908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0083, 0.1367, 0.0301, 0.2779, 0.1877, 0.0895, 0.0206]) \n",
      "Test Loss tensor([0.0076, 0.1097, 0.0303, 0.2686, 0.1806, 0.0799, 0.0152])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7149577140808105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0074, 0.1018, 0.0280, 0.2650, 0.1754, 0.0746, 0.0148]) \n",
      "Test Loss tensor([0.0067, 0.1029, 0.0293, 0.2590, 0.1835, 0.0753, 0.0121])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7089705467224121 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0066, 0.1020, 0.0279, 0.2435, 0.1801, 0.0788, 0.0127]) \n",
      "Test Loss tensor([0.0059, 0.0968, 0.0285, 0.2534, 0.1788, 0.0724, 0.0108])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7689182758331299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0059, 0.0977, 0.0318, 0.2527, 0.1970, 0.0704, 0.0111]) \n",
      "Test Loss tensor([0.0053, 0.1019, 0.0249, 0.2396, 0.1790, 0.0700, 0.0098])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.690157413482666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0053, 0.0988, 0.0277, 0.2511, 0.1789, 0.0711, 0.0099]) \n",
      "Test Loss tensor([0.0046, 0.1067, 0.0243, 0.2211, 0.1835, 0.0706, 0.0091])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7532069683074951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0047, 0.1056, 0.0235, 0.2184, 0.1863, 0.0729, 0.0087]) \n",
      "Test Loss tensor([0.0041, 0.1134, 0.0232, 0.2031, 0.1836, 0.0713, 0.0090])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6753489971160889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0041, 0.1131, 0.0205, 0.1997, 0.1856, 0.0673, 0.0082]) \n",
      "Test Loss tensor([0.0037, 0.1124, 0.0220, 0.2007, 0.1828, 0.0680, 0.0081])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7000491619110107 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0037, 0.1163, 0.0196, 0.1895, 0.1966, 0.0695, 0.0080]) \n",
      "Test Loss tensor([0.0034, 0.1035, 0.0218, 0.2009, 0.1817, 0.0637, 0.0084])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.5926549434661865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0034, 0.1114, 0.0220, 0.2091, 0.1910, 0.0692, 0.0072]) \n",
      "Test Loss tensor([0.0031, 0.1009, 0.0198, 0.1994, 0.1841, 0.0634, 0.0069])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5720162391662598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0033, 0.1060, 0.0210, 0.1956, 0.1864, 0.0672, 0.0053]) \n",
      "Test Loss tensor([0.0029, 0.1008, 0.0194, 0.1952, 0.1829, 0.0628, 0.0068])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5913443565368652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0029, 0.1047, 0.0171, 0.1856, 0.1907, 0.0605, 0.0056]) \n",
      "Test Loss tensor([0.0027, 0.1027, 0.0181, 0.1879, 0.1833, 0.0642, 0.0069])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6200613975524902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0027, 0.1109, 0.0198, 0.1904, 0.1888, 0.0620, 0.0064]) \n",
      "Test Loss tensor([0.0025, 0.1051, 0.0174, 0.1747, 0.1834, 0.0606, 0.0066])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6276297569274902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0025, 0.1138, 0.0160, 0.1758, 0.1913, 0.0634, 0.0063]) \n",
      "Test Loss tensor([0.0023, 0.1106, 0.0168, 0.1685, 0.1853, 0.0617, 0.0058])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6357705593109131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0023, 0.1177, 0.0181, 0.1716, 0.1817, 0.0623, 0.0082]) \n",
      "Test Loss tensor([0.0022, 0.1077, 0.0176, 0.1641, 0.1825, 0.0623, 0.0062])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7127985954284668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0022, 0.1122, 0.0174, 0.1590, 0.1896, 0.0647, 0.0061]) \n",
      "Test Loss tensor([0.0022, 0.1028, 0.0164, 0.1662, 0.1838, 0.0615, 0.0064])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6183111667633057 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0022, 0.1009, 0.0186, 0.1748, 0.1859, 0.0608, 0.0054]) \n",
      "Test Loss tensor([0.0021, 0.0989, 0.0155, 0.1647, 0.1856, 0.0602, 0.0064])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6079220771789551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.1019, 0.0176, 0.1581, 0.1893, 0.0660, 0.0073]) \n",
      "Test Loss tensor([0.0020, 0.1045, 0.0144, 0.1600, 0.1833, 0.0608, 0.0060])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.608640193939209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.1163, 0.0137, 0.1585, 0.1844, 0.0600, 0.0076]) \n",
      "Test Loss tensor([0.0019, 0.1112, 0.0137, 0.1484, 0.1843, 0.0602, 0.0060])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6104044914245605 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.1158, 0.0147, 0.1464, 0.1812, 0.0602, 0.0070]) \n",
      "Test Loss tensor([0.0019, 0.1150, 0.0136, 0.1406, 0.1846, 0.0604, 0.0057])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6283957958221436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.1187, 0.0124, 0.1310, 0.1844, 0.0672, 0.0059]) \n",
      "Test Loss tensor([0.0019, 0.1047, 0.0132, 0.1447, 0.1850, 0.0605, 0.0057])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.636742115020752 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.1056, 0.0113, 0.1599, 0.1894, 0.0619, 0.0063]) \n",
      "Test Loss tensor([0.0019, 0.0969, 0.0133, 0.1514, 0.1874, 0.0602, 0.0063])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6201894283294678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.1013, 0.0126, 0.1456, 0.1798, 0.0627, 0.0074]) \n",
      "Test Loss tensor([0.0018, 0.0936, 0.0140, 0.1536, 0.1853, 0.0608, 0.0069])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6351058483123779 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0969, 0.0114, 0.1389, 0.1897, 0.0628, 0.0064]) \n",
      "Test Loss tensor([0.0018, 0.0969, 0.0134, 0.1421, 0.1840, 0.0611, 0.0060])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6381433010101318 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0991, 0.0154, 0.1530, 0.1851, 0.0643, 0.0067]) \n",
      "Test Loss tensor([0.0018, 0.1064, 0.0128, 0.1321, 0.1839, 0.0605, 0.0055])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6356353759765625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.1071, 0.0138, 0.1310, 0.1952, 0.0615, 0.0067]) \n",
      "Test Loss tensor([0.0018, 0.1120, 0.0119, 0.1234, 0.1835, 0.0621, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6199119091033936 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.1087, 0.0139, 0.1243, 0.1932, 0.0612, 0.0053]) \n",
      "Test Loss tensor([0.0018, 0.1022, 0.0122, 0.1291, 0.1819, 0.0599, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5998985767364502 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0996, 0.0133, 0.1250, 0.1835, 0.0599, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0927, 0.0122, 0.1376, 0.1807, 0.0608, 0.0055])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7432897090911865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0975, 0.0138, 0.1340, 0.1871, 0.0577, 0.0064]) \n",
      "Test Loss tensor([0.0018, 0.0921, 0.0129, 0.1371, 0.1824, 0.0585, 0.0059])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.770256757736206 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0983, 0.0143, 0.1367, 0.1808, 0.0588, 0.0057]) \n",
      "Test Loss tensor([0.0018, 0.0980, 0.0113, 0.1291, 0.1815, 0.0595, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6585671901702881 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.1013, 0.0137, 0.1248, 0.1738, 0.0623, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.1064, 0.0118, 0.1160, 0.1814, 0.0630, 0.0053])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 416 in 0.687758207321167 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.1070, 0.0117, 0.1176, 0.1839, 0.0687, 0.0056]) \n",
      "Test Loss tensor([0.0018, 0.1017, 0.0114, 0.1127, 0.1834, 0.0617, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.639775276184082 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.1052, 0.0134, 0.1146, 0.1901, 0.0614, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.0939, 0.0128, 0.1249, 0.1793, 0.0620, 0.0054])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6222953796386719 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0896, 0.0118, 0.1166, 0.1834, 0.0614, 0.0057]) \n",
      "Test Loss tensor([0.0017, 0.0868, 0.0134, 0.1334, 0.1807, 0.0592, 0.0060])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6673645973205566 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0835, 0.0131, 0.1340, 0.1698, 0.0593, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0896, 0.0134, 0.1234, 0.1775, 0.0622, 0.0053])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6107938289642334 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0976, 0.0131, 0.1324, 0.1769, 0.0621, 0.0058]) \n",
      "Test Loss tensor([0.0018, 0.0971, 0.0124, 0.1192, 0.1792, 0.0618, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5975069999694824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0903, 0.0125, 0.1111, 0.1724, 0.0610, 0.0065]) \n",
      "Test Loss tensor([0.0018, 0.1025, 0.0107, 0.1040, 0.1821, 0.0609, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5870306491851807 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.1084, 0.0112, 0.1062, 0.1715, 0.0576, 0.0053]) \n",
      "Test Loss tensor([0.0017, 0.0985, 0.0113, 0.1085, 0.1779, 0.0627, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6014745235443115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0911, 0.0107, 0.1041, 0.1889, 0.0584, 0.0053]) \n",
      "Test Loss tensor([0.0017, 0.0931, 0.0116, 0.1122, 0.1729, 0.0594, 0.0054])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.581740140914917 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0885, 0.0149, 0.1146, 0.1668, 0.0561, 0.0053]) \n",
      "Test Loss tensor([0.0017, 0.0902, 0.0122, 0.1136, 0.1715, 0.0590, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5881521701812744 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0892, 0.0128, 0.1293, 0.1814, 0.0550, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0934, 0.0127, 0.1111, 0.1757, 0.0592, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6355786323547363 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0940, 0.0129, 0.1181, 0.1827, 0.0570, 0.0054]) \n",
      "Test Loss tensor([0.0017, 0.0949, 0.0118, 0.1046, 0.1742, 0.0589, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5859804153442383 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.1053, 0.0143, 0.1121, 0.1742, 0.0596, 0.0055]) \n",
      "Test Loss tensor([0.0017, 0.0938, 0.0122, 0.1025, 0.1770, 0.0584, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.5942280292510986 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0929, 0.0107, 0.1104, 0.1760, 0.0619, 0.0058]) \n",
      "Test Loss tensor([0.0017, 0.0932, 0.0114, 0.1076, 0.1747, 0.0567, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5822136402130127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0912, 0.0141, 0.1006, 0.1816, 0.0617, 0.0055]) \n",
      "Test Loss tensor([0.0017, 0.0939, 0.0122, 0.1038, 0.1715, 0.0568, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5846388339996338 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0875, 0.0124, 0.1071, 0.1731, 0.0616, 0.0052]) \n",
      "Test Loss tensor([0.0017, 0.0978, 0.0118, 0.1000, 0.1729, 0.0587, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.5995373725891113 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0932, 0.0118, 0.0984, 0.1749, 0.0564, 0.0046]) \n",
      "Test Loss tensor([0.0017, 0.0995, 0.0112, 0.0935, 0.1735, 0.0571, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6126618385314941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0955, 0.0130, 0.0960, 0.1761, 0.0583, 0.0046]) \n",
      "Test Loss tensor([0.0017, 0.0924, 0.0108, 0.0997, 0.1693, 0.0573, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5961964130401611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0930, 0.0134, 0.1034, 0.1762, 0.0582, 0.0053]) \n",
      "Test Loss tensor([0.0017, 0.0883, 0.0113, 0.1038, 0.1671, 0.0575, 0.0055])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.591223955154419 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0922, 0.0114, 0.1025, 0.1698, 0.0578, 0.0063]) \n",
      "Test Loss tensor([0.0017, 0.0876, 0.0115, 0.0999, 0.1691, 0.0569, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6040453910827637 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0883, 0.0118, 0.0946, 0.1681, 0.0576, 0.0061]) \n",
      "Test Loss tensor([0.0017, 0.0919, 0.0106, 0.0941, 0.1690, 0.0564, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.603426456451416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0889, 0.0103, 0.0926, 0.1751, 0.0645, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0921, 0.0103, 0.0941, 0.1713, 0.0559, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6423177719116211 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0921, 0.0119, 0.0989, 0.1880, 0.0586, 0.0061]) \n",
      "Test Loss tensor([0.0017, 0.0859, 0.0121, 0.0996, 0.1697, 0.0546, 0.0053])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5893075466156006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0897, 0.0128, 0.0945, 0.1592, 0.0535, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0847, 0.0114, 0.1005, 0.1672, 0.0562, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5924968719482422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0886, 0.0128, 0.1084, 0.1740, 0.0663, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0880, 0.0106, 0.0970, 0.1691, 0.0559, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5886917114257812 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0928, 0.0126, 0.0957, 0.1819, 0.0582, 0.0063]) \n",
      "Test Loss tensor([0.0017, 0.0912, 0.0101, 0.0935, 0.1677, 0.0557, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.5870883464813232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0935, 0.0121, 0.1000, 0.1799, 0.0510, 0.0050]) \n",
      "Test Loss tensor([0.0017, 0.0874, 0.0109, 0.0953, 0.1654, 0.0554, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.60282301902771 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0879, 0.0096, 0.0958, 0.1750, 0.0531, 0.0055]) \n",
      "Test Loss tensor([0.0017, 0.0820, 0.0108, 0.0967, 0.1643, 0.0530, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.5988211631774902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0867, 0.0120, 0.0960, 0.1710, 0.0501, 0.0057]) \n",
      "Test Loss tensor([0.0017, 0.0848, 0.0109, 0.0971, 0.1639, 0.0535, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.607107400894165 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0838, 0.0106, 0.0996, 0.1708, 0.0568, 0.0046]) \n",
      "Test Loss tensor([0.0017, 0.0853, 0.0108, 0.0963, 0.1633, 0.0552, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6081945896148682 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0845, 0.0114, 0.0962, 0.1708, 0.0566, 0.0041]) \n",
      "Test Loss tensor([0.0017, 0.0873, 0.0104, 0.0934, 0.1660, 0.0553, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5859394073486328 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0849, 0.0113, 0.0891, 0.1667, 0.0552, 0.0042]) \n",
      "Test Loss tensor([0.0017, 0.0839, 0.0103, 0.0947, 0.1639, 0.0537, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5913407802581787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0879, 0.0103, 0.0980, 0.1701, 0.0559, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0831, 0.0106, 0.0946, 0.1628, 0.0519, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.5970208644866943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0840, 0.0114, 0.0991, 0.1655, 0.0456, 0.0060]) \n",
      "Test Loss tensor([0.0017, 0.0820, 0.0100, 0.0912, 0.1622, 0.0549, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6044478416442871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0871, 0.0138, 0.0914, 0.1676, 0.0522, 0.0049]) \n",
      "Test Loss tensor([0.0017, 0.0858, 0.0101, 0.0905, 0.1660, 0.0520, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6138756275177002 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0847, 0.0122, 0.0824, 0.1686, 0.0506, 0.0059]) \n",
      "Test Loss tensor([0.0017, 0.0881, 0.0101, 0.0902, 0.1650, 0.0531, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.5986363887786865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0899, 0.0113, 0.0914, 0.1697, 0.0494, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0848, 0.0100, 0.0898, 0.1626, 0.0509, 0.0042])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 560 in 0.5958564281463623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0819, 0.0082, 0.0863, 0.1635, 0.0538, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0787, 0.0118, 0.0970, 0.1602, 0.0538, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5936985015869141 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0783, 0.0114, 0.0896, 0.1647, 0.0527, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0815, 0.0118, 0.0954, 0.1579, 0.0526, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5928201675415039 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0816, 0.0108, 0.0963, 0.1672, 0.0534, 0.0056]) \n",
      "Test Loss tensor([0.0017, 0.0863, 0.0095, 0.0852, 0.1633, 0.0512, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5929036140441895 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0880, 0.0089, 0.0865, 0.1647, 0.0492, 0.0046]) \n",
      "Test Loss tensor([0.0017, 0.0860, 0.0092, 0.0819, 0.1624, 0.0517, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.613621711730957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0841, 0.0080, 0.0815, 0.1650, 0.0520, 0.0049]) \n",
      "Test Loss tensor([0.0017, 0.0796, 0.0105, 0.0914, 0.1583, 0.0502, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5940229892730713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0836, 0.0118, 0.0876, 0.1508, 0.0567, 0.0041]) \n",
      "Test Loss tensor([0.0017, 0.0778, 0.0107, 0.0938, 0.1552, 0.0544, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6080989837646484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0859, 0.0138, 0.0997, 0.1667, 0.0542, 0.0057]) \n",
      "Test Loss tensor([0.0017, 0.0800, 0.0112, 0.0885, 0.1562, 0.0522, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5946612358093262 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0868, 0.0121, 0.0846, 0.1578, 0.0540, 0.0044]) \n",
      "Test Loss tensor([0.0017, 0.0835, 0.0103, 0.0825, 0.1568, 0.0516, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5929908752441406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0895, 0.0126, 0.0847, 0.1573, 0.0581, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0834, 0.0106, 0.0814, 0.1614, 0.0528, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5852639675140381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0900, 0.0082, 0.0774, 0.1691, 0.0503, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0797, 0.0112, 0.0893, 0.1576, 0.0506, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5838184356689453 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0852, 0.0116, 0.0823, 0.1594, 0.0458, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0772, 0.0117, 0.0929, 0.1536, 0.0505, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5858056545257568 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0770, 0.0089, 0.0895, 0.1509, 0.0511, 0.0043]) \n",
      "Test Loss tensor([0.0017, 0.0779, 0.0111, 0.0892, 0.1511, 0.0516, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5901367664337158 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0808, 0.0104, 0.0932, 0.1586, 0.0529, 0.0053]) \n",
      "Test Loss tensor([0.0017, 0.0831, 0.0112, 0.0832, 0.1530, 0.0503, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6089797019958496 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0858, 0.0096, 0.0904, 0.1696, 0.0568, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0825, 0.0101, 0.0813, 0.1536, 0.0501, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6315183639526367 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0870, 0.0101, 0.0753, 0.1527, 0.0493, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0802, 0.0106, 0.0837, 0.1523, 0.0509, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6120882034301758 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0782, 0.0100, 0.0783, 0.1463, 0.0454, 0.0039]) \n",
      "Test Loss tensor([0.0017, 0.0789, 0.0097, 0.0874, 0.1537, 0.0484, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6215157508850098 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0739, 0.0097, 0.0849, 0.1491, 0.0507, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0797, 0.0105, 0.0859, 0.1526, 0.0484, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6144001483917236 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0801, 0.0093, 0.0869, 0.1568, 0.0531, 0.0041]) \n",
      "Test Loss tensor([0.0017, 0.0815, 0.0099, 0.0800, 0.1522, 0.0502, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.7852694988250732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0789, 0.0109, 0.0810, 0.1605, 0.0513, 0.0043]) \n",
      "Test Loss tensor([0.0017, 0.0813, 0.0097, 0.0808, 0.1526, 0.0508, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.7898905277252197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0834, 0.0110, 0.0820, 0.1470, 0.0505, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0759, 0.0111, 0.0850, 0.1526, 0.0506, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6931309700012207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0803, 0.0116, 0.0867, 0.1493, 0.0457, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0745, 0.0115, 0.0857, 0.1509, 0.0491, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.8129115104675293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0710, 0.0118, 0.0849, 0.1503, 0.0509, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0779, 0.0094, 0.0833, 0.1504, 0.0503, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.728297233581543 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0767, 0.0104, 0.0787, 0.1500, 0.0489, 0.0041]) \n",
      "Test Loss tensor([0.0017, 0.0800, 0.0096, 0.0788, 0.1528, 0.0495, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6207444667816162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0808, 0.0092, 0.0769, 0.1567, 0.0506, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0802, 0.0090, 0.0798, 0.1524, 0.0498, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6285305023193359 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0820, 0.0115, 0.0801, 0.1518, 0.0505, 0.0037]) \n",
      "Test Loss tensor([0.0017, 0.0769, 0.0099, 0.0832, 0.1480, 0.0498, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6368536949157715 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0793, 0.0115, 0.0870, 0.1554, 0.0527, 0.0045]) \n",
      "Test Loss tensor([0.0017, 0.0748, 0.0107, 0.0860, 0.1452, 0.0494, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6126673221588135 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0770, 0.0095, 0.0773, 0.1609, 0.0483, 0.0042]) \n",
      "Test Loss tensor([0.0017, 0.0769, 0.0100, 0.0820, 0.1440, 0.0471, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6221871376037598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0782, 0.0089, 0.0892, 0.1504, 0.0482, 0.0041]) \n",
      "Test Loss tensor([0.0017, 0.0769, 0.0102, 0.0803, 0.1503, 0.0489, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6263515949249268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0772, 0.0113, 0.0907, 0.1647, 0.0519, 0.0044]) \n",
      "Test Loss tensor([0.0017, 0.0766, 0.0097, 0.0792, 0.1488, 0.0481, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6031973361968994 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0741, 0.0075, 0.0801, 0.1484, 0.0511, 0.0037]) \n",
      "Test Loss tensor([0.0017, 0.0732, 0.0101, 0.0811, 0.1494, 0.0490, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6605677604675293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0690, 0.0103, 0.0774, 0.1423, 0.0481, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0738, 0.0103, 0.0799, 0.1434, 0.0487, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6284358501434326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0709, 0.0123, 0.0804, 0.1462, 0.0481, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0757, 0.0108, 0.0770, 0.1448, 0.0464, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.600414514541626 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0838, 0.0103, 0.0820, 0.1510, 0.0505, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0738, 0.0107, 0.0767, 0.1398, 0.0472, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6187365055084229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0747, 0.0137, 0.0850, 0.1589, 0.0492, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0734, 0.0101, 0.0782, 0.1422, 0.0480, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6244173049926758 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0797, 0.0082, 0.0861, 0.1446, 0.0504, 0.0039]) \n",
      "Test Loss tensor([0.0017, 0.0733, 0.0103, 0.0783, 0.1442, 0.0497, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.60980224609375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0662, 0.0114, 0.0780, 0.1409, 0.0468, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0739, 0.0108, 0.0775, 0.1414, 0.0485, 0.0036])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 704 in 0.6331462860107422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0782, 0.0097, 0.0759, 0.1499, 0.0496, 0.0045]) \n",
      "Test Loss tensor([0.0017, 0.0749, 0.0101, 0.0760, 0.1422, 0.0486, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6583890914916992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0751, 0.0120, 0.0820, 0.1406, 0.0519, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0752, 0.0106, 0.0779, 0.1381, 0.0479, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5983209609985352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0701, 0.0108, 0.0746, 0.1420, 0.0495, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0723, 0.0111, 0.0803, 0.1426, 0.0471, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5910673141479492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0723, 0.0125, 0.0785, 0.1445, 0.0493, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0715, 0.0109, 0.0790, 0.1398, 0.0471, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5887472629547119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0694, 0.0109, 0.0807, 0.1388, 0.0482, 0.0041]) \n",
      "Test Loss tensor([0.0018, 0.0771, 0.0098, 0.0767, 0.1404, 0.0471, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5903644561767578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0743, 0.0087, 0.0763, 0.1500, 0.0495, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0776, 0.0103, 0.0726, 0.1388, 0.0466, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5848584175109863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0778, 0.0101, 0.0677, 0.1404, 0.0494, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0729, 0.0103, 0.0750, 0.1405, 0.0467, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.5879898071289062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0719, 0.0100, 0.0699, 0.1438, 0.0480, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0717, 0.0113, 0.0763, 0.1358, 0.0462, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6132457256317139 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0736, 0.0114, 0.0771, 0.1466, 0.0498, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0725, 0.0102, 0.0737, 0.1385, 0.0469, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6065504550933838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0710, 0.0111, 0.0728, 0.1404, 0.0510, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0749, 0.0096, 0.0701, 0.1395, 0.0471, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.619678258895874 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0693, 0.0103, 0.0784, 0.1468, 0.0417, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0730, 0.0096, 0.0741, 0.1404, 0.0458, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6819496154785156 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0728, 0.0093, 0.0714, 0.1433, 0.0521, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0693, 0.0109, 0.0787, 0.1327, 0.0462, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6914258003234863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0729, 0.0112, 0.0774, 0.1338, 0.0470, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0715, 0.0099, 0.0729, 0.1371, 0.0461, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6438033580780029 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0697, 0.0099, 0.0725, 0.1401, 0.0426, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0754, 0.0091, 0.0709, 0.1432, 0.0472, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6777276992797852 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0730, 0.0069, 0.0727, 0.1397, 0.0493, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0716, 0.0094, 0.0748, 0.1349, 0.0454, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6683404445648193 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0656, 0.0099, 0.0795, 0.1448, 0.0434, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0686, 0.0111, 0.0798, 0.1374, 0.0471, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6838922500610352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0671, 0.0113, 0.0817, 0.1345, 0.0444, 0.0044]) \n",
      "Test Loss tensor([0.0017, 0.0698, 0.0102, 0.0737, 0.1304, 0.0458, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6740891933441162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0719, 0.0123, 0.0750, 0.1375, 0.0460, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0741, 0.0093, 0.0699, 0.1400, 0.0466, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5836358070373535 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0715, 0.0080, 0.0633, 0.1354, 0.0491, 0.0038]) \n",
      "Test Loss tensor([0.0017, 0.0709, 0.0088, 0.0723, 0.1349, 0.0450, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.5905029773712158 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0723, 0.0087, 0.0679, 0.1303, 0.0463, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0697, 0.0113, 0.0742, 0.1318, 0.0439, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6046886444091797 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0690, 0.0119, 0.0810, 0.1288, 0.0436, 0.0039]) \n",
      "Test Loss tensor([0.0017, 0.0677, 0.0109, 0.0769, 0.1311, 0.0457, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.7006220817565918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0691, 0.0113, 0.0834, 0.1382, 0.0449, 0.0041]) \n",
      "Test Loss tensor([0.0018, 0.0687, 0.0102, 0.0713, 0.1355, 0.0453, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6779203414916992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0680, 0.0134, 0.0775, 0.1322, 0.0423, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0705, 0.0088, 0.0676, 0.1352, 0.0465, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6781394481658936 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0657, 0.0109, 0.0658, 0.1383, 0.0448, 0.0040]) \n",
      "Test Loss tensor([0.0017, 0.0671, 0.0111, 0.0738, 0.1294, 0.0448, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6842870712280273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0659, 0.0132, 0.0829, 0.1355, 0.0475, 0.0048]) \n",
      "Test Loss tensor([0.0017, 0.0684, 0.0116, 0.0761, 0.1281, 0.0469, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.658381462097168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0698, 0.0092, 0.0724, 0.1323, 0.0432, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.0697, 0.0109, 0.0731, 0.1282, 0.0455, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6757323741912842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0662, 0.0077, 0.0661, 0.1237, 0.0416, 0.0037]) \n",
      "Test Loss tensor([0.0018, 0.0720, 0.0090, 0.0684, 0.1302, 0.0441, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.649695873260498 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0721, 0.0096, 0.0666, 0.1289, 0.0414, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0671, 0.0101, 0.0712, 0.1274, 0.0452, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6721558570861816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0702, 0.0130, 0.0672, 0.1273, 0.0433, 0.0042]) \n",
      "Test Loss tensor([0.0017, 0.0666, 0.0125, 0.0751, 0.1258, 0.0442, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6791965961456299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0669, 0.0130, 0.0761, 0.1310, 0.0454, 0.0046]) \n",
      "Test Loss tensor([0.0018, 0.0679, 0.0113, 0.0695, 0.1254, 0.0442, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6211757659912109 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0664, 0.0106, 0.0660, 0.1264, 0.0436, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.0728, 0.0092, 0.0689, 0.1290, 0.0453, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.7046685218811035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0768, 0.0082, 0.0684, 0.1305, 0.0491, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0698, 0.0096, 0.0666, 0.1252, 0.0456, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6770286560058594 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0700, 0.0088, 0.0651, 0.1265, 0.0437, 0.0051]) \n",
      "Test Loss tensor([0.0018, 0.0651, 0.0118, 0.0734, 0.1252, 0.0458, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7174866199493408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0604, 0.0127, 0.0799, 0.1335, 0.0471, 0.0050]) \n",
      "Test Loss tensor([0.0018, 0.0664, 0.0115, 0.0714, 0.1233, 0.0448, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6384880542755127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0655, 0.0127, 0.0713, 0.1135, 0.0438, 0.0041]) \n",
      "Test Loss tensor([0.0018, 0.0733, 0.0089, 0.0685, 0.1274, 0.0455, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6909928321838379 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0735, 0.0071, 0.0583, 0.1249, 0.0475, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0701, 0.0088, 0.0637, 0.1228, 0.0452, 0.0043])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 848 in 0.7124667167663574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0646, 0.0086, 0.0642, 0.1298, 0.0443, 0.0047]) \n",
      "Test Loss tensor([0.0018, 0.0648, 0.0107, 0.0707, 0.1227, 0.0455, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6520090103149414 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0650, 0.0121, 0.0678, 0.1197, 0.0443, 0.0039]) \n",
      "Test Loss tensor([0.0018, 0.0637, 0.0127, 0.0718, 0.1203, 0.0460, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.7058563232421875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0706, 0.0086, 0.0686, 0.1172, 0.0436, 0.0039]) \n",
      "Test Loss tensor([0.0018, 0.0639, 0.0100, 0.0679, 0.1212, 0.0444, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6791605949401855 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0650, 0.0105, 0.0667, 0.1235, 0.0462, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0721, 0.0084, 0.0635, 0.1284, 0.0447, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6285557746887207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0753, 0.0076, 0.0634, 0.1233, 0.0441, 0.0046]) \n",
      "Test Loss tensor([0.0018, 0.0678, 0.0088, 0.0653, 0.1229, 0.0441, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6527814865112305 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0707, 0.0069, 0.0662, 0.1184, 0.0476, 0.0041]) \n",
      "Test Loss tensor([0.0018, 0.0610, 0.0107, 0.0717, 0.1213, 0.0480, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6362216472625732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0587, 0.0103, 0.0725, 0.1153, 0.0435, 0.0038]) \n",
      "Test Loss tensor([0.0018, 0.0615, 0.0103, 0.0688, 0.1192, 0.0455, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5821702480316162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0013, 0.0523, 0.0087, 0.0524, 0.0887, 0.0370, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0654, 0.0084, 0.0647, 0.1208, 0.0426, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6438078880310059 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0591, 0.0099, 0.0698, 0.1173, 0.0423, 0.0059]) \n",
      "Test Loss tensor([0.0017, 0.0637, 0.0079, 0.0639, 0.1207, 0.0437, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6186895370483398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0658, 0.0079, 0.0711, 0.1344, 0.0411, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0638, 0.0096, 0.0685, 0.1183, 0.0426, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6054613590240479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0626, 0.0114, 0.0685, 0.1122, 0.0429, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0630, 0.0101, 0.0673, 0.1178, 0.0427, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6308717727661133 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0622, 0.0096, 0.0747, 0.1171, 0.0492, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0631, 0.0094, 0.0647, 0.1184, 0.0442, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6145026683807373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0643, 0.0089, 0.0612, 0.1221, 0.0425, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0628, 0.0090, 0.0655, 0.1175, 0.0433, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6149022579193115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0671, 0.0101, 0.0602, 0.1117, 0.0485, 0.0038]) \n",
      "Test Loss tensor([0.0018, 0.0610, 0.0105, 0.0676, 0.1155, 0.0446, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6142704486846924 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0608, 0.0099, 0.0664, 0.1195, 0.0445, 0.0050]) \n",
      "Test Loss tensor([0.0018, 0.0598, 0.0106, 0.0694, 0.1135, 0.0447, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6079895496368408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0667, 0.0108, 0.0710, 0.1245, 0.0453, 0.0037]) \n",
      "Test Loss tensor([0.0018, 0.0619, 0.0103, 0.0671, 0.1161, 0.0436, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6071603298187256 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0631, 0.0122, 0.0715, 0.1117, 0.0458, 0.0038]) \n",
      "Test Loss tensor([0.0018, 0.0641, 0.0091, 0.0665, 0.1165, 0.0428, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6698665618896484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0670, 0.0097, 0.0666, 0.1158, 0.0401, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0624, 0.0104, 0.0680, 0.1135, 0.0422, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.648923397064209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0608, 0.0104, 0.0640, 0.1171, 0.0384, 0.0043]) \n",
      "Test Loss tensor([0.0018, 0.0598, 0.0115, 0.0665, 0.1118, 0.0431, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6281816959381104 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0628, 0.0113, 0.0635, 0.1080, 0.0466, 0.0038]) \n",
      "Test Loss tensor([0.0018, 0.0613, 0.0096, 0.0657, 0.1126, 0.0432, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6479125022888184 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0590, 0.0107, 0.0638, 0.1147, 0.0431, 0.0050]) \n",
      "Test Loss tensor([0.0018, 0.0619, 0.0097, 0.0659, 0.1121, 0.0433, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6261944770812988 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0574, 0.0101, 0.0585, 0.1094, 0.0401, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0614, 0.0094, 0.0642, 0.1155, 0.0423, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.643925666809082 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0607, 0.0100, 0.0593, 0.1083, 0.0416, 0.0056]) \n",
      "Test Loss tensor([0.0018, 0.0607, 0.0111, 0.0677, 0.1100, 0.0425, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6291813850402832 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0567, 0.0098, 0.0720, 0.1068, 0.0424, 0.0047]) \n",
      "Test Loss tensor([0.0018, 0.0597, 0.0108, 0.0655, 0.1096, 0.0436, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6988990306854248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0570, 0.0114, 0.0669, 0.1173, 0.0444, 0.0055]) \n",
      "Test Loss tensor([0.0018, 0.0607, 0.0092, 0.0655, 0.1116, 0.0428, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6469366550445557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0626, 0.0108, 0.0619, 0.1095, 0.0374, 0.0047]) \n",
      "Test Loss tensor([0.0018, 0.0606, 0.0084, 0.0623, 0.1133, 0.0423, 0.0053])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6464200019836426 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0642, 0.0099, 0.0646, 0.1108, 0.0421, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0602, 0.0091, 0.0623, 0.1125, 0.0423, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5949287414550781 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0584, 0.0098, 0.0674, 0.1110, 0.0402, 0.0051]) \n",
      "Test Loss tensor([0.0018, 0.0590, 0.0104, 0.0646, 0.1089, 0.0433, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6154265403747559 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0568, 0.0100, 0.0728, 0.1146, 0.0458, 0.0049]) \n",
      "Test Loss tensor([0.0018, 0.0581, 0.0107, 0.0661, 0.1056, 0.0434, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6415624618530273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0613, 0.0130, 0.0663, 0.1121, 0.0436, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0585, 0.0095, 0.0628, 0.1103, 0.0420, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6341118812561035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0581, 0.0104, 0.0629, 0.1111, 0.0438, 0.0047]) \n",
      "Test Loss tensor([0.0018, 0.0597, 0.0097, 0.0665, 0.1110, 0.0425, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6575150489807129 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0510, 0.0121, 0.0523, 0.1094, 0.0465, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0595, 0.0106, 0.0641, 0.1078, 0.0416, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6116476058959961 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0589, 0.0076, 0.0680, 0.1063, 0.0390, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0575, 0.0103, 0.0655, 0.1103, 0.0426, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6583278179168701 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0587, 0.0128, 0.0697, 0.1003, 0.0417, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0574, 0.0095, 0.0643, 0.1080, 0.0425, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6437432765960693 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0568, 0.0100, 0.0651, 0.0998, 0.0414, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0577, 0.0090, 0.0612, 0.1078, 0.0421, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6005475521087646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0599, 0.0091, 0.0680, 0.1082, 0.0440, 0.0055]) \n",
      "Test Loss tensor([0.0018, 0.0578, 0.0098, 0.0638, 0.1069, 0.0429, 0.0046])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 112 in 0.6170749664306641 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0545, 0.0103, 0.0629, 0.1101, 0.0466, 0.0043]) \n",
      "Test Loss tensor([0.0018, 0.0566, 0.0111, 0.0670, 0.1057, 0.0421, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.5881597995758057 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0585, 0.0118, 0.0650, 0.1015, 0.0434, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0564, 0.0092, 0.0610, 0.1042, 0.0419, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.5921981334686279 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0539, 0.0081, 0.0617, 0.1016, 0.0432, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0575, 0.0098, 0.0608, 0.1048, 0.0422, 0.0053])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5891335010528564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0582, 0.0088, 0.0665, 0.1126, 0.0434, 0.0057]) \n",
      "Test Loss tensor([0.0018, 0.0556, 0.0102, 0.0626, 0.1047, 0.0425, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5871186256408691 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0583, 0.0108, 0.0604, 0.1004, 0.0394, 0.0054]) \n",
      "Test Loss tensor([0.0018, 0.0552, 0.0109, 0.0638, 0.1039, 0.0420, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5872316360473633 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0569, 0.0112, 0.0611, 0.0984, 0.0431, 0.0052]) \n",
      "Test Loss tensor([0.0018, 0.0539, 0.0098, 0.0604, 0.1036, 0.0428, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5926918983459473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0574, 0.0092, 0.0684, 0.1006, 0.0390, 0.0051]) \n",
      "Test Loss tensor([0.0018, 0.0552, 0.0094, 0.0614, 0.1031, 0.0426, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5952849388122559 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0580, 0.0084, 0.0618, 0.1097, 0.0422, 0.0048]) \n",
      "Test Loss tensor([0.0018, 0.0545, 0.0115, 0.0632, 0.1018, 0.0425, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6551735401153564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0558, 0.0127, 0.0596, 0.0954, 0.0433, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0546, 0.0104, 0.0640, 0.1003, 0.0427, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5952239036560059 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0495, 0.0111, 0.0613, 0.0998, 0.0390, 0.0046]) \n",
      "Test Loss tensor([0.0019, 0.0549, 0.0097, 0.0594, 0.1036, 0.0405, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.611065149307251 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0588, 0.0117, 0.0651, 0.1001, 0.0391, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0538, 0.0091, 0.0635, 0.1013, 0.0410, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6182162761688232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0569, 0.0086, 0.0603, 0.1066, 0.0438, 0.0054]) \n",
      "Test Loss tensor([0.0018, 0.0517, 0.0124, 0.0651, 0.1016, 0.0430, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6152455806732178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0569, 0.0124, 0.0675, 0.0968, 0.0407, 0.0047]) \n",
      "Test Loss tensor([0.0018, 0.0515, 0.0102, 0.0623, 0.1030, 0.0429, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6223373413085938 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0529, 0.0121, 0.0658, 0.1009, 0.0431, 0.0047]) \n",
      "Test Loss tensor([0.0019, 0.0551, 0.0092, 0.0622, 0.1029, 0.0427, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.701937198638916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0587, 0.0090, 0.0635, 0.1081, 0.0424, 0.0058]) \n",
      "Test Loss tensor([0.0019, 0.0547, 0.0092, 0.0596, 0.0988, 0.0412, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.5999934673309326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0528, 0.0099, 0.0603, 0.1045, 0.0401, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0516, 0.0109, 0.0612, 0.0969, 0.0419, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.5917701721191406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0506, 0.0136, 0.0661, 0.1118, 0.0496, 0.0046]) \n",
      "Test Loss tensor([0.0018, 0.0532, 0.0101, 0.0627, 0.0988, 0.0425, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.601442813873291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0526, 0.0109, 0.0695, 0.0965, 0.0401, 0.0039]) \n",
      "Test Loss tensor([0.0019, 0.0546, 0.0088, 0.0607, 0.1008, 0.0409, 0.0058])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5895800590515137 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0516, 0.0082, 0.0548, 0.1053, 0.0425, 0.0055]) \n",
      "Test Loss tensor([0.0019, 0.0512, 0.0088, 0.0606, 0.0973, 0.0421, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5898067951202393 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0496, 0.0091, 0.0620, 0.0985, 0.0376, 0.0044]) \n",
      "Test Loss tensor([0.0018, 0.0508, 0.0100, 0.0627, 0.0984, 0.0427, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.5911259651184082 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0572, 0.0098, 0.0616, 0.0950, 0.0417, 0.0039]) \n",
      "Test Loss tensor([0.0018, 0.0504, 0.0090, 0.0609, 0.1000, 0.0430, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5929460525512695 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0512, 0.0079, 0.0635, 0.0948, 0.0388, 0.0048]) \n",
      "Test Loss tensor([0.0019, 0.0518, 0.0071, 0.0605, 0.1016, 0.0418, 0.0059])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.5933742523193359 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0539, 0.0099, 0.0567, 0.0959, 0.0363, 0.0060]) \n",
      "Test Loss tensor([0.0019, 0.0505, 0.0079, 0.0603, 0.0993, 0.0418, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.5949411392211914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0502, 0.0088, 0.0613, 0.1046, 0.0436, 0.0055]) \n",
      "Test Loss tensor([0.0019, 0.0491, 0.0093, 0.0627, 0.0963, 0.0431, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5966973304748535 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0518, 0.0087, 0.0644, 0.0948, 0.0404, 0.0057]) \n",
      "Test Loss tensor([0.0019, 0.0496, 0.0096, 0.0626, 0.0952, 0.0420, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5869629383087158 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0486, 0.0108, 0.0636, 0.1039, 0.0413, 0.0049]) \n",
      "Test Loss tensor([0.0019, 0.0521, 0.0083, 0.0590, 0.1000, 0.0413, 0.0058])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.5988926887512207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0542, 0.0098, 0.0615, 0.1059, 0.0396, 0.0054]) \n",
      "Test Loss tensor([0.0019, 0.0500, 0.0095, 0.0604, 0.0969, 0.0423, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6288259029388428 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0509, 0.0115, 0.0621, 0.1007, 0.0398, 0.0049]) \n",
      "Test Loss tensor([0.0019, 0.0491, 0.0106, 0.0624, 0.0944, 0.0435, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6261835098266602 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0529, 0.0115, 0.0642, 0.0923, 0.0430, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0499, 0.0090, 0.0610, 0.0948, 0.0400, 0.0052])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6634902954101562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0525, 0.0093, 0.0620, 0.0949, 0.0409, 0.0053]) \n",
      "Test Loss tensor([0.0019, 0.0509, 0.0079, 0.0591, 0.0970, 0.0407, 0.0059])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6090116500854492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0515, 0.0086, 0.0627, 0.1036, 0.0427, 0.0059]) \n",
      "Test Loss tensor([0.0019, 0.0497, 0.0084, 0.0610, 0.0943, 0.0404, 0.0053])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6344664096832275 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0547, 0.0098, 0.0597, 0.0936, 0.0446, 0.0052]) \n",
      "Test Loss tensor([0.0019, 0.0491, 0.0098, 0.0644, 0.0926, 0.0420, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6457233428955078 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0454, 0.0096, 0.0622, 0.0934, 0.0405, 0.0055]) \n",
      "Test Loss tensor([0.0019, 0.0492, 0.0094, 0.0578, 0.0902, 0.0419, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6179378032684326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0465, 0.0096, 0.0585, 0.0897, 0.0439, 0.0047]) \n",
      "Test Loss tensor([0.0019, 0.0492, 0.0084, 0.0595, 0.0952, 0.0412, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6302886009216309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0496, 0.0085, 0.0517, 0.1006, 0.0403, 0.0055]) \n",
      "Test Loss tensor([0.0019, 0.0501, 0.0086, 0.0611, 0.0912, 0.0407, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.642197847366333 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0499, 0.0097, 0.0574, 0.1038, 0.0442, 0.0045]) \n",
      "Test Loss tensor([0.0019, 0.0490, 0.0095, 0.0613, 0.0924, 0.0414, 0.0045])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 256 in 0.5973448753356934 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0472, 0.0130, 0.0620, 0.0887, 0.0406, 0.0050]) \n",
      "Test Loss tensor([0.0019, 0.0474, 0.0092, 0.0580, 0.0907, 0.0413, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.615426778793335 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0527, 0.0075, 0.0611, 0.0970, 0.0376, 0.0052]) \n",
      "Test Loss tensor([0.0019, 0.0495, 0.0087, 0.0613, 0.0947, 0.0409, 0.0055])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.7085614204406738 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0499, 0.0072, 0.0633, 0.0968, 0.0445, 0.0053]) \n",
      "Test Loss tensor([0.0019, 0.0486, 0.0089, 0.0588, 0.0926, 0.0405, 0.0050])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6594181060791016 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0467, 0.0095, 0.0647, 0.0965, 0.0398, 0.0064]) \n",
      "Test Loss tensor([0.0019, 0.0476, 0.0098, 0.0634, 0.0898, 0.0422, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6223540306091309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0452, 0.0091, 0.0566, 0.0881, 0.0409, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0482, 0.0083, 0.0591, 0.0897, 0.0404, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6202714443206787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0494, 0.0074, 0.0652, 0.0943, 0.0444, 0.0046]) \n",
      "Test Loss tensor([0.0019, 0.0483, 0.0095, 0.0585, 0.0930, 0.0396, 0.0059])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6720974445343018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0467, 0.0090, 0.0568, 0.0920, 0.0444, 0.0049]) \n",
      "Test Loss tensor([0.0019, 0.0465, 0.0087, 0.0591, 0.0915, 0.0420, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6282832622528076 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0456, 0.0115, 0.0595, 0.0945, 0.0410, 0.0058]) \n",
      "Test Loss tensor([0.0019, 0.0474, 0.0092, 0.0614, 0.0888, 0.0419, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6412482261657715 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0484, 0.0107, 0.0636, 0.0934, 0.0439, 0.0047]) \n",
      "Test Loss tensor([0.0019, 0.0465, 0.0084, 0.0595, 0.0885, 0.0412, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.618372917175293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0497, 0.0100, 0.0555, 0.0978, 0.0376, 0.0050]) \n",
      "Test Loss tensor([0.0019, 0.0462, 0.0083, 0.0593, 0.0929, 0.0398, 0.0051])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6077158451080322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0502, 0.0079, 0.0526, 0.0840, 0.0411, 0.0060]) \n",
      "Test Loss tensor([0.0019, 0.0462, 0.0092, 0.0606, 0.0905, 0.0415, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5995700359344482 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0502, 0.0091, 0.0613, 0.0919, 0.0414, 0.0048]) \n",
      "Test Loss tensor([0.0019, 0.0457, 0.0086, 0.0579, 0.0882, 0.0410, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6030185222625732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0435, 0.0098, 0.0577, 0.0953, 0.0374, 0.0051]) \n",
      "Test Loss tensor([0.0019, 0.0471, 0.0089, 0.0608, 0.0897, 0.0414, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6024370193481445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0452, 0.0088, 0.0595, 0.0962, 0.0387, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0474, 0.0076, 0.0588, 0.0881, 0.0417, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5987906455993652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0478, 0.0077, 0.0576, 0.0935, 0.0449, 0.0048]) \n",
      "Test Loss tensor([0.0019, 0.0450, 0.0086, 0.0583, 0.0859, 0.0415, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5982530117034912 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0451, 0.0101, 0.0629, 0.0897, 0.0374, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0450, 0.0097, 0.0600, 0.0877, 0.0425, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6124327182769775 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0467, 0.0094, 0.0561, 0.0829, 0.0363, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0455, 0.0089, 0.0601, 0.0885, 0.0405, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6506063938140869 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0503, 0.0083, 0.0591, 0.0910, 0.0423, 0.0049]) \n",
      "Test Loss tensor([0.0019, 0.0463, 0.0073, 0.0549, 0.0930, 0.0389, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6483621597290039 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0436, 0.0069, 0.0554, 0.0986, 0.0395, 0.0053]) \n",
      "Test Loss tensor([0.0019, 0.0436, 0.0098, 0.0602, 0.0872, 0.0422, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7790336608886719 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0471, 0.0120, 0.0565, 0.0870, 0.0442, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0437, 0.0107, 0.0633, 0.0881, 0.0442, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.763782262802124 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0480, 0.0114, 0.0580, 0.0867, 0.0408, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0442, 0.0078, 0.0578, 0.0867, 0.0413, 0.0048])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6883654594421387 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0474, 0.0081, 0.0602, 0.0867, 0.0410, 0.0050]) \n",
      "Test Loss tensor([0.0019, 0.0467, 0.0076, 0.0562, 0.0919, 0.0404, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6319758892059326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0433, 0.0071, 0.0548, 0.0933, 0.0352, 0.0055]) \n",
      "Test Loss tensor([0.0019, 0.0427, 0.0100, 0.0591, 0.0857, 0.0435, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.7048828601837158 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0486, 0.0119, 0.0578, 0.0922, 0.0413, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0432, 0.0102, 0.0583, 0.0871, 0.0435, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7787892818450928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0433, 0.0091, 0.0576, 0.0846, 0.0416, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0446, 0.0075, 0.0577, 0.0871, 0.0399, 0.0054])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6611230373382568 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0438, 0.0072, 0.0519, 0.0897, 0.0386, 0.0057]) \n",
      "Test Loss tensor([0.0020, 0.0445, 0.0075, 0.0566, 0.0876, 0.0397, 0.0054])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.7928228378295898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0497, 0.0072, 0.0513, 0.0886, 0.0444, 0.0052]) \n",
      "Test Loss tensor([0.0020, 0.0426, 0.0085, 0.0564, 0.0865, 0.0418, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.716956377029419 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0431, 0.0069, 0.0632, 0.0863, 0.0448, 0.0040]) \n",
      "Test Loss tensor([0.0019, 0.0419, 0.0088, 0.0600, 0.0868, 0.0419, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7183945178985596 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0431, 0.0128, 0.0607, 0.0911, 0.0417, 0.0040]) \n",
      "Test Loss tensor([0.0019, 0.0434, 0.0077, 0.0565, 0.0832, 0.0422, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6928920745849609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0462, 0.0088, 0.0628, 0.0849, 0.0376, 0.0053]) \n",
      "Test Loss tensor([0.0019, 0.0457, 0.0065, 0.0580, 0.0901, 0.0402, 0.0061])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6391119956970215 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0524, 0.0069, 0.0603, 0.0902, 0.0434, 0.0065]) \n",
      "Test Loss tensor([0.0020, 0.0426, 0.0077, 0.0577, 0.0857, 0.0417, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6244909763336182 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0419, 0.0087, 0.0600, 0.0860, 0.0427, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0434, 0.0093, 0.0588, 0.0842, 0.0422, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6189897060394287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0433, 0.0097, 0.0591, 0.0869, 0.0450, 0.0040]) \n",
      "Test Loss tensor([0.0019, 0.0431, 0.0075, 0.0576, 0.0848, 0.0406, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.647270917892456 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0455, 0.0089, 0.0593, 0.0906, 0.0435, 0.0050]) \n",
      "Test Loss tensor([0.0019, 0.0454, 0.0072, 0.0558, 0.0899, 0.0399, 0.0057])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6246638298034668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0475, 0.0084, 0.0626, 0.0958, 0.0430, 0.0057]) \n",
      "Test Loss tensor([0.0019, 0.0407, 0.0077, 0.0573, 0.0830, 0.0415, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6042335033416748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0449, 0.0080, 0.0581, 0.0824, 0.0390, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0415, 0.0096, 0.0615, 0.0856, 0.0426, 0.0037])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.6001672744750977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0423, 0.0076, 0.0637, 0.0857, 0.0436, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0424, 0.0075, 0.0591, 0.0820, 0.0426, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5975069999694824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0417, 0.0076, 0.0602, 0.0818, 0.0392, 0.0046]) \n",
      "Test Loss tensor([0.0019, 0.0437, 0.0069, 0.0560, 0.0897, 0.0394, 0.0057])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5946922302246094 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0487, 0.0085, 0.0549, 0.0896, 0.0421, 0.0056]) \n",
      "Test Loss tensor([0.0019, 0.0419, 0.0073, 0.0555, 0.0832, 0.0397, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6068282127380371 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0440, 0.0060, 0.0549, 0.0861, 0.0391, 0.0048]) \n",
      "Test Loss tensor([0.0019, 0.0399, 0.0085, 0.0581, 0.0836, 0.0431, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6260111331939697 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0413, 0.0118, 0.0619, 0.0814, 0.0437, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0412, 0.0080, 0.0570, 0.0820, 0.0416, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6121735572814941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0430, 0.0082, 0.0562, 0.0848, 0.0424, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0427, 0.0065, 0.0555, 0.0899, 0.0407, 0.0056])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6096587181091309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0420, 0.0085, 0.0561, 0.0840, 0.0387, 0.0060]) \n",
      "Test Loss tensor([0.0020, 0.0413, 0.0071, 0.0555, 0.0827, 0.0404, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6127729415893555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0454, 0.0108, 0.0556, 0.0810, 0.0399, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0406, 0.0088, 0.0600, 0.0831, 0.0434, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6255743503570557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0435, 0.0114, 0.0683, 0.0847, 0.0428, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0410, 0.0082, 0.0561, 0.0808, 0.0403, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6076374053955078 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0410, 0.0086, 0.0575, 0.0810, 0.0461, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0407, 0.0065, 0.0572, 0.0884, 0.0407, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6029219627380371 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0455, 0.0087, 0.0575, 0.0836, 0.0341, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0414, 0.0081, 0.0563, 0.0816, 0.0400, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6083130836486816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0442, 0.0061, 0.0581, 0.0806, 0.0424, 0.0042]) \n",
      "Test Loss tensor([0.0019, 0.0423, 0.0084, 0.0593, 0.0810, 0.0410, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6244287490844727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0418, 0.0091, 0.0592, 0.0788, 0.0394, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0395, 0.0081, 0.0579, 0.0820, 0.0414, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6136965751647949 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0464, 0.0087, 0.0591, 0.0854, 0.0403, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0417, 0.0075, 0.0570, 0.0818, 0.0404, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6090688705444336 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0396, 0.0079, 0.0520, 0.0768, 0.0400, 0.0048]) \n",
      "Test Loss tensor([0.0020, 0.0424, 0.0076, 0.0539, 0.0798, 0.0405, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6207537651062012 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0448, 0.0078, 0.0537, 0.0729, 0.0425, 0.0045]) \n",
      "Test Loss tensor([0.0020, 0.0403, 0.0068, 0.0539, 0.0784, 0.0407, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6360244750976562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0412, 0.0088, 0.0566, 0.0818, 0.0387, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0405, 0.0078, 0.0556, 0.0802, 0.0409, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6152479648590088 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0394, 0.0095, 0.0623, 0.0871, 0.0402, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0395, 0.0074, 0.0545, 0.0807, 0.0410, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6080522537231445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0407, 0.0075, 0.0528, 0.0832, 0.0458, 0.0043]) \n",
      "Test Loss tensor([0.0020, 0.0403, 0.0071, 0.0550, 0.0786, 0.0411, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6100606918334961 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0405, 0.0062, 0.0598, 0.0847, 0.0387, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0404, 0.0072, 0.0560, 0.0814, 0.0406, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6113417148590088 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0424, 0.0055, 0.0492, 0.0810, 0.0347, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0413, 0.0077, 0.0559, 0.0780, 0.0404, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6100974082946777 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0448, 0.0060, 0.0550, 0.0801, 0.0382, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0395, 0.0065, 0.0565, 0.0794, 0.0409, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.610978364944458 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0418, 0.0074, 0.0594, 0.0807, 0.0404, 0.0048]) \n",
      "Test Loss tensor([0.0020, 0.0406, 0.0071, 0.0563, 0.0837, 0.0392, 0.0047])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6079816818237305 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0377, 0.0062, 0.0559, 0.0782, 0.0371, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0397, 0.0069, 0.0569, 0.0801, 0.0405, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6045949459075928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0439, 0.0066, 0.0607, 0.0792, 0.0404, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0391, 0.0065, 0.0557, 0.0791, 0.0410, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.602043867111206 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0417, 0.0076, 0.0548, 0.0802, 0.0401, 0.0046]) \n",
      "Test Loss tensor([0.0019, 0.0395, 0.0073, 0.0552, 0.0786, 0.0423, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.603492021560669 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0390, 0.0069, 0.0562, 0.0754, 0.0434, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0384, 0.0068, 0.0562, 0.0785, 0.0409, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5979442596435547 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0393, 0.0088, 0.0547, 0.0792, 0.0406, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0401, 0.0068, 0.0540, 0.0783, 0.0397, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6070220470428467 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0422, 0.0055, 0.0614, 0.0816, 0.0420, 0.0050]) \n",
      "Test Loss tensor([0.0020, 0.0394, 0.0072, 0.0551, 0.0780, 0.0402, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6258594989776611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0380, 0.0074, 0.0572, 0.0846, 0.0447, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0403, 0.0076, 0.0560, 0.0783, 0.0398, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6230971813201904 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0391, 0.0074, 0.0566, 0.0801, 0.0437, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0385, 0.0068, 0.0555, 0.0781, 0.0410, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6027042865753174 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0389, 0.0053, 0.0526, 0.0779, 0.0373, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0389, 0.0068, 0.0569, 0.0789, 0.0400, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.612485408782959 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0429, 0.0078, 0.0514, 0.0723, 0.0456, 0.0042]) \n",
      "Test Loss tensor([0.0019, 0.0396, 0.0067, 0.0537, 0.0784, 0.0403, 0.0042])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.608994722366333 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0380, 0.0092, 0.0576, 0.0818, 0.0391, 0.0045]) \n",
      "Test Loss tensor([0.0019, 0.0391, 0.0069, 0.0549, 0.0784, 0.0401, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.607093334197998 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0399, 0.0064, 0.0523, 0.0859, 0.0438, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0385, 0.0064, 0.0540, 0.0784, 0.0415, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6315126419067383 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0389, 0.0082, 0.0558, 0.0835, 0.0413, 0.0048]) \n",
      "Test Loss tensor([0.0020, 0.0384, 0.0062, 0.0540, 0.0773, 0.0402, 0.0040])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 544 in 0.6067776679992676 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0411, 0.0057, 0.0552, 0.0796, 0.0423, 0.0047]) \n",
      "Test Loss tensor([0.0020, 0.0393, 0.0066, 0.0560, 0.0765, 0.0402, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6123373508453369 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0375, 0.0057, 0.0503, 0.0794, 0.0421, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0387, 0.0067, 0.0533, 0.0794, 0.0415, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5985045433044434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0363, 0.0062, 0.0605, 0.0794, 0.0391, 0.0046]) \n",
      "Test Loss tensor([0.0020, 0.0399, 0.0065, 0.0536, 0.0790, 0.0388, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6027271747589111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0382, 0.0072, 0.0562, 0.0795, 0.0366, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0383, 0.0072, 0.0529, 0.0772, 0.0418, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6150434017181396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0407, 0.0066, 0.0599, 0.0692, 0.0424, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0380, 0.0067, 0.0557, 0.0765, 0.0432, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6253440380096436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0388, 0.0073, 0.0558, 0.0749, 0.0410, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0391, 0.0066, 0.0559, 0.0761, 0.0397, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6440377235412598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0390, 0.0080, 0.0529, 0.0757, 0.0396, 0.0043]) \n",
      "Test Loss tensor([0.0020, 0.0392, 0.0066, 0.0559, 0.0753, 0.0400, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6428561210632324 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0354, 0.0054, 0.0522, 0.0780, 0.0442, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0384, 0.0073, 0.0552, 0.0761, 0.0419, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6226818561553955 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0362, 0.0061, 0.0535, 0.0770, 0.0389, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0374, 0.0073, 0.0560, 0.0759, 0.0416, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.678309440612793 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0352, 0.0083, 0.0551, 0.0724, 0.0438, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0388, 0.0064, 0.0529, 0.0806, 0.0398, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6861512660980225 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0400, 0.0073, 0.0556, 0.0812, 0.0379, 0.0047]) \n",
      "Test Loss tensor([0.0020, 0.0382, 0.0066, 0.0535, 0.0766, 0.0406, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6849265098571777 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0373, 0.0064, 0.0624, 0.0752, 0.0402, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0387, 0.0072, 0.0571, 0.0772, 0.0417, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6362650394439697 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0393, 0.0087, 0.0508, 0.0711, 0.0429, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0383, 0.0064, 0.0551, 0.0738, 0.0396, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.7410809993743896 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0421, 0.0065, 0.0553, 0.0747, 0.0381, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0379, 0.0063, 0.0540, 0.0792, 0.0384, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 600 in 1.0444118976593018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0355, 0.0072, 0.0524, 0.0821, 0.0378, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0383, 0.0060, 0.0522, 0.0758, 0.0412, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.8359954357147217 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0342, 0.0068, 0.0504, 0.0798, 0.0425, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0389, 0.0064, 0.0548, 0.0734, 0.0411, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.8100690841674805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0386, 0.0057, 0.0524, 0.0791, 0.0402, 0.0046]) \n",
      "Test Loss tensor([0.0020, 0.0376, 0.0059, 0.0543, 0.0774, 0.0389, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.75046706199646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0396, 0.0047, 0.0542, 0.0750, 0.0475, 0.0046]) \n",
      "Test Loss tensor([0.0020, 0.0388, 0.0061, 0.0533, 0.0741, 0.0402, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.7064297199249268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0404, 0.0059, 0.0539, 0.0744, 0.0374, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0370, 0.0058, 0.0531, 0.0755, 0.0406, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.8362503051757812 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0379, 0.0067, 0.0520, 0.0694, 0.0349, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0372, 0.0068, 0.0543, 0.0761, 0.0397, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.7496371269226074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0404, 0.0061, 0.0557, 0.0756, 0.0475, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0386, 0.0061, 0.0543, 0.0761, 0.0388, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6524214744567871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0389, 0.0061, 0.0584, 0.0734, 0.0377, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0376, 0.0061, 0.0532, 0.0762, 0.0400, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.663902997970581 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0420, 0.0046, 0.0475, 0.0776, 0.0420, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0371, 0.0069, 0.0559, 0.0742, 0.0410, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6208071708679199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0396, 0.0077, 0.0577, 0.0741, 0.0387, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0384, 0.0069, 0.0556, 0.0733, 0.0406, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6939024925231934 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0376, 0.0066, 0.0520, 0.0782, 0.0432, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0385, 0.0063, 0.0543, 0.0761, 0.0381, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6412196159362793 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0346, 0.0061, 0.0544, 0.0767, 0.0374, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0371, 0.0062, 0.0535, 0.0732, 0.0404, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.7116961479187012 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0353, 0.0078, 0.0526, 0.0741, 0.0367, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0365, 0.0061, 0.0526, 0.0745, 0.0407, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6248776912689209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0373, 0.0077, 0.0562, 0.0741, 0.0417, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0359, 0.0062, 0.0521, 0.0731, 0.0392, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6466774940490723 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0369, 0.0072, 0.0470, 0.0756, 0.0398, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0390, 0.0065, 0.0534, 0.0715, 0.0403, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6473469734191895 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0379, 0.0073, 0.0508, 0.0777, 0.0472, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0376, 0.0061, 0.0541, 0.0733, 0.0386, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6410484313964844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0331, 0.0057, 0.0493, 0.0717, 0.0421, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0375, 0.0061, 0.0534, 0.0758, 0.0384, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6318881511688232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0401, 0.0045, 0.0494, 0.0802, 0.0361, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0374, 0.0063, 0.0555, 0.0731, 0.0394, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6273822784423828 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0355, 0.0063, 0.0567, 0.0717, 0.0386, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0369, 0.0066, 0.0538, 0.0749, 0.0412, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6398286819458008 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0357, 0.0079, 0.0531, 0.0779, 0.0442, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0379, 0.0054, 0.0527, 0.0735, 0.0387, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6146445274353027 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0361, 0.0071, 0.0463, 0.0751, 0.0400, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0364, 0.0062, 0.0500, 0.0744, 0.0395, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6340320110321045 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0395, 0.0064, 0.0453, 0.0688, 0.0353, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0073, 0.0558, 0.0718, 0.0398, 0.0033])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 688 in 0.635218620300293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0387, 0.0055, 0.0593, 0.0728, 0.0413, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0376, 0.0062, 0.0536, 0.0752, 0.0403, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6718475818634033 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0356, 0.0062, 0.0513, 0.0747, 0.0401, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0384, 0.0052, 0.0522, 0.0782, 0.0377, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6111130714416504 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0410, 0.0048, 0.0507, 0.0818, 0.0337, 0.0050]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0061, 0.0535, 0.0749, 0.0403, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6831254959106445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0409, 0.0069, 0.0521, 0.0699, 0.0374, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0374, 0.0059, 0.0526, 0.0733, 0.0410, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6887416839599609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0366, 0.0074, 0.0523, 0.0687, 0.0435, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0361, 0.0061, 0.0521, 0.0746, 0.0391, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.654803991317749 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0342, 0.0050, 0.0516, 0.0714, 0.0390, 0.0049]) \n",
      "Test Loss tensor([0.0020, 0.0368, 0.0058, 0.0519, 0.0765, 0.0383, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6435003280639648 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0349, 0.0068, 0.0490, 0.0772, 0.0409, 0.0048]) \n",
      "Test Loss tensor([0.0020, 0.0363, 0.0063, 0.0539, 0.0725, 0.0406, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6815927028656006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0365, 0.0060, 0.0544, 0.0763, 0.0429, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0370, 0.0068, 0.0536, 0.0712, 0.0423, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6539008617401123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0356, 0.0049, 0.0483, 0.0709, 0.0433, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0374, 0.0053, 0.0523, 0.0730, 0.0388, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.7057175636291504 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0369, 0.0045, 0.0424, 0.0735, 0.0405, 0.0043]) \n",
      "Test Loss tensor([0.0020, 0.0373, 0.0056, 0.0506, 0.0731, 0.0392, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.688772439956665 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0451, 0.0054, 0.0512, 0.0698, 0.0398, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0350, 0.0059, 0.0523, 0.0742, 0.0412, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6680347919464111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0368, 0.0070, 0.0529, 0.0708, 0.0410, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0361, 0.0055, 0.0523, 0.0727, 0.0395, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6840152740478516 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0395, 0.0062, 0.0520, 0.0694, 0.0394, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0357, 0.0059, 0.0503, 0.0729, 0.0388, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6465291976928711 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0389, 0.0068, 0.0534, 0.0677, 0.0413, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0364, 0.0062, 0.0534, 0.0707, 0.0389, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6522016525268555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0382, 0.0049, 0.0512, 0.0757, 0.0365, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0359, 0.0055, 0.0523, 0.0725, 0.0380, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7464966773986816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0390, 0.0053, 0.0525, 0.0677, 0.0354, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0364, 0.0058, 0.0501, 0.0715, 0.0385, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6132590770721436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0408, 0.0051, 0.0496, 0.0676, 0.0414, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0361, 0.0056, 0.0523, 0.0711, 0.0401, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6812596321105957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0343, 0.0061, 0.0527, 0.0680, 0.0351, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0344, 0.0053, 0.0509, 0.0711, 0.0393, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6618638038635254 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0347, 0.0050, 0.0516, 0.0736, 0.0351, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0057, 0.0534, 0.0710, 0.0392, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7319116592407227 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0352, 0.0052, 0.0511, 0.0675, 0.0448, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0362, 0.0059, 0.0529, 0.0696, 0.0382, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6948468685150146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0360, 0.0053, 0.0510, 0.0684, 0.0352, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0354, 0.0058, 0.0517, 0.0718, 0.0398, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6284201145172119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0348, 0.0050, 0.0528, 0.0710, 0.0411, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0365, 0.0054, 0.0518, 0.0706, 0.0385, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.679091215133667 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0327, 0.0058, 0.0500, 0.0721, 0.0374, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0355, 0.0062, 0.0504, 0.0708, 0.0380, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6165726184844971 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0392, 0.0059, 0.0523, 0.0748, 0.0385, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0354, 0.0053, 0.0484, 0.0689, 0.0395, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.7500977516174316 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0371, 0.0065, 0.0559, 0.0717, 0.0413, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0362, 0.0056, 0.0526, 0.0696, 0.0400, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.7973957061767578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0354, 0.0067, 0.0574, 0.0734, 0.0417, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0363, 0.0051, 0.0504, 0.0694, 0.0384, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.7587640285491943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0405, 0.0062, 0.0477, 0.0674, 0.0401, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0369, 0.0051, 0.0513, 0.0727, 0.0380, 0.0045])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6704761981964111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0392, 0.0046, 0.0518, 0.0668, 0.0403, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0354, 0.0056, 0.0517, 0.0693, 0.0392, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6543104648590088 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0408, 0.0060, 0.0517, 0.0662, 0.0391, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0361, 0.0058, 0.0524, 0.0695, 0.0397, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6964409351348877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0379, 0.0069, 0.0539, 0.0728, 0.0373, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0362, 0.0054, 0.0500, 0.0715, 0.0387, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6261007785797119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0379, 0.0040, 0.0517, 0.0699, 0.0397, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0050, 0.0502, 0.0726, 0.0380, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6366081237792969 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0348, 0.0055, 0.0536, 0.0664, 0.0380, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0362, 0.0060, 0.0522, 0.0695, 0.0393, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.8471696376800537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0358, 0.0064, 0.0479, 0.0647, 0.0380, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0368, 0.0059, 0.0496, 0.0689, 0.0405, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7284986972808838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0369, 0.0061, 0.0581, 0.0687, 0.0436, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0364, 0.0051, 0.0518, 0.0731, 0.0388, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6433496475219727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0383, 0.0049, 0.0528, 0.0725, 0.0361, 0.0045]) \n",
      "Test Loss tensor([0.0020, 0.0358, 0.0053, 0.0506, 0.0692, 0.0386, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6502008438110352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0337, 0.0051, 0.0539, 0.0656, 0.0391, 0.0047]) \n",
      "Test Loss tensor([0.0019, 0.0358, 0.0055, 0.0517, 0.0681, 0.0392, 0.0035])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 832 in 0.6389431953430176 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0360, 0.0066, 0.0512, 0.0718, 0.0405, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0357, 0.0054, 0.0505, 0.0695, 0.0379, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.634425163269043 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0361, 0.0047, 0.0523, 0.0689, 0.0364, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0350, 0.0050, 0.0495, 0.0692, 0.0380, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6148643493652344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0316, 0.0057, 0.0426, 0.0710, 0.0386, 0.0042]) \n",
      "Test Loss tensor([0.0019, 0.0357, 0.0067, 0.0507, 0.0663, 0.0403, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.645883321762085 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0073, 0.0462, 0.0749, 0.0411, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0355, 0.0050, 0.0509, 0.0681, 0.0398, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6142363548278809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0345, 0.0062, 0.0466, 0.0726, 0.0371, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0044, 0.0505, 0.0705, 0.0381, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6196038722991943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0423, 0.0060, 0.0480, 0.0645, 0.0348, 0.0047]) \n",
      "Test Loss tensor([0.0020, 0.0349, 0.0051, 0.0513, 0.0703, 0.0395, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6305553913116455 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0343, 0.0048, 0.0468, 0.0647, 0.0392, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0352, 0.0060, 0.0509, 0.0684, 0.0396, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6314895153045654 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0369, 0.0051, 0.0505, 0.0701, 0.0417, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0355, 0.0052, 0.0484, 0.0673, 0.0391, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6334865093231201 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0374, 0.0066, 0.0427, 0.0644, 0.0390, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0366, 0.0051, 0.0487, 0.0705, 0.0371, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6106889247894287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0406, 0.0044, 0.0499, 0.0787, 0.0390, 0.0044]) \n",
      "Test Loss tensor([0.0020, 0.0353, 0.0051, 0.0494, 0.0685, 0.0378, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.619757890701294 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0386, 0.0040, 0.0460, 0.0670, 0.0446, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0347, 0.0053, 0.0505, 0.0673, 0.0400, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5914781093597412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0015, 0.0273, 0.0028, 0.0386, 0.0507, 0.0287, 0.0022]) \n",
      "Test Loss tensor([0.0020, 0.0352, 0.0052, 0.0509, 0.0703, 0.0368, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7111573219299316 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0371, 0.0050, 0.0530, 0.0705, 0.0437, 0.0043]) \n",
      "Test Loss tensor([0.0020, 0.0354, 0.0048, 0.0491, 0.0669, 0.0372, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6644303798675537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0346, 0.0055, 0.0501, 0.0710, 0.0400, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0358, 0.0054, 0.0503, 0.0655, 0.0400, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7020361423492432 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0350, 0.0052, 0.0509, 0.0631, 0.0415, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0351, 0.0045, 0.0504, 0.0692, 0.0383, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6296329498291016 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0347, 0.0046, 0.0439, 0.0750, 0.0399, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0346, 0.0053, 0.0482, 0.0679, 0.0373, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6436069011688232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0352, 0.0050, 0.0444, 0.0707, 0.0382, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0344, 0.0051, 0.0514, 0.0684, 0.0391, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.9507796764373779 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0341, 0.0043, 0.0555, 0.0690, 0.0376, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0347, 0.0052, 0.0484, 0.0654, 0.0386, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.9132921695709229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0378, 0.0062, 0.0528, 0.0703, 0.0369, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0046, 0.0480, 0.0680, 0.0374, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.8711564540863037 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0357, 0.0043, 0.0521, 0.0678, 0.0423, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0357, 0.0044, 0.0507, 0.0691, 0.0368, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.9126937389373779 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0385, 0.0046, 0.0494, 0.0704, 0.0367, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0353, 0.0051, 0.0483, 0.0681, 0.0392, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6325991153717041 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0324, 0.0055, 0.0494, 0.0696, 0.0348, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0351, 0.0049, 0.0501, 0.0667, 0.0391, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6853761672973633 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0348, 0.0048, 0.0470, 0.0658, 0.0416, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0341, 0.0053, 0.0496, 0.0675, 0.0378, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6943891048431396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0396, 0.0058, 0.0551, 0.0668, 0.0364, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0357, 0.0048, 0.0499, 0.0667, 0.0385, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6078968048095703 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0356, 0.0066, 0.0504, 0.0690, 0.0399, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0352, 0.0050, 0.0498, 0.0662, 0.0381, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6279330253601074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0336, 0.0062, 0.0518, 0.0715, 0.0379, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0341, 0.0048, 0.0475, 0.0670, 0.0387, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6421821117401123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0335, 0.0055, 0.0497, 0.0721, 0.0386, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0349, 0.0044, 0.0498, 0.0659, 0.0375, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6352014541625977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0352, 0.0058, 0.0492, 0.0635, 0.0343, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0349, 0.0052, 0.0500, 0.0668, 0.0384, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6264488697052002 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0314, 0.0058, 0.0498, 0.0593, 0.0352, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0344, 0.0054, 0.0501, 0.0663, 0.0382, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6245839595794678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0341, 0.0049, 0.0520, 0.0690, 0.0359, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0359, 0.0051, 0.0495, 0.0661, 0.0387, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6677875518798828 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0320, 0.0061, 0.0461, 0.0704, 0.0409, 0.0029]) \n",
      "Test Loss tensor([0.0020, 0.0340, 0.0058, 0.0504, 0.0665, 0.0394, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.638317346572876 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0345, 0.0053, 0.0489, 0.0629, 0.0380, 0.0029]) \n",
      "Test Loss tensor([0.0020, 0.0332, 0.0050, 0.0503, 0.0657, 0.0382, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6347653865814209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0388, 0.0050, 0.0493, 0.0632, 0.0382, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0337, 0.0049, 0.0472, 0.0676, 0.0388, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6186332702636719 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0313, 0.0050, 0.0461, 0.0648, 0.0418, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0342, 0.0052, 0.0491, 0.0664, 0.0370, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6310298442840576 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0319, 0.0057, 0.0460, 0.0737, 0.0428, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0354, 0.0043, 0.0493, 0.0691, 0.0365, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.640108585357666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0347, 0.0044, 0.0456, 0.0644, 0.0364, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0350, 0.0050, 0.0488, 0.0656, 0.0388, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 96 in 0.6600127220153809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0351, 0.0038, 0.0427, 0.0660, 0.0379, 0.0029]) \n",
      "Test Loss tensor([0.0020, 0.0339, 0.0048, 0.0501, 0.0648, 0.0386, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.634986400604248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0386, 0.0055, 0.0481, 0.0638, 0.0363, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0344, 0.0048, 0.0488, 0.0667, 0.0367, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6239771842956543 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0318, 0.0047, 0.0443, 0.0666, 0.0388, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0048, 0.0480, 0.0672, 0.0377, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6302578449249268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0375, 0.0048, 0.0514, 0.0644, 0.0378, 0.0042]) \n",
      "Test Loss tensor([0.0020, 0.0342, 0.0050, 0.0503, 0.0664, 0.0379, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6443898677825928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0364, 0.0027, 0.0479, 0.0658, 0.0328, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0340, 0.0048, 0.0492, 0.0642, 0.0382, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.62026047706604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0353, 0.0039, 0.0505, 0.0759, 0.0422, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0330, 0.0048, 0.0504, 0.0649, 0.0386, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6421937942504883 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0358, 0.0058, 0.0504, 0.0638, 0.0420, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0373, 0.0043, 0.0487, 0.0723, 0.0358, 0.0049])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6462082862854004 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0044, 0.0527, 0.0756, 0.0380, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0348, 0.0047, 0.0505, 0.0664, 0.0381, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6913225650787354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0315, 0.0058, 0.0470, 0.0707, 0.0412, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0340, 0.0054, 0.0482, 0.0644, 0.0383, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6853640079498291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0340, 0.0047, 0.0529, 0.0604, 0.0356, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0342, 0.0045, 0.0473, 0.0683, 0.0374, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6557836532592773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0333, 0.0040, 0.0451, 0.0662, 0.0358, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0335, 0.0048, 0.0479, 0.0657, 0.0382, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6449503898620605 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0358, 0.0044, 0.0461, 0.0638, 0.0377, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0341, 0.0046, 0.0462, 0.0641, 0.0380, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6633648872375488 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0344, 0.0058, 0.0435, 0.0652, 0.0391, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0346, 0.0041, 0.0505, 0.0629, 0.0378, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.659013032913208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0343, 0.0051, 0.0526, 0.0674, 0.0386, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0044, 0.0471, 0.0658, 0.0373, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6778934001922607 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0330, 0.0035, 0.0448, 0.0686, 0.0366, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0347, 0.0051, 0.0466, 0.0642, 0.0376, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6561291217803955 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0345, 0.0070, 0.0391, 0.0703, 0.0378, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0340, 0.0043, 0.0484, 0.0662, 0.0360, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6390924453735352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0355, 0.0042, 0.0503, 0.0678, 0.0373, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0336, 0.0048, 0.0496, 0.0639, 0.0372, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6325802803039551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0339, 0.0046, 0.0438, 0.0660, 0.0356, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0349, 0.0044, 0.0501, 0.0645, 0.0384, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6568324565887451 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0319, 0.0046, 0.0432, 0.0639, 0.0381, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0355, 0.0045, 0.0472, 0.0655, 0.0365, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6763896942138672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0355, 0.0041, 0.0487, 0.0607, 0.0305, 0.0048]) \n",
      "Test Loss tensor([0.0020, 0.0342, 0.0039, 0.0478, 0.0658, 0.0372, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6858086585998535 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0341, 0.0046, 0.0478, 0.0646, 0.0352, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0337, 0.0049, 0.0493, 0.0657, 0.0394, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6682307720184326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0331, 0.0043, 0.0535, 0.0687, 0.0400, 0.0033]) \n",
      "Test Loss tensor([0.0020, 0.0340, 0.0048, 0.0498, 0.0644, 0.0386, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6127643585205078 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0361, 0.0042, 0.0522, 0.0629, 0.0390, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0355, 0.0042, 0.0486, 0.0684, 0.0364, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6792895793914795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0379, 0.0041, 0.0417, 0.0703, 0.0415, 0.0038]) \n",
      "Test Loss tensor([0.0020, 0.0343, 0.0043, 0.0480, 0.0655, 0.0366, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6242740154266357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0357, 0.0038, 0.0487, 0.0624, 0.0405, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0339, 0.0047, 0.0486, 0.0660, 0.0390, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6567511558532715 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0347, 0.0063, 0.0499, 0.0660, 0.0363, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0347, 0.0044, 0.0489, 0.0642, 0.0381, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6878294944763184 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0335, 0.0057, 0.0517, 0.0645, 0.0347, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0342, 0.0043, 0.0472, 0.0673, 0.0350, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.722052812576294 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0366, 0.0032, 0.0447, 0.0655, 0.0357, 0.0045]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0043, 0.0470, 0.0651, 0.0373, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.7085802555084229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0322, 0.0046, 0.0439, 0.0643, 0.0390, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0333, 0.0049, 0.0487, 0.0624, 0.0380, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6458742618560791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0398, 0.0057, 0.0456, 0.0593, 0.0384, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0332, 0.0046, 0.0477, 0.0652, 0.0370, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7580564022064209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0372, 0.0053, 0.0483, 0.0648, 0.0394, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0339, 0.0040, 0.0458, 0.0662, 0.0354, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.7212283611297607 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0342, 0.0043, 0.0476, 0.0674, 0.0362, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0332, 0.0044, 0.0478, 0.0645, 0.0365, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6907665729522705 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0323, 0.0051, 0.0448, 0.0636, 0.0370, 0.0029]) \n",
      "Test Loss tensor([0.0020, 0.0325, 0.0047, 0.0467, 0.0625, 0.0383, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6865901947021484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0361, 0.0028, 0.0463, 0.0674, 0.0394, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0336, 0.0052, 0.0480, 0.0612, 0.0383, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6193246841430664 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0340, 0.0059, 0.0428, 0.0622, 0.0406, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0334, 0.0040, 0.0476, 0.0664, 0.0361, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6925382614135742 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0365, 0.0039, 0.0486, 0.0645, 0.0353, 0.0041]) \n",
      "Test Loss tensor([0.0020, 0.0323, 0.0043, 0.0479, 0.0644, 0.0368, 0.0034])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 240 in 0.624563455581665 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0313, 0.0029, 0.0451, 0.0595, 0.0326, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0339, 0.0050, 0.0471, 0.0623, 0.0391, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.641409158706665 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0367, 0.0053, 0.0521, 0.0656, 0.0381, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0038, 0.0455, 0.0632, 0.0357, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6508424282073975 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0338, 0.0038, 0.0492, 0.0612, 0.0380, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0040, 0.0465, 0.0652, 0.0367, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6645548343658447 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0357, 0.0047, 0.0472, 0.0680, 0.0382, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0347, 0.0042, 0.0463, 0.0618, 0.0394, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6684515476226807 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0327, 0.0045, 0.0498, 0.0663, 0.0402, 0.0028]) \n",
      "Test Loss tensor([0.0020, 0.0335, 0.0039, 0.0457, 0.0632, 0.0376, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6480038166046143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0333, 0.0041, 0.0454, 0.0612, 0.0355, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0336, 0.0039, 0.0469, 0.0661, 0.0365, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6797122955322266 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0361, 0.0039, 0.0382, 0.0596, 0.0357, 0.0028]) \n",
      "Test Loss tensor([0.0020, 0.0331, 0.0039, 0.0466, 0.0630, 0.0362, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6361517906188965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0333, 0.0055, 0.0507, 0.0641, 0.0381, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0335, 0.0044, 0.0470, 0.0610, 0.0365, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6556434631347656 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0309, 0.0043, 0.0493, 0.0641, 0.0403, 0.0032]) \n",
      "Test Loss tensor([0.0020, 0.0329, 0.0041, 0.0455, 0.0639, 0.0367, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6544196605682373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0352, 0.0054, 0.0467, 0.0689, 0.0431, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0338, 0.0040, 0.0459, 0.0621, 0.0375, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6228034496307373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0311, 0.0041, 0.0515, 0.0632, 0.0411, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0334, 0.0043, 0.0469, 0.0630, 0.0375, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6213316917419434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0359, 0.0048, 0.0482, 0.0640, 0.0427, 0.0031]) \n",
      "Test Loss tensor([0.0019, 0.0335, 0.0043, 0.0456, 0.0605, 0.0364, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5956790447235107 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0349, 0.0055, 0.0429, 0.0596, 0.0406, 0.0039]) \n",
      "Test Loss tensor([0.0020, 0.0336, 0.0039, 0.0471, 0.0629, 0.0370, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6223363876342773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0345, 0.0045, 0.0426, 0.0595, 0.0406, 0.0034]) \n",
      "Test Loss tensor([0.0020, 0.0329, 0.0040, 0.0463, 0.0619, 0.0385, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5985162258148193 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0336, 0.0042, 0.0466, 0.0662, 0.0355, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0337, 0.0041, 0.0473, 0.0631, 0.0368, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5916945934295654 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0393, 0.0044, 0.0486, 0.0669, 0.0340, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0041, 0.0469, 0.0624, 0.0358, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6019229888916016 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0343, 0.0034, 0.0468, 0.0582, 0.0348, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0043, 0.0461, 0.0619, 0.0359, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5957565307617188 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0301, 0.0034, 0.0467, 0.0609, 0.0331, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0040, 0.0463, 0.0605, 0.0372, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.608677864074707 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0357, 0.0049, 0.0409, 0.0610, 0.0411, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0039, 0.0453, 0.0627, 0.0362, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5946059226989746 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0306, 0.0030, 0.0468, 0.0648, 0.0385, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0334, 0.0039, 0.0445, 0.0624, 0.0361, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5994551181793213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0341, 0.0048, 0.0469, 0.0664, 0.0377, 0.0030]) \n",
      "Test Loss tensor([0.0020, 0.0334, 0.0040, 0.0464, 0.0620, 0.0357, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6200554370880127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0337, 0.0042, 0.0472, 0.0634, 0.0358, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0332, 0.0046, 0.0451, 0.0614, 0.0343, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.664170503616333 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0374, 0.0042, 0.0466, 0.0667, 0.0352, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0044, 0.0450, 0.0620, 0.0366, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6328251361846924 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0332, 0.0041, 0.0485, 0.0741, 0.0447, 0.0039]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0038, 0.0457, 0.0627, 0.0351, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6275506019592285 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0360, 0.0042, 0.0448, 0.0652, 0.0357, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0330, 0.0041, 0.0451, 0.0618, 0.0360, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6459550857543945 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0328, 0.0040, 0.0460, 0.0638, 0.0367, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0329, 0.0040, 0.0462, 0.0618, 0.0366, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6453547477722168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0339, 0.0058, 0.0469, 0.0623, 0.0374, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0041, 0.0440, 0.0606, 0.0365, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6530213356018066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0360, 0.0047, 0.0421, 0.0615, 0.0375, 0.0036]) \n",
      "Test Loss tensor([0.0020, 0.0328, 0.0041, 0.0431, 0.0619, 0.0368, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6324279308319092 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0044, 0.0493, 0.0648, 0.0356, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0038, 0.0440, 0.0606, 0.0366, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6395361423492432 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0334, 0.0046, 0.0445, 0.0542, 0.0363, 0.0031]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0038, 0.0458, 0.0613, 0.0360, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6607534885406494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0333, 0.0046, 0.0453, 0.0637, 0.0325, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0332, 0.0039, 0.0446, 0.0617, 0.0371, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6307122707366943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0329, 0.0044, 0.0474, 0.0622, 0.0376, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0041, 0.0435, 0.0609, 0.0354, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6575899124145508 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0034, 0.0421, 0.0613, 0.0409, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0332, 0.0039, 0.0462, 0.0610, 0.0375, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6612646579742432 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0362, 0.0033, 0.0508, 0.0584, 0.0316, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0335, 0.0044, 0.0448, 0.0610, 0.0368, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.653395414352417 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0338, 0.0031, 0.0488, 0.0699, 0.0426, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0342, 0.0041, 0.0433, 0.0625, 0.0365, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6332008838653564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0329, 0.0026, 0.0467, 0.0610, 0.0352, 0.0035]) \n",
      "Test Loss tensor([0.0020, 0.0343, 0.0037, 0.0452, 0.0632, 0.0357, 0.0039])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 384 in 0.6363465785980225 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0043, 0.0470, 0.0641, 0.0368, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0333, 0.0043, 0.0438, 0.0610, 0.0379, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7193245887756348 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0303, 0.0042, 0.0410, 0.0561, 0.0328, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0339, 0.0044, 0.0451, 0.0614, 0.0385, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6996808052062988 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0354, 0.0034, 0.0446, 0.0570, 0.0401, 0.0031]) \n",
      "Test Loss tensor([0.0019, 0.0348, 0.0044, 0.0450, 0.0652, 0.0345, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6899232864379883 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0331, 0.0047, 0.0364, 0.0643, 0.0353, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0332, 0.0040, 0.0431, 0.0599, 0.0366, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6192684173583984 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0324, 0.0047, 0.0448, 0.0612, 0.0358, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0044, 0.0448, 0.0607, 0.0373, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7012901306152344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0342, 0.0031, 0.0472, 0.0615, 0.0391, 0.0031]) \n",
      "Test Loss tensor([0.0019, 0.0329, 0.0043, 0.0439, 0.0646, 0.0350, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6280436515808105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0310, 0.0032, 0.0413, 0.0617, 0.0361, 0.0040]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0041, 0.0446, 0.0608, 0.0359, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7197299003601074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0332, 0.0023, 0.0415, 0.0610, 0.0326, 0.0031]) \n",
      "Test Loss tensor([0.0020, 0.0332, 0.0047, 0.0442, 0.0604, 0.0369, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6343982219696045 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0343, 0.0028, 0.0384, 0.0610, 0.0373, 0.0028]) \n",
      "Test Loss tensor([0.0020, 0.0336, 0.0035, 0.0428, 0.0613, 0.0364, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6579360961914062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0357, 0.0049, 0.0427, 0.0606, 0.0383, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0338, 0.0036, 0.0440, 0.0616, 0.0351, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6357536315917969 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0337, 0.0040, 0.0409, 0.0581, 0.0340, 0.0037]) \n",
      "Test Loss tensor([0.0020, 0.0338, 0.0039, 0.0425, 0.0589, 0.0353, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6345593929290771 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0348, 0.0036, 0.0438, 0.0592, 0.0349, 0.0029]) \n",
      "Test Loss tensor([0.0020, 0.0332, 0.0043, 0.0436, 0.0597, 0.0349, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6656873226165771 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0337, 0.0040, 0.0426, 0.0650, 0.0339, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0041, 0.0432, 0.0614, 0.0354, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6627609729766846 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0320, 0.0036, 0.0392, 0.0599, 0.0382, 0.0041]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0039, 0.0424, 0.0616, 0.0361, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6408922672271729 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0347, 0.0044, 0.0436, 0.0555, 0.0344, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0042, 0.0443, 0.0616, 0.0358, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.626812219619751 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0334, 0.0049, 0.0372, 0.0657, 0.0403, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0039, 0.0420, 0.0593, 0.0358, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6423530578613281 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0340, 0.0057, 0.0432, 0.0586, 0.0376, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0039, 0.0438, 0.0600, 0.0356, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6934247016906738 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0335, 0.0039, 0.0455, 0.0583, 0.0378, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0045, 0.0445, 0.0616, 0.0373, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6282236576080322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0322, 0.0045, 0.0395, 0.0561, 0.0372, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0040, 0.0437, 0.0610, 0.0342, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.618950605392456 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0348, 0.0044, 0.0402, 0.0663, 0.0370, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0319, 0.0042, 0.0438, 0.0601, 0.0364, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6166410446166992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0326, 0.0050, 0.0454, 0.0652, 0.0335, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0044, 0.0431, 0.0611, 0.0372, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6159117221832275 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0341, 0.0046, 0.0419, 0.0593, 0.0375, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0043, 0.0428, 0.0602, 0.0353, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6431460380554199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0339, 0.0049, 0.0435, 0.0557, 0.0307, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0039, 0.0432, 0.0611, 0.0353, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6192998886108398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0318, 0.0040, 0.0462, 0.0566, 0.0402, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0041, 0.0426, 0.0596, 0.0354, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.658470869064331 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0064, 0.0454, 0.0585, 0.0396, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0314, 0.0044, 0.0423, 0.0588, 0.0361, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.718268632888794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0334, 0.0038, 0.0460, 0.0606, 0.0346, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0323, 0.0038, 0.0420, 0.0592, 0.0364, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6214399337768555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0308, 0.0045, 0.0437, 0.0577, 0.0373, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0043, 0.0413, 0.0598, 0.0366, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6316030025482178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0329, 0.0042, 0.0458, 0.0591, 0.0400, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0040, 0.0427, 0.0587, 0.0358, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.611572265625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0302, 0.0035, 0.0441, 0.0612, 0.0346, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0037, 0.0417, 0.0597, 0.0355, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6268908977508545 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0330, 0.0039, 0.0408, 0.0581, 0.0337, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0032, 0.0424, 0.0595, 0.0360, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6505000591278076 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0039, 0.0398, 0.0605, 0.0343, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0040, 0.0412, 0.0587, 0.0350, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6614277362823486 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0317, 0.0046, 0.0411, 0.0561, 0.0337, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0041, 0.0420, 0.0590, 0.0363, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6429939270019531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0372, 0.0036, 0.0484, 0.0609, 0.0352, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0042, 0.0436, 0.0595, 0.0352, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6436116695404053 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0040, 0.0419, 0.0559, 0.0293, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0041, 0.0429, 0.0590, 0.0355, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6993744373321533 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0314, 0.0032, 0.0408, 0.0605, 0.0356, 0.0045]) \n",
      "Test Loss tensor([0.0019, 0.0338, 0.0040, 0.0418, 0.0574, 0.0359, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6294937133789062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0346, 0.0042, 0.0450, 0.0566, 0.0373, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0034, 0.0427, 0.0590, 0.0364, 0.0036])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 528 in 0.8167204856872559 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0330, 0.0034, 0.0378, 0.0581, 0.0385, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0037, 0.0425, 0.0623, 0.0345, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.7738282680511475 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0373, 0.0032, 0.0398, 0.0587, 0.0336, 0.0061]) \n",
      "Test Loss tensor([0.0019, 0.0343, 0.0043, 0.0424, 0.0597, 0.0374, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.7159628868103027 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0341, 0.0039, 0.0403, 0.0564, 0.0360, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0036, 0.0417, 0.0603, 0.0368, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.7043778896331787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0311, 0.0037, 0.0381, 0.0557, 0.0354, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0035, 0.0406, 0.0604, 0.0340, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6783430576324463 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0354, 0.0047, 0.0370, 0.0576, 0.0371, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0040, 0.0408, 0.0593, 0.0354, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6071555614471436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0310, 0.0046, 0.0443, 0.0600, 0.0330, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0310, 0.0039, 0.0431, 0.0591, 0.0363, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6398794651031494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0338, 0.0044, 0.0407, 0.0595, 0.0379, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0040, 0.0406, 0.0575, 0.0356, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6257355213165283 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0322, 0.0035, 0.0425, 0.0568, 0.0355, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0037, 0.0409, 0.0579, 0.0347, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6696398258209229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0342, 0.0039, 0.0391, 0.0565, 0.0339, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0316, 0.0038, 0.0425, 0.0576, 0.0355, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6456549167633057 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0336, 0.0033, 0.0413, 0.0598, 0.0334, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0327, 0.0043, 0.0425, 0.0569, 0.0359, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6502110958099365 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0278, 0.0041, 0.0426, 0.0626, 0.0393, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0038, 0.0409, 0.0563, 0.0365, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6323955059051514 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0315, 0.0031, 0.0425, 0.0596, 0.0346, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0040, 0.0401, 0.0583, 0.0354, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6215596199035645 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0377, 0.0030, 0.0369, 0.0559, 0.0352, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0035, 0.0425, 0.0599, 0.0348, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6086211204528809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0344, 0.0050, 0.0393, 0.0568, 0.0348, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0310, 0.0042, 0.0402, 0.0605, 0.0363, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6313624382019043 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0333, 0.0037, 0.0423, 0.0528, 0.0371, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0038, 0.0416, 0.0586, 0.0359, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6111495494842529 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0336, 0.0038, 0.0399, 0.0599, 0.0338, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0322, 0.0040, 0.0421, 0.0590, 0.0353, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6070261001586914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0345, 0.0042, 0.0385, 0.0595, 0.0305, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0040, 0.0416, 0.0585, 0.0353, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6073288917541504 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0349, 0.0048, 0.0441, 0.0601, 0.0403, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0316, 0.0041, 0.0399, 0.0567, 0.0363, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6088855266571045 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0336, 0.0044, 0.0425, 0.0548, 0.0383, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0316, 0.0037, 0.0407, 0.0589, 0.0348, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6049177646636963 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0312, 0.0042, 0.0436, 0.0644, 0.0400, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0041, 0.0421, 0.0582, 0.0354, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6034266948699951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0343, 0.0037, 0.0402, 0.0562, 0.0382, 0.0031]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0038, 0.0418, 0.0590, 0.0363, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6127374172210693 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0332, 0.0041, 0.0429, 0.0626, 0.0376, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0036, 0.0405, 0.0578, 0.0353, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6243200302124023 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0291, 0.0034, 0.0378, 0.0554, 0.0319, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0035, 0.0409, 0.0587, 0.0348, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5956051349639893 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0316, 0.0031, 0.0479, 0.0537, 0.0356, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0036, 0.0414, 0.0580, 0.0350, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6051068305969238 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0277, 0.0036, 0.0360, 0.0581, 0.0299, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0323, 0.0036, 0.0416, 0.0593, 0.0368, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6172356605529785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0289, 0.0034, 0.0346, 0.0621, 0.0372, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0038, 0.0408, 0.0586, 0.0356, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6283648014068604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0344, 0.0041, 0.0409, 0.0591, 0.0388, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0035, 0.0398, 0.0620, 0.0338, 0.0044])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6006693840026855 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0327, 0.0041, 0.0439, 0.0664, 0.0319, 0.0042]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0038, 0.0417, 0.0602, 0.0387, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6242718696594238 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0354, 0.0039, 0.0411, 0.0627, 0.0403, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0036, 0.0404, 0.0576, 0.0348, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6294717788696289 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0354, 0.0033, 0.0356, 0.0544, 0.0370, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0352, 0.0038, 0.0413, 0.0703, 0.0335, 0.0046])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6227304935455322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0337, 0.0042, 0.0360, 0.0721, 0.0298, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0037, 0.0411, 0.0594, 0.0367, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6077322959899902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0320, 0.0037, 0.0433, 0.0600, 0.0327, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0036, 0.0425, 0.0613, 0.0369, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6187386512756348 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0034, 0.0410, 0.0609, 0.0407, 0.0025]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0035, 0.0415, 0.0630, 0.0335, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6099565029144287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0339, 0.0034, 0.0436, 0.0611, 0.0340, 0.0036]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0036, 0.0411, 0.0621, 0.0332, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6112620830535889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0373, 0.0041, 0.0382, 0.0613, 0.0330, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0041, 0.0420, 0.0608, 0.0379, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6601662635803223 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0327, 0.0051, 0.0389, 0.0591, 0.0401, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0037, 0.0398, 0.0615, 0.0372, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 672 in 0.6185224056243896 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0332, 0.0036, 0.0412, 0.0584, 0.0394, 0.0024]) \n",
      "Test Loss tensor([0.0019, 0.0349, 0.0037, 0.0431, 0.0633, 0.0327, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6282248497009277 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0347, 0.0038, 0.0389, 0.0588, 0.0363, 0.0039]) \n",
      "Test Loss tensor([0.0019, 0.0322, 0.0034, 0.0400, 0.0587, 0.0342, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6284527778625488 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0021, 0.0370, 0.0030, 0.0433, 0.0590, 0.0350, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0339, 0.0040, 0.0415, 0.0591, 0.0372, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6137683391571045 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0332, 0.0041, 0.0417, 0.0581, 0.0349, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0318, 0.0040, 0.0403, 0.0564, 0.0350, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6137816905975342 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0330, 0.0033, 0.0394, 0.0543, 0.0366, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0343, 0.0039, 0.0414, 0.0669, 0.0340, 0.0038])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.633944034576416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0350, 0.0032, 0.0414, 0.0622, 0.0299, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0316, 0.0039, 0.0405, 0.0574, 0.0357, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6299614906311035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0048, 0.0440, 0.0599, 0.0346, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0334, 0.0043, 0.0411, 0.0589, 0.0366, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6163730621337891 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0320, 0.0044, 0.0460, 0.0571, 0.0349, 0.0025]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0040, 0.0410, 0.0605, 0.0343, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6331088542938232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0336, 0.0040, 0.0402, 0.0598, 0.0358, 0.0039]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0031, 0.0424, 0.0647, 0.0336, 0.0037])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6325681209564209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0357, 0.0044, 0.0420, 0.0619, 0.0389, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0040, 0.0403, 0.0582, 0.0370, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6198251247406006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0340, 0.0056, 0.0373, 0.0559, 0.0346, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0324, 0.0044, 0.0394, 0.0592, 0.0376, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6276860237121582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0037, 0.0373, 0.0620, 0.0339, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0327, 0.0036, 0.0409, 0.0593, 0.0339, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6293723583221436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0354, 0.0039, 0.0397, 0.0605, 0.0387, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0039, 0.0400, 0.0581, 0.0343, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6108033657073975 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0334, 0.0035, 0.0389, 0.0566, 0.0370, 0.0039]) \n",
      "Test Loss tensor([0.0018, 0.0323, 0.0038, 0.0397, 0.0585, 0.0366, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6270480155944824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0329, 0.0033, 0.0385, 0.0585, 0.0344, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0307, 0.0039, 0.0404, 0.0572, 0.0354, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6157848834991455 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0041, 0.0395, 0.0617, 0.0383, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0327, 0.0035, 0.0406, 0.0592, 0.0342, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6124448776245117 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0335, 0.0026, 0.0349, 0.0623, 0.0324, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0039, 0.0392, 0.0559, 0.0344, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6289892196655273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0338, 0.0038, 0.0351, 0.0580, 0.0365, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0312, 0.0037, 0.0398, 0.0570, 0.0364, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6556615829467773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0300, 0.0030, 0.0374, 0.0590, 0.0356, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0319, 0.0040, 0.0397, 0.0562, 0.0352, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6536450386047363 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0314, 0.0034, 0.0392, 0.0550, 0.0299, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0323, 0.0035, 0.0403, 0.0566, 0.0331, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6356148719787598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0357, 0.0042, 0.0391, 0.0518, 0.0330, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0323, 0.0035, 0.0389, 0.0569, 0.0329, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6163370609283447 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0310, 0.0044, 0.0381, 0.0564, 0.0356, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0318, 0.0036, 0.0397, 0.0562, 0.0350, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6168043613433838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0030, 0.0346, 0.0558, 0.0334, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0318, 0.0034, 0.0403, 0.0561, 0.0358, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6203882694244385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0341, 0.0038, 0.0389, 0.0521, 0.0347, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0319, 0.0036, 0.0386, 0.0583, 0.0342, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6442720890045166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0320, 0.0041, 0.0405, 0.0536, 0.0372, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0323, 0.0036, 0.0386, 0.0577, 0.0340, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6508088111877441 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0313, 0.0042, 0.0393, 0.0550, 0.0279, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0041, 0.0425, 0.0583, 0.0370, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6917104721069336 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0343, 0.0047, 0.0343, 0.0600, 0.0365, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0036, 0.0394, 0.0561, 0.0339, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.64212965965271 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0310, 0.0027, 0.0394, 0.0579, 0.0319, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0327, 0.0039, 0.0408, 0.0600, 0.0339, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6299681663513184 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0364, 0.0031, 0.0413, 0.0618, 0.0335, 0.0045]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0039, 0.0388, 0.0554, 0.0370, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6509010791778564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0338, 0.0048, 0.0425, 0.0553, 0.0396, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0326, 0.0034, 0.0411, 0.0591, 0.0376, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.7000730037689209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0308, 0.0029, 0.0439, 0.0607, 0.0380, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0312, 0.0034, 0.0387, 0.0573, 0.0345, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.973447322845459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0031, 0.0401, 0.0542, 0.0306, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0336, 0.0036, 0.0402, 0.0604, 0.0337, 0.0039])\n",
      "\n",
      "\n",
      "************** Batch 800 in 1.0075719356536865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0336, 0.0030, 0.0336, 0.0610, 0.0313, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0036, 0.0402, 0.0562, 0.0363, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.8279502391815186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0315, 0.0035, 0.0372, 0.0529, 0.0314, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0034, 0.0417, 0.0620, 0.0370, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6796875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0342, 0.0039, 0.0471, 0.0610, 0.0388, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0331, 0.0033, 0.0393, 0.0576, 0.0345, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6213672161102295 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0341, 0.0033, 0.0370, 0.0554, 0.0345, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0333, 0.0034, 0.0406, 0.0628, 0.0337, 0.0041])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 816 in 0.6336014270782471 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0026, 0.0402, 0.0656, 0.0336, 0.0044]) \n",
      "Test Loss tensor([0.0019, 0.0329, 0.0036, 0.0406, 0.0579, 0.0359, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6534614562988281 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0359, 0.0031, 0.0382, 0.0597, 0.0336, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0328, 0.0039, 0.0424, 0.0612, 0.0371, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6284608840942383 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0366, 0.0036, 0.0390, 0.0553, 0.0364, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0330, 0.0035, 0.0380, 0.0563, 0.0334, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6046574115753174 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0307, 0.0031, 0.0368, 0.0509, 0.0339, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0341, 0.0035, 0.0406, 0.0637, 0.0336, 0.0041])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6046960353851318 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0331, 0.0038, 0.0356, 0.0617, 0.0330, 0.0043]) \n",
      "Test Loss tensor([0.0019, 0.0316, 0.0038, 0.0400, 0.0557, 0.0347, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6030192375183105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0301, 0.0035, 0.0381, 0.0524, 0.0358, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0329, 0.0040, 0.0401, 0.0595, 0.0364, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6212043762207031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0365, 0.0031, 0.0439, 0.0681, 0.0312, 0.0026]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0032, 0.0372, 0.0545, 0.0338, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.5937891006469727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0339, 0.0032, 0.0386, 0.0576, 0.0348, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0342, 0.0032, 0.0409, 0.0640, 0.0335, 0.0040])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.5979936122894287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0349, 0.0029, 0.0376, 0.0687, 0.0343, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0320, 0.0035, 0.0392, 0.0573, 0.0348, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6012067794799805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0061, 0.0393, 0.0608, 0.0380, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0328, 0.0045, 0.0423, 0.0603, 0.0361, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5959100723266602 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0336, 0.0041, 0.0433, 0.0535, 0.0347, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0318, 0.0037, 0.0385, 0.0562, 0.0338, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.5919654369354248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0031, 0.0419, 0.0524, 0.0370, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0320, 0.0035, 0.0383, 0.0608, 0.0347, 0.0034])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.623410701751709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0325, 0.0034, 0.0348, 0.0590, 0.0305, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0315, 0.0036, 0.0391, 0.0551, 0.0341, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6764745712280273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0325, 0.0031, 0.0362, 0.0565, 0.0368, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0037, 0.0392, 0.0552, 0.0347, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6395483016967773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0347, 0.0037, 0.0408, 0.0567, 0.0336, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0041, 0.0384, 0.0547, 0.0343, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6091110706329346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0014, 0.0259, 0.0031, 0.0293, 0.0383, 0.0289, 0.0023]) \n",
      "Test Loss tensor([0.0019, 0.0314, 0.0034, 0.0387, 0.0561, 0.0328, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.65325927734375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0310, 0.0033, 0.0412, 0.0533, 0.0389, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0034, 0.0397, 0.0555, 0.0338, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6353964805603027 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0367, 0.0032, 0.0393, 0.0560, 0.0339, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0307, 0.0037, 0.0383, 0.0549, 0.0346, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6344325542449951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0032, 0.0364, 0.0568, 0.0341, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0316, 0.0038, 0.0390, 0.0552, 0.0355, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6321420669555664 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0305, 0.0028, 0.0372, 0.0573, 0.0381, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0039, 0.0391, 0.0562, 0.0330, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6448194980621338 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0331, 0.0025, 0.0349, 0.0536, 0.0351, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0035, 0.0354, 0.0564, 0.0343, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6296603679656982 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0327, 0.0036, 0.0371, 0.0554, 0.0365, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0319, 0.0036, 0.0372, 0.0558, 0.0346, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6340794563293457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0040, 0.0338, 0.0505, 0.0302, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0312, 0.0044, 0.0377, 0.0537, 0.0348, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6393392086029053 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0315, 0.0053, 0.0386, 0.0549, 0.0375, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0031, 0.0374, 0.0572, 0.0332, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.633551836013794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0031, 0.0383, 0.0581, 0.0317, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0033, 0.0366, 0.0555, 0.0341, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.687875509262085 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0028, 0.0359, 0.0596, 0.0402, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0316, 0.0034, 0.0380, 0.0555, 0.0342, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6900207996368408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0313, 0.0038, 0.0386, 0.0553, 0.0356, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0326, 0.0034, 0.0374, 0.0535, 0.0336, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6099493503570557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0029, 0.0377, 0.0577, 0.0343, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0319, 0.0029, 0.0379, 0.0565, 0.0341, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6539616584777832 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0358, 0.0036, 0.0382, 0.0561, 0.0341, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0034, 0.0355, 0.0556, 0.0347, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6246263980865479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0331, 0.0032, 0.0376, 0.0565, 0.0362, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0035, 0.0387, 0.0555, 0.0342, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6882069110870361 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0316, 0.0029, 0.0375, 0.0536, 0.0340, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0311, 0.0036, 0.0388, 0.0543, 0.0347, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6141819953918457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0327, 0.0043, 0.0375, 0.0581, 0.0376, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0307, 0.0036, 0.0383, 0.0551, 0.0340, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6237471103668213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0312, 0.0041, 0.0410, 0.0537, 0.0328, 0.0025]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0035, 0.0375, 0.0568, 0.0340, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.612952709197998 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0335, 0.0042, 0.0372, 0.0531, 0.0348, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0314, 0.0033, 0.0383, 0.0559, 0.0329, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5959746837615967 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0030, 0.0400, 0.0599, 0.0348, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0034, 0.0375, 0.0547, 0.0336, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.5938222408294678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0038, 0.0378, 0.0592, 0.0372, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0308, 0.0038, 0.0375, 0.0547, 0.0338, 0.0029])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 80 in 0.5946660041809082 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0321, 0.0032, 0.0405, 0.0553, 0.0378, 0.0034]) \n",
      "Test Loss tensor([0.0019, 0.0310, 0.0033, 0.0370, 0.0569, 0.0335, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5965168476104736 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0294, 0.0034, 0.0403, 0.0595, 0.0320, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0321, 0.0033, 0.0373, 0.0545, 0.0334, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5974476337432861 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0025, 0.0370, 0.0525, 0.0318, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0325, 0.0036, 0.0378, 0.0547, 0.0343, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.5930871963500977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0299, 0.0041, 0.0389, 0.0534, 0.0365, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0035, 0.0369, 0.0544, 0.0339, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5896985530853271 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0314, 0.0030, 0.0423, 0.0528, 0.0373, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0311, 0.0033, 0.0379, 0.0551, 0.0324, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5907840728759766 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0033, 0.0323, 0.0579, 0.0347, 0.0025]) \n",
      "Test Loss tensor([0.0019, 0.0305, 0.0034, 0.0370, 0.0560, 0.0332, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.5916106700897217 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0033, 0.0394, 0.0589, 0.0324, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0300, 0.0033, 0.0370, 0.0549, 0.0334, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5953330993652344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0049, 0.0328, 0.0563, 0.0371, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0035, 0.0383, 0.0545, 0.0329, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.602548360824585 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0030, 0.0333, 0.0515, 0.0324, 0.0028]) \n",
      "Test Loss tensor([0.0019, 0.0312, 0.0031, 0.0370, 0.0539, 0.0331, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.62534499168396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0324, 0.0025, 0.0353, 0.0571, 0.0292, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0033, 0.0376, 0.0540, 0.0332, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6549856662750244 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0343, 0.0042, 0.0381, 0.0590, 0.0409, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0316, 0.0035, 0.0370, 0.0527, 0.0328, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6338784694671631 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0310, 0.0041, 0.0344, 0.0616, 0.0390, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0299, 0.0035, 0.0363, 0.0524, 0.0340, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.627190113067627 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0029, 0.0319, 0.0569, 0.0331, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0036, 0.0381, 0.0541, 0.0335, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6162424087524414 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0359, 0.0025, 0.0366, 0.0510, 0.0344, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0034, 0.0381, 0.0547, 0.0332, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6318964958190918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0307, 0.0035, 0.0358, 0.0571, 0.0306, 0.0038]) \n",
      "Test Loss tensor([0.0019, 0.0310, 0.0035, 0.0382, 0.0536, 0.0317, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6198770999908447 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0322, 0.0040, 0.0403, 0.0556, 0.0294, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0040, 0.0390, 0.0557, 0.0335, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5980885028839111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0331, 0.0029, 0.0346, 0.0510, 0.0313, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0036, 0.0376, 0.0539, 0.0328, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6112585067749023 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0341, 0.0033, 0.0378, 0.0509, 0.0342, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0307, 0.0034, 0.0376, 0.0533, 0.0333, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6166477203369141 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0033, 0.0387, 0.0555, 0.0312, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0034, 0.0372, 0.0542, 0.0331, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.5956778526306152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0036, 0.0346, 0.0552, 0.0307, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0037, 0.0383, 0.0550, 0.0329, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5922648906707764 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0030, 0.0386, 0.0539, 0.0359, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0033, 0.0368, 0.0544, 0.0328, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.5921165943145752 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0328, 0.0031, 0.0364, 0.0553, 0.0284, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0036, 0.0381, 0.0533, 0.0342, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6578128337860107 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0300, 0.0027, 0.0361, 0.0477, 0.0349, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0034, 0.0372, 0.0524, 0.0333, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6262814998626709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0034, 0.0333, 0.0484, 0.0320, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0034, 0.0370, 0.0534, 0.0335, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.595287561416626 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0300, 0.0041, 0.0397, 0.0563, 0.0318, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0312, 0.0034, 0.0369, 0.0547, 0.0329, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.5950887203216553 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0321, 0.0024, 0.0331, 0.0522, 0.0351, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0033, 0.0381, 0.0556, 0.0339, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.5917348861694336 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0307, 0.0030, 0.0418, 0.0551, 0.0390, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0322, 0.0032, 0.0356, 0.0547, 0.0346, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5933310985565186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0293, 0.0028, 0.0374, 0.0543, 0.0354, 0.0037]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0032, 0.0383, 0.0540, 0.0329, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6351363658905029 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0325, 0.0035, 0.0411, 0.0575, 0.0365, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0032, 0.0367, 0.0541, 0.0342, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.5923416614532471 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0321, 0.0028, 0.0355, 0.0569, 0.0399, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0036, 0.0383, 0.0547, 0.0331, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.623640775680542 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0321, 0.0027, 0.0378, 0.0528, 0.0313, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0034, 0.0387, 0.0537, 0.0331, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6526596546173096 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0032, 0.0391, 0.0554, 0.0329, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0032, 0.0373, 0.0543, 0.0326, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6294245719909668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0295, 0.0039, 0.0369, 0.0569, 0.0327, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0032, 0.0365, 0.0535, 0.0328, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6441895961761475 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0270, 0.0031, 0.0402, 0.0510, 0.0313, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0034, 0.0375, 0.0548, 0.0338, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6551961898803711 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0317, 0.0044, 0.0381, 0.0526, 0.0328, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0031, 0.0370, 0.0538, 0.0333, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6503124237060547 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0035, 0.0343, 0.0536, 0.0349, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0029, 0.0380, 0.0551, 0.0333, 0.0032])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 224 in 0.6283860206604004 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0336, 0.0031, 0.0375, 0.0574, 0.0279, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0033, 0.0371, 0.0534, 0.0344, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6223015785217285 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0325, 0.0034, 0.0408, 0.0497, 0.0353, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0033, 0.0379, 0.0525, 0.0341, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6125850677490234 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0321, 0.0035, 0.0412, 0.0526, 0.0309, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0317, 0.0030, 0.0376, 0.0526, 0.0331, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.617286205291748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0307, 0.0026, 0.0406, 0.0523, 0.0343, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0033, 0.0360, 0.0542, 0.0337, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.61086106300354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0324, 0.0038, 0.0316, 0.0522, 0.0324, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0033, 0.0377, 0.0549, 0.0332, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6441807746887207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0330, 0.0029, 0.0394, 0.0538, 0.0354, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0031, 0.0357, 0.0534, 0.0340, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6267826557159424 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0324, 0.0024, 0.0348, 0.0552, 0.0346, 0.0035]) \n",
      "Test Loss tensor([0.0019, 0.0319, 0.0032, 0.0374, 0.0524, 0.0325, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5909578800201416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0307, 0.0038, 0.0362, 0.0528, 0.0307, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0034, 0.0354, 0.0547, 0.0342, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5947444438934326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0036, 0.0348, 0.0577, 0.0360, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0033, 0.0371, 0.0538, 0.0340, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.5933811664581299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0042, 0.0365, 0.0538, 0.0334, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0032, 0.0386, 0.0522, 0.0336, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5910556316375732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0291, 0.0041, 0.0386, 0.0519, 0.0345, 0.0030]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0034, 0.0362, 0.0526, 0.0321, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5945894718170166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0040, 0.0387, 0.0530, 0.0364, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0320, 0.0029, 0.0372, 0.0539, 0.0337, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5936050415039062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0314, 0.0034, 0.0344, 0.0539, 0.0304, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0035, 0.0369, 0.0530, 0.0328, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6004922389984131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0324, 0.0038, 0.0401, 0.0543, 0.0340, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0032, 0.0367, 0.0538, 0.0346, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5922873020172119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0315, 0.0027, 0.0372, 0.0496, 0.0362, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0034, 0.0365, 0.0518, 0.0328, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5932328701019287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0318, 0.0033, 0.0372, 0.0534, 0.0328, 0.0027]) \n",
      "Test Loss tensor([0.0019, 0.0309, 0.0036, 0.0386, 0.0543, 0.0326, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5923867225646973 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0030, 0.0369, 0.0522, 0.0318, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0034, 0.0378, 0.0540, 0.0345, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5940060615539551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0031, 0.0353, 0.0521, 0.0386, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0038, 0.0377, 0.0537, 0.0334, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.5966675281524658 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0039, 0.0363, 0.0544, 0.0324, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0316, 0.0033, 0.0375, 0.0523, 0.0319, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5999276638031006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0296, 0.0034, 0.0331, 0.0552, 0.0389, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0320, 0.0031, 0.0370, 0.0530, 0.0330, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5919821262359619 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0307, 0.0037, 0.0418, 0.0541, 0.0363, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0033, 0.0371, 0.0517, 0.0330, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6037895679473877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0034, 0.0370, 0.0573, 0.0328, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0032, 0.0367, 0.0513, 0.0339, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5919959545135498 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0040, 0.0432, 0.0518, 0.0361, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0307, 0.0032, 0.0370, 0.0523, 0.0335, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6027610301971436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0312, 0.0027, 0.0389, 0.0520, 0.0351, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0033, 0.0367, 0.0527, 0.0323, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.5966758728027344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0320, 0.0033, 0.0350, 0.0505, 0.0283, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0033, 0.0358, 0.0530, 0.0333, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.5936577320098877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0322, 0.0029, 0.0362, 0.0507, 0.0340, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0033, 0.0360, 0.0523, 0.0326, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.600405216217041 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0314, 0.0044, 0.0343, 0.0526, 0.0323, 0.0029]) \n",
      "Test Loss tensor([0.0019, 0.0305, 0.0036, 0.0382, 0.0532, 0.0319, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.5949230194091797 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0028, 0.0413, 0.0547, 0.0331, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0029, 0.0355, 0.0527, 0.0329, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.5947246551513672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0292, 0.0049, 0.0374, 0.0480, 0.0374, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0031, 0.0352, 0.0533, 0.0329, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5935981273651123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0312, 0.0025, 0.0366, 0.0562, 0.0302, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0027, 0.0370, 0.0540, 0.0316, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5930612087249756 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0039, 0.0390, 0.0561, 0.0336, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0031, 0.0351, 0.0539, 0.0325, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5970249176025391 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0322, 0.0037, 0.0369, 0.0507, 0.0334, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0034, 0.0360, 0.0553, 0.0326, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6149096488952637 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0261, 0.0043, 0.0320, 0.0509, 0.0315, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0033, 0.0382, 0.0525, 0.0338, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6085691452026367 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0352, 0.0033, 0.0421, 0.0499, 0.0325, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0032, 0.0364, 0.0514, 0.0332, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.608544111251831 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0031, 0.0357, 0.0592, 0.0345, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0034, 0.0363, 0.0524, 0.0341, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6296868324279785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0039, 0.0396, 0.0495, 0.0306, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0036, 0.0361, 0.0512, 0.0330, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 368 in 0.6486928462982178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0323, 0.0031, 0.0427, 0.0563, 0.0311, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0031, 0.0367, 0.0535, 0.0335, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6744379997253418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0023, 0.0377, 0.0492, 0.0297, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0032, 0.0361, 0.0528, 0.0327, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6082215309143066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0327, 0.0035, 0.0362, 0.0540, 0.0359, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0031, 0.0363, 0.0538, 0.0334, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5956382751464844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0051, 0.0321, 0.0520, 0.0350, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0035, 0.0363, 0.0524, 0.0330, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.5928685665130615 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0035, 0.0286, 0.0493, 0.0341, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0038, 0.0364, 0.0518, 0.0307, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.598128080368042 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0027, 0.0325, 0.0539, 0.0319, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0032, 0.0341, 0.0501, 0.0320, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5923693180084229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0328, 0.0038, 0.0380, 0.0502, 0.0283, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0307, 0.0034, 0.0362, 0.0524, 0.0335, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.5915780067443848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0314, 0.0028, 0.0366, 0.0491, 0.0410, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0035, 0.0354, 0.0515, 0.0326, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5980827808380127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0329, 0.0029, 0.0350, 0.0515, 0.0336, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0033, 0.0360, 0.0528, 0.0336, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.5972626209259033 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0311, 0.0047, 0.0347, 0.0532, 0.0339, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0031, 0.0353, 0.0523, 0.0330, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5994079113006592 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0336, 0.0029, 0.0317, 0.0540, 0.0335, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0029, 0.0356, 0.0524, 0.0316, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5991570949554443 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0322, 0.0040, 0.0376, 0.0504, 0.0348, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0035, 0.0372, 0.0532, 0.0334, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5979361534118652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0037, 0.0378, 0.0523, 0.0319, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0034, 0.0370, 0.0523, 0.0342, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6669278144836426 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0278, 0.0040, 0.0336, 0.0500, 0.0331, 0.0032]) \n",
      "Test Loss tensor([0.0019, 0.0305, 0.0032, 0.0359, 0.0526, 0.0319, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6849181652069092 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0036, 0.0345, 0.0549, 0.0304, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0032, 0.0362, 0.0523, 0.0330, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6218397617340088 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0331, 0.0030, 0.0356, 0.0512, 0.0320, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0033, 0.0381, 0.0534, 0.0347, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6878464221954346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0314, 0.0037, 0.0380, 0.0551, 0.0388, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0032, 0.0361, 0.0520, 0.0334, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6206037998199463 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0319, 0.0030, 0.0333, 0.0461, 0.0329, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0031, 0.0373, 0.0558, 0.0319, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6317381858825684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0353, 0.0035, 0.0388, 0.0569, 0.0364, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0033, 0.0366, 0.0517, 0.0328, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6873354911804199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0320, 0.0027, 0.0432, 0.0502, 0.0323, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0035, 0.0352, 0.0527, 0.0342, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6152825355529785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0027, 0.0342, 0.0489, 0.0357, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0035, 0.0355, 0.0520, 0.0325, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6177232265472412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0022, 0.0355, 0.0468, 0.0326, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0031, 0.0370, 0.0562, 0.0321, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6758589744567871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0317, 0.0034, 0.0417, 0.0531, 0.0311, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0032, 0.0363, 0.0517, 0.0330, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6523058414459229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0267, 0.0028, 0.0366, 0.0546, 0.0335, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0034, 0.0379, 0.0576, 0.0341, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6165344715118408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0036, 0.0337, 0.0478, 0.0389, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0033, 0.0358, 0.0546, 0.0323, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.617889404296875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0035, 0.0329, 0.0516, 0.0300, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0033, 0.0370, 0.0556, 0.0321, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6404585838317871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0315, 0.0027, 0.0385, 0.0610, 0.0299, 0.0038]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0032, 0.0361, 0.0529, 0.0316, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6169652938842773 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0033, 0.0352, 0.0549, 0.0351, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0034, 0.0385, 0.0551, 0.0336, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6156940460205078 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0316, 0.0029, 0.0385, 0.0521, 0.0348, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0034, 0.0374, 0.0508, 0.0317, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6136765480041504 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0307, 0.0027, 0.0390, 0.0492, 0.0316, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0323, 0.0032, 0.0362, 0.0565, 0.0316, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6163616180419922 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0314, 0.0021, 0.0376, 0.0582, 0.0342, 0.0033]) \n",
      "Test Loss tensor([0.0019, 0.0300, 0.0033, 0.0372, 0.0531, 0.0341, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6176996231079102 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0040, 0.0408, 0.0506, 0.0338, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0035, 0.0377, 0.0536, 0.0341, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6194508075714111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0346, 0.0031, 0.0454, 0.0542, 0.0354, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0323, 0.0030, 0.0356, 0.0533, 0.0320, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.620354413986206 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0318, 0.0036, 0.0366, 0.0615, 0.0287, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0031, 0.0375, 0.0557, 0.0315, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6193256378173828 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0325, 0.0035, 0.0355, 0.0541, 0.0344, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0035, 0.0386, 0.0550, 0.0343, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6184132099151611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0030, 0.0428, 0.0572, 0.0334, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0036, 0.0385, 0.0555, 0.0331, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 512 in 0.6133620738983154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0027, 0.0354, 0.0554, 0.0372, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0029, 0.0370, 0.0553, 0.0310, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.617194414138794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0034, 0.0354, 0.0531, 0.0290, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0029, 0.0372, 0.0546, 0.0322, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6170587539672852 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0314, 0.0030, 0.0338, 0.0527, 0.0309, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0034, 0.0364, 0.0539, 0.0338, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6201760768890381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0034, 0.0340, 0.0530, 0.0334, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0322, 0.0033, 0.0371, 0.0527, 0.0337, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6357653141021729 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0330, 0.0023, 0.0329, 0.0510, 0.0364, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0030, 0.0362, 0.0546, 0.0307, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6197526454925537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0347, 0.0032, 0.0364, 0.0572, 0.0289, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0325, 0.0029, 0.0369, 0.0573, 0.0319, 0.0035])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6240596771240234 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0333, 0.0035, 0.0354, 0.0570, 0.0310, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0033, 0.0380, 0.0525, 0.0329, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6220393180847168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0353, 0.0031, 0.0376, 0.0538, 0.0382, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0037, 0.0366, 0.0543, 0.0330, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6232707500457764 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0033, 0.0383, 0.0517, 0.0325, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0320, 0.0031, 0.0362, 0.0531, 0.0310, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6259040832519531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0344, 0.0029, 0.0312, 0.0535, 0.0376, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0030, 0.0365, 0.0545, 0.0323, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6292877197265625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0037, 0.0328, 0.0534, 0.0308, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0033, 0.0365, 0.0520, 0.0324, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.7125022411346436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0032, 0.0331, 0.0537, 0.0346, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0035, 0.0383, 0.0538, 0.0337, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.7206711769104004 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0040, 0.0351, 0.0503, 0.0374, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0351, 0.0522, 0.0332, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6638736724853516 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0034, 0.0358, 0.0514, 0.0307, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0314, 0.0031, 0.0370, 0.0536, 0.0317, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6214706897735596 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0333, 0.0029, 0.0315, 0.0542, 0.0286, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0033, 0.0359, 0.0507, 0.0326, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6207971572875977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0284, 0.0028, 0.0334, 0.0474, 0.0323, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0036, 0.0352, 0.0518, 0.0317, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6772098541259766 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0310, 0.0037, 0.0377, 0.0544, 0.0313, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0032, 0.0368, 0.0519, 0.0326, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6529896259307861 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0331, 0.0034, 0.0392, 0.0504, 0.0341, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0031, 0.0350, 0.0522, 0.0309, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6167917251586914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0330, 0.0035, 0.0331, 0.0497, 0.0303, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0030, 0.0357, 0.0513, 0.0328, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6674888134002686 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0043, 0.0380, 0.0512, 0.0312, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0034, 0.0345, 0.0509, 0.0321, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6446340084075928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0041, 0.0381, 0.0507, 0.0308, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0030, 0.0354, 0.0531, 0.0314, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6581954956054688 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0026, 0.0353, 0.0500, 0.0307, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0034, 0.0349, 0.0520, 0.0322, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6738095283508301 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0316, 0.0026, 0.0344, 0.0495, 0.0316, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0362, 0.0505, 0.0317, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.7028515338897705 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0026, 0.0347, 0.0500, 0.0345, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0030, 0.0351, 0.0512, 0.0321, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.647904634475708 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0031, 0.0368, 0.0511, 0.0342, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0031, 0.0362, 0.0526, 0.0323, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6708986759185791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0333, 0.0029, 0.0313, 0.0510, 0.0331, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0360, 0.0511, 0.0326, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.635505199432373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0036, 0.0345, 0.0518, 0.0303, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0031, 0.0371, 0.0503, 0.0318, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.7011330127716064 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0308, 0.0022, 0.0320, 0.0497, 0.0283, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0028, 0.0354, 0.0520, 0.0316, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.712132453918457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0023, 0.0311, 0.0556, 0.0287, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0031, 0.0353, 0.0512, 0.0321, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.7624828815460205 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0031, 0.0372, 0.0472, 0.0274, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0033, 0.0356, 0.0507, 0.0318, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6530005931854248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0339, 0.0022, 0.0363, 0.0500, 0.0331, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0034, 0.0358, 0.0504, 0.0308, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.7544536590576172 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0030, 0.0343, 0.0542, 0.0341, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0031, 0.0364, 0.0511, 0.0310, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.689199686050415 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0308, 0.0028, 0.0374, 0.0504, 0.0316, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0033, 0.0365, 0.0513, 0.0319, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6369893550872803 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0029, 0.0328, 0.0513, 0.0327, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0031, 0.0364, 0.0515, 0.0327, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6707031726837158 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0030, 0.0337, 0.0538, 0.0343, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0030, 0.0357, 0.0496, 0.0314, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6338851451873779 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0294, 0.0025, 0.0369, 0.0535, 0.0334, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0325, 0.0031, 0.0358, 0.0521, 0.0310, 0.0031])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 656 in 0.6254162788391113 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0333, 0.0021, 0.0356, 0.0558, 0.0358, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0032, 0.0343, 0.0515, 0.0323, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6264324188232422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0038, 0.0337, 0.0537, 0.0390, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0030, 0.0361, 0.0514, 0.0322, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6322793960571289 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0316, 0.0043, 0.0349, 0.0443, 0.0281, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0030, 0.0360, 0.0525, 0.0312, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.655850887298584 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0304, 0.0030, 0.0347, 0.0508, 0.0330, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0032, 0.0342, 0.0508, 0.0318, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.65138840675354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0316, 0.0027, 0.0353, 0.0517, 0.0304, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0316, 0.0032, 0.0362, 0.0509, 0.0320, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6228306293487549 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0036, 0.0334, 0.0480, 0.0277, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0312, 0.0032, 0.0362, 0.0505, 0.0323, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6909527778625488 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0311, 0.0036, 0.0358, 0.0511, 0.0273, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0033, 0.0355, 0.0511, 0.0314, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6781396865844727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0282, 0.0029, 0.0323, 0.0532, 0.0319, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0029, 0.0368, 0.0537, 0.0311, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6837306022644043 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0027, 0.0371, 0.0523, 0.0284, 0.0040]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0033, 0.0363, 0.0504, 0.0312, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6713364124298096 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0027, 0.0361, 0.0533, 0.0348, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0035, 0.0369, 0.0504, 0.0319, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6836686134338379 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0334, 0.0029, 0.0371, 0.0502, 0.0262, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0355, 0.0508, 0.0310, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.616940975189209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0025, 0.0336, 0.0506, 0.0310, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0031, 0.0348, 0.0500, 0.0321, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6916933059692383 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0028, 0.0359, 0.0550, 0.0325, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0034, 0.0352, 0.0500, 0.0332, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6850757598876953 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0337, 0.0034, 0.0346, 0.0518, 0.0346, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0030, 0.0358, 0.0493, 0.0330, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6272115707397461 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0028, 0.0352, 0.0497, 0.0326, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0029, 0.0342, 0.0524, 0.0312, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6184983253479004 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0307, 0.0028, 0.0353, 0.0522, 0.0323, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0033, 0.0351, 0.0495, 0.0303, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6147434711456299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0332, 0.0023, 0.0341, 0.0526, 0.0315, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0030, 0.0353, 0.0507, 0.0339, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6169555187225342 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0328, 0.0029, 0.0372, 0.0463, 0.0339, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0032, 0.0351, 0.0526, 0.0321, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6196675300598145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0308, 0.0025, 0.0335, 0.0531, 0.0349, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0031, 0.0341, 0.0510, 0.0304, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6127779483795166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0323, 0.0036, 0.0362, 0.0532, 0.0367, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0030, 0.0350, 0.0511, 0.0304, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6709325313568115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0037, 0.0323, 0.0517, 0.0329, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0034, 0.0350, 0.0514, 0.0326, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6758255958557129 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0314, 0.0024, 0.0360, 0.0496, 0.0312, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0032, 0.0346, 0.0505, 0.0317, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6163613796234131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0029, 0.0387, 0.0496, 0.0256, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0030, 0.0350, 0.0507, 0.0327, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6236419677734375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0031, 0.0389, 0.0489, 0.0304, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0030, 0.0348, 0.0493, 0.0310, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.7026243209838867 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0273, 0.0032, 0.0355, 0.0507, 0.0302, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0350, 0.0495, 0.0318, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6121935844421387 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0042, 0.0354, 0.0515, 0.0339, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0030, 0.0358, 0.0508, 0.0317, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6306898593902588 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0288, 0.0034, 0.0315, 0.0518, 0.0334, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0030, 0.0337, 0.0509, 0.0325, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7201516628265381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0038, 0.0340, 0.0516, 0.0291, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0030, 0.0355, 0.0494, 0.0312, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6686594486236572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0312, 0.0030, 0.0392, 0.0454, 0.0306, 0.0042]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0350, 0.0488, 0.0323, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.606560468673706 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0025, 0.0374, 0.0484, 0.0318, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0030, 0.0348, 0.0498, 0.0319, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.627244234085083 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0314, 0.0028, 0.0365, 0.0501, 0.0303, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0030, 0.0354, 0.0495, 0.0299, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6375319957733154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0041, 0.0311, 0.0529, 0.0305, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0027, 0.0349, 0.0508, 0.0312, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.639538049697876 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0042, 0.0316, 0.0482, 0.0335, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0031, 0.0348, 0.0507, 0.0313, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5991578102111816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0031, 0.0369, 0.0501, 0.0326, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0030, 0.0329, 0.0496, 0.0309, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5986385345458984 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0034, 0.0325, 0.0545, 0.0321, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0029, 0.0342, 0.0506, 0.0312, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6925272941589355 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0329, 0.0033, 0.0366, 0.0500, 0.0368, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0307, 0.0030, 0.0353, 0.0497, 0.0303, 0.0030])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 800 in 0.6992990970611572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0023, 0.0365, 0.0499, 0.0291, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0027, 0.0360, 0.0486, 0.0314, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6428356170654297 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0029, 0.0332, 0.0472, 0.0324, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0031, 0.0349, 0.0502, 0.0310, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6417388916015625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0024, 0.0343, 0.0451, 0.0314, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0031, 0.0354, 0.0493, 0.0318, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.654355525970459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0301, 0.0028, 0.0356, 0.0447, 0.0339, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0030, 0.0343, 0.0516, 0.0322, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6320688724517822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0027, 0.0293, 0.0460, 0.0339, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0030, 0.0349, 0.0508, 0.0323, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7220637798309326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0311, 0.0029, 0.0359, 0.0522, 0.0276, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0346, 0.0501, 0.0306, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6915643215179443 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0292, 0.0024, 0.0314, 0.0495, 0.0294, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0309, 0.0028, 0.0361, 0.0508, 0.0288, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6441717147827148 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0023, 0.0377, 0.0481, 0.0284, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0031, 0.0378, 0.0496, 0.0319, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7384271621704102 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0038, 0.0395, 0.0475, 0.0307, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0031, 0.0349, 0.0509, 0.0329, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7673389911651611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0031, 0.0369, 0.0509, 0.0295, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0028, 0.0360, 0.0496, 0.0318, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7355659008026123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0282, 0.0030, 0.0327, 0.0488, 0.0364, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0030, 0.0352, 0.0519, 0.0305, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.7362868785858154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0024, 0.0317, 0.0555, 0.0308, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0031, 0.0341, 0.0495, 0.0313, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6512613296508789 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0026, 0.0333, 0.0462, 0.0318, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0029, 0.0346, 0.0494, 0.0316, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.730438232421875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0306, 0.0034, 0.0374, 0.0494, 0.0309, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0032, 0.0349, 0.0497, 0.0320, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6253280639648438 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0030, 0.0294, 0.0500, 0.0292, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0029, 0.0341, 0.0509, 0.0317, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6239495277404785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0308, 0.0030, 0.0385, 0.0466, 0.0338, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0353, 0.0494, 0.0306, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.618769645690918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0294, 0.0025, 0.0329, 0.0491, 0.0296, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0029, 0.0355, 0.0485, 0.0311, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6186904907226562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0029, 0.0374, 0.0520, 0.0302, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0029, 0.0364, 0.0507, 0.0307, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6337206363677979 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0036, 0.0304, 0.0441, 0.0287, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0031, 0.0344, 0.0483, 0.0307, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6103549003601074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0013, 0.0229, 0.0023, 0.0232, 0.0377, 0.0208, 0.0020]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0352, 0.0501, 0.0304, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7495806217193604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0340, 0.0038, 0.0322, 0.0462, 0.0326, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0030, 0.0356, 0.0499, 0.0320, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6356604099273682 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0035, 0.0349, 0.0502, 0.0362, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0030, 0.0364, 0.0508, 0.0323, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6289520263671875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0026, 0.0383, 0.0534, 0.0322, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0032, 0.0355, 0.0491, 0.0318, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7047359943389893 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0025, 0.0366, 0.0463, 0.0274, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0360, 0.0500, 0.0311, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.7686879634857178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0326, 0.0026, 0.0337, 0.0487, 0.0289, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0033, 0.0349, 0.0493, 0.0313, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7695159912109375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0028, 0.0389, 0.0495, 0.0342, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0031, 0.0349, 0.0496, 0.0312, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.7446255683898926 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0040, 0.0355, 0.0505, 0.0302, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0032, 0.0343, 0.0488, 0.0309, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.7266378402709961 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0034, 0.0352, 0.0523, 0.0317, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0029, 0.0344, 0.0494, 0.0307, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.7040755748748779 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0023, 0.0283, 0.0501, 0.0340, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0033, 0.0338, 0.0496, 0.0313, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7185513973236084 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0029, 0.0349, 0.0482, 0.0307, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0030, 0.0353, 0.0490, 0.0307, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.7973544597625732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0312, 0.0028, 0.0326, 0.0464, 0.0316, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0031, 0.0342, 0.0490, 0.0316, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7837557792663574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0025, 0.0347, 0.0503, 0.0322, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0030, 0.0362, 0.0503, 0.0305, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7869937419891357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0031, 0.0317, 0.0539, 0.0303, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0031, 0.0345, 0.0482, 0.0309, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.7537498474121094 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0029, 0.0346, 0.0438, 0.0308, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0300, 0.0029, 0.0351, 0.0487, 0.0302, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.8233237266540527 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0027, 0.0331, 0.0503, 0.0320, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0029, 0.0352, 0.0493, 0.0302, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.744096040725708 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0291, 0.0026, 0.0359, 0.0463, 0.0312, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0030, 0.0356, 0.0482, 0.0323, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 64 in 0.7866828441619873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0043, 0.0367, 0.0488, 0.0302, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0028, 0.0348, 0.0499, 0.0313, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.713860034942627 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0029, 0.0314, 0.0507, 0.0328, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0030, 0.0355, 0.0499, 0.0310, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.707228422164917 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0035, 0.0358, 0.0500, 0.0285, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0029, 0.0358, 0.0501, 0.0311, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6754474639892578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0028, 0.0353, 0.0528, 0.0368, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0030, 0.0351, 0.0494, 0.0311, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6682095527648926 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0329, 0.0034, 0.0350, 0.0491, 0.0309, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0029, 0.0366, 0.0476, 0.0305, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6839451789855957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0308, 0.0030, 0.0356, 0.0503, 0.0287, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0028, 0.0349, 0.0497, 0.0311, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6727044582366943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0020, 0.0329, 0.0481, 0.0287, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0032, 0.0350, 0.0488, 0.0309, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7012994289398193 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0038, 0.0328, 0.0459, 0.0311, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0028, 0.0350, 0.0473, 0.0322, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6784865856170654 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0025, 0.0356, 0.0478, 0.0326, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0027, 0.0345, 0.0497, 0.0308, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6811714172363281 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0022, 0.0314, 0.0484, 0.0343, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0031, 0.0339, 0.0499, 0.0308, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6982617378234863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0030, 0.0356, 0.0511, 0.0323, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0350, 0.0488, 0.0312, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6808326244354248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0307, 0.0030, 0.0379, 0.0464, 0.0343, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0031, 0.0353, 0.0506, 0.0307, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6788215637207031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0041, 0.0326, 0.0535, 0.0343, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0347, 0.0484, 0.0301, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6735072135925293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0034, 0.0355, 0.0485, 0.0287, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0029, 0.0337, 0.0490, 0.0304, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6720359325408936 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0031, 0.0359, 0.0551, 0.0280, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0032, 0.0349, 0.0475, 0.0308, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.666433572769165 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0040, 0.0344, 0.0533, 0.0324, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0030, 0.0348, 0.0502, 0.0309, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.7202208042144775 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0284, 0.0042, 0.0337, 0.0459, 0.0307, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0028, 0.0357, 0.0503, 0.0305, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6955468654632568 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0284, 0.0028, 0.0347, 0.0513, 0.0329, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0027, 0.0352, 0.0489, 0.0309, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6689603328704834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0030, 0.0284, 0.0524, 0.0289, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0029, 0.0350, 0.0512, 0.0321, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7206649780273438 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0034, 0.0354, 0.0485, 0.0320, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0028, 0.0345, 0.0475, 0.0312, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.7623293399810791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0031, 0.0371, 0.0472, 0.0303, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0029, 0.0336, 0.0509, 0.0305, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7762572765350342 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0331, 0.0025, 0.0315, 0.0521, 0.0336, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0030, 0.0348, 0.0510, 0.0294, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7263174057006836 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0305, 0.0033, 0.0339, 0.0505, 0.0365, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0031, 0.0358, 0.0494, 0.0319, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7026710510253906 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0025, 0.0341, 0.0493, 0.0325, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0028, 0.0342, 0.0499, 0.0307, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7215559482574463 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0312, 0.0026, 0.0331, 0.0510, 0.0317, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0300, 0.0028, 0.0345, 0.0510, 0.0308, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6353559494018555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0328, 0.0026, 0.0388, 0.0514, 0.0339, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0030, 0.0352, 0.0482, 0.0305, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.646735668182373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0027, 0.0354, 0.0507, 0.0326, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0029, 0.0344, 0.0487, 0.0309, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6351051330566406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0310, 0.0035, 0.0410, 0.0506, 0.0351, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0031, 0.0338, 0.0487, 0.0302, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7008841037750244 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0304, 0.0032, 0.0347, 0.0490, 0.0317, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0027, 0.0338, 0.0509, 0.0305, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.727668285369873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0023, 0.0313, 0.0521, 0.0332, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0302, 0.0029, 0.0355, 0.0506, 0.0311, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7113730907440186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0021, 0.0362, 0.0464, 0.0287, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0032, 0.0347, 0.0508, 0.0324, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.626812219619751 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0324, 0.0026, 0.0367, 0.0472, 0.0316, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0310, 0.0027, 0.0327, 0.0475, 0.0300, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6576569080352783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0033, 0.0353, 0.0487, 0.0335, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0300, 0.0029, 0.0342, 0.0518, 0.0313, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6898205280303955 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0028, 0.0348, 0.0491, 0.0298, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0300, 0.0031, 0.0331, 0.0493, 0.0311, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6709139347076416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0045, 0.0359, 0.0462, 0.0300, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0305, 0.0029, 0.0356, 0.0510, 0.0317, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6694245338439941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0034, 0.0338, 0.0468, 0.0306, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0030, 0.0351, 0.0500, 0.0306, 0.0030])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 208 in 0.7395975589752197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0306, 0.0021, 0.0348, 0.0531, 0.0297, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0028, 0.0347, 0.0510, 0.0301, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.7540531158447266 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0327, 0.0023, 0.0361, 0.0503, 0.0268, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0033, 0.0345, 0.0510, 0.0317, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.657602071762085 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0315, 0.0030, 0.0270, 0.0450, 0.0325, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0030, 0.0363, 0.0514, 0.0324, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6905288696289062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0336, 0.0025, 0.0311, 0.0515, 0.0323, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0029, 0.0335, 0.0484, 0.0307, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6963169574737549 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0038, 0.0293, 0.0467, 0.0327, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0026, 0.0355, 0.0505, 0.0305, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6178545951843262 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0294, 0.0030, 0.0333, 0.0479, 0.0281, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0292, 0.0032, 0.0346, 0.0496, 0.0316, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6131162643432617 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0031, 0.0353, 0.0443, 0.0295, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0031, 0.0354, 0.0484, 0.0322, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6163833141326904 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0301, 0.0030, 0.0316, 0.0490, 0.0340, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0343, 0.0504, 0.0308, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6312236785888672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0023, 0.0325, 0.0466, 0.0319, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0030, 0.0345, 0.0493, 0.0298, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6178267002105713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0319, 0.0021, 0.0312, 0.0558, 0.0322, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0031, 0.0329, 0.0496, 0.0314, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.5996739864349365 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0315, 0.0035, 0.0325, 0.0474, 0.0307, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0294, 0.0030, 0.0333, 0.0496, 0.0317, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6258909702301025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0042, 0.0330, 0.0475, 0.0348, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0306, 0.0028, 0.0341, 0.0484, 0.0309, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.608548641204834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0025, 0.0285, 0.0498, 0.0308, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0298, 0.0030, 0.0343, 0.0487, 0.0314, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6048550605773926 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0295, 0.0028, 0.0360, 0.0478, 0.0308, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0030, 0.0346, 0.0492, 0.0315, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6116995811462402 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0025, 0.0343, 0.0508, 0.0396, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0030, 0.0337, 0.0488, 0.0321, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6127076148986816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0020, 0.0281, 0.0026, 0.0321, 0.0467, 0.0310, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0028, 0.0355, 0.0486, 0.0299, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.603614091873169 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0325, 0.0030, 0.0379, 0.0531, 0.0294, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0028, 0.0353, 0.0476, 0.0302, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6479334831237793 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0019, 0.0327, 0.0482, 0.0291, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0030, 0.0343, 0.0484, 0.0327, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6369693279266357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0021, 0.0336, 0.0479, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0030, 0.0342, 0.0489, 0.0312, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6306900978088379 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0030, 0.0355, 0.0496, 0.0297, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0028, 0.0351, 0.0509, 0.0301, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6285057067871094 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0027, 0.0383, 0.0473, 0.0294, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0028, 0.0329, 0.0488, 0.0304, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6231169700622559 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0028, 0.0308, 0.0486, 0.0299, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0029, 0.0364, 0.0500, 0.0316, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6073915958404541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0295, 0.0032, 0.0351, 0.0494, 0.0365, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0028, 0.0343, 0.0471, 0.0300, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5950994491577148 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0035, 0.0309, 0.0459, 0.0300, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0029, 0.0352, 0.0509, 0.0297, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6107890605926514 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0024, 0.0306, 0.0518, 0.0343, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0029, 0.0330, 0.0479, 0.0319, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.5994894504547119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0275, 0.0039, 0.0343, 0.0422, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0031, 0.0349, 0.0479, 0.0306, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6498403549194336 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0031, 0.0377, 0.0501, 0.0273, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0028, 0.0347, 0.0465, 0.0311, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6936218738555908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0024, 0.0307, 0.0460, 0.0344, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0029, 0.0341, 0.0499, 0.0311, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6396644115447998 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0310, 0.0024, 0.0331, 0.0510, 0.0368, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0030, 0.0335, 0.0472, 0.0301, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6407105922698975 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0342, 0.0026, 0.0317, 0.0459, 0.0285, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0030, 0.0356, 0.0481, 0.0303, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6922397613525391 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0028, 0.0317, 0.0521, 0.0303, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0028, 0.0342, 0.0481, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7282073497772217 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0322, 0.0025, 0.0308, 0.0468, 0.0322, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0029, 0.0333, 0.0486, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7290170192718506 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0023, 0.0338, 0.0492, 0.0291, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0030, 0.0338, 0.0489, 0.0303, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6812970638275146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0030, 0.0361, 0.0489, 0.0272, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0032, 0.0332, 0.0479, 0.0310, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6541547775268555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0033, 0.0343, 0.0494, 0.0241, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0030, 0.0340, 0.0485, 0.0300, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6356649398803711 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0326, 0.0032, 0.0343, 0.0470, 0.0274, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0029, 0.0336, 0.0497, 0.0315, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 352 in 0.6957464218139648 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0027, 0.0353, 0.0489, 0.0307, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0284, 0.0030, 0.0333, 0.0472, 0.0303, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6794412136077881 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0339, 0.0018, 0.0356, 0.0460, 0.0307, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0029, 0.0350, 0.0482, 0.0300, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6778368949890137 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0021, 0.0312, 0.0485, 0.0313, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0029, 0.0341, 0.0494, 0.0295, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.685401439666748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0030, 0.0335, 0.0496, 0.0310, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0027, 0.0340, 0.0486, 0.0301, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6406922340393066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0326, 0.0038, 0.0292, 0.0454, 0.0276, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0029, 0.0339, 0.0474, 0.0304, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6303932666778564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0322, 0.0031, 0.0336, 0.0488, 0.0321, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0030, 0.0336, 0.0490, 0.0315, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.659320592880249 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0316, 0.0023, 0.0292, 0.0447, 0.0262, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0028, 0.0328, 0.0481, 0.0296, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6076300144195557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0024, 0.0355, 0.0543, 0.0320, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0028, 0.0336, 0.0463, 0.0294, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6092925071716309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0266, 0.0040, 0.0316, 0.0467, 0.0313, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0030, 0.0345, 0.0466, 0.0307, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6619184017181396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0039, 0.0318, 0.0474, 0.0311, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0027, 0.0345, 0.0469, 0.0294, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6623835563659668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0030, 0.0311, 0.0445, 0.0297, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0304, 0.0025, 0.0337, 0.0495, 0.0298, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6896171569824219 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0277, 0.0027, 0.0315, 0.0536, 0.0314, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0028, 0.0334, 0.0480, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6124231815338135 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0027, 0.0355, 0.0504, 0.0313, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0025, 0.0337, 0.0490, 0.0314, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6350464820861816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0030, 0.0348, 0.0525, 0.0333, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0028, 0.0335, 0.0485, 0.0295, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6344399452209473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0307, 0.0030, 0.0328, 0.0455, 0.0284, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0025, 0.0342, 0.0485, 0.0305, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6034657955169678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0025, 0.0343, 0.0480, 0.0289, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0025, 0.0338, 0.0480, 0.0304, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6087207794189453 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0031, 0.0337, 0.0466, 0.0317, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0027, 0.0344, 0.0496, 0.0324, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6099750995635986 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0329, 0.0028, 0.0289, 0.0515, 0.0327, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0028, 0.0332, 0.0467, 0.0295, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6080887317657471 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0282, 0.0028, 0.0368, 0.0456, 0.0298, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0027, 0.0343, 0.0505, 0.0307, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6083500385284424 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0028, 0.0279, 0.0497, 0.0288, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0026, 0.0345, 0.0480, 0.0303, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6063785552978516 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0039, 0.0350, 0.0457, 0.0284, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0029, 0.0347, 0.0499, 0.0312, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6038374900817871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0023, 0.0344, 0.0485, 0.0308, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0027, 0.0344, 0.0476, 0.0297, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6454694271087646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0329, 0.0025, 0.0318, 0.0489, 0.0317, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0319, 0.0027, 0.0334, 0.0529, 0.0307, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6810755729675293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0310, 0.0028, 0.0333, 0.0521, 0.0323, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0300, 0.0031, 0.0356, 0.0484, 0.0316, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6835627555847168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0334, 0.0029, 0.0327, 0.0521, 0.0341, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0030, 0.0364, 0.0502, 0.0316, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6834871768951416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0028, 0.0312, 0.0453, 0.0422, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0028, 0.0331, 0.0492, 0.0301, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6842067241668701 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0032, 0.0366, 0.0483, 0.0286, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0311, 0.0027, 0.0345, 0.0527, 0.0303, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6849720478057861 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0322, 0.0024, 0.0355, 0.0562, 0.0265, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0299, 0.0030, 0.0364, 0.0520, 0.0305, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6716692447662354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0342, 0.0025, 0.0385, 0.0470, 0.0316, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0028, 0.0375, 0.0539, 0.0327, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.7227139472961426 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0337, 0.0028, 0.0391, 0.0544, 0.0323, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0028, 0.0340, 0.0499, 0.0307, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6845352649688721 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0025, 0.0361, 0.0538, 0.0266, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0321, 0.0025, 0.0353, 0.0550, 0.0305, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6553962230682373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0316, 0.0027, 0.0346, 0.0603, 0.0312, 0.0043]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0031, 0.0353, 0.0500, 0.0308, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.7061853408813477 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0024, 0.0315, 0.0494, 0.0291, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0319, 0.0030, 0.0365, 0.0563, 0.0341, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.686692476272583 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0304, 0.0040, 0.0351, 0.0532, 0.0314, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0029, 0.0336, 0.0488, 0.0303, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6850748062133789 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0290, 0.0037, 0.0344, 0.0511, 0.0324, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0330, 0.0027, 0.0350, 0.0582, 0.0304, 0.0033])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.655099630355835 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0347, 0.0029, 0.0422, 0.0573, 0.0326, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0026, 0.0341, 0.0482, 0.0312, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 496 in 0.6446354389190674 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0323, 0.0031, 0.0308, 0.0465, 0.0293, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0318, 0.0031, 0.0377, 0.0555, 0.0320, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6489930152893066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0312, 0.0035, 0.0352, 0.0530, 0.0327, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0027, 0.0331, 0.0476, 0.0295, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6113450527191162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0030, 0.0317, 0.0417, 0.0364, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0308, 0.0026, 0.0341, 0.0553, 0.0299, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6944499015808105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0030, 0.0368, 0.0565, 0.0334, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0026, 0.0340, 0.0474, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6040706634521484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0266, 0.0030, 0.0327, 0.0476, 0.0281, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0031, 0.0355, 0.0521, 0.0316, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6429169178009033 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0024, 0.0313, 0.0528, 0.0316, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0028, 0.0348, 0.0496, 0.0316, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6454460620880127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0032, 0.0355, 0.0502, 0.0325, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0027, 0.0334, 0.0513, 0.0302, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6476132869720459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0320, 0.0027, 0.0295, 0.0457, 0.0291, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0294, 0.0028, 0.0333, 0.0498, 0.0300, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6858901977539062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0022, 0.0286, 0.0511, 0.0349, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0029, 0.0338, 0.0492, 0.0305, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.682091474533081 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0025, 0.0355, 0.0489, 0.0325, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0299, 0.0029, 0.0342, 0.0499, 0.0322, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6203551292419434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0021, 0.0365, 0.0471, 0.0381, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0029, 0.0333, 0.0491, 0.0304, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6413681507110596 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0304, 0.0029, 0.0316, 0.0477, 0.0320, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0027, 0.0342, 0.0511, 0.0289, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6497693061828613 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0315, 0.0033, 0.0341, 0.0495, 0.0290, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0343, 0.0485, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6027717590332031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0032, 0.0380, 0.0434, 0.0291, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0300, 0.0032, 0.0351, 0.0500, 0.0319, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5979373455047607 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0028, 0.0327, 0.0461, 0.0305, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0029, 0.0335, 0.0474, 0.0295, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6079652309417725 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0020, 0.0312, 0.0519, 0.0298, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0315, 0.0025, 0.0333, 0.0504, 0.0297, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6052494049072266 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0310, 0.0026, 0.0344, 0.0481, 0.0302, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0029, 0.0334, 0.0463, 0.0294, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.597527265548706 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0307, 0.0026, 0.0341, 0.0491, 0.0333, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0301, 0.0029, 0.0342, 0.0471, 0.0316, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.5925657749176025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0318, 0.0030, 0.0339, 0.0493, 0.0314, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0026, 0.0342, 0.0480, 0.0300, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.5979485511779785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0033, 0.0301, 0.0499, 0.0386, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0027, 0.0331, 0.0488, 0.0295, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5980808734893799 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0022, 0.0326, 0.0486, 0.0316, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0027, 0.0332, 0.0499, 0.0297, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.59783935546875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0281, 0.0026, 0.0273, 0.0492, 0.0288, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0292, 0.0028, 0.0320, 0.0468, 0.0297, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.5930294990539551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0028, 0.0345, 0.0516, 0.0324, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0026, 0.0349, 0.0472, 0.0310, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5983963012695312 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0022, 0.0347, 0.0477, 0.0349, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0294, 0.0028, 0.0330, 0.0471, 0.0296, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.5929863452911377 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0294, 0.0025, 0.0348, 0.0495, 0.0323, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0303, 0.0028, 0.0329, 0.0503, 0.0290, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5963499546051025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0027, 0.0298, 0.0460, 0.0291, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0028, 0.0340, 0.0471, 0.0302, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5919337272644043 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0269, 0.0028, 0.0325, 0.0469, 0.0292, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0029, 0.0320, 0.0491, 0.0315, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6072397232055664 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0321, 0.0024, 0.0294, 0.0436, 0.0309, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0028, 0.0346, 0.0461, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.5980629920959473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0022, 0.0390, 0.0482, 0.0287, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0028, 0.0321, 0.0460, 0.0304, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5923953056335449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0024, 0.0338, 0.0470, 0.0290, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0338, 0.0472, 0.0291, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5924403667449951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0026, 0.0333, 0.0470, 0.0298, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0027, 0.0338, 0.0470, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.590238094329834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0312, 0.0025, 0.0301, 0.0434, 0.0334, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0030, 0.0336, 0.0470, 0.0300, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.5917644500732422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0299, 0.0026, 0.0310, 0.0441, 0.0273, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0026, 0.0332, 0.0466, 0.0285, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5940952301025391 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0025, 0.0331, 0.0461, 0.0300, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0028, 0.0331, 0.0484, 0.0303, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6109592914581299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0251, 0.0033, 0.0305, 0.0457, 0.0331, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0028, 0.0337, 0.0460, 0.0298, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5952479839324951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0033, 0.0370, 0.0430, 0.0290, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0029, 0.0328, 0.0460, 0.0298, 0.0029])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 640 in 0.6001427173614502 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0030, 0.0358, 0.0462, 0.0348, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0333, 0.0470, 0.0306, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.595343828201294 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0031, 0.0327, 0.0446, 0.0320, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0338, 0.0467, 0.0295, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6017611026763916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0027, 0.0296, 0.0457, 0.0272, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0025, 0.0327, 0.0473, 0.0304, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5934476852416992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0022, 0.0305, 0.0469, 0.0335, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0334, 0.0468, 0.0308, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6588644981384277 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0030, 0.0303, 0.0484, 0.0315, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0027, 0.0317, 0.0471, 0.0289, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.64739990234375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0027, 0.0321, 0.0453, 0.0278, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0025, 0.0328, 0.0470, 0.0294, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6422371864318848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0028, 0.0343, 0.0446, 0.0310, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0027, 0.0348, 0.0473, 0.0294, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6481597423553467 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0266, 0.0022, 0.0307, 0.0476, 0.0315, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0025, 0.0331, 0.0464, 0.0298, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.7079477310180664 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0287, 0.0027, 0.0319, 0.0509, 0.0306, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0025, 0.0343, 0.0478, 0.0289, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6061131954193115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0028, 0.0367, 0.0476, 0.0281, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0028, 0.0330, 0.0479, 0.0289, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6105556488037109 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0026, 0.0317, 0.0443, 0.0285, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0029, 0.0339, 0.0469, 0.0295, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.7207412719726562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0023, 0.0306, 0.0473, 0.0314, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0028, 0.0327, 0.0484, 0.0300, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6431329250335693 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0026, 0.0313, 0.0468, 0.0321, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0029, 0.0333, 0.0454, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6992430686950684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0023, 0.0357, 0.0449, 0.0289, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0028, 0.0329, 0.0461, 0.0282, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6337435245513916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0022, 0.0335, 0.0497, 0.0318, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0028, 0.0332, 0.0492, 0.0312, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.712803840637207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0030, 0.0352, 0.0504, 0.0268, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0028, 0.0322, 0.0480, 0.0309, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.7521398067474365 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0026, 0.0337, 0.0512, 0.0291, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0028, 0.0326, 0.0465, 0.0296, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.8168699741363525 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0024, 0.0356, 0.0442, 0.0321, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0027, 0.0334, 0.0469, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6584889888763428 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0297, 0.0025, 0.0341, 0.0477, 0.0295, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0029, 0.0320, 0.0470, 0.0296, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6415715217590332 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0022, 0.0315, 0.0478, 0.0298, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0028, 0.0340, 0.0470, 0.0304, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6836190223693848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0307, 0.0033, 0.0342, 0.0478, 0.0308, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0029, 0.0326, 0.0483, 0.0300, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.694195032119751 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0023, 0.0314, 0.0487, 0.0314, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0027, 0.0334, 0.0463, 0.0287, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.7233152389526367 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0030, 0.0357, 0.0462, 0.0269, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0029, 0.0324, 0.0448, 0.0287, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.8606109619140625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0027, 0.0319, 0.0480, 0.0282, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0343, 0.0469, 0.0301, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.8083000183105469 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0309, 0.0024, 0.0329, 0.0439, 0.0314, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0028, 0.0322, 0.0460, 0.0283, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.7505500316619873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0028, 0.0342, 0.0489, 0.0309, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0028, 0.0328, 0.0467, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.7392668724060059 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0020, 0.0311, 0.0486, 0.0291, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0026, 0.0342, 0.0475, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7609415054321289 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0031, 0.0359, 0.0464, 0.0279, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0027, 0.0325, 0.0448, 0.0295, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6889173984527588 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0026, 0.0363, 0.0460, 0.0254, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0026, 0.0326, 0.0476, 0.0298, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.7168121337890625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0025, 0.0339, 0.0468, 0.0269, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0329, 0.0468, 0.0292, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7764577865600586 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0026, 0.0323, 0.0424, 0.0278, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0283, 0.0026, 0.0343, 0.0469, 0.0301, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.712007999420166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0030, 0.0340, 0.0472, 0.0290, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0028, 0.0332, 0.0450, 0.0288, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6581244468688965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0025, 0.0372, 0.0463, 0.0315, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0027, 0.0338, 0.0471, 0.0290, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.734605073928833 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0024, 0.0286, 0.0509, 0.0318, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0028, 0.0338, 0.0449, 0.0293, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.8787741661071777 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0023, 0.0333, 0.0460, 0.0341, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0027, 0.0310, 0.0454, 0.0300, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.8446042537689209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0025, 0.0329, 0.0476, 0.0311, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0027, 0.0327, 0.0460, 0.0293, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 784 in 0.6873385906219482 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0026, 0.0307, 0.0510, 0.0303, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0027, 0.0335, 0.0456, 0.0293, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.7326157093048096 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0028, 0.0353, 0.0431, 0.0320, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0029, 0.0326, 0.0471, 0.0291, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.8472881317138672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0024, 0.0335, 0.0486, 0.0285, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0027, 0.0326, 0.0454, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.7740249633789062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0308, 0.0027, 0.0278, 0.0486, 0.0338, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0284, 0.0027, 0.0327, 0.0464, 0.0292, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.7075541019439697 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0027, 0.0385, 0.0459, 0.0252, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0025, 0.0332, 0.0462, 0.0292, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6664767265319824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0312, 0.0022, 0.0319, 0.0476, 0.0319, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0288, 0.0024, 0.0333, 0.0458, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6548600196838379 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0028, 0.0288, 0.0444, 0.0344, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0292, 0.0027, 0.0331, 0.0473, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6462788581848145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0307, 0.0025, 0.0357, 0.0431, 0.0308, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0028, 0.0324, 0.0462, 0.0286, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6334755420684814 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0025, 0.0286, 0.0479, 0.0295, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0026, 0.0327, 0.0473, 0.0289, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6537783145904541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0295, 0.0028, 0.0342, 0.0462, 0.0299, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0028, 0.0325, 0.0466, 0.0299, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6135790348052979 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0028, 0.0345, 0.0455, 0.0282, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0027, 0.0319, 0.0457, 0.0301, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6098809242248535 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0295, 0.0031, 0.0332, 0.0457, 0.0303, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0029, 0.0332, 0.0461, 0.0292, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.638566255569458 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0033, 0.0349, 0.0430, 0.0306, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0026, 0.0329, 0.0458, 0.0291, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.63462233543396 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0326, 0.0024, 0.0317, 0.0487, 0.0273, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0029, 0.0322, 0.0458, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6425845623016357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0020, 0.0303, 0.0449, 0.0344, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0026, 0.0331, 0.0468, 0.0289, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6900084018707275 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0034, 0.0318, 0.0435, 0.0247, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0332, 0.0466, 0.0284, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6355082988739014 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0022, 0.0392, 0.0478, 0.0302, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0028, 0.0332, 0.0469, 0.0283, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6583359241485596 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0273, 0.0030, 0.0332, 0.0429, 0.0299, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0029, 0.0316, 0.0456, 0.0303, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6197314262390137 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0272, 0.0030, 0.0332, 0.0459, 0.0285, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0025, 0.0339, 0.0468, 0.0304, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6091296672821045 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0029, 0.0328, 0.0489, 0.0292, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0027, 0.0339, 0.0455, 0.0283, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6034369468688965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0273, 0.0022, 0.0342, 0.0440, 0.0256, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0027, 0.0338, 0.0462, 0.0284, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6471841335296631 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0021, 0.0310, 0.0451, 0.0291, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0029, 0.0326, 0.0451, 0.0291, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6073968410491943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0031, 0.0307, 0.0479, 0.0287, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0026, 0.0338, 0.0459, 0.0290, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5785958766937256 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0014, 0.0231, 0.0019, 0.0309, 0.0392, 0.0200, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0028, 0.0314, 0.0452, 0.0282, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6721186637878418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0027, 0.0295, 0.0450, 0.0301, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0320, 0.0469, 0.0292, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6191675662994385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0024, 0.0321, 0.0452, 0.0328, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0026, 0.0342, 0.0450, 0.0294, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6142261028289795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0024, 0.0336, 0.0440, 0.0320, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0028, 0.0314, 0.0449, 0.0296, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.5976099967956543 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0027, 0.0294, 0.0402, 0.0308, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0028, 0.0315, 0.0459, 0.0292, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6487739086151123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0031, 0.0384, 0.0446, 0.0320, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0283, 0.0028, 0.0327, 0.0442, 0.0293, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6685268878936768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0310, 0.0028, 0.0308, 0.0475, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0029, 0.0332, 0.0456, 0.0305, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6335432529449463 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0026, 0.0334, 0.0459, 0.0322, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0028, 0.0326, 0.0451, 0.0298, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6502597332000732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0030, 0.0303, 0.0492, 0.0302, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0318, 0.0451, 0.0297, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6050701141357422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0026, 0.0345, 0.0463, 0.0300, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0027, 0.0327, 0.0443, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6629385948181152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0023, 0.0308, 0.0434, 0.0344, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0316, 0.0455, 0.0291, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.726536750793457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0021, 0.0356, 0.0421, 0.0308, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0026, 0.0338, 0.0452, 0.0295, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6902241706848145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0030, 0.0284, 0.0425, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0028, 0.0318, 0.0450, 0.0288, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 48 in 0.6432638168334961 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0027, 0.0327, 0.0487, 0.0317, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0025, 0.0324, 0.0502, 0.0294, 0.0031])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.677361011505127 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0020, 0.0305, 0.0513, 0.0324, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0026, 0.0325, 0.0463, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.7056562900543213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0024, 0.0269, 0.0437, 0.0251, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0296, 0.0028, 0.0341, 0.0466, 0.0298, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.687086820602417 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0026, 0.0308, 0.0452, 0.0284, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0025, 0.0344, 0.0456, 0.0285, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.605818510055542 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0327, 0.0029, 0.0281, 0.0470, 0.0311, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0025, 0.0324, 0.0475, 0.0290, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7581233978271484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0032, 0.0353, 0.0447, 0.0325, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0026, 0.0334, 0.0466, 0.0283, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.8531863689422607 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0317, 0.0020, 0.0316, 0.0438, 0.0283, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0287, 0.0028, 0.0332, 0.0474, 0.0301, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7324991226196289 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0022, 0.0333, 0.0501, 0.0320, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0290, 0.0027, 0.0305, 0.0454, 0.0287, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6970102787017822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0025, 0.0318, 0.0440, 0.0313, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0299, 0.0025, 0.0332, 0.0458, 0.0285, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6162111759185791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0034, 0.0337, 0.0503, 0.0270, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0337, 0.0475, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6356897354125977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0029, 0.0319, 0.0434, 0.0291, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0027, 0.0323, 0.0476, 0.0289, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7013387680053711 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0301, 0.0022, 0.0295, 0.0419, 0.0274, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0293, 0.0025, 0.0326, 0.0463, 0.0289, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7017924785614014 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0027, 0.0300, 0.0485, 0.0291, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0347, 0.0455, 0.0290, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6541957855224609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0027, 0.0356, 0.0448, 0.0305, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0341, 0.0471, 0.0294, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.7118206024169922 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0026, 0.0331, 0.0461, 0.0285, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0030, 0.0329, 0.0457, 0.0286, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.7361545562744141 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0035, 0.0334, 0.0474, 0.0301, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0328, 0.0455, 0.0293, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6897251605987549 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0023, 0.0349, 0.0450, 0.0314, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0027, 0.0338, 0.0479, 0.0281, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6851470470428467 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0025, 0.0313, 0.0490, 0.0272, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0027, 0.0311, 0.0463, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6863245964050293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0023, 0.0346, 0.0469, 0.0312, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0340, 0.0479, 0.0302, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6627740859985352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0022, 0.0308, 0.0459, 0.0273, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0028, 0.0313, 0.0469, 0.0292, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6888942718505859 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0025, 0.0318, 0.0454, 0.0298, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0295, 0.0026, 0.0324, 0.0475, 0.0299, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6861648559570312 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0026, 0.0358, 0.0433, 0.0304, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0025, 0.0322, 0.0461, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6661491394042969 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0025, 0.0325, 0.0454, 0.0266, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0027, 0.0333, 0.0470, 0.0302, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6878085136413574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0026, 0.0342, 0.0486, 0.0293, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0027, 0.0318, 0.0457, 0.0298, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6714560985565186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0285, 0.0023, 0.0293, 0.0429, 0.0309, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0290, 0.0026, 0.0317, 0.0465, 0.0292, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.734325647354126 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0029, 0.0318, 0.0459, 0.0318, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0028, 0.0326, 0.0450, 0.0280, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6347546577453613 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0319, 0.0024, 0.0342, 0.0477, 0.0290, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0026, 0.0312, 0.0451, 0.0304, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6331510543823242 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0292, 0.0033, 0.0291, 0.0476, 0.0323, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0027, 0.0315, 0.0451, 0.0286, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6222975254058838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0287, 0.0022, 0.0291, 0.0448, 0.0284, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0026, 0.0315, 0.0445, 0.0283, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6649413108825684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0266, 0.0025, 0.0323, 0.0490, 0.0287, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0026, 0.0327, 0.0452, 0.0284, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.639122486114502 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0030, 0.0302, 0.0423, 0.0262, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0027, 0.0329, 0.0462, 0.0284, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6481051445007324 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0026, 0.0308, 0.0459, 0.0285, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0024, 0.0318, 0.0459, 0.0285, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7756824493408203 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0027, 0.0312, 0.0467, 0.0299, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0318, 0.0474, 0.0288, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7661728858947754 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0031, 0.0320, 0.0485, 0.0302, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0284, 0.0025, 0.0324, 0.0464, 0.0286, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.696263313293457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0024, 0.0331, 0.0498, 0.0292, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0027, 0.0324, 0.0462, 0.0285, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.8447535037994385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0278, 0.0022, 0.0321, 0.0520, 0.0308, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0025, 0.0315, 0.0450, 0.0293, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 192 in 0.6942946910858154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0302, 0.0025, 0.0304, 0.0422, 0.0278, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0029, 0.0328, 0.0442, 0.0285, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7425572872161865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0025, 0.0306, 0.0432, 0.0309, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0027, 0.0319, 0.0447, 0.0288, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.791184663772583 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0024, 0.0362, 0.0456, 0.0308, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0027, 0.0323, 0.0459, 0.0296, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7792577743530273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0027, 0.0324, 0.0458, 0.0290, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0026, 0.0323, 0.0458, 0.0295, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 208 in 1.0283324718475342 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0026, 0.0343, 0.0440, 0.0300, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0330, 0.0455, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.8381516933441162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0026, 0.0318, 0.0428, 0.0294, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0024, 0.0326, 0.0463, 0.0288, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.8872356414794922 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0025, 0.0325, 0.0460, 0.0303, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0319, 0.0451, 0.0286, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.684699535369873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0300, 0.0025, 0.0319, 0.0437, 0.0301, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0027, 0.0325, 0.0458, 0.0287, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.754976749420166 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0021, 0.0338, 0.0438, 0.0264, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0329, 0.0450, 0.0290, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.8283517360687256 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0025, 0.0313, 0.0440, 0.0261, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0319, 0.0455, 0.0292, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.9720003604888916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0026, 0.0296, 0.0435, 0.0292, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0026, 0.0333, 0.0454, 0.0283, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 236 in 1.0407207012176514 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0025, 0.0327, 0.0400, 0.0295, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0026, 0.0333, 0.0453, 0.0286, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.7841718196868896 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0024, 0.0320, 0.0473, 0.0291, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0028, 0.0317, 0.0443, 0.0287, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6621942520141602 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0024, 0.0348, 0.0434, 0.0303, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0319, 0.0448, 0.0286, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6557350158691406 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0023, 0.0294, 0.0437, 0.0288, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0026, 0.0333, 0.0451, 0.0293, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6718130111694336 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0294, 0.0026, 0.0347, 0.0406, 0.0250, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0026, 0.0326, 0.0461, 0.0304, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6634268760681152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0027, 0.0331, 0.0460, 0.0303, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0027, 0.0321, 0.0436, 0.0289, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7056183815002441 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0027, 0.0346, 0.0515, 0.0313, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0290, 0.0027, 0.0320, 0.0452, 0.0302, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6379544734954834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0022, 0.0343, 0.0476, 0.0280, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0027, 0.0343, 0.0463, 0.0286, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6957988739013672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0024, 0.0338, 0.0555, 0.0300, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0027, 0.0336, 0.0453, 0.0292, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6768124103546143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0283, 0.0025, 0.0344, 0.0435, 0.0293, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0028, 0.0327, 0.0455, 0.0296, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6927690505981445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0027, 0.0338, 0.0455, 0.0269, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0027, 0.0310, 0.0450, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.7002279758453369 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0281, 0.0032, 0.0323, 0.0443, 0.0302, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0025, 0.0323, 0.0489, 0.0289, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6488263607025146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0022, 0.0364, 0.0514, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0026, 0.0311, 0.0460, 0.0291, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6580228805541992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0026, 0.0316, 0.0459, 0.0298, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0026, 0.0330, 0.0490, 0.0300, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6267764568328857 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0031, 0.0337, 0.0458, 0.0319, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0027, 0.0320, 0.0436, 0.0287, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6808230876922607 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0024, 0.0360, 0.0451, 0.0245, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0026, 0.0332, 0.0467, 0.0288, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.701462984085083 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0026, 0.0308, 0.0490, 0.0321, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0289, 0.0025, 0.0323, 0.0449, 0.0290, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6224439144134521 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0308, 0.0024, 0.0312, 0.0479, 0.0348, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0029, 0.0318, 0.0443, 0.0295, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6387989521026611 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0024, 0.0290, 0.0465, 0.0276, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0315, 0.0460, 0.0284, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6555721759796143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0025, 0.0295, 0.0448, 0.0333, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0027, 0.0321, 0.0457, 0.0279, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6851687431335449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0025, 0.0330, 0.0428, 0.0281, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0026, 0.0324, 0.0453, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.751936674118042 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0025, 0.0367, 0.0438, 0.0270, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0028, 0.0315, 0.0445, 0.0283, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.8305234909057617 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0025, 0.0323, 0.0447, 0.0323, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0029, 0.0326, 0.0456, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.7371194362640381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0027, 0.0304, 0.0436, 0.0263, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0311, 0.0453, 0.0284, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6496496200561523 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0024, 0.0316, 0.0447, 0.0270, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0026, 0.0323, 0.0450, 0.0281, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 336 in 0.6187014579772949 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0027, 0.0316, 0.0466, 0.0288, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0028, 0.0324, 0.0458, 0.0278, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6945638656616211 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0279, 0.0026, 0.0292, 0.0450, 0.0270, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0027, 0.0307, 0.0445, 0.0277, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6968460083007812 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0029, 0.0328, 0.0426, 0.0258, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0028, 0.0317, 0.0456, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6343216896057129 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0029, 0.0302, 0.0420, 0.0310, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0025, 0.0317, 0.0437, 0.0279, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6398413181304932 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0032, 0.0314, 0.0457, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0308, 0.0448, 0.0292, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6197760105133057 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0269, 0.0025, 0.0296, 0.0429, 0.0287, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0028, 0.0324, 0.0445, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6155705451965332 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0025, 0.0333, 0.0466, 0.0308, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0027, 0.0325, 0.0451, 0.0293, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6182146072387695 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0300, 0.0029, 0.0276, 0.0442, 0.0228, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0027, 0.0328, 0.0456, 0.0272, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6433014869689941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0023, 0.0362, 0.0408, 0.0266, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0024, 0.0320, 0.0465, 0.0290, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6446020603179932 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0027, 0.0317, 0.0405, 0.0291, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0323, 0.0458, 0.0295, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6514980792999268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0025, 0.0318, 0.0442, 0.0277, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0025, 0.0320, 0.0445, 0.0279, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6253812313079834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0027, 0.0329, 0.0430, 0.0289, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0289, 0.0026, 0.0329, 0.0452, 0.0279, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6276793479919434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0029, 0.0300, 0.0469, 0.0309, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0320, 0.0445, 0.0287, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6295855045318604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0022, 0.0310, 0.0450, 0.0294, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0025, 0.0336, 0.0455, 0.0285, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6206188201904297 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0304, 0.0024, 0.0325, 0.0496, 0.0279, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0027, 0.0323, 0.0435, 0.0276, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6484181880950928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0021, 0.0300, 0.0458, 0.0273, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0320, 0.0455, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6325690746307373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0309, 0.0025, 0.0275, 0.0425, 0.0288, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0028, 0.0334, 0.0444, 0.0291, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6260988712310791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0260, 0.0024, 0.0357, 0.0475, 0.0309, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0027, 0.0327, 0.0452, 0.0290, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5933775901794434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0027, 0.0325, 0.0471, 0.0289, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0026, 0.0326, 0.0447, 0.0284, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6209795475006104 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0024, 0.0320, 0.0446, 0.0305, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0317, 0.0446, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6344504356384277 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0309, 0.0024, 0.0337, 0.0439, 0.0309, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0027, 0.0329, 0.0441, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6344714164733887 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0022, 0.0339, 0.0433, 0.0271, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0028, 0.0325, 0.0440, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6349432468414307 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0306, 0.0025, 0.0309, 0.0442, 0.0315, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0026, 0.0312, 0.0458, 0.0284, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6542203426361084 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0030, 0.0334, 0.0494, 0.0249, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0024, 0.0327, 0.0459, 0.0275, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6410608291625977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0029, 0.0301, 0.0430, 0.0285, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0026, 0.0334, 0.0474, 0.0292, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6654312610626221 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0023, 0.0311, 0.0447, 0.0247, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0028, 0.0324, 0.0466, 0.0297, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6526200771331787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0287, 0.0027, 0.0336, 0.0446, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0293, 0.0027, 0.0309, 0.0479, 0.0281, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6514077186584473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0030, 0.0309, 0.0462, 0.0296, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0290, 0.0025, 0.0304, 0.0449, 0.0281, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6380186080932617 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0026, 0.0309, 0.0428, 0.0277, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0027, 0.0333, 0.0466, 0.0291, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6319844722747803 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0024, 0.0324, 0.0406, 0.0299, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0028, 0.0319, 0.0442, 0.0293, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.634915828704834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0022, 0.0287, 0.0435, 0.0309, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0313, 0.0025, 0.0318, 0.0440, 0.0281, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6415407657623291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0031, 0.0328, 0.0459, 0.0252, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0025, 0.0317, 0.0435, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6184704303741455 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0023, 0.0301, 0.0475, 0.0291, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0027, 0.0322, 0.0442, 0.0292, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6276743412017822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0314, 0.0024, 0.0291, 0.0423, 0.0318, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0025, 0.0309, 0.0434, 0.0295, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6405143737792969 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0311, 0.0031, 0.0288, 0.0431, 0.0262, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0026, 0.0325, 0.0435, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6108388900756836 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0281, 0.0020, 0.0304, 0.0434, 0.0292, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0027, 0.0329, 0.0434, 0.0282, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 480 in 0.6037368774414062 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0025, 0.0310, 0.0452, 0.0281, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0027, 0.0310, 0.0438, 0.0284, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5936505794525146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0324, 0.0024, 0.0243, 0.0428, 0.0266, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0027, 0.0317, 0.0436, 0.0279, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5953752994537354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0029, 0.0251, 0.0478, 0.0293, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0288, 0.0025, 0.0321, 0.0453, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.5991189479827881 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0031, 0.0320, 0.0452, 0.0276, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0025, 0.0310, 0.0451, 0.0292, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5972192287445068 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0025, 0.0251, 0.0500, 0.0269, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0295, 0.0024, 0.0307, 0.0437, 0.0288, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6092877388000488 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0021, 0.0310, 0.0454, 0.0281, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0025, 0.0314, 0.0457, 0.0280, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.7034039497375488 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0025, 0.0339, 0.0481, 0.0273, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0026, 0.0314, 0.0437, 0.0282, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6944777965545654 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0027, 0.0333, 0.0423, 0.0276, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0027, 0.0315, 0.0451, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6268577575683594 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0031, 0.0335, 0.0437, 0.0287, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0026, 0.0313, 0.0450, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6843440532684326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0025, 0.0312, 0.0460, 0.0257, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0024, 0.0323, 0.0447, 0.0283, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.7096583843231201 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0278, 0.0027, 0.0344, 0.0462, 0.0272, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0025, 0.0328, 0.0458, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6604108810424805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0026, 0.0340, 0.0481, 0.0299, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0027, 0.0317, 0.0447, 0.0288, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.622499942779541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0301, 0.0023, 0.0263, 0.0410, 0.0332, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0025, 0.0311, 0.0447, 0.0286, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6836941242218018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0028, 0.0286, 0.0480, 0.0305, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0027, 0.0334, 0.0450, 0.0283, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6382722854614258 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0026, 0.0312, 0.0417, 0.0272, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0027, 0.0313, 0.0453, 0.0287, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6419851779937744 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0031, 0.0295, 0.0432, 0.0328, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0027, 0.0323, 0.0460, 0.0291, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.597905158996582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0032, 0.0296, 0.0440, 0.0308, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0026, 0.0309, 0.0445, 0.0293, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.5955181121826172 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0026, 0.0271, 0.0402, 0.0302, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0024, 0.0323, 0.0435, 0.0284, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5964004993438721 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0287, 0.0029, 0.0333, 0.0435, 0.0262, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0327, 0.0443, 0.0280, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6194865703582764 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0026, 0.0292, 0.0434, 0.0283, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0028, 0.0325, 0.0438, 0.0276, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.7430479526519775 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0027, 0.0299, 0.0431, 0.0284, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0026, 0.0324, 0.0446, 0.0278, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.677983283996582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0286, 0.0022, 0.0301, 0.0459, 0.0269, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0311, 0.0440, 0.0281, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.727503776550293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0241, 0.0018, 0.0300, 0.0438, 0.0279, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0026, 0.0319, 0.0436, 0.0281, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6766092777252197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0028, 0.0330, 0.0468, 0.0287, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0027, 0.0307, 0.0448, 0.0277, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6877899169921875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0024, 0.0322, 0.0461, 0.0294, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0024, 0.0326, 0.0443, 0.0284, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6545290946960449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0024, 0.0292, 0.0434, 0.0295, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0315, 0.0450, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.624523401260376 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0024, 0.0324, 0.0446, 0.0286, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0027, 0.0322, 0.0456, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6279046535491943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0024, 0.0312, 0.0478, 0.0289, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0025, 0.0326, 0.0436, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6388227939605713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0311, 0.0029, 0.0296, 0.0443, 0.0278, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0297, 0.0025, 0.0333, 0.0464, 0.0278, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.7980518341064453 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0326, 0.0018, 0.0309, 0.0501, 0.0322, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0024, 0.0313, 0.0455, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.650010347366333 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0256, 0.0026, 0.0308, 0.0413, 0.0285, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0291, 0.0027, 0.0328, 0.0479, 0.0298, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6303234100341797 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0023, 0.0341, 0.0472, 0.0264, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0317, 0.0443, 0.0276, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.7444853782653809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0022, 0.0363, 0.0445, 0.0305, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0290, 0.0023, 0.0321, 0.0460, 0.0278, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6507155895233154 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0311, 0.0030, 0.0326, 0.0440, 0.0286, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0026, 0.0311, 0.0438, 0.0281, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.671149492263794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0307, 0.0023, 0.0328, 0.0472, 0.0269, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0028, 0.0336, 0.0449, 0.0290, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6893482208251953 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0026, 0.0306, 0.0469, 0.0305, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0026, 0.0321, 0.0434, 0.0272, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 624 in 0.6934211254119873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0021, 0.0312, 0.0443, 0.0289, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0026, 0.0300, 0.0455, 0.0283, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6403021812438965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0021, 0.0325, 0.0440, 0.0262, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0027, 0.0325, 0.0446, 0.0272, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6181225776672363 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0026, 0.0335, 0.0433, 0.0283, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0028, 0.0343, 0.0429, 0.0290, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.5994341373443604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0024, 0.0384, 0.0426, 0.0293, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0321, 0.0456, 0.0280, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5909316539764404 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0025, 0.0309, 0.0435, 0.0298, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0027, 0.0325, 0.0459, 0.0279, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.5918123722076416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0024, 0.0313, 0.0472, 0.0315, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0024, 0.0325, 0.0440, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.5913159847259521 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0036, 0.0337, 0.0447, 0.0247, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0315, 0.0453, 0.0286, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.5920722484588623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0028, 0.0348, 0.0455, 0.0279, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0025, 0.0321, 0.0435, 0.0276, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5879538059234619 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0274, 0.0023, 0.0283, 0.0404, 0.0290, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0025, 0.0327, 0.0453, 0.0275, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.589301347732544 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0022, 0.0271, 0.0487, 0.0289, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0307, 0.0435, 0.0269, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5921878814697266 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0028, 0.0367, 0.0392, 0.0277, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0025, 0.0331, 0.0466, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5910441875457764 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0026, 0.0303, 0.0516, 0.0300, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0026, 0.0320, 0.0453, 0.0274, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5921604633331299 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0022, 0.0364, 0.0423, 0.0270, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0025, 0.0310, 0.0451, 0.0275, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.589073657989502 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0306, 0.0026, 0.0315, 0.0453, 0.0272, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0024, 0.0307, 0.0447, 0.0281, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5914011001586914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0033, 0.0288, 0.0462, 0.0297, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0024, 0.0316, 0.0448, 0.0278, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5979628562927246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0284, 0.0028, 0.0320, 0.0423, 0.0292, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0026, 0.0316, 0.0443, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6050870418548584 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0283, 0.0023, 0.0319, 0.0434, 0.0311, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0291, 0.0025, 0.0312, 0.0464, 0.0286, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.599839448928833 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0289, 0.0025, 0.0329, 0.0486, 0.0310, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0321, 0.0431, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5945773124694824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0025, 0.0258, 0.0434, 0.0310, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0026, 0.0313, 0.0435, 0.0286, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6043257713317871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0327, 0.0471, 0.0311, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0319, 0.0452, 0.0278, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5964174270629883 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0032, 0.0276, 0.0431, 0.0283, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0313, 0.0448, 0.0279, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5937819480895996 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0023, 0.0316, 0.0451, 0.0285, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0318, 0.0437, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6244707107543945 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0024, 0.0333, 0.0433, 0.0318, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0284, 0.0028, 0.0319, 0.0443, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5907607078552246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0021, 0.0280, 0.0416, 0.0317, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0025, 0.0307, 0.0441, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5918247699737549 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0033, 0.0303, 0.0418, 0.0298, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0027, 0.0314, 0.0457, 0.0271, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5927889347076416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0024, 0.0331, 0.0453, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0026, 0.0307, 0.0453, 0.0279, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5972006320953369 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0023, 0.0331, 0.0416, 0.0241, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0026, 0.0312, 0.0438, 0.0278, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6069915294647217 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0032, 0.0315, 0.0447, 0.0278, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0026, 0.0312, 0.0431, 0.0276, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.589083194732666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0269, 0.0461, 0.0268, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0026, 0.0309, 0.0426, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5925030708312988 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0023, 0.0324, 0.0422, 0.0300, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0318, 0.0443, 0.0279, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.5940158367156982 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0292, 0.0022, 0.0363, 0.0448, 0.0251, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0318, 0.0444, 0.0284, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5903878211975098 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0295, 0.0033, 0.0311, 0.0473, 0.0258, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0027, 0.0317, 0.0422, 0.0268, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.5933692455291748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0284, 0.0021, 0.0288, 0.0426, 0.0257, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0319, 0.0440, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.5991353988647461 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0023, 0.0271, 0.0488, 0.0274, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0024, 0.0314, 0.0434, 0.0279, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5975217819213867 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0025, 0.0332, 0.0461, 0.0295, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0027, 0.0333, 0.0427, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5998260974884033 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0267, 0.0028, 0.0320, 0.0421, 0.0323, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0286, 0.0026, 0.0324, 0.0434, 0.0283, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 768 in 0.5927009582519531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0030, 0.0355, 0.0416, 0.0297, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0300, 0.0421, 0.0280, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.5927140712738037 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0027, 0.0286, 0.0436, 0.0303, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0027, 0.0311, 0.0430, 0.0276, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.5932934284210205 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0028, 0.0310, 0.0443, 0.0284, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0025, 0.0304, 0.0439, 0.0279, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6314897537231445 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0027, 0.0317, 0.0433, 0.0273, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0324, 0.0449, 0.0281, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.5927705764770508 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0032, 0.0307, 0.0435, 0.0280, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0026, 0.0313, 0.0435, 0.0275, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.5920569896697998 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0301, 0.0027, 0.0340, 0.0407, 0.0261, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0321, 0.0461, 0.0279, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.5941476821899414 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0021, 0.0307, 0.0457, 0.0314, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0024, 0.0299, 0.0444, 0.0272, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6139287948608398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0028, 0.0316, 0.0457, 0.0246, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0313, 0.0455, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6073501110076904 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0024, 0.0309, 0.0474, 0.0275, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0026, 0.0315, 0.0443, 0.0274, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.5916500091552734 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0024, 0.0316, 0.0459, 0.0265, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0283, 0.0025, 0.0327, 0.0441, 0.0284, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6081836223602295 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0024, 0.0266, 0.0433, 0.0320, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0025, 0.0315, 0.0450, 0.0271, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6008484363555908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0026, 0.0313, 0.0479, 0.0332, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0026, 0.0311, 0.0439, 0.0275, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.5967934131622314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0033, 0.0343, 0.0431, 0.0322, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0331, 0.0441, 0.0283, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.5947287082672119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0266, 0.0025, 0.0315, 0.0430, 0.0299, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0026, 0.0318, 0.0432, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6082220077514648 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0027, 0.0327, 0.0433, 0.0291, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0026, 0.0306, 0.0437, 0.0273, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6018965244293213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0038, 0.0292, 0.0463, 0.0272, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0024, 0.0314, 0.0444, 0.0271, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6014976501464844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0025, 0.0285, 0.0443, 0.0282, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0028, 0.0310, 0.0455, 0.0282, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.5975804328918457 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0265, 0.0034, 0.0347, 0.0416, 0.0290, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0027, 0.0324, 0.0441, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.5948071479797363 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0028, 0.0282, 0.0457, 0.0272, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0024, 0.0304, 0.0445, 0.0264, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6013836860656738 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0025, 0.0304, 0.0469, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0027, 0.0322, 0.0438, 0.0265, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6058237552642822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0260, 0.0029, 0.0281, 0.0420, 0.0214, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0026, 0.0321, 0.0441, 0.0277, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6084725856781006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0022, 0.0301, 0.0387, 0.0262, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0025, 0.0311, 0.0427, 0.0272, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5992350578308105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0325, 0.0450, 0.0288, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0025, 0.0305, 0.0431, 0.0271, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6020328998565674 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0303, 0.0025, 0.0307, 0.0414, 0.0282, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0314, 0.0442, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6148331165313721 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0026, 0.0349, 0.0370, 0.0281, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0025, 0.0312, 0.0442, 0.0285, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6000411510467529 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0031, 0.0267, 0.0435, 0.0288, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0024, 0.0314, 0.0444, 0.0281, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.599616289138794 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0028, 0.0289, 0.0429, 0.0299, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0307, 0.0431, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.5797574520111084 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0013, 0.0200, 0.0025, 0.0214, 0.0338, 0.0217, 0.0018]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0023, 0.0319, 0.0436, 0.0281, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6324248313903809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0022, 0.0266, 0.0425, 0.0269, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0312, 0.0433, 0.0266, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.593242883682251 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0024, 0.0299, 0.0476, 0.0281, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0304, 0.0436, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5948014259338379 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0027, 0.0303, 0.0464, 0.0293, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0313, 0.0433, 0.0275, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6034958362579346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0283, 0.0025, 0.0305, 0.0456, 0.0256, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0025, 0.0324, 0.0438, 0.0287, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.5937356948852539 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0273, 0.0026, 0.0267, 0.0400, 0.0293, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0311, 0.0425, 0.0269, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5982747077941895 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0308, 0.0029, 0.0316, 0.0472, 0.0272, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0027, 0.0312, 0.0418, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.5984680652618408 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0035, 0.0374, 0.0455, 0.0255, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0313, 0.0430, 0.0276, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.5947802066802979 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0029, 0.0323, 0.0403, 0.0255, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0316, 0.0438, 0.0282, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 32 in 0.6049444675445557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0024, 0.0263, 0.0446, 0.0285, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0025, 0.0316, 0.0423, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5964384078979492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0032, 0.0333, 0.0393, 0.0252, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0029, 0.0307, 0.0431, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.5943381786346436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0020, 0.0295, 0.0472, 0.0275, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0025, 0.0308, 0.0439, 0.0274, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.5987331867218018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0027, 0.0305, 0.0419, 0.0261, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0026, 0.0303, 0.0438, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6118643283843994 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0276, 0.0021, 0.0284, 0.0432, 0.0270, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0026, 0.0309, 0.0427, 0.0281, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6062510013580322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0025, 0.0333, 0.0457, 0.0284, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0027, 0.0303, 0.0440, 0.0279, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.5959141254425049 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0033, 0.0351, 0.0447, 0.0290, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0025, 0.0318, 0.0410, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.5931870937347412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0024, 0.0285, 0.0422, 0.0280, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0024, 0.0311, 0.0445, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.5968492031097412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0027, 0.0301, 0.0415, 0.0302, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0300, 0.0435, 0.0278, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6014468669891357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0302, 0.0024, 0.0336, 0.0426, 0.0284, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0029, 0.0300, 0.0443, 0.0256, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.5996792316436768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0311, 0.0023, 0.0284, 0.0440, 0.0291, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0026, 0.0297, 0.0428, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.597358226776123 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0024, 0.0298, 0.0412, 0.0270, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0024, 0.0317, 0.0424, 0.0263, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6031961441040039 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0027, 0.0314, 0.0446, 0.0282, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0025, 0.0301, 0.0423, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.5998239517211914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0036, 0.0327, 0.0468, 0.0318, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0310, 0.0432, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.5942521095275879 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0028, 0.0277, 0.0417, 0.0334, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0027, 0.0305, 0.0423, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.6066324710845947 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0024, 0.0319, 0.0413, 0.0277, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0024, 0.0304, 0.0425, 0.0275, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.5967118740081787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0027, 0.0289, 0.0407, 0.0249, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0027, 0.0311, 0.0437, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.5916779041290283 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0289, 0.0026, 0.0348, 0.0437, 0.0283, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0025, 0.0303, 0.0427, 0.0274, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.59787917137146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0029, 0.0343, 0.0458, 0.0270, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0026, 0.0308, 0.0423, 0.0265, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.5895271301269531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0025, 0.0288, 0.0405, 0.0295, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0026, 0.0310, 0.0421, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.5989906787872314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0029, 0.0261, 0.0426, 0.0259, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0027, 0.0302, 0.0445, 0.0272, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6054074764251709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0250, 0.0019, 0.0295, 0.0447, 0.0265, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0027, 0.0308, 0.0432, 0.0276, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.592756986618042 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0027, 0.0317, 0.0437, 0.0237, 0.0021]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0024, 0.0312, 0.0429, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.5930581092834473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0023, 0.0298, 0.0435, 0.0301, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0318, 0.0430, 0.0267, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.5906221866607666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0024, 0.0334, 0.0500, 0.0276, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0029, 0.0310, 0.0416, 0.0278, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.5956659317016602 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0022, 0.0294, 0.0451, 0.0272, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0301, 0.0431, 0.0286, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.5959298610687256 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0025, 0.0300, 0.0457, 0.0318, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0026, 0.0306, 0.0430, 0.0262, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.5926470756530762 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0022, 0.0275, 0.0413, 0.0294, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0283, 0.0025, 0.0303, 0.0442, 0.0268, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.5914962291717529 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0024, 0.0304, 0.0414, 0.0284, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0025, 0.0322, 0.0441, 0.0290, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.5909767150878906 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0021, 0.0309, 0.0428, 0.0312, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0281, 0.0026, 0.0310, 0.0439, 0.0282, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.5987257957458496 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0030, 0.0291, 0.0403, 0.0339, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0311, 0.0456, 0.0274, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.594871997833252 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0036, 0.0374, 0.0469, 0.0320, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0024, 0.0309, 0.0427, 0.0268, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.5912525653839111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0027, 0.0297, 0.0400, 0.0272, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0027, 0.0300, 0.0426, 0.0277, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6144411563873291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0261, 0.0028, 0.0335, 0.0421, 0.0289, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0316, 0.0418, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6498241424560547 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0267, 0.0029, 0.0287, 0.0419, 0.0275, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0023, 0.0319, 0.0454, 0.0269, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6017658710479736 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0024, 0.0324, 0.0414, 0.0248, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0311, 0.0427, 0.0269, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 176 in 0.609135627746582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0025, 0.0340, 0.0439, 0.0307, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0026, 0.0320, 0.0441, 0.0277, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6014769077301025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0029, 0.0323, 0.0410, 0.0265, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0026, 0.0309, 0.0434, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6034929752349854 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0023, 0.0292, 0.0448, 0.0256, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0026, 0.0308, 0.0435, 0.0255, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.5981910228729248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0021, 0.0275, 0.0476, 0.0300, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0271, 0.0023, 0.0315, 0.0435, 0.0265, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6604573726654053 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0024, 0.0290, 0.0388, 0.0288, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0308, 0.0426, 0.0272, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6123385429382324 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0268, 0.0024, 0.0333, 0.0389, 0.0292, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0025, 0.0304, 0.0425, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.601691722869873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0020, 0.0341, 0.0442, 0.0299, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0284, 0.0025, 0.0302, 0.0432, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6007027626037598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0313, 0.0021, 0.0292, 0.0406, 0.0270, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0281, 0.0026, 0.0311, 0.0421, 0.0281, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.5974299907684326 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0024, 0.0321, 0.0435, 0.0300, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0315, 0.0436, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.5943934917449951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0022, 0.0288, 0.0437, 0.0256, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0308, 0.0433, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6047210693359375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0243, 0.0019, 0.0327, 0.0416, 0.0311, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0024, 0.0303, 0.0420, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.5968878269195557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0283, 0.0022, 0.0313, 0.0434, 0.0260, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0023, 0.0302, 0.0428, 0.0269, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.5958859920501709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0313, 0.0024, 0.0292, 0.0448, 0.0253, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0024, 0.0305, 0.0427, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.600440502166748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0021, 0.0307, 0.0402, 0.0309, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0025, 0.0319, 0.0446, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.5972678661346436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0326, 0.0027, 0.0305, 0.0438, 0.0254, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0025, 0.0315, 0.0420, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.5998196601867676 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0021, 0.0321, 0.0416, 0.0292, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0303, 0.0443, 0.0268, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.5967526435852051 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0278, 0.0026, 0.0296, 0.0424, 0.0282, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0027, 0.0316, 0.0428, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.5977652072906494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0253, 0.0028, 0.0331, 0.0426, 0.0238, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0284, 0.0025, 0.0310, 0.0451, 0.0286, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6174702644348145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0029, 0.0283, 0.0461, 0.0302, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0025, 0.0303, 0.0428, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.5970892906188965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0257, 0.0022, 0.0292, 0.0457, 0.0290, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0285, 0.0026, 0.0298, 0.0476, 0.0269, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.5952858924865723 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0270, 0.0026, 0.0308, 0.0475, 0.0284, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0310, 0.0430, 0.0272, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.594804048538208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0022, 0.0331, 0.0416, 0.0327, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0027, 0.0311, 0.0442, 0.0271, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.5978195667266846 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0313, 0.0027, 0.0313, 0.0471, 0.0245, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0026, 0.0306, 0.0439, 0.0265, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.5981385707855225 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0027, 0.0292, 0.0419, 0.0270, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0286, 0.0025, 0.0309, 0.0470, 0.0280, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.5926299095153809 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0022, 0.0295, 0.0469, 0.0248, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0025, 0.0288, 0.0447, 0.0280, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.598543643951416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0025, 0.0308, 0.0434, 0.0280, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0026, 0.0326, 0.0435, 0.0282, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.5962011814117432 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0263, 0.0030, 0.0273, 0.0430, 0.0301, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0024, 0.0305, 0.0450, 0.0274, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.5976004600524902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0315, 0.0022, 0.0268, 0.0452, 0.0294, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0271, 0.0025, 0.0306, 0.0417, 0.0275, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.5952358245849609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0029, 0.0253, 0.0409, 0.0252, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0292, 0.0025, 0.0323, 0.0437, 0.0282, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.5942211151123047 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0027, 0.0347, 0.0425, 0.0302, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0025, 0.0303, 0.0422, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.599783182144165 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0021, 0.0340, 0.0399, 0.0290, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0024, 0.0305, 0.0468, 0.0269, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.5977251529693604 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0032, 0.0318, 0.0518, 0.0297, 0.0036]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0027, 0.0307, 0.0422, 0.0271, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.5958473682403564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0274, 0.0022, 0.0288, 0.0430, 0.0279, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0314, 0.0438, 0.0283, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.591425895690918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0033, 0.0317, 0.0375, 0.0276, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0304, 0.0417, 0.0276, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.5924181938171387 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0026, 0.0290, 0.0421, 0.0280, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0027, 0.0304, 0.0428, 0.0257, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.5960335731506348 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0303, 0.0020, 0.0344, 0.0456, 0.0269, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0307, 0.0423, 0.0265, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 320 in 0.591865062713623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0020, 0.0337, 0.0403, 0.0259, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0025, 0.0277, 0.0437, 0.0283, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6112754344940186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0034, 0.0337, 0.0460, 0.0311, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0025, 0.0308, 0.0420, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6190223693847656 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0231, 0.0027, 0.0239, 0.0434, 0.0272, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0026, 0.0301, 0.0430, 0.0258, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6016688346862793 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0022, 0.0288, 0.0405, 0.0255, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0025, 0.0310, 0.0427, 0.0268, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6000738143920898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0024, 0.0304, 0.0476, 0.0296, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0028, 0.0301, 0.0430, 0.0273, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.5930044651031494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0023, 0.0273, 0.0416, 0.0302, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0026, 0.0299, 0.0414, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.5975217819213867 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0026, 0.0354, 0.0402, 0.0280, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0025, 0.0303, 0.0453, 0.0272, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.5981597900390625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0026, 0.0337, 0.0494, 0.0275, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0027, 0.0298, 0.0419, 0.0274, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6165530681610107 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0245, 0.0023, 0.0326, 0.0407, 0.0288, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0026, 0.0312, 0.0430, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6083104610443115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0023, 0.0303, 0.0430, 0.0268, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0025, 0.0311, 0.0427, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.5971517562866211 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0023, 0.0300, 0.0427, 0.0282, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0024, 0.0319, 0.0421, 0.0272, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.5966522693634033 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0025, 0.0324, 0.0434, 0.0286, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0290, 0.0027, 0.0307, 0.0430, 0.0273, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.5989913940429688 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0022, 0.0292, 0.0458, 0.0297, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0027, 0.0328, 0.0440, 0.0279, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.5978739261627197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0030, 0.0323, 0.0429, 0.0283, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0306, 0.0447, 0.0268, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.5996744632720947 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0025, 0.0291, 0.0462, 0.0283, 0.0036]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0303, 0.0433, 0.0264, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.5979297161102295 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0307, 0.0022, 0.0299, 0.0445, 0.0289, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0024, 0.0316, 0.0433, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6082086563110352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0035, 0.0292, 0.0460, 0.0275, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0027, 0.0303, 0.0432, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6081295013427734 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0306, 0.0024, 0.0339, 0.0435, 0.0268, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0286, 0.0024, 0.0286, 0.0432, 0.0277, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5967917442321777 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0021, 0.0282, 0.0422, 0.0260, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0027, 0.0311, 0.0414, 0.0266, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6048238277435303 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0027, 0.0277, 0.0425, 0.0259, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0025, 0.0312, 0.0435, 0.0284, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.5979092121124268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0296, 0.0024, 0.0341, 0.0428, 0.0277, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0026, 0.0296, 0.0424, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6002151966094971 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0293, 0.0027, 0.0305, 0.0481, 0.0290, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0309, 0.0412, 0.0274, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.5960581302642822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0026, 0.0289, 0.0425, 0.0257, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0283, 0.0023, 0.0318, 0.0420, 0.0266, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6076452732086182 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0018, 0.0324, 0.0424, 0.0297, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0025, 0.0308, 0.0428, 0.0268, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.5970070362091064 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0292, 0.0028, 0.0323, 0.0462, 0.0294, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0313, 0.0424, 0.0268, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5945167541503906 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0025, 0.0313, 0.0407, 0.0252, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0023, 0.0284, 0.0416, 0.0274, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.5969300270080566 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0273, 0.0026, 0.0288, 0.0462, 0.0304, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0024, 0.0303, 0.0423, 0.0260, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5968716144561768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0024, 0.0267, 0.0427, 0.0269, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0026, 0.0296, 0.0421, 0.0268, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.5963022708892822 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0025, 0.0302, 0.0409, 0.0292, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0025, 0.0301, 0.0426, 0.0264, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.5942754745483398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0027, 0.0321, 0.0439, 0.0292, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0024, 0.0311, 0.0436, 0.0268, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.5975885391235352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0022, 0.0269, 0.0439, 0.0250, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0028, 0.0306, 0.0410, 0.0276, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5990550518035889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0020, 0.0291, 0.0424, 0.0261, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0027, 0.0306, 0.0415, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.602492094039917 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0025, 0.0319, 0.0388, 0.0269, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0298, 0.0418, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.5968055725097656 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0021, 0.0267, 0.0424, 0.0238, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0025, 0.0286, 0.0411, 0.0275, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.5973949432373047 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0297, 0.0035, 0.0304, 0.0413, 0.0307, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0026, 0.0296, 0.0420, 0.0270, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.5963244438171387 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0027, 0.0259, 0.0442, 0.0284, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0025, 0.0299, 0.0410, 0.0273, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 464 in 0.5949127674102783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0022, 0.0313, 0.0412, 0.0272, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0025, 0.0309, 0.0419, 0.0271, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.5946595668792725 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0021, 0.0346, 0.0388, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0303, 0.0417, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.5964336395263672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0021, 0.0275, 0.0398, 0.0232, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0028, 0.0302, 0.0407, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6025762557983398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0033, 0.0313, 0.0432, 0.0278, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0307, 0.0428, 0.0261, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.5954513549804688 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0286, 0.0025, 0.0299, 0.0444, 0.0282, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0026, 0.0298, 0.0409, 0.0264, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.5956447124481201 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0022, 0.0295, 0.0409, 0.0272, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0302, 0.0422, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.5984082221984863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0024, 0.0231, 0.0419, 0.0262, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0024, 0.0306, 0.0429, 0.0264, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6017320156097412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0024, 0.0299, 0.0416, 0.0263, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0026, 0.0290, 0.0419, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.5949430465698242 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0240, 0.0022, 0.0295, 0.0401, 0.0316, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0025, 0.0284, 0.0416, 0.0266, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.595283031463623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0025, 0.0282, 0.0415, 0.0300, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0025, 0.0289, 0.0421, 0.0266, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.5997390747070312 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0284, 0.0022, 0.0303, 0.0398, 0.0262, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0026, 0.0287, 0.0431, 0.0276, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.5989341735839844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0035, 0.0290, 0.0455, 0.0300, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0296, 0.0424, 0.0266, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.5971870422363281 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0267, 0.0020, 0.0299, 0.0404, 0.0271, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0312, 0.0438, 0.0268, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6164226531982422 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0022, 0.0258, 0.0388, 0.0269, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0299, 0.0416, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.5960679054260254 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0024, 0.0321, 0.0409, 0.0237, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0306, 0.0439, 0.0282, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6005444526672363 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0309, 0.0022, 0.0262, 0.0471, 0.0312, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0024, 0.0314, 0.0417, 0.0263, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6004889011383057 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0248, 0.0025, 0.0309, 0.0420, 0.0264, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0311, 0.0429, 0.0274, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.5967631340026855 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0025, 0.0309, 0.0370, 0.0287, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0025, 0.0290, 0.0410, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.5993342399597168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0023, 0.0291, 0.0434, 0.0263, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0026, 0.0300, 0.0418, 0.0271, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.5975346565246582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0024, 0.0322, 0.0399, 0.0257, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0026, 0.0303, 0.0432, 0.0271, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6086108684539795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0023, 0.0307, 0.0383, 0.0254, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0023, 0.0300, 0.0421, 0.0268, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.598069429397583 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0027, 0.0278, 0.0414, 0.0272, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0318, 0.0426, 0.0259, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.5972044467926025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0021, 0.0309, 0.0442, 0.0270, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0026, 0.0298, 0.0423, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.596271276473999 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0024, 0.0304, 0.0449, 0.0263, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0306, 0.0417, 0.0259, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.5957262516021729 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0027, 0.0304, 0.0392, 0.0218, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0026, 0.0295, 0.0422, 0.0267, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.5983893871307373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0023, 0.0276, 0.0376, 0.0260, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0023, 0.0296, 0.0421, 0.0265, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6030128002166748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0023, 0.0276, 0.0411, 0.0277, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0025, 0.0305, 0.0434, 0.0264, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.592031717300415 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0024, 0.0302, 0.0394, 0.0268, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0026, 0.0308, 0.0427, 0.0269, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.5905680656433105 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0298, 0.0022, 0.0296, 0.0441, 0.0250, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0025, 0.0298, 0.0438, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.5999267101287842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0022, 0.0270, 0.0394, 0.0266, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0287, 0.0024, 0.0300, 0.0424, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6045117378234863 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0021, 0.0254, 0.0447, 0.0281, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0310, 0.0418, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.5964212417602539 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0033, 0.0282, 0.0425, 0.0290, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0025, 0.0319, 0.0414, 0.0271, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.598602294921875 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0022, 0.0274, 0.0389, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0271, 0.0025, 0.0301, 0.0415, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.5987660884857178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0022, 0.0282, 0.0454, 0.0242, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0024, 0.0307, 0.0436, 0.0259, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.5973341464996338 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0026, 0.0314, 0.0452, 0.0258, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0025, 0.0298, 0.0423, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.5985269546508789 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0025, 0.0349, 0.0415, 0.0294, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0307, 0.0413, 0.0258, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 608 in 0.5975818634033203 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0022, 0.0370, 0.0397, 0.0272, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0309, 0.0423, 0.0270, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.5986731052398682 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0021, 0.0312, 0.0454, 0.0236, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0026, 0.0310, 0.0427, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.5927755832672119 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0289, 0.0024, 0.0305, 0.0420, 0.0254, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0309, 0.0419, 0.0266, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.5929162502288818 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0253, 0.0022, 0.0299, 0.0433, 0.0295, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0026, 0.0299, 0.0426, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.593987226486206 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0025, 0.0307, 0.0391, 0.0235, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0026, 0.0287, 0.0419, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.5970981121063232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0284, 0.0021, 0.0278, 0.0408, 0.0249, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0025, 0.0295, 0.0418, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.5958845615386963 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0021, 0.0329, 0.0446, 0.0238, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0287, 0.0402, 0.0270, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.598421573638916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0273, 0.0032, 0.0259, 0.0395, 0.0273, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0024, 0.0304, 0.0424, 0.0260, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.5994391441345215 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0022, 0.0298, 0.0385, 0.0235, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0025, 0.0304, 0.0411, 0.0260, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.593684196472168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0020, 0.0329, 0.0392, 0.0274, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0306, 0.0418, 0.0268, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6128253936767578 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0020, 0.0267, 0.0413, 0.0253, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0304, 0.0416, 0.0267, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6119232177734375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0273, 0.0030, 0.0287, 0.0422, 0.0246, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0298, 0.0426, 0.0264, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.5936729907989502 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0300, 0.0030, 0.0262, 0.0398, 0.0262, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0292, 0.0408, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.5945885181427002 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0025, 0.0310, 0.0447, 0.0297, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0282, 0.0024, 0.0307, 0.0421, 0.0257, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.5973751544952393 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0025, 0.0282, 0.0413, 0.0255, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0027, 0.0296, 0.0429, 0.0277, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.5993442535400391 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0028, 0.0298, 0.0438, 0.0270, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0314, 0.0428, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.5974557399749756 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0025, 0.0315, 0.0427, 0.0285, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0289, 0.0415, 0.0258, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6006529331207275 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0025, 0.0350, 0.0446, 0.0238, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0025, 0.0294, 0.0425, 0.0259, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.5970494747161865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0286, 0.0025, 0.0251, 0.0419, 0.0282, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0026, 0.0301, 0.0416, 0.0263, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.5960550308227539 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0025, 0.0296, 0.0419, 0.0234, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0025, 0.0288, 0.0426, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.5934774875640869 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0020, 0.0295, 0.0451, 0.0250, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0289, 0.0413, 0.0252, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5939877033233643 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0021, 0.0268, 0.0395, 0.0287, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0023, 0.0304, 0.0413, 0.0268, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.5960848331451416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0026, 0.0275, 0.0422, 0.0253, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0025, 0.0298, 0.0409, 0.0263, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.5920016765594482 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0023, 0.0311, 0.0419, 0.0244, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0297, 0.0415, 0.0260, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.5953996181488037 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0029, 0.0261, 0.0444, 0.0271, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0026, 0.0293, 0.0403, 0.0257, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.5946898460388184 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0027, 0.0314, 0.0359, 0.0263, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0309, 0.0404, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.5971086025238037 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0277, 0.0023, 0.0295, 0.0462, 0.0238, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0024, 0.0305, 0.0425, 0.0263, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.5980644226074219 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0027, 0.0298, 0.0436, 0.0289, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0026, 0.0305, 0.0394, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.5944805145263672 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0026, 0.0336, 0.0405, 0.0263, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0297, 0.0409, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5953125953674316 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0241, 0.0030, 0.0313, 0.0388, 0.0253, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0298, 0.0423, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.5958962440490723 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0027, 0.0280, 0.0411, 0.0280, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0025, 0.0302, 0.0429, 0.0266, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.593372106552124 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0025, 0.0298, 0.0413, 0.0259, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0024, 0.0291, 0.0424, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6019632816314697 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0022, 0.0261, 0.0395, 0.0262, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0027, 0.0293, 0.0418, 0.0258, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.5963687896728516 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0023, 0.0258, 0.0404, 0.0279, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0024, 0.0300, 0.0404, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6001107692718506 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0253, 0.0027, 0.0276, 0.0381, 0.0255, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0024, 0.0303, 0.0427, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.5947468280792236 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0248, 0.0021, 0.0284, 0.0423, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0026, 0.0305, 0.0424, 0.0261, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 752 in 0.5987682342529297 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0023, 0.0274, 0.0418, 0.0259, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0026, 0.0294, 0.0426, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6405689716339111 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0292, 0.0022, 0.0273, 0.0409, 0.0281, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0023, 0.0304, 0.0408, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.5955102443695068 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0279, 0.0028, 0.0313, 0.0398, 0.0275, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0025, 0.0300, 0.0427, 0.0257, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.5957324504852295 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0023, 0.0293, 0.0397, 0.0255, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0024, 0.0296, 0.0415, 0.0253, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6033973693847656 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0022, 0.0314, 0.0389, 0.0273, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0024, 0.0299, 0.0427, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6243789196014404 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0251, 0.0026, 0.0260, 0.0404, 0.0292, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0299, 0.0408, 0.0254, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6151604652404785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0026, 0.0248, 0.0437, 0.0289, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0024, 0.0287, 0.0404, 0.0257, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.611041784286499 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0023, 0.0263, 0.0399, 0.0275, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0308, 0.0418, 0.0265, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6991465091705322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0305, 0.0022, 0.0287, 0.0444, 0.0270, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0027, 0.0295, 0.0410, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6077945232391357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0026, 0.0280, 0.0379, 0.0256, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0023, 0.0305, 0.0417, 0.0263, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6075832843780518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0295, 0.0037, 0.0282, 0.0403, 0.0246, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0279, 0.0412, 0.0268, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6087043285369873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0022, 0.0298, 0.0369, 0.0249, 0.0020]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0313, 0.0404, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6064231395721436 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0022, 0.0311, 0.0420, 0.0301, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0313, 0.0416, 0.0251, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6069486141204834 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0021, 0.0285, 0.0407, 0.0257, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0295, 0.0406, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6153397560119629 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0025, 0.0314, 0.0348, 0.0270, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0025, 0.0289, 0.0408, 0.0263, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6152021884918213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0026, 0.0302, 0.0446, 0.0279, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0026, 0.0295, 0.0428, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6138062477111816 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0022, 0.0307, 0.0421, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0292, 0.0409, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6114785671234131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0277, 0.0024, 0.0291, 0.0434, 0.0259, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0026, 0.0300, 0.0420, 0.0246, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.611868143081665 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0021, 0.0279, 0.0410, 0.0247, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0303, 0.0400, 0.0270, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6053850650787354 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0025, 0.0325, 0.0405, 0.0227, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0025, 0.0295, 0.0415, 0.0270, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6146693229675293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0022, 0.0306, 0.0446, 0.0265, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0297, 0.0408, 0.0260, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6611273288726807 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0277, 0.0026, 0.0313, 0.0441, 0.0287, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0280, 0.0026, 0.0306, 0.0398, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6496467590332031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0022, 0.0274, 0.0381, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0287, 0.0411, 0.0264, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6090853214263916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0023, 0.0317, 0.0422, 0.0313, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0026, 0.0285, 0.0417, 0.0272, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6121299266815186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0026, 0.0319, 0.0402, 0.0288, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0024, 0.0286, 0.0420, 0.0272, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6090085506439209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0026, 0.0311, 0.0393, 0.0286, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0024, 0.0291, 0.0406, 0.0267, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6074604988098145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0029, 0.0262, 0.0421, 0.0295, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0024, 0.0295, 0.0396, 0.0256, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6044352054595947 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0022, 0.0271, 0.0410, 0.0258, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0025, 0.0298, 0.0409, 0.0249, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6065082550048828 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0030, 0.0268, 0.0423, 0.0238, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0024, 0.0293, 0.0429, 0.0266, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6119265556335449 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0028, 0.0258, 0.0398, 0.0273, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0025, 0.0306, 0.0402, 0.0260, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6067540645599365 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0026, 0.0331, 0.0423, 0.0278, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0296, 0.0409, 0.0263, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.591792106628418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0013, 0.0203, 0.0017, 0.0218, 0.0306, 0.0196, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0295, 0.0414, 0.0263, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.6481795310974121 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0237, 0.0031, 0.0292, 0.0369, 0.0264, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0027, 0.0286, 0.0416, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6079130172729492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0269, 0.0391, 0.0258, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0025, 0.0290, 0.0413, 0.0277, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6119685173034668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0030, 0.0303, 0.0427, 0.0287, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0023, 0.0282, 0.0418, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6150970458984375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0253, 0.0031, 0.0278, 0.0421, 0.0264, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0027, 0.0286, 0.0395, 0.0262, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 16 in 0.6131167411804199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0020, 0.0288, 0.0378, 0.0232, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0300, 0.0424, 0.0272, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6257154941558838 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0268, 0.0022, 0.0272, 0.0422, 0.0254, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0294, 0.0417, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6221096515655518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0252, 0.0026, 0.0283, 0.0394, 0.0270, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0024, 0.0286, 0.0430, 0.0260, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6205332279205322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0283, 0.0020, 0.0280, 0.0447, 0.0224, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0302, 0.0427, 0.0254, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6274123191833496 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0022, 0.0309, 0.0432, 0.0249, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0025, 0.0320, 0.0416, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6128840446472168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0027, 0.0290, 0.0435, 0.0250, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0022, 0.0309, 0.0424, 0.0259, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6176278591156006 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0026, 0.0319, 0.0398, 0.0282, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0023, 0.0293, 0.0421, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6141247749328613 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0027, 0.0359, 0.0395, 0.0265, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0026, 0.0299, 0.0412, 0.0271, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6117739677429199 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0021, 0.0291, 0.0439, 0.0254, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0026, 0.0289, 0.0402, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6130611896514893 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0260, 0.0028, 0.0319, 0.0416, 0.0248, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0297, 0.0419, 0.0245, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6047835350036621 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0253, 0.0020, 0.0284, 0.0437, 0.0270, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0026, 0.0292, 0.0422, 0.0271, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.7090675830841064 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0026, 0.0297, 0.0449, 0.0248, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0025, 0.0304, 0.0422, 0.0263, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6178538799285889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0253, 0.0026, 0.0281, 0.0378, 0.0260, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0024, 0.0311, 0.0414, 0.0258, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6145803928375244 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0020, 0.0269, 0.0428, 0.0277, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0026, 0.0292, 0.0410, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6127350330352783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0022, 0.0288, 0.0388, 0.0260, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0294, 0.0420, 0.0260, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6249196529388428 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0268, 0.0023, 0.0271, 0.0436, 0.0286, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0298, 0.0414, 0.0265, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6138975620269775 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0024, 0.0291, 0.0462, 0.0288, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0024, 0.0286, 0.0404, 0.0246, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6096479892730713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0021, 0.0260, 0.0364, 0.0259, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0023, 0.0287, 0.0428, 0.0259, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6116328239440918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0024, 0.0265, 0.0435, 0.0239, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0025, 0.0307, 0.0400, 0.0257, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.65163254737854 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0022, 0.0308, 0.0402, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0024, 0.0298, 0.0416, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.6524062156677246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0032, 0.0281, 0.0427, 0.0264, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0284, 0.0415, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6222095489501953 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0288, 0.0019, 0.0284, 0.0450, 0.0295, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0024, 0.0309, 0.0409, 0.0252, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6095881462097168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0026, 0.0269, 0.0403, 0.0270, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0025, 0.0302, 0.0407, 0.0265, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6670281887054443 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0295, 0.0020, 0.0345, 0.0422, 0.0261, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0023, 0.0300, 0.0404, 0.0262, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6324212551116943 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0318, 0.0029, 0.0327, 0.0413, 0.0269, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0290, 0.0404, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6148715019226074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0296, 0.0024, 0.0280, 0.0399, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0024, 0.0295, 0.0418, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6068398952484131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0291, 0.0033, 0.0298, 0.0457, 0.0269, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0026, 0.0283, 0.0410, 0.0261, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6134529113769531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0020, 0.0318, 0.0392, 0.0276, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0026, 0.0287, 0.0407, 0.0267, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6107022762298584 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0020, 0.0303, 0.0388, 0.0230, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0023, 0.0299, 0.0409, 0.0264, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6171536445617676 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0236, 0.0024, 0.0303, 0.0411, 0.0223, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0294, 0.0420, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6091995239257812 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0236, 0.0021, 0.0266, 0.0373, 0.0256, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0023, 0.0293, 0.0411, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6120848655700684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0025, 0.0295, 0.0413, 0.0250, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0298, 0.0424, 0.0261, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6112534999847412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0277, 0.0024, 0.0295, 0.0398, 0.0296, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0024, 0.0277, 0.0401, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6088340282440186 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0254, 0.0020, 0.0298, 0.0432, 0.0261, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0025, 0.0291, 0.0408, 0.0258, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6125550270080566 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0022, 0.0296, 0.0411, 0.0245, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0024, 0.0308, 0.0411, 0.0259, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6171739101409912 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0301, 0.0023, 0.0307, 0.0415, 0.0251, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0025, 0.0299, 0.0411, 0.0255, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 160 in 0.6363756656646729 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0023, 0.0262, 0.0426, 0.0251, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0278, 0.0024, 0.0303, 0.0410, 0.0253, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6157701015472412 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0022, 0.0279, 0.0391, 0.0256, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0026, 0.0297, 0.0394, 0.0256, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6141393184661865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0269, 0.0028, 0.0250, 0.0419, 0.0269, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0287, 0.0409, 0.0254, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6161854267120361 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0026, 0.0327, 0.0390, 0.0293, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0024, 0.0280, 0.0396, 0.0261, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6142880916595459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0273, 0.0024, 0.0261, 0.0380, 0.0252, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0025, 0.0288, 0.0397, 0.0269, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6138787269592285 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0292, 0.0020, 0.0294, 0.0399, 0.0261, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0024, 0.0301, 0.0404, 0.0269, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6133637428283691 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0025, 0.0312, 0.0396, 0.0260, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0026, 0.0288, 0.0387, 0.0251, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6174294948577881 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0022, 0.0323, 0.0408, 0.0234, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0024, 0.0295, 0.0419, 0.0260, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6156125068664551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0297, 0.0027, 0.0276, 0.0398, 0.0235, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0027, 0.0301, 0.0397, 0.0251, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6108019351959229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0022, 0.0319, 0.0404, 0.0281, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0025, 0.0298, 0.0425, 0.0253, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6113491058349609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0023, 0.0308, 0.0434, 0.0250, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0293, 0.0398, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6125397682189941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0021, 0.0321, 0.0402, 0.0252, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0025, 0.0280, 0.0401, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6115045547485352 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0024, 0.0331, 0.0401, 0.0256, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0024, 0.0294, 0.0394, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6100265979766846 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0266, 0.0028, 0.0284, 0.0408, 0.0245, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0025, 0.0282, 0.0407, 0.0261, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6100444793701172 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0020, 0.0247, 0.0380, 0.0276, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0276, 0.0406, 0.0271, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6163918972015381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0024, 0.0275, 0.0360, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0026, 0.0291, 0.0416, 0.0267, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6136248111724854 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0023, 0.0305, 0.0402, 0.0269, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0293, 0.0418, 0.0254, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6094038486480713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0306, 0.0026, 0.0296, 0.0364, 0.0252, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0027, 0.0302, 0.0400, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6115429401397705 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0270, 0.0026, 0.0284, 0.0434, 0.0259, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0276, 0.0025, 0.0288, 0.0411, 0.0258, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6120905876159668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0028, 0.0294, 0.0464, 0.0274, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0026, 0.0297, 0.0401, 0.0256, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6094470024108887 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0022, 0.0261, 0.0389, 0.0251, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0300, 0.0455, 0.0259, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6130132675170898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0025, 0.0240, 0.0418, 0.0245, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0309, 0.0441, 0.0273, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6393132209777832 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0261, 0.0023, 0.0325, 0.0437, 0.0270, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0024, 0.0289, 0.0417, 0.0267, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6225674152374268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0020, 0.0301, 0.0424, 0.0294, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0303, 0.0428, 0.0249, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6165804862976074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0026, 0.0288, 0.0451, 0.0241, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0274, 0.0415, 0.0260, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6151275634765625 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0023, 0.0315, 0.0391, 0.0252, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0278, 0.0408, 0.0253, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6230332851409912 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0314, 0.0025, 0.0290, 0.0368, 0.0280, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0026, 0.0294, 0.0397, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6162753105163574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0268, 0.0025, 0.0261, 0.0431, 0.0264, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0025, 0.0293, 0.0427, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6168773174285889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0023, 0.0309, 0.0437, 0.0259, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0023, 0.0297, 0.0399, 0.0245, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6243093013763428 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0023, 0.0279, 0.0392, 0.0265, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0027, 0.0293, 0.0410, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6134119033813477 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0024, 0.0280, 0.0392, 0.0259, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0025, 0.0289, 0.0411, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6142959594726562 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0024, 0.0323, 0.0435, 0.0308, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0024, 0.0286, 0.0395, 0.0251, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.628058910369873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0283, 0.0027, 0.0301, 0.0453, 0.0227, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0296, 0.0395, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6606817245483398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0221, 0.0020, 0.0298, 0.0423, 0.0258, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0290, 0.0408, 0.0261, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6155092716217041 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0031, 0.0291, 0.0404, 0.0296, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0301, 0.0406, 0.0241, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6134035587310791 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0288, 0.0022, 0.0279, 0.0393, 0.0259, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0285, 0.0399, 0.0252, 0.0028])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 304 in 0.6162965297698975 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0026, 0.0301, 0.0411, 0.0259, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0282, 0.0398, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6155931949615479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0021, 0.0320, 0.0368, 0.0240, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0025, 0.0294, 0.0404, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6131105422973633 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0033, 0.0270, 0.0424, 0.0264, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0025, 0.0291, 0.0414, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6188197135925293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0020, 0.0316, 0.0398, 0.0276, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0024, 0.0289, 0.0409, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6131210327148438 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0024, 0.0287, 0.0410, 0.0281, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0025, 0.0286, 0.0402, 0.0248, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6140015125274658 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0031, 0.0272, 0.0403, 0.0244, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0025, 0.0286, 0.0397, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.614699125289917 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0256, 0.0023, 0.0287, 0.0463, 0.0262, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0026, 0.0294, 0.0409, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6117227077484131 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0280, 0.0394, 0.0265, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0026, 0.0294, 0.0412, 0.0261, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6149256229400635 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0251, 0.0024, 0.0292, 0.0393, 0.0257, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0286, 0.0410, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6147994995117188 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0027, 0.0281, 0.0402, 0.0211, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0022, 0.0288, 0.0409, 0.0259, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6231329441070557 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0254, 0.0025, 0.0335, 0.0415, 0.0260, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0025, 0.0300, 0.0407, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6186919212341309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0243, 0.0020, 0.0324, 0.0412, 0.0302, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0026, 0.0281, 0.0413, 0.0259, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6136131286621094 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0022, 0.0294, 0.0461, 0.0239, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0026, 0.0290, 0.0408, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6164493560791016 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0024, 0.0270, 0.0405, 0.0252, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0024, 0.0290, 0.0430, 0.0266, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6128389835357666 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0305, 0.0020, 0.0284, 0.0435, 0.0248, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0025, 0.0303, 0.0406, 0.0259, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6157989501953125 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0026, 0.0282, 0.0421, 0.0246, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0026, 0.0294, 0.0428, 0.0274, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6125156879425049 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0292, 0.0023, 0.0340, 0.0442, 0.0256, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0024, 0.0286, 0.0424, 0.0256, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6116631031036377 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0299, 0.0022, 0.0306, 0.0370, 0.0263, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0025, 0.0276, 0.0410, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6179959774017334 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0028, 0.0305, 0.0419, 0.0265, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0025, 0.0296, 0.0432, 0.0265, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6187112331390381 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0023, 0.0278, 0.0415, 0.0297, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0026, 0.0298, 0.0420, 0.0259, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6170511245727539 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0026, 0.0329, 0.0413, 0.0277, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0024, 0.0291, 0.0428, 0.0265, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6178748607635498 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0025, 0.0277, 0.0431, 0.0297, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0024, 0.0301, 0.0397, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6147701740264893 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0021, 0.0283, 0.0372, 0.0270, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0024, 0.0290, 0.0418, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6288857460021973 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0023, 0.0275, 0.0414, 0.0301, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0025, 0.0294, 0.0403, 0.0266, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6138877868652344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0021, 0.0264, 0.0372, 0.0240, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0274, 0.0024, 0.0297, 0.0421, 0.0256, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6165249347686768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0293, 0.0021, 0.0249, 0.0415, 0.0243, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0025, 0.0293, 0.0389, 0.0255, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6158299446105957 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0029, 0.0297, 0.0418, 0.0260, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0025, 0.0285, 0.0418, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.7314636707305908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0028, 0.0274, 0.0396, 0.0271, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0025, 0.0287, 0.0415, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.8391268253326416 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0025, 0.0265, 0.0392, 0.0282, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0026, 0.0291, 0.0421, 0.0253, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6391079425811768 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0256, 0.0030, 0.0302, 0.0394, 0.0263, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0291, 0.0400, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6162824630737305 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0020, 0.0250, 0.0421, 0.0245, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0295, 0.0409, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6140971183776855 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0023, 0.0260, 0.0397, 0.0249, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0025, 0.0291, 0.0396, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6140952110290527 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0247, 0.0029, 0.0258, 0.0431, 0.0256, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0026, 0.0288, 0.0414, 0.0263, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6152737140655518 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0268, 0.0026, 0.0305, 0.0397, 0.0253, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0025, 0.0292, 0.0394, 0.0259, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6310558319091797 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0031, 0.0288, 0.0407, 0.0272, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0025, 0.0284, 0.0400, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6650891304016113 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0260, 0.0026, 0.0276, 0.0440, 0.0253, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0026, 0.0291, 0.0398, 0.0250, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 448 in 0.6616783142089844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0296, 0.0024, 0.0251, 0.0445, 0.0250, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0285, 0.0402, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6133029460906982 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0022, 0.0281, 0.0411, 0.0253, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0024, 0.0279, 0.0410, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.617692232131958 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0027, 0.0337, 0.0381, 0.0281, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0025, 0.0286, 0.0404, 0.0253, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6112751960754395 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0020, 0.0291, 0.0389, 0.0287, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0291, 0.0401, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6175978183746338 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0022, 0.0320, 0.0407, 0.0237, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0025, 0.0290, 0.0401, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6195800304412842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0020, 0.0257, 0.0374, 0.0197, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0026, 0.0276, 0.0409, 0.0252, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6126301288604736 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0021, 0.0247, 0.0402, 0.0287, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0023, 0.0300, 0.0417, 0.0253, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6130645275115967 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0021, 0.0306, 0.0399, 0.0254, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0026, 0.0282, 0.0410, 0.0251, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6144635677337646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0026, 0.0340, 0.0401, 0.0285, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0304, 0.0422, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6104011535644531 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0024, 0.0282, 0.0387, 0.0266, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0287, 0.0383, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6141533851623535 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0023, 0.0225, 0.0383, 0.0260, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0258, 0.0025, 0.0279, 0.0401, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6125969886779785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0025, 0.0283, 0.0429, 0.0252, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0026, 0.0283, 0.0411, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6144084930419922 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0292, 0.0019, 0.0262, 0.0403, 0.0249, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0277, 0.0391, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.613100528717041 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0022, 0.0306, 0.0426, 0.0273, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0289, 0.0415, 0.0255, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.611807107925415 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0287, 0.0027, 0.0303, 0.0389, 0.0276, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0297, 0.0409, 0.0256, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6157009601593018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0024, 0.0290, 0.0438, 0.0260, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0258, 0.0027, 0.0282, 0.0392, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6104824542999268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0025, 0.0304, 0.0389, 0.0251, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0024, 0.0281, 0.0398, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6118788719177246 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0314, 0.0024, 0.0326, 0.0379, 0.0273, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0026, 0.0282, 0.0400, 0.0259, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6077094078063965 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0289, 0.0027, 0.0298, 0.0422, 0.0255, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0024, 0.0294, 0.0414, 0.0253, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6118173599243164 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0299, 0.0025, 0.0291, 0.0397, 0.0256, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0023, 0.0298, 0.0414, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6106691360473633 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0023, 0.0320, 0.0365, 0.0279, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0027, 0.0291, 0.0410, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6092715263366699 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0022, 0.0320, 0.0366, 0.0295, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0025, 0.0265, 0.0395, 0.0249, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6083896160125732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0018, 0.0292, 0.0350, 0.0284, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0284, 0.0415, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6110856533050537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0025, 0.0330, 0.0415, 0.0275, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0027, 0.0284, 0.0393, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6051673889160156 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0023, 0.0268, 0.0381, 0.0280, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0025, 0.0276, 0.0401, 0.0253, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.630378246307373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0255, 0.0023, 0.0273, 0.0393, 0.0220, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0285, 0.0413, 0.0243, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6087756156921387 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0266, 0.0025, 0.0281, 0.0421, 0.0269, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0304, 0.0420, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6108336448669434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0243, 0.0025, 0.0264, 0.0411, 0.0233, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0286, 0.0396, 0.0244, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6105692386627197 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0271, 0.0019, 0.0268, 0.0379, 0.0226, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0025, 0.0285, 0.0394, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6082892417907715 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0021, 0.0295, 0.0392, 0.0221, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0291, 0.0385, 0.0257, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6102652549743652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0245, 0.0025, 0.0260, 0.0338, 0.0267, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0025, 0.0274, 0.0396, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6071579456329346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0279, 0.0024, 0.0255, 0.0394, 0.0237, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0027, 0.0282, 0.0398, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.603456974029541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0024, 0.0294, 0.0402, 0.0264, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0025, 0.0298, 0.0381, 0.0252, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6134214401245117 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0253, 0.0024, 0.0265, 0.0372, 0.0283, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0025, 0.0278, 0.0410, 0.0258, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6075739860534668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0304, 0.0022, 0.0279, 0.0402, 0.0275, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0279, 0.0392, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6078307628631592 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0027, 0.0268, 0.0398, 0.0286, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0025, 0.0296, 0.0421, 0.0265, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 592 in 0.6080124378204346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0244, 0.0033, 0.0273, 0.0420, 0.0260, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0294, 0.0387, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6110179424285889 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0024, 0.0292, 0.0396, 0.0259, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0282, 0.0023, 0.0293, 0.0434, 0.0260, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6090281009674072 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0028, 0.0334, 0.0418, 0.0234, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0025, 0.0291, 0.0384, 0.0260, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6052641868591309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0022, 0.0258, 0.0395, 0.0255, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0027, 0.0283, 0.0400, 0.0258, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.608971357345581 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0248, 0.0022, 0.0288, 0.0399, 0.0258, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0026, 0.0287, 0.0398, 0.0248, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6124205589294434 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0024, 0.0261, 0.0418, 0.0241, 0.0033]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0289, 0.0401, 0.0239, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6043269634246826 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0023, 0.0240, 0.0402, 0.0257, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0026, 0.0284, 0.0389, 0.0249, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6104037761688232 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0251, 0.0023, 0.0255, 0.0428, 0.0265, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0026, 0.0286, 0.0403, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6108517646789551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0022, 0.0270, 0.0429, 0.0270, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0025, 0.0277, 0.0395, 0.0241, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6057765483856201 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0026, 0.0276, 0.0406, 0.0274, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0271, 0.0024, 0.0295, 0.0410, 0.0273, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6172428131103516 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0029, 0.0241, 0.0392, 0.0283, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0290, 0.0407, 0.0245, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6152377128601074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0025, 0.0315, 0.0379, 0.0230, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0025, 0.0281, 0.0417, 0.0259, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6174986362457275 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0023, 0.0232, 0.0393, 0.0272, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0025, 0.0280, 0.0398, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6140069961547852 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0032, 0.0293, 0.0375, 0.0256, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0025, 0.0284, 0.0404, 0.0254, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.615748405456543 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0030, 0.0326, 0.0402, 0.0288, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0282, 0.0396, 0.0249, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6179664134979248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0035, 0.0295, 0.0443, 0.0208, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0024, 0.0292, 0.0412, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6121342182159424 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0282, 0.0021, 0.0277, 0.0446, 0.0267, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0024, 0.0290, 0.0421, 0.0263, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6078870296478271 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0247, 0.0024, 0.0253, 0.0398, 0.0262, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0024, 0.0291, 0.0394, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.605546236038208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0027, 0.0296, 0.0367, 0.0269, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0024, 0.0281, 0.0454, 0.0251, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6041646003723145 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0026, 0.0285, 0.0499, 0.0276, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0027, 0.0289, 0.0438, 0.0265, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.620142936706543 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0027, 0.0320, 0.0404, 0.0239, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0026, 0.0301, 0.0426, 0.0264, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6196393966674805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0030, 0.0319, 0.0412, 0.0310, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0289, 0.0025, 0.0298, 0.0457, 0.0258, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6079502105712891 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0022, 0.0271, 0.0472, 0.0237, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0024, 0.0293, 0.0396, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6056687831878662 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0022, 0.0264, 0.0435, 0.0234, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0026, 0.0296, 0.0405, 0.0251, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6097061634063721 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0029, 0.0276, 0.0416, 0.0294, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0022, 0.0287, 0.0410, 0.0248, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.609795331954956 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0030, 0.0227, 0.0409, 0.0238, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0301, 0.0414, 0.0248, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6067748069763184 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0024, 0.0300, 0.0471, 0.0256, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0026, 0.0290, 0.0423, 0.0254, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6137886047363281 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0021, 0.0334, 0.0378, 0.0249, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0023, 0.0292, 0.0446, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6362416744232178 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0021, 0.0263, 0.0411, 0.0261, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0025, 0.0279, 0.0423, 0.0248, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6843245029449463 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0020, 0.0286, 0.0443, 0.0286, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0277, 0.0024, 0.0287, 0.0416, 0.0250, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6156473159790039 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0024, 0.0302, 0.0478, 0.0259, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0283, 0.0025, 0.0315, 0.0443, 0.0270, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6117234230041504 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0302, 0.0022, 0.0300, 0.0478, 0.0260, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0302, 0.0410, 0.0256, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.634204626083374 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0240, 0.0024, 0.0347, 0.0376, 0.0282, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0285, 0.0023, 0.0309, 0.0455, 0.0262, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6042757034301758 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0030, 0.0271, 0.0452, 0.0285, 0.0033]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0026, 0.0285, 0.0395, 0.0244, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6041486263275146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0237, 0.0022, 0.0273, 0.0414, 0.0267, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0026, 0.0284, 0.0410, 0.0250, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6049258708953857 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0024, 0.0285, 0.0448, 0.0265, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0286, 0.0398, 0.0257, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 736 in 0.6134579181671143 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0030, 0.0251, 0.0384, 0.0240, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0026, 0.0293, 0.0411, 0.0245, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6092476844787598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0027, 0.0257, 0.0415, 0.0239, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0025, 0.0291, 0.0387, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.619828462600708 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0276, 0.0023, 0.0298, 0.0381, 0.0251, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0300, 0.0411, 0.0246, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6073510646820068 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0021, 0.0292, 0.0432, 0.0286, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0282, 0.0395, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6030600070953369 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0020, 0.0285, 0.0358, 0.0227, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0025, 0.0290, 0.0428, 0.0254, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6071460247039795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0025, 0.0268, 0.0374, 0.0259, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0023, 0.0274, 0.0390, 0.0250, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6063888072967529 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0023, 0.0318, 0.0414, 0.0273, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0292, 0.0413, 0.0256, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.610429048538208 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0267, 0.0023, 0.0245, 0.0406, 0.0272, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0028, 0.0292, 0.0394, 0.0249, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6036672592163086 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0276, 0.0026, 0.0302, 0.0411, 0.0248, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0279, 0.0025, 0.0295, 0.0458, 0.0265, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.61989426612854 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0282, 0.0022, 0.0268, 0.0479, 0.0285, 0.0032]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0023, 0.0301, 0.0433, 0.0249, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6245572566986084 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0025, 0.0303, 0.0439, 0.0249, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0027, 0.0305, 0.0408, 0.0266, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6599128246307373 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0258, 0.0023, 0.0268, 0.0386, 0.0244, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0024, 0.0294, 0.0416, 0.0247, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6544106006622314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0024, 0.0239, 0.0427, 0.0259, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0025, 0.0289, 0.0406, 0.0249, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6594574451446533 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0019, 0.0313, 0.0425, 0.0297, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0277, 0.0023, 0.0289, 0.0412, 0.0253, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6119184494018555 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0280, 0.0028, 0.0262, 0.0403, 0.0259, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0278, 0.0389, 0.0247, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6184933185577393 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0258, 0.0019, 0.0271, 0.0373, 0.0252, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0271, 0.0025, 0.0293, 0.0418, 0.0249, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6265547275543213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0026, 0.0291, 0.0429, 0.0270, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0291, 0.0394, 0.0244, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6074726581573486 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0027, 0.0273, 0.0419, 0.0244, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0026, 0.0310, 0.0411, 0.0254, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7516899108886719 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0248, 0.0024, 0.0240, 0.0428, 0.0261, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0298, 0.0388, 0.0240, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6326584815979004 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0263, 0.0026, 0.0261, 0.0366, 0.0278, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0288, 0.0025, 0.0292, 0.0449, 0.0261, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6071062088012695 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0281, 0.0026, 0.0296, 0.0468, 0.0255, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0273, 0.0027, 0.0277, 0.0389, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6082401275634766 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0249, 0.0025, 0.0260, 0.0394, 0.0261, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0279, 0.0026, 0.0303, 0.0426, 0.0271, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6074576377868652 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0276, 0.0022, 0.0304, 0.0434, 0.0281, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0290, 0.0398, 0.0244, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6042037010192871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0261, 0.0025, 0.0270, 0.0387, 0.0268, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0278, 0.0023, 0.0289, 0.0430, 0.0255, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.610285758972168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0352, 0.0432, 0.0244, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0026, 0.0298, 0.0417, 0.0257, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.639289379119873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0031, 0.0277, 0.0387, 0.0282, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0289, 0.0391, 0.0259, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6757395267486572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0030, 0.0232, 0.0394, 0.0225, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0280, 0.0025, 0.0301, 0.0438, 0.0241, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.607621431350708 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0026, 0.0280, 0.0452, 0.0228, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0026, 0.0281, 0.0395, 0.0262, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6126277446746826 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0022, 0.0269, 0.0374, 0.0262, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0293, 0.0416, 0.0258, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6091561317443848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0252, 0.0024, 0.0259, 0.0456, 0.0292, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0270, 0.0025, 0.0278, 0.0394, 0.0255, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.604128360748291 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0024, 0.0263, 0.0362, 0.0274, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0295, 0.0396, 0.0251, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6111850738525391 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0302, 0.0021, 0.0304, 0.0395, 0.0246, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0023, 0.0280, 0.0393, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6075222492218018 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0020, 0.0317, 0.0348, 0.0261, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0023, 0.0293, 0.0394, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6055350303649902 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0284, 0.0028, 0.0284, 0.0379, 0.0252, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0024, 0.0287, 0.0395, 0.0257, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6417624950408936 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0021, 0.0245, 0.0416, 0.0218, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0024, 0.0290, 0.0406, 0.0257, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.63681960105896 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0013, 0.0217, 0.0020, 0.0203, 0.0263, 0.0206, 0.0021]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0024, 0.0294, 0.0405, 0.0237, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.6977407932281494 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0289, 0.0022, 0.0287, 0.0372, 0.0222, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0299, 0.0403, 0.0260, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.6821742057800293 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0023, 0.0280, 0.0393, 0.0268, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0023, 0.0287, 0.0388, 0.0246, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6377489566802979 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0020, 0.0244, 0.0397, 0.0238, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0272, 0.0025, 0.0283, 0.0410, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6136608123779297 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0268, 0.0025, 0.0265, 0.0365, 0.0243, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0024, 0.0275, 0.0394, 0.0242, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6269862651824951 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0281, 0.0023, 0.0277, 0.0414, 0.0258, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0305, 0.0404, 0.0255, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6230454444885254 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0267, 0.0022, 0.0291, 0.0421, 0.0263, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0291, 0.0413, 0.0246, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6256098747253418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0298, 0.0022, 0.0270, 0.0407, 0.0284, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0296, 0.0412, 0.0244, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6096835136413574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0249, 0.0020, 0.0256, 0.0431, 0.0257, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0292, 0.0397, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6410520076751709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0232, 0.0026, 0.0258, 0.0394, 0.0219, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0025, 0.0278, 0.0391, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7541730403900146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0250, 0.0021, 0.0277, 0.0416, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0026, 0.0289, 0.0400, 0.0244, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6768419742584229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0306, 0.0025, 0.0334, 0.0415, 0.0305, 0.0035]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0023, 0.0278, 0.0398, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7132515907287598 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0021, 0.0282, 0.0398, 0.0254, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0283, 0.0393, 0.0252, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6858768463134766 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0021, 0.0270, 0.0385, 0.0254, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0258, 0.0024, 0.0294, 0.0397, 0.0243, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.9589860439300537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0023, 0.0285, 0.0367, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0274, 0.0024, 0.0283, 0.0406, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.7840611934661865 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0021, 0.0286, 0.0387, 0.0227, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0288, 0.0405, 0.0249, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.759723424911499 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0025, 0.0252, 0.0424, 0.0264, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0256, 0.0024, 0.0288, 0.0403, 0.0255, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7374153137207031 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0258, 0.0030, 0.0254, 0.0385, 0.0250, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0025, 0.0272, 0.0377, 0.0245, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6315820217132568 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0288, 0.0019, 0.0303, 0.0370, 0.0227, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0025, 0.0270, 0.0384, 0.0242, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.748236894607544 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0023, 0.0254, 0.0417, 0.0218, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0027, 0.0281, 0.0386, 0.0251, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6570634841918945 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0022, 0.0260, 0.0428, 0.0230, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0023, 0.0280, 0.0406, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6401317119598389 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0315, 0.0024, 0.0249, 0.0394, 0.0226, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0025, 0.0292, 0.0397, 0.0244, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6643023490905762 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0024, 0.0231, 0.0382, 0.0268, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0282, 0.0402, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6814720630645752 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0021, 0.0242, 0.0350, 0.0263, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0027, 0.0285, 0.0381, 0.0239, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.696774959564209 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0263, 0.0025, 0.0247, 0.0418, 0.0241, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0271, 0.0397, 0.0245, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.8775508403778076 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0023, 0.0268, 0.0361, 0.0272, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0023, 0.0289, 0.0399, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7263960838317871 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0253, 0.0022, 0.0252, 0.0393, 0.0273, 0.0034]) \n",
      "Test Loss tensor([0.0018, 0.0257, 0.0024, 0.0274, 0.0392, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6442368030548096 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0280, 0.0029, 0.0231, 0.0447, 0.0265, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0025, 0.0277, 0.0394, 0.0250, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6423771381378174 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0260, 0.0022, 0.0320, 0.0382, 0.0218, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0025, 0.0290, 0.0411, 0.0253, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6270532608032227 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0275, 0.0029, 0.0327, 0.0385, 0.0215, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0025, 0.0294, 0.0399, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.9740471839904785 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0246, 0.0019, 0.0278, 0.0410, 0.0243, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0273, 0.0024, 0.0286, 0.0395, 0.0248, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7447435855865479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0294, 0.0022, 0.0308, 0.0416, 0.0230, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0295, 0.0398, 0.0245, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.8685719966888428 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0259, 0.0022, 0.0258, 0.0391, 0.0260, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0257, 0.0024, 0.0279, 0.0396, 0.0243, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.9698669910430908 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0262, 0.0019, 0.0275, 0.0401, 0.0270, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0024, 0.0285, 0.0380, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.9100806713104248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0027, 0.0285, 0.0398, 0.0225, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0026, 0.0271, 0.0395, 0.0240, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.7720701694488525 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0234, 0.0024, 0.0260, 0.0422, 0.0228, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0024, 0.0289, 0.0374, 0.0245, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6983106136322021 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0243, 0.0023, 0.0327, 0.0398, 0.0272, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0299, 0.0395, 0.0234, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 144 in 0.6395449638366699 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0238, 0.0020, 0.0289, 0.0400, 0.0235, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0023, 0.0293, 0.0389, 0.0240, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6571993827819824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0030, 0.0298, 0.0410, 0.0224, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0253, 0.0024, 0.0274, 0.0388, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6603188514709473 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0019, 0.0284, 0.0371, 0.0226, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0024, 0.0281, 0.0381, 0.0259, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6686975955963135 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0025, 0.0258, 0.0397, 0.0270, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0024, 0.0283, 0.0392, 0.0243, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7199509143829346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0029, 0.0311, 0.0401, 0.0281, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0023, 0.0280, 0.0386, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6534686088562012 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0024, 0.0251, 0.0424, 0.0287, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0264, 0.0392, 0.0240, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6721322536468506 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0242, 0.0026, 0.0250, 0.0403, 0.0276, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0023, 0.0289, 0.0384, 0.0243, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6919658184051514 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0027, 0.0270, 0.0370, 0.0311, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0023, 0.0285, 0.0392, 0.0230, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6971724033355713 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0258, 0.0026, 0.0271, 0.0412, 0.0210, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0023, 0.0286, 0.0386, 0.0240, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.7458064556121826 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0024, 0.0278, 0.0437, 0.0240, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0025, 0.0283, 0.0386, 0.0243, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.6983263492584229 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0279, 0.0025, 0.0347, 0.0396, 0.0242, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0275, 0.0393, 0.0251, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6564481258392334 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0024, 0.0299, 0.0412, 0.0261, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0024, 0.0269, 0.0388, 0.0241, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.694159984588623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0028, 0.0320, 0.0398, 0.0279, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0288, 0.0393, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6755855083465576 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0028, 0.0290, 0.0396, 0.0258, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0026, 0.0294, 0.0408, 0.0249, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6716780662536621 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0023, 0.0322, 0.0398, 0.0271, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0024, 0.0285, 0.0389, 0.0239, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7228810787200928 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0025, 0.0231, 0.0364, 0.0234, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0024, 0.0271, 0.0413, 0.0248, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.698009729385376 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0289, 0.0021, 0.0289, 0.0414, 0.0254, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0275, 0.0379, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6694505214691162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0308, 0.0027, 0.0280, 0.0410, 0.0264, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0023, 0.0285, 0.0390, 0.0254, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.719012975692749 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0023, 0.0273, 0.0370, 0.0278, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0260, 0.0024, 0.0290, 0.0404, 0.0238, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.8735823631286621 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0027, 0.0265, 0.0393, 0.0244, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0281, 0.0383, 0.0249, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7039706707000732 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0279, 0.0024, 0.0273, 0.0409, 0.0272, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0025, 0.0271, 0.0391, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.719794750213623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0253, 0.0026, 0.0252, 0.0358, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0026, 0.0272, 0.0376, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.727165937423706 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0024, 0.0265, 0.0400, 0.0270, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0256, 0.0027, 0.0277, 0.0395, 0.0243, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6649792194366455 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0248, 0.0022, 0.0248, 0.0426, 0.0226, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0025, 0.0279, 0.0395, 0.0242, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6692566871643066 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0249, 0.0023, 0.0280, 0.0408, 0.0223, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0025, 0.0261, 0.0394, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7057616710662842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0290, 0.0023, 0.0278, 0.0409, 0.0272, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0285, 0.0379, 0.0238, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6157777309417725 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0244, 0.0021, 0.0281, 0.0379, 0.0229, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0290, 0.0401, 0.0244, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6156506538391113 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0280, 0.0033, 0.0305, 0.0394, 0.0254, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0283, 0.0390, 0.0241, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6180884838104248 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0018, 0.0314, 0.0427, 0.0260, 0.0035]) \n",
      "Test Loss tensor([0.0018, 0.0264, 0.0024, 0.0276, 0.0397, 0.0251, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6216609477996826 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0023, 0.0249, 0.0379, 0.0253, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0025, 0.0276, 0.0401, 0.0245, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6138310432434082 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0268, 0.0024, 0.0271, 0.0435, 0.0243, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0023, 0.0272, 0.0379, 0.0244, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6448073387145996 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0274, 0.0021, 0.0276, 0.0382, 0.0212, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0301, 0.0409, 0.0251, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6496973037719727 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0234, 0.0021, 0.0286, 0.0438, 0.0266, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0258, 0.0025, 0.0275, 0.0395, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7162666320800781 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0023, 0.0282, 0.0438, 0.0279, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0024, 0.0297, 0.0389, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6897602081298828 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0022, 0.0284, 0.0406, 0.0244, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0282, 0.0375, 0.0245, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7882401943206787 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0018, 0.0284, 0.0421, 0.0264, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0023, 0.0281, 0.0411, 0.0252, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 288 in 0.7397477626800537 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0023, 0.0246, 0.0434, 0.0267, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0262, 0.0024, 0.0282, 0.0383, 0.0253, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.7283151149749756 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0254, 0.0019, 0.0267, 0.0415, 0.0294, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0276, 0.0024, 0.0286, 0.0393, 0.0244, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.7657556533813477 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0039, 0.0266, 0.0398, 0.0242, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0024, 0.0283, 0.0386, 0.0240, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7657349109649658 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0289, 0.0022, 0.0268, 0.0410, 0.0243, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0024, 0.0281, 0.0392, 0.0245, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.8931400775909424 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0253, 0.0023, 0.0296, 0.0399, 0.0261, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0023, 0.0277, 0.0402, 0.0243, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.8209052085876465 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0030, 0.0303, 0.0430, 0.0240, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0024, 0.0282, 0.0401, 0.0240, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.8881745338439941 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0022, 0.0309, 0.0443, 0.0251, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0024, 0.0290, 0.0383, 0.0247, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.8307526111602783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0251, 0.0025, 0.0299, 0.0375, 0.0230, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0251, 0.0026, 0.0291, 0.0399, 0.0246, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.8089020252227783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0024, 0.0291, 0.0438, 0.0233, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0025, 0.0274, 0.0385, 0.0249, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.880681037902832 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0023, 0.0292, 0.0353, 0.0241, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0275, 0.0024, 0.0268, 0.0394, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.8331694602966309 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0018, 0.0285, 0.0410, 0.0262, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0027, 0.0269, 0.0390, 0.0251, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7961041927337646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0024, 0.0291, 0.0406, 0.0268, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0024, 0.0278, 0.0371, 0.0239, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.754462718963623 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0232, 0.0024, 0.0275, 0.0370, 0.0251, 0.0030]) \n",
      "Test Loss tensor([0.0018, 0.0254, 0.0024, 0.0285, 0.0380, 0.0234, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6882052421569824 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0269, 0.0021, 0.0278, 0.0460, 0.0218, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0283, 0.0386, 0.0241, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.7235798835754395 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0029, 0.0284, 0.0352, 0.0227, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0023, 0.0277, 0.0384, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.7356679439544678 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0027, 0.0265, 0.0384, 0.0257, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0025, 0.0275, 0.0377, 0.0244, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7405552864074707 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0243, 0.0028, 0.0255, 0.0378, 0.0243, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0272, 0.0026, 0.0287, 0.0397, 0.0243, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.7005305290222168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0254, 0.0023, 0.0280, 0.0393, 0.0235, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0024, 0.0278, 0.0397, 0.0243, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6216530799865723 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0245, 0.0024, 0.0316, 0.0384, 0.0245, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0024, 0.0284, 0.0419, 0.0249, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6134302616119385 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0296, 0.0023, 0.0328, 0.0427, 0.0228, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0023, 0.0299, 0.0396, 0.0246, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7331247329711914 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0257, 0.0021, 0.0260, 0.0388, 0.0237, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0266, 0.0400, 0.0228, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6922683715820312 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0021, 0.0283, 0.0344, 0.0264, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0274, 0.0387, 0.0246, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6446280479431152 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0023, 0.0298, 0.0337, 0.0219, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0025, 0.0274, 0.0385, 0.0239, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6462700366973877 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0024, 0.0340, 0.0352, 0.0217, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0026, 0.0268, 0.0396, 0.0245, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6009137630462646 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0239, 0.0026, 0.0299, 0.0423, 0.0233, 0.0037]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0025, 0.0284, 0.0401, 0.0247, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.632969856262207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0027, 0.0290, 0.0409, 0.0242, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0254, 0.0025, 0.0273, 0.0379, 0.0242, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.5783991813659668 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0021, 0.0292, 0.0360, 0.0215, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0287, 0.0389, 0.0236, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6343600749969482 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0022, 0.0259, 0.0373, 0.0262, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0024, 0.0268, 0.0386, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6551342010498047 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0034, 0.0233, 0.0394, 0.0231, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0026, 0.0288, 0.0379, 0.0245, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6605184078216553 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0251, 0.0030, 0.0268, 0.0362, 0.0218, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0274, 0.0386, 0.0249, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6465775966644287 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0281, 0.0025, 0.0272, 0.0431, 0.0238, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0024, 0.0279, 0.0372, 0.0230, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.5962333679199219 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0287, 0.0028, 0.0277, 0.0362, 0.0239, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0282, 0.0399, 0.0238, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6149237155914307 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0239, 0.0023, 0.0260, 0.0377, 0.0252, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0024, 0.0296, 0.0393, 0.0239, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.5904457569122314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0018, 0.0253, 0.0380, 0.0241, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0023, 0.0281, 0.0390, 0.0243, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6137497425079346 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0251, 0.0023, 0.0300, 0.0401, 0.0246, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0025, 0.0286, 0.0380, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.5690381526947021 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0239, 0.0029, 0.0234, 0.0351, 0.0227, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0025, 0.0295, 0.0386, 0.0259, 0.0024])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 432 in 0.6220269203186035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0021, 0.0264, 0.0358, 0.0239, 0.0022]) \n",
      "Test Loss tensor([0.0018, 0.0258, 0.0026, 0.0285, 0.0395, 0.0235, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 436 in 1.0629427433013916 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0021, 0.0294, 0.0398, 0.0234, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0269, 0.0381, 0.0236, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6602132320404053 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0026, 0.0303, 0.0341, 0.0244, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0281, 0.0381, 0.0241, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.5790581703186035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0256, 0.0025, 0.0268, 0.0412, 0.0258, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0294, 0.0389, 0.0245, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.5797340869903564 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0022, 0.0251, 0.0398, 0.0250, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0023, 0.0273, 0.0369, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6075122356414795 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0247, 0.0030, 0.0276, 0.0372, 0.0295, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0273, 0.0367, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6140873432159424 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0243, 0.0025, 0.0274, 0.0346, 0.0257, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0260, 0.0025, 0.0275, 0.0374, 0.0248, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6187915802001953 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0261, 0.0024, 0.0266, 0.0384, 0.0226, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0026, 0.0286, 0.0389, 0.0248, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7345395088195801 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0270, 0.0024, 0.0272, 0.0385, 0.0240, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0025, 0.0285, 0.0379, 0.0233, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6898961067199707 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0267, 0.0025, 0.0277, 0.0397, 0.0256, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0256, 0.0024, 0.0276, 0.0384, 0.0238, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6944808959960938 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0282, 0.0023, 0.0283, 0.0391, 0.0254, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0262, 0.0380, 0.0238, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6973330974578857 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0024, 0.0279, 0.0343, 0.0248, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0026, 0.0275, 0.0386, 0.0237, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6778488159179688 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0252, 0.0022, 0.0297, 0.0343, 0.0244, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0022, 0.0298, 0.0380, 0.0240, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6984472274780273 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0251, 0.0026, 0.0285, 0.0351, 0.0235, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0024, 0.0273, 0.0384, 0.0235, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6960146427154541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0024, 0.0263, 0.0375, 0.0269, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0268, 0.0024, 0.0277, 0.0394, 0.0247, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6900551319122314 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0309, 0.0024, 0.0279, 0.0378, 0.0251, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0023, 0.0274, 0.0383, 0.0236, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7007977962493896 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0024, 0.0256, 0.0370, 0.0279, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0257, 0.0023, 0.0281, 0.0396, 0.0237, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6914565563201904 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0023, 0.0241, 0.0420, 0.0235, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0023, 0.0284, 0.0382, 0.0236, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.707460880279541 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0257, 0.0019, 0.0244, 0.0397, 0.0282, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0255, 0.0025, 0.0283, 0.0385, 0.0240, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6980047225952148 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0265, 0.0022, 0.0298, 0.0367, 0.0249, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0265, 0.0024, 0.0280, 0.0385, 0.0243, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6950771808624268 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0242, 0.0023, 0.0267, 0.0407, 0.0258, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0024, 0.0283, 0.0382, 0.0233, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6988768577575684 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0253, 0.0022, 0.0300, 0.0411, 0.0257, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0023, 0.0282, 0.0399, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.721630334854126 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0021, 0.0289, 0.0400, 0.0234, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0289, 0.0369, 0.0236, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.7678508758544922 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0290, 0.0023, 0.0266, 0.0376, 0.0245, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0256, 0.0023, 0.0267, 0.0384, 0.0235, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7365708351135254 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0286, 0.0020, 0.0256, 0.0359, 0.0261, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0024, 0.0279, 0.0388, 0.0232, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.7003276348114014 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0020, 0.0236, 0.0386, 0.0270, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0023, 0.0276, 0.0390, 0.0246, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.7254114151000977 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0263, 0.0020, 0.0302, 0.0382, 0.0251, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0025, 0.0288, 0.0388, 0.0236, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6632041931152344 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0022, 0.0268, 0.0358, 0.0246, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0022, 0.0286, 0.0381, 0.0239, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.7578904628753662 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0018, 0.0302, 0.0378, 0.0242, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0023, 0.0286, 0.0391, 0.0243, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.7094883918762207 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0273, 0.0025, 0.0279, 0.0387, 0.0244, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0280, 0.0391, 0.0240, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.7014164924621582 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0026, 0.0264, 0.0376, 0.0271, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0263, 0.0023, 0.0276, 0.0391, 0.0236, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.7948136329650879 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0271, 0.0025, 0.0298, 0.0428, 0.0265, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0272, 0.0389, 0.0242, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.7033796310424805 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0027, 0.0259, 0.0352, 0.0223, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0023, 0.0275, 0.0380, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6955523490905762 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0028, 0.0267, 0.0331, 0.0231, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0025, 0.0271, 0.0390, 0.0241, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6689143180847168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0278, 0.0029, 0.0298, 0.0338, 0.0233, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0025, 0.0288, 0.0378, 0.0244, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6708104610443115 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0260, 0.0021, 0.0261, 0.0364, 0.0246, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0023, 0.0291, 0.0384, 0.0240, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 576 in 0.7039721012115479 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0226, 0.0020, 0.0238, 0.0353, 0.0231, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0268, 0.0385, 0.0247, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6693530082702637 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0024, 0.0296, 0.0383, 0.0269, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0024, 0.0273, 0.0394, 0.0243, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6874420642852783 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0257, 0.0028, 0.0293, 0.0367, 0.0253, 0.0031]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0024, 0.0272, 0.0373, 0.0250, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6883573532104492 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0257, 0.0026, 0.0236, 0.0366, 0.0231, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0253, 0.0025, 0.0270, 0.0378, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.8015239238739014 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0257, 0.0026, 0.0290, 0.0389, 0.0240, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0023, 0.0273, 0.0401, 0.0237, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6741847991943359 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0239, 0.0020, 0.0315, 0.0383, 0.0237, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0025, 0.0267, 0.0360, 0.0234, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.7506313323974609 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0261, 0.0024, 0.0288, 0.0402, 0.0257, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0024, 0.0278, 0.0395, 0.0240, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.8011784553527832 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0247, 0.0024, 0.0265, 0.0380, 0.0249, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0256, 0.0024, 0.0267, 0.0388, 0.0238, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6428256034851074 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0018, 0.0261, 0.0342, 0.0240, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0023, 0.0285, 0.0411, 0.0242, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6740961074829102 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0236, 0.0025, 0.0257, 0.0382, 0.0232, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0269, 0.0025, 0.0284, 0.0407, 0.0254, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.7608237266540527 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0244, 0.0025, 0.0233, 0.0374, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0282, 0.0394, 0.0244, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6825523376464844 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0024, 0.0260, 0.0407, 0.0273, 0.0025]) \n",
      "Test Loss tensor([0.0018, 0.0270, 0.0024, 0.0282, 0.0381, 0.0235, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6594116687774658 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0024, 0.0341, 0.0407, 0.0216, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0024, 0.0273, 0.0389, 0.0231, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6620783805847168 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0247, 0.0021, 0.0274, 0.0387, 0.0248, 0.0027]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0023, 0.0285, 0.0401, 0.0257, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6466007232666016 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0267, 0.0021, 0.0279, 0.0416, 0.0256, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0255, 0.0023, 0.0290, 0.0377, 0.0238, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6230032444000244 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0285, 0.0028, 0.0296, 0.0391, 0.0259, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0269, 0.0023, 0.0293, 0.0403, 0.0239, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6655912399291992 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0026, 0.0242, 0.0408, 0.0235, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0266, 0.0024, 0.0291, 0.0404, 0.0258, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6156272888183594 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0277, 0.0028, 0.0285, 0.0386, 0.0242, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0280, 0.0391, 0.0241, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6220464706420898 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0277, 0.0019, 0.0260, 0.0371, 0.0249, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0275, 0.0024, 0.0279, 0.0416, 0.0245, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6366753578186035 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0278, 0.0019, 0.0226, 0.0402, 0.0238, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0259, 0.0024, 0.0280, 0.0378, 0.0241, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6351785659790039 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0264, 0.0023, 0.0252, 0.0355, 0.0254, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0023, 0.0280, 0.0395, 0.0252, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6225681304931641 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0263, 0.0029, 0.0314, 0.0406, 0.0261, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0024, 0.0268, 0.0369, 0.0245, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.605614423751831 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0235, 0.0024, 0.0261, 0.0356, 0.0229, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0279, 0.0399, 0.0234, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6361310482025146 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0255, 0.0020, 0.0266, 0.0416, 0.0243, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0283, 0.0375, 0.0242, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6387090682983398 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0259, 0.0025, 0.0233, 0.0369, 0.0228, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0022, 0.0261, 0.0382, 0.0252, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6255958080291748 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0286, 0.0025, 0.0247, 0.0406, 0.0254, 0.0022]) \n",
      "Test Loss tensor([0.0017, 0.0268, 0.0025, 0.0267, 0.0395, 0.0240, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.630145788192749 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0024, 0.0302, 0.0399, 0.0256, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0251, 0.0024, 0.0277, 0.0377, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.588470458984375 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0254, 0.0022, 0.0241, 0.0362, 0.0236, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0260, 0.0024, 0.0276, 0.0370, 0.0250, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.631831169128418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0265, 0.0031, 0.0321, 0.0374, 0.0233, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0264, 0.0385, 0.0238, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.5826561450958252 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0246, 0.0021, 0.0234, 0.0392, 0.0256, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0022, 0.0302, 0.0387, 0.0235, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7397677898406982 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0285, 0.0023, 0.0282, 0.0410, 0.0230, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0277, 0.0385, 0.0226, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6837503910064697 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0260, 0.0021, 0.0316, 0.0390, 0.0225, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0023, 0.0276, 0.0386, 0.0242, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6539440155029297 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0243, 0.0020, 0.0301, 0.0370, 0.0239, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0024, 0.0294, 0.0380, 0.0238, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6232824325561523 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0264, 0.0030, 0.0277, 0.0352, 0.0225, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0253, 0.0023, 0.0268, 0.0382, 0.0237, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6041865348815918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0292, 0.0023, 0.0287, 0.0362, 0.0260, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0023, 0.0271, 0.0378, 0.0232, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.600775957107544 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0244, 0.0026, 0.0265, 0.0377, 0.0241, 0.0029]) \n",
      "Test Loss tensor([0.0018, 0.0247, 0.0024, 0.0282, 0.0389, 0.0234, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 720 in 0.6178164482116699 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0023, 0.0357, 0.0402, 0.0253, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0023, 0.0278, 0.0378, 0.0234, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.5927903652191162 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0293, 0.0023, 0.0258, 0.0377, 0.0243, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0251, 0.0025, 0.0273, 0.0383, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.60819411277771 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0275, 0.0025, 0.0238, 0.0372, 0.0223, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0255, 0.0023, 0.0276, 0.0390, 0.0231, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6017529964447021 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0247, 0.0023, 0.0267, 0.0390, 0.0235, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0023, 0.0285, 0.0386, 0.0230, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6097006797790527 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0259, 0.0033, 0.0262, 0.0405, 0.0260, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0024, 0.0268, 0.0383, 0.0244, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6292307376861572 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0273, 0.0023, 0.0264, 0.0393, 0.0253, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0026, 0.0288, 0.0382, 0.0232, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6020443439483643 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0291, 0.0027, 0.0246, 0.0403, 0.0252, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0262, 0.0367, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6055185794830322 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0256, 0.0023, 0.0221, 0.0371, 0.0257, 0.0028]) \n",
      "Test Loss tensor([0.0018, 0.0256, 0.0025, 0.0282, 0.0376, 0.0235, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6562879085540771 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0248, 0.0023, 0.0267, 0.0392, 0.0241, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0288, 0.0401, 0.0242, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6345455646514893 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0278, 0.0022, 0.0232, 0.0367, 0.0289, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0026, 0.0280, 0.0385, 0.0239, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.655231237411499 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0259, 0.0023, 0.0264, 0.0386, 0.0263, 0.0032]) \n",
      "Test Loss tensor([0.0017, 0.0256, 0.0024, 0.0283, 0.0395, 0.0232, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6390500068664551 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0318, 0.0023, 0.0316, 0.0363, 0.0246, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0286, 0.0384, 0.0244, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6562888622283936 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0024, 0.0245, 0.0372, 0.0268, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0025, 0.0275, 0.0385, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6760859489440918 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0266, 0.0025, 0.0255, 0.0421, 0.0259, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0264, 0.0024, 0.0267, 0.0381, 0.0242, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6535148620605469 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0021, 0.0318, 0.0385, 0.0247, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0024, 0.0274, 0.0378, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6442549228668213 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0267, 0.0022, 0.0271, 0.0383, 0.0240, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0025, 0.0272, 0.0367, 0.0231, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6443514823913574 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0252, 0.0019, 0.0281, 0.0365, 0.0216, 0.0021]) \n",
      "Test Loss tensor([0.0017, 0.0252, 0.0024, 0.0270, 0.0374, 0.0233, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.645484209060669 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0271, 0.0027, 0.0275, 0.0381, 0.0254, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0022, 0.0281, 0.0392, 0.0232, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.663297176361084 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0248, 0.0026, 0.0260, 0.0386, 0.0220, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0254, 0.0024, 0.0274, 0.0368, 0.0235, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.715634822845459 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0264, 0.0022, 0.0278, 0.0405, 0.0221, 0.0026]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0024, 0.0281, 0.0377, 0.0239, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6526243686676025 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0247, 0.0023, 0.0228, 0.0403, 0.0229, 0.0027]) \n",
      "Test Loss tensor([0.0017, 0.0254, 0.0023, 0.0270, 0.0382, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.627436637878418 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0255, 0.0023, 0.0254, 0.0400, 0.0224, 0.0023]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0024, 0.0274, 0.0379, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.7289426326751709 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0248, 0.0027, 0.0219, 0.0341, 0.0207, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0263, 0.0025, 0.0274, 0.0380, 0.0238, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6529793739318848 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0019, 0.0257, 0.0023, 0.0294, 0.0360, 0.0244, 0.0029]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0267, 0.0376, 0.0234, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6875059604644775 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0262, 0.0031, 0.0265, 0.0355, 0.0276, 0.0023]) \n",
      "Test Loss tensor([0.0018, 0.0256, 0.0024, 0.0273, 0.0384, 0.0237, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6944007873535156 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0028, 0.0287, 0.0373, 0.0261, 0.0031]) \n",
      "Test Loss tensor([0.0018, 0.0266, 0.0025, 0.0287, 0.0381, 0.0232, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6765804290771484 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0237, 0.0022, 0.0253, 0.0357, 0.0282, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0024, 0.0280, 0.0393, 0.0237, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6286849975585938 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0021, 0.0228, 0.0379, 0.0223, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0265, 0.0022, 0.0290, 0.0369, 0.0232, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6856200695037842 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0249, 0.0021, 0.0257, 0.0397, 0.0244, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0259, 0.0025, 0.0274, 0.0387, 0.0231, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.7345561981201172 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0256, 0.0021, 0.0267, 0.0334, 0.0242, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0258, 0.0023, 0.0280, 0.0385, 0.0236, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.7379422187805176 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0269, 0.0023, 0.0298, 0.0403, 0.0233, 0.0025]) \n",
      "Test Loss tensor([0.0017, 0.0253, 0.0024, 0.0268, 0.0380, 0.0232, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.631436824798584 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0016, 0.0254, 0.0028, 0.0243, 0.0371, 0.0226, 0.0034]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0024, 0.0270, 0.0370, 0.0233, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6547915935516357 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0272, 0.0029, 0.0263, 0.0384, 0.0272, 0.0024]) \n",
      "Test Loss tensor([0.0018, 0.0261, 0.0024, 0.0275, 0.0374, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.7766077518463135 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0272, 0.0023, 0.0274, 0.0369, 0.0240, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0261, 0.0023, 0.0280, 0.0375, 0.0237, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.5961933135986328 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0025, 0.0298, 0.0430, 0.0255, 0.0026]) \n",
      "Test Loss tensor([0.0018, 0.0267, 0.0024, 0.0294, 0.0372, 0.0242, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7149784564971924 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0262, 0.0020, 0.0271, 0.0368, 0.0252, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0254, 0.0024, 0.0279, 0.0379, 0.0234, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 864 in 0.6014962196350098 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0270, 0.0025, 0.0225, 0.0364, 0.0257, 0.0030]) \n",
      "Test Loss tensor([0.0017, 0.0260, 0.0026, 0.0265, 0.0372, 0.0243, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.5851922035217285 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0017, 0.0274, 0.0021, 0.0300, 0.0411, 0.0301, 0.0024]) \n",
      "Test Loss tensor([0.0017, 0.0262, 0.0025, 0.0273, 0.0374, 0.0236, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.593879222869873 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0018, 0.0254, 0.0020, 0.0264, 0.0401, 0.0236, 0.0028]) \n",
      "Test Loss tensor([0.0017, 0.0267, 0.0024, 0.0289, 0.0378, 0.0236, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6102869510650635 **************\n",
      "\n",
      "Training Idx 5 \n",
      "Train Loss tensor([0.0012, 0.0206, 0.0015, 0.0160, 0.0273, 0.0171, 0.0017]) \n",
      "Test Loss tensor([0.0017, 0.0257, 0.0024, 0.0275, 0.0373, 0.0245, 0.0025])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.7472286224365234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4840, 0.4755, 0.4355, 0.4382, 0.4382, 0.4860, 0.3931, 0.4875]) \n",
      "Test Loss tensor([0.4834, 0.4757, 0.4380, 0.4404, 0.4400, 0.4863, 0.3925, 0.4860])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.8184876441955566 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4836, 0.4730, 0.4379, 0.4404, 0.4387, 0.4866, 0.3925, 0.4853]) \n",
      "Test Loss tensor([0.4818, 0.4740, 0.4390, 0.4414, 0.4410, 0.4847, 0.3914, 0.4844])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7043814659118652 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4822, 0.4773, 0.4375, 0.4418, 0.4409, 0.4850, 0.3920, 0.4843]) \n",
      "Test Loss tensor([0.4804, 0.4726, 0.4404, 0.4435, 0.4430, 0.4830, 0.3915, 0.4829])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7536087036132812 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4807, 0.4725, 0.4401, 0.4434, 0.4420, 0.4816, 0.3897, 0.4843]) \n",
      "Test Loss tensor([0.4797, 0.4716, 0.4415, 0.4439, 0.4440, 0.4812, 0.3912, 0.4813])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6865642070770264 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4785, 0.4722, 0.4407, 0.4445, 0.4440, 0.4808, 0.3922, 0.4820]) \n",
      "Test Loss tensor([0.4773, 0.4700, 0.4435, 0.4458, 0.4456, 0.4799, 0.3906, 0.4797])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7195456027984619 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4784, 0.4709, 0.4442, 0.4467, 0.4454, 0.4787, 0.3913, 0.4803]) \n",
      "Test Loss tensor([0.4765, 0.4691, 0.4450, 0.4472, 0.4472, 0.4784, 0.3901, 0.4782])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6606810092926025 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4744, 0.4704, 0.4448, 0.4487, 0.4468, 0.4796, 0.3897, 0.4788]) \n",
      "Test Loss tensor([0.4745, 0.4678, 0.4466, 0.4483, 0.4481, 0.4769, 0.3906, 0.4769])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.9775612354278564 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4757, 0.4672, 0.4468, 0.4487, 0.4483, 0.4763, 0.3883, 0.4769]) \n",
      "Test Loss tensor([0.4733, 0.4667, 0.4479, 0.4498, 0.4502, 0.4755, 0.3912, 0.4752])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.828984260559082 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4746, 0.4663, 0.4481, 0.4507, 0.4508, 0.4740, 0.3859, 0.4745]) \n",
      "Test Loss tensor([0.4716, 0.4650, 0.4492, 0.4510, 0.4517, 0.4742, 0.3905, 0.4737])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.8456296920776367 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4723, 0.4657, 0.4490, 0.4516, 0.4528, 0.4729, 0.3906, 0.4754]) \n",
      "Test Loss tensor([0.4701, 0.4638, 0.4505, 0.4525, 0.4535, 0.4723, 0.3927, 0.4724])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.8898074626922607 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4705, 0.4662, 0.4510, 0.4524, 0.4514, 0.4712, 0.3884, 0.4718]) \n",
      "Test Loss tensor([0.4688, 0.4626, 0.4518, 0.4539, 0.4544, 0.4709, 0.3912, 0.4711])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6460566520690918 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4698, 0.4615, 0.4506, 0.4543, 0.4537, 0.4713, 0.3894, 0.4716]) \n",
      "Test Loss tensor([0.4672, 0.4606, 0.4537, 0.4546, 0.4558, 0.4694, 0.3904, 0.4690])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6815366744995117 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4670, 0.4603, 0.4520, 0.4561, 0.4558, 0.4692, 0.3910, 0.4693]) \n",
      "Test Loss tensor([0.4654, 0.4600, 0.4554, 0.4563, 0.4577, 0.4680, 0.3914, 0.4675])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6711921691894531 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4671, 0.4599, 0.4553, 0.4559, 0.4566, 0.4681, 0.3882, 0.4666]) \n",
      "Test Loss tensor([0.4651, 0.4591, 0.4561, 0.4576, 0.4585, 0.4664, 0.3904, 0.4659])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6968722343444824 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4654, 0.4582, 0.4555, 0.4573, 0.4597, 0.4660, 0.3905, 0.4674]) \n",
      "Test Loss tensor([0.4631, 0.4580, 0.4578, 0.4590, 0.4601, 0.4645, 0.3906, 0.4648])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6668097972869873 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4647, 0.4587, 0.4566, 0.4601, 0.4607, 0.4647, 0.3945, 0.4644]) \n",
      "Test Loss tensor([0.4619, 0.4561, 0.4596, 0.4602, 0.4624, 0.4631, 0.3910, 0.4629])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.684535026550293 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4627, 0.4546, 0.4587, 0.4611, 0.4605, 0.4635, 0.3887, 0.4642]) \n",
      "Test Loss tensor([0.4602, 0.4545, 0.4608, 0.4619, 0.4639, 0.4620, 0.3892, 0.4616])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6417033672332764 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4607, 0.4530, 0.4602, 0.4610, 0.4633, 0.4612, 0.3874, 0.4610]) \n",
      "Test Loss tensor([0.4592, 0.4538, 0.4623, 0.4636, 0.4652, 0.4600, 0.3898, 0.4593])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.8772392272949219 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4609, 0.4524, 0.4634, 0.4633, 0.4643, 0.4595, 0.3892, 0.4602]) \n",
      "Test Loss tensor([0.4578, 0.4523, 0.4637, 0.4648, 0.4665, 0.4586, 0.3885, 0.4582])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7883796691894531 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4576, 0.4514, 0.4632, 0.4650, 0.4646, 0.4592, 0.3924, 0.4601]) \n",
      "Test Loss tensor([0.4556, 0.4513, 0.4649, 0.4656, 0.4678, 0.4573, 0.3892, 0.4573])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.939488410949707 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4557, 0.4500, 0.4643, 0.4654, 0.4672, 0.4587, 0.3929, 0.4568]) \n",
      "Test Loss tensor([0.4545, 0.4501, 0.4667, 0.4667, 0.4692, 0.4557, 0.3901, 0.4558])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.8671455383300781 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4553, 0.4481, 0.4667, 0.4678, 0.4694, 0.4554, 0.3883, 0.4565]) \n",
      "Test Loss tensor([0.4533, 0.4485, 0.4680, 0.4684, 0.4715, 0.4546, 0.3896, 0.4542])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.7280969619750977 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4529, 0.4486, 0.4667, 0.4689, 0.4707, 0.4541, 0.3889, 0.4538]) \n",
      "Test Loss tensor([0.4515, 0.4470, 0.4695, 0.4697, 0.4723, 0.4529, 0.3898, 0.4528])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.873671293258667 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4514, 0.4473, 0.4683, 0.4707, 0.4727, 0.4526, 0.3935, 0.4526]) \n",
      "Test Loss tensor([0.4504, 0.4464, 0.4710, 0.4709, 0.4740, 0.4513, 0.3895, 0.4509])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7773714065551758 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4516, 0.4466, 0.4707, 0.4725, 0.4734, 0.4507, 0.3899, 0.4506]) \n",
      "Test Loss tensor([0.4488, 0.4446, 0.4726, 0.4725, 0.4756, 0.4498, 0.3895, 0.4493])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.791795015335083 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4504, 0.4454, 0.4706, 0.4724, 0.4763, 0.4504, 0.3891, 0.4501]) \n",
      "Test Loss tensor([0.4475, 0.4436, 0.4741, 0.4737, 0.4768, 0.4485, 0.3887, 0.4478])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.9232139587402344 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4491, 0.4426, 0.4734, 0.4755, 0.4775, 0.4487, 0.3929, 0.4480]) \n",
      "Test Loss tensor([0.4457, 0.4426, 0.4753, 0.4749, 0.4787, 0.4470, 0.3897, 0.4465])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.9516677856445312 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4460, 0.4425, 0.4735, 0.4748, 0.4777, 0.4488, 0.3897, 0.4462]) \n",
      "Test Loss tensor([0.4442, 0.4410, 0.4767, 0.4770, 0.4803, 0.4455, 0.3902, 0.4448])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7874798774719238 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4445, 0.4403, 0.4780, 0.4747, 0.4804, 0.4459, 0.3915, 0.4453]) \n",
      "Test Loss tensor([0.4432, 0.4401, 0.4781, 0.4779, 0.4819, 0.4438, 0.3883, 0.4431])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.7778847217559814 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4424, 0.4392, 0.4778, 0.4781, 0.4804, 0.4454, 0.3883, 0.4427]) \n",
      "Test Loss tensor([0.4414, 0.4384, 0.4805, 0.4792, 0.4833, 0.4427, 0.3898, 0.4419])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7834570407867432 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4415, 0.4364, 0.4812, 0.4800, 0.4830, 0.4428, 0.3905, 0.4425]) \n",
      "Test Loss tensor([0.4401, 0.4370, 0.4813, 0.4803, 0.4849, 0.4405, 0.3896, 0.4410])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.8258669376373291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4400, 0.4368, 0.4818, 0.4816, 0.4846, 0.4414, 0.3886, 0.4405]) \n",
      "Test Loss tensor([0.4389, 0.4361, 0.4826, 0.4816, 0.4861, 0.4399, 0.3889, 0.4393])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.810056209564209 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4400, 0.4365, 0.4825, 0.4820, 0.4854, 0.4393, 0.3915, 0.4391]) \n",
      "Test Loss tensor([0.4376, 0.4345, 0.4841, 0.4835, 0.4875, 0.4378, 0.3894, 0.4375])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.9842159748077393 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4358, 0.4358, 0.4844, 0.4840, 0.4876, 0.4376, 0.3883, 0.4379]) \n",
      "Test Loss tensor([0.4359, 0.4336, 0.4856, 0.4849, 0.4890, 0.4367, 0.3898, 0.4361])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 136 in 0.7691977024078369 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4367, 0.4347, 0.4860, 0.4855, 0.4880, 0.4355, 0.3912, 0.4362]) \n",
      "Test Loss tensor([0.4344, 0.4324, 0.4873, 0.4859, 0.4906, 0.4352, 0.3896, 0.4350])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7736284732818604 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4337, 0.4328, 0.4874, 0.4855, 0.4915, 0.4348, 0.3875, 0.4346]) \n",
      "Test Loss tensor([0.4327, 0.4318, 0.4892, 0.4874, 0.4922, 0.4339, 0.3893, 0.4334])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.8052802085876465 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4328, 0.4318, 0.4886, 0.4889, 0.4907, 0.4341, 0.3877, 0.4337]) \n",
      "Test Loss tensor([0.4320, 0.4302, 0.4896, 0.4885, 0.4941, 0.4325, 0.3897, 0.4322])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7635929584503174 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4309, 0.4296, 0.4897, 0.4892, 0.4935, 0.4323, 0.3884, 0.4324]) \n",
      "Test Loss tensor([0.4306, 0.4285, 0.4914, 0.4900, 0.4953, 0.4308, 0.3886, 0.4308])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7858140468597412 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4321, 0.4273, 0.4892, 0.4901, 0.4944, 0.4294, 0.3867, 0.4311]) \n",
      "Test Loss tensor([0.4292, 0.4279, 0.4930, 0.4917, 0.4970, 0.4296, 0.3902, 0.4295])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7772500514984131 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4289, 0.4271, 0.4911, 0.4930, 0.4950, 0.4298, 0.3899, 0.4294]) \n",
      "Test Loss tensor([0.4282, 0.4267, 0.4943, 0.4924, 0.4983, 0.4283, 0.3884, 0.4280])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.8046696186065674 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4282, 0.4265, 0.4947, 0.4907, 0.4984, 0.4295, 0.3904, 0.4287]) \n",
      "Test Loss tensor([0.4267, 0.4253, 0.4958, 0.4939, 0.4996, 0.4269, 0.3884, 0.4262])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.8490972518920898 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4265, 0.4269, 0.4961, 0.4944, 0.4984, 0.4268, 0.3888, 0.4244]) \n",
      "Test Loss tensor([0.4261, 0.4242, 0.4970, 0.4951, 0.5008, 0.4253, 0.3890, 0.4254])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.7959895133972168 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4237, 0.4242, 0.4980, 0.4956, 0.5012, 0.4240, 0.3880, 0.4242]) \n",
      "Test Loss tensor([0.4240, 0.4229, 0.4983, 0.4963, 0.5029, 0.4242, 0.3901, 0.4237])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.8109703063964844 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4254, 0.4248, 0.4986, 0.4960, 0.5023, 0.4239, 0.3860, 0.4228]) \n",
      "Test Loss tensor([0.4225, 0.4223, 0.4995, 0.4982, 0.5040, 0.4228, 0.3886, 0.4229])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.8110835552215576 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4234, 0.4214, 0.5004, 0.4982, 0.5033, 0.4232, 0.3862, 0.4233]) \n",
      "Test Loss tensor([0.4215, 0.4207, 0.5015, 0.4992, 0.5058, 0.4214, 0.3886, 0.4207])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.8404476642608643 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4206, 0.4200, 0.5014, 0.4987, 0.5059, 0.4216, 0.3878, 0.4204]) \n",
      "Test Loss tensor([0.4205, 0.4191, 0.5032, 0.5000, 0.5072, 0.4201, 0.3883, 0.4194])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.800015926361084 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4206, 0.4204, 0.5043, 0.4996, 0.5062, 0.4199, 0.3887, 0.4208]) \n",
      "Test Loss tensor([0.4194, 0.4188, 0.5041, 0.5018, 0.5077, 0.4187, 0.3887, 0.4187])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.8968079090118408 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4205, 0.4187, 0.5012, 0.5016, 0.5068, 0.4188, 0.3881, 0.4187]) \n",
      "Test Loss tensor([0.4187, 0.4184, 0.5054, 0.5026, 0.5091, 0.4179, 0.3894, 0.4179])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.7714040279388428 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4179, 0.4176, 0.5047, 0.5024, 0.5087, 0.4170, 0.3874, 0.4184]) \n",
      "Test Loss tensor([0.4172, 0.4169, 0.5065, 0.5040, 0.5103, 0.4165, 0.3882, 0.4166])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.7614080905914307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4170, 0.4177, 0.5063, 0.5037, 0.5103, 0.4152, 0.3849, 0.4168]) \n",
      "Test Loss tensor([0.4154, 0.4159, 0.5075, 0.5048, 0.5114, 0.4152, 0.3865, 0.4151])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.7477657794952393 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4174, 0.4157, 0.5059, 0.5044, 0.5108, 0.4165, 0.3877, 0.4152]) \n",
      "Test Loss tensor([0.4142, 0.4145, 0.5089, 0.5056, 0.5128, 0.4143, 0.3887, 0.4140])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.7774648666381836 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4152, 0.4157, 0.5077, 0.5065, 0.5132, 0.4148, 0.3902, 0.4148]) \n",
      "Test Loss tensor([0.4136, 0.4138, 0.5102, 0.5073, 0.5138, 0.4129, 0.3878, 0.4128])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.7988917827606201 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4141, 0.4124, 0.5082, 0.5070, 0.5139, 0.4124, 0.3898, 0.4129]) \n",
      "Test Loss tensor([0.4126, 0.4129, 0.5110, 0.5084, 0.5152, 0.4122, 0.3881, 0.4115])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.8042700290679932 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4122, 0.4130, 0.5102, 0.5078, 0.5149, 0.4116, 0.3873, 0.4117]) \n",
      "Test Loss tensor([0.4108, 0.4117, 0.5128, 0.5092, 0.5169, 0.4106, 0.3880, 0.4107])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7975673675537109 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4105, 0.4142, 0.5123, 0.5082, 0.5151, 0.4117, 0.3878, 0.4101]) \n",
      "Test Loss tensor([0.4101, 0.4112, 0.5136, 0.5109, 0.5183, 0.4092, 0.3885, 0.4088])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.789647102355957 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4083, 0.4105, 0.5132, 0.5117, 0.5187, 0.4100, 0.3880, 0.4091]) \n",
      "Test Loss tensor([0.4086, 0.4097, 0.5152, 0.5117, 0.5198, 0.4084, 0.3883, 0.4075])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.7821004390716553 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4092, 0.4103, 0.5163, 0.5126, 0.5188, 0.4089, 0.3896, 0.4068]) \n",
      "Test Loss tensor([0.4078, 0.4091, 0.5165, 0.5128, 0.5208, 0.4066, 0.3885, 0.4067])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.852933406829834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4085, 0.4070, 0.5162, 0.5132, 0.5184, 0.4080, 0.3906, 0.4072]) \n",
      "Test Loss tensor([0.4063, 0.4073, 0.5179, 0.5141, 0.5217, 0.4056, 0.3885, 0.4058])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.8389077186584473 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4058, 0.4069, 0.5156, 0.5149, 0.5232, 0.4062, 0.3906, 0.4057]) \n",
      "Test Loss tensor([0.4052, 0.4067, 0.5194, 0.5157, 0.5240, 0.4050, 0.3878, 0.4040])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.8077397346496582 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4076, 0.4082, 0.5178, 0.5144, 0.5237, 0.4035, 0.3853, 0.4046]) \n",
      "Test Loss tensor([0.4043, 0.4057, 0.5202, 0.5161, 0.5252, 0.4033, 0.3879, 0.4031])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.800356388092041 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4052, 0.4047, 0.5218, 0.5166, 0.5253, 0.4028, 0.3859, 0.4023]) \n",
      "Test Loss tensor([0.4030, 0.4051, 0.5212, 0.5176, 0.5256, 0.4020, 0.3877, 0.4018])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.8176257610321045 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4038, 0.4050, 0.5200, 0.5179, 0.5255, 0.4018, 0.3866, 0.4011]) \n",
      "Test Loss tensor([0.4020, 0.4039, 0.5230, 0.5192, 0.5278, 0.4008, 0.3888, 0.4007])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.8004012107849121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4013, 0.4021, 0.5228, 0.5178, 0.5264, 0.4008, 0.3881, 0.4001]) \n",
      "Test Loss tensor([0.4005, 0.4030, 0.5243, 0.5202, 0.5292, 0.3995, 0.3905, 0.3998])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.8076550960540771 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.4012, 0.4031, 0.5244, 0.5202, 0.5276, 0.3979, 0.3895, 0.3984]) \n",
      "Test Loss tensor([0.3997, 0.4020, 0.5250, 0.5211, 0.5304, 0.3984, 0.3886, 0.3985])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.8217475414276123 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3983, 0.4037, 0.5258, 0.5204, 0.5286, 0.3989, 0.3845, 0.3996]) \n",
      "Test Loss tensor([0.3982, 0.4007, 0.5272, 0.5225, 0.5318, 0.3972, 0.3884, 0.3968])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7826128005981445 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3980, 0.4016, 0.5247, 0.5236, 0.5308, 0.3977, 0.3867, 0.3962]) \n",
      "Test Loss tensor([0.3967, 0.4000, 0.5280, 0.5241, 0.5330, 0.3957, 0.3867, 0.3951])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.7844600677490234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3978, 0.3988, 0.5288, 0.5224, 0.5332, 0.3943, 0.3882, 0.3959]) \n",
      "Test Loss tensor([0.3954, 0.3984, 0.5299, 0.5254, 0.5347, 0.3947, 0.3886, 0.3942])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 268 in 0.7427000999450684 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3963, 0.3977, 0.5264, 0.5252, 0.5325, 0.3947, 0.3937, 0.3944]) \n",
      "Test Loss tensor([0.3948, 0.3979, 0.5307, 0.5261, 0.5356, 0.3934, 0.3871, 0.3928])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7798924446105957 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3940, 0.3985, 0.5300, 0.5260, 0.5337, 0.3924, 0.3888, 0.3937]) \n",
      "Test Loss tensor([0.3930, 0.3961, 0.5322, 0.5279, 0.5374, 0.3916, 0.3881, 0.3918])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.8030047416687012 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3926, 0.3970, 0.5325, 0.5298, 0.5362, 0.3916, 0.3895, 0.3915]) \n",
      "Test Loss tensor([0.3919, 0.3955, 0.5337, 0.5289, 0.5388, 0.3909, 0.3879, 0.3905])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.8076670169830322 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3908, 0.3944, 0.5358, 0.5310, 0.5384, 0.3907, 0.3873, 0.3916]) \n",
      "Test Loss tensor([0.3911, 0.3947, 0.5351, 0.5305, 0.5401, 0.3892, 0.3870, 0.3889])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7785143852233887 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3916, 0.3930, 0.5347, 0.5294, 0.5399, 0.3901, 0.3886, 0.3879]) \n",
      "Test Loss tensor([0.3899, 0.3931, 0.5365, 0.5319, 0.5414, 0.3881, 0.3875, 0.3884])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.7733614444732666 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3891, 0.3943, 0.5355, 0.5336, 0.5412, 0.3870, 0.3877, 0.3883]) \n",
      "Test Loss tensor([0.3882, 0.3919, 0.5380, 0.5334, 0.5435, 0.3870, 0.3890, 0.3868])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.7672584056854248 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3885, 0.3925, 0.5392, 0.5342, 0.5423, 0.3876, 0.3836, 0.3852]) \n",
      "Test Loss tensor([0.3871, 0.3912, 0.5396, 0.5333, 0.5450, 0.3856, 0.3862, 0.3851])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.825660228729248 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3871, 0.3920, 0.5390, 0.5342, 0.5429, 0.3843, 0.3844, 0.3847]) \n",
      "Test Loss tensor([0.3858, 0.3902, 0.5405, 0.5355, 0.5461, 0.3843, 0.3898, 0.3842])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7570939064025879 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3852, 0.3894, 0.5389, 0.5356, 0.5462, 0.3842, 0.3852, 0.3823]) \n",
      "Test Loss tensor([0.3845, 0.3892, 0.5414, 0.5371, 0.5475, 0.3826, 0.3886, 0.3830])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.8019778728485107 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3834, 0.3894, 0.5420, 0.5363, 0.5473, 0.3818, 0.3915, 0.3837]) \n",
      "Test Loss tensor([0.3823, 0.3881, 0.5444, 0.5384, 0.5493, 0.3815, 0.3886, 0.3814])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7732346057891846 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3835, 0.3878, 0.5436, 0.5379, 0.5502, 0.3825, 0.3878, 0.3820]) \n",
      "Test Loss tensor([0.3818, 0.3861, 0.5457, 0.5399, 0.5509, 0.3802, 0.3880, 0.3801])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7575368881225586 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3820, 0.3870, 0.5467, 0.5401, 0.5491, 0.3786, 0.3907, 0.3806]) \n",
      "Test Loss tensor([0.3804, 0.3862, 0.5462, 0.5409, 0.5519, 0.3790, 0.3882, 0.3790])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7633726596832275 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3805, 0.3871, 0.5480, 0.5408, 0.5517, 0.3794, 0.3915, 0.3771]) \n",
      "Test Loss tensor([0.3792, 0.3845, 0.5484, 0.5420, 0.5539, 0.3773, 0.3883, 0.3775])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7667722702026367 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3793, 0.3826, 0.5474, 0.5430, 0.5535, 0.3765, 0.3851, 0.3778]) \n",
      "Test Loss tensor([0.3775, 0.3837, 0.5501, 0.5437, 0.5550, 0.3762, 0.3885, 0.3760])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7904791831970215 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3791, 0.3834, 0.5502, 0.5427, 0.5553, 0.3759, 0.3891, 0.3750]) \n",
      "Test Loss tensor([0.3760, 0.3819, 0.5517, 0.5452, 0.5571, 0.3751, 0.3881, 0.3748])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.7790994644165039 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3765, 0.3824, 0.5493, 0.5471, 0.5564, 0.3724, 0.3895, 0.3737]) \n",
      "Test Loss tensor([0.3750, 0.3808, 0.5531, 0.5468, 0.5586, 0.3735, 0.3884, 0.3734])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.7899692058563232 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3764, 0.3822, 0.5522, 0.5463, 0.5575, 0.3736, 0.3940, 0.3734]) \n",
      "Test Loss tensor([0.3731, 0.3792, 0.5547, 0.5481, 0.5599, 0.3718, 0.3881, 0.3716])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7709522247314453 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3745, 0.3794, 0.5531, 0.5495, 0.5597, 0.3721, 0.3865, 0.3722]) \n",
      "Test Loss tensor([0.3718, 0.3782, 0.5560, 0.5502, 0.5610, 0.3706, 0.3876, 0.3702])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.7746891975402832 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3730, 0.3787, 0.5556, 0.5496, 0.5614, 0.3700, 0.3867, 0.3696]) \n",
      "Test Loss tensor([0.3707, 0.3776, 0.5576, 0.5512, 0.5632, 0.3690, 0.3887, 0.3689])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.7954044342041016 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3695, 0.3774, 0.5567, 0.5507, 0.5633, 0.3691, 0.3888, 0.3704]) \n",
      "Test Loss tensor([0.3701, 0.3757, 0.5590, 0.5521, 0.5649, 0.3674, 0.3882, 0.3677])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.817021369934082 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3705, 0.3775, 0.5591, 0.5516, 0.5634, 0.3677, 0.3948, 0.3672]) \n",
      "Test Loss tensor([0.3674, 0.3750, 0.5616, 0.5539, 0.5671, 0.3660, 0.3894, 0.3665])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7551209926605225 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3677, 0.3757, 0.5595, 0.5538, 0.5663, 0.3651, 0.3892, 0.3660]) \n",
      "Test Loss tensor([0.3668, 0.3740, 0.5622, 0.5550, 0.5679, 0.3652, 0.3894, 0.3651])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.800724983215332 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3664, 0.3718, 0.5624, 0.5554, 0.5659, 0.3661, 0.3904, 0.3649]) \n",
      "Test Loss tensor([0.3653, 0.3729, 0.5640, 0.5568, 0.5697, 0.3632, 0.3900, 0.3635])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.8205549716949463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3657, 0.3697, 0.5633, 0.5575, 0.5698, 0.3640, 0.3923, 0.3648]) \n",
      "Test Loss tensor([0.3637, 0.3718, 0.5658, 0.5582, 0.5716, 0.3619, 0.3889, 0.3621])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.8701176643371582 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3644, 0.3713, 0.5660, 0.5590, 0.5697, 0.3612, 0.3909, 0.3617]) \n",
      "Test Loss tensor([0.3624, 0.3705, 0.5667, 0.5593, 0.5736, 0.3605, 0.3898, 0.3607])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.8780770301818848 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3628, 0.3692, 0.5669, 0.5604, 0.5740, 0.3603, 0.3850, 0.3605]) \n",
      "Test Loss tensor([0.3604, 0.3689, 0.5691, 0.5612, 0.5747, 0.3593, 0.3883, 0.3594])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7865808010101318 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3607, 0.3699, 0.5686, 0.5614, 0.5739, 0.3590, 0.3898, 0.3594]) \n",
      "Test Loss tensor([0.3593, 0.3683, 0.5706, 0.5629, 0.5768, 0.3572, 0.3891, 0.3580])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7648429870605469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3608, 0.3683, 0.5700, 0.5636, 0.5763, 0.3579, 0.3912, 0.3583]) \n",
      "Test Loss tensor([0.3574, 0.3669, 0.5723, 0.5649, 0.5788, 0.3564, 0.3893, 0.3563])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.775799036026001 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3587, 0.3676, 0.5684, 0.5624, 0.5797, 0.3556, 0.3929, 0.3567]) \n",
      "Test Loss tensor([0.3562, 0.3655, 0.5739, 0.5659, 0.5801, 0.3549, 0.3868, 0.3546])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.7799780368804932 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3564, 0.3639, 0.5744, 0.5666, 0.5805, 0.3537, 0.3876, 0.3543]) \n",
      "Test Loss tensor([0.3544, 0.3640, 0.5760, 0.5678, 0.5816, 0.3530, 0.3895, 0.3535])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.8705742359161377 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3540, 0.3649, 0.5756, 0.5668, 0.5797, 0.3528, 0.3863, 0.3524]) \n",
      "Test Loss tensor([0.3532, 0.3634, 0.5772, 0.5690, 0.5840, 0.3515, 0.3898, 0.3522])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7669198513031006 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3548, 0.3624, 0.5747, 0.5703, 0.5822, 0.3511, 0.3927, 0.3527]) \n",
      "Test Loss tensor([0.3516, 0.3611, 0.5796, 0.5714, 0.5852, 0.3500, 0.3881, 0.3502])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.7649688720703125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3514, 0.3623, 0.5791, 0.5707, 0.5839, 0.3498, 0.3877, 0.3527]) \n",
      "Test Loss tensor([0.3501, 0.3604, 0.5813, 0.5722, 0.5872, 0.3484, 0.3885, 0.3490])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 400 in 0.7728068828582764 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3498, 0.3591, 0.5799, 0.5724, 0.5845, 0.3475, 0.3865, 0.3481]) \n",
      "Test Loss tensor([0.3487, 0.3592, 0.5821, 0.5744, 0.5887, 0.3473, 0.3905, 0.3475])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7628269195556641 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3482, 0.3585, 0.5821, 0.5720, 0.5888, 0.3473, 0.3875, 0.3473]) \n",
      "Test Loss tensor([0.3467, 0.3577, 0.5854, 0.5758, 0.5911, 0.3457, 0.3890, 0.3461])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.7630918025970459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3464, 0.3583, 0.5857, 0.5748, 0.5891, 0.3460, 0.3892, 0.3461]) \n",
      "Test Loss tensor([0.3456, 0.3577, 0.5865, 0.5765, 0.5929, 0.3442, 0.3890, 0.3444])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.8397791385650635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3465, 0.3577, 0.5858, 0.5759, 0.5926, 0.3434, 0.3937, 0.3441]) \n",
      "Test Loss tensor([0.3439, 0.3551, 0.5883, 0.5786, 0.5952, 0.3425, 0.3901, 0.3429])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.8053817749023438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3442, 0.3551, 0.5869, 0.5800, 0.5936, 0.3431, 0.3892, 0.3429]) \n",
      "Test Loss tensor([0.3416, 0.3544, 0.5902, 0.5805, 0.5964, 0.3407, 0.3906, 0.3417])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.795924186706543 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3443, 0.3537, 0.5914, 0.5826, 0.5958, 0.3411, 0.3877, 0.3421]) \n",
      "Test Loss tensor([0.3401, 0.3525, 0.5913, 0.5824, 0.5983, 0.3394, 0.3898, 0.3399])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.8457260131835938 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3407, 0.3513, 0.5908, 0.5830, 0.5972, 0.3385, 0.3835, 0.3407]) \n",
      "Test Loss tensor([0.3383, 0.3512, 0.5938, 0.5836, 0.6006, 0.3375, 0.3892, 0.3385])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.7781081199645996 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3387, 0.3526, 0.5929, 0.5845, 0.6011, 0.3388, 0.3933, 0.3386]) \n",
      "Test Loss tensor([0.3363, 0.3495, 0.5958, 0.5859, 0.6024, 0.3361, 0.3879, 0.3371])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.8667798042297363 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3369, 0.3495, 0.5957, 0.5857, 0.6019, 0.3369, 0.3865, 0.3366]) \n",
      "Test Loss tensor([0.3350, 0.3486, 0.5974, 0.5873, 0.6050, 0.3344, 0.3908, 0.3356])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.8488309383392334 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3362, 0.3490, 0.5974, 0.5850, 0.6044, 0.3336, 0.3890, 0.3362]) \n",
      "Test Loss tensor([0.3331, 0.3472, 0.6001, 0.5891, 0.6065, 0.3328, 0.3911, 0.3339])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.8248946666717529 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3340, 0.3472, 0.5982, 0.5901, 0.6058, 0.3316, 0.3903, 0.3351]) \n",
      "Test Loss tensor([0.3311, 0.3466, 0.6013, 0.5904, 0.6081, 0.3311, 0.3891, 0.3321])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.8379509449005127 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3311, 0.3460, 0.6003, 0.5903, 0.6071, 0.3310, 0.3915, 0.3311]) \n",
      "Test Loss tensor([0.3291, 0.3448, 0.6038, 0.5919, 0.6107, 0.3290, 0.3912, 0.3306])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.88027024269104 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3297, 0.3448, 0.6035, 0.5943, 0.6104, 0.3305, 0.3848, 0.3306]) \n",
      "Test Loss tensor([0.3274, 0.3421, 0.6056, 0.5946, 0.6127, 0.3277, 0.3898, 0.3290])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.7746908664703369 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3295, 0.3468, 0.6030, 0.5920, 0.6107, 0.3282, 0.3906, 0.3281]) \n",
      "Test Loss tensor([0.3254, 0.3416, 0.6074, 0.5961, 0.6144, 0.3261, 0.3886, 0.3274])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.7166738510131836 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3251, 0.3390, 0.6070, 0.5971, 0.6143, 0.3246, 0.3855, 0.3279]) \n",
      "Test Loss tensor([0.3239, 0.3404, 0.6095, 0.5971, 0.6172, 0.3245, 0.3896, 0.3260])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7028021812438965 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3236, 0.3399, 0.6114, 0.5979, 0.6161, 0.3239, 0.3940, 0.3261]) \n",
      "Test Loss tensor([0.3211, 0.3392, 0.6118, 0.5998, 0.6188, 0.3227, 0.3900, 0.3242])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6174285411834717 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3217, 0.3391, 0.6109, 0.5987, 0.6194, 0.3212, 0.3921, 0.3237]) \n",
      "Test Loss tensor([0.3197, 0.3372, 0.6142, 0.6012, 0.6213, 0.3210, 0.3910, 0.3227])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6405789852142334 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3188, 0.3380, 0.6118, 0.6000, 0.6209, 0.3200, 0.3879, 0.3212]) \n",
      "Test Loss tensor([0.3171, 0.3360, 0.6160, 0.6033, 0.6231, 0.3192, 0.3899, 0.3210])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6837890148162842 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3161, 0.3338, 0.6165, 0.6073, 0.6227, 0.3186, 0.3899, 0.3222]) \n",
      "Test Loss tensor([0.3142, 0.3345, 0.6186, 0.6054, 0.6256, 0.3173, 0.3930, 0.3193])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6733932495117188 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3142, 0.3344, 0.6186, 0.6035, 0.6245, 0.3165, 0.3916, 0.3187]) \n",
      "Test Loss tensor([0.3131, 0.3327, 0.6203, 0.6070, 0.6274, 0.3154, 0.3885, 0.3176])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.7543158531188965 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3135, 0.3336, 0.6195, 0.6062, 0.6277, 0.3152, 0.3928, 0.3185]) \n",
      "Test Loss tensor([0.3104, 0.3322, 0.6225, 0.6091, 0.6297, 0.3138, 0.3910, 0.3160])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.68017578125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3094, 0.3299, 0.6197, 0.6098, 0.6275, 0.3129, 0.3836, 0.3145]) \n",
      "Test Loss tensor([0.3089, 0.3315, 0.6241, 0.6094, 0.6322, 0.3120, 0.3914, 0.3146])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6167809963226318 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3083, 0.3333, 0.6229, 0.6102, 0.6320, 0.3115, 0.3951, 0.3138]) \n",
      "Test Loss tensor([0.3059, 0.3291, 0.6267, 0.6123, 0.6346, 0.3100, 0.3917, 0.3128])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.8916959762573242 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3065, 0.3289, 0.6262, 0.6134, 0.6356, 0.3095, 0.3873, 0.3129]) \n",
      "Test Loss tensor([0.3031, 0.3268, 0.6293, 0.6142, 0.6370, 0.3087, 0.3926, 0.3114])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6530568599700928 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3047, 0.3276, 0.6292, 0.6132, 0.6363, 0.3077, 0.3859, 0.3116]) \n",
      "Test Loss tensor([0.3013, 0.3255, 0.6307, 0.6163, 0.6395, 0.3066, 0.3922, 0.3097])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6511895656585693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.3020, 0.3259, 0.6289, 0.6136, 0.6392, 0.3058, 0.3930, 0.3086]) \n",
      "Test Loss tensor([0.2990, 0.3242, 0.6333, 0.6171, 0.6422, 0.3048, 0.3903, 0.3081])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6726009845733643 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2977, 0.3220, 0.6343, 0.6190, 0.6406, 0.3036, 0.3963, 0.3076]) \n",
      "Test Loss tensor([0.2965, 0.3231, 0.6350, 0.6196, 0.6440, 0.3030, 0.3911, 0.3067])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6510272026062012 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2954, 0.3225, 0.6343, 0.6200, 0.6444, 0.3023, 0.3945, 0.3056]) \n",
      "Test Loss tensor([0.2939, 0.3216, 0.6376, 0.6217, 0.6459, 0.3012, 0.3917, 0.3052])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6801652908325195 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2929, 0.3207, 0.6408, 0.6218, 0.6447, 0.3007, 0.3964, 0.3045]) \n",
      "Test Loss tensor([0.2920, 0.3203, 0.6392, 0.6225, 0.6481, 0.3000, 0.3925, 0.3042])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.8076510429382324 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2908, 0.3184, 0.6398, 0.6244, 0.6484, 0.3006, 0.3956, 0.3037]) \n",
      "Test Loss tensor([0.2898, 0.3186, 0.6412, 0.6241, 0.6499, 0.2982, 0.3925, 0.3026])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.681861162185669 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2897, 0.3188, 0.6417, 0.6251, 0.6501, 0.2979, 0.3880, 0.3032]) \n",
      "Test Loss tensor([0.2874, 0.3175, 0.6432, 0.6252, 0.6516, 0.2972, 0.3926, 0.3015])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.7495324611663818 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2857, 0.3189, 0.6427, 0.6230, 0.6523, 0.2967, 0.3869, 0.3023]) \n",
      "Test Loss tensor([0.2847, 0.3177, 0.6446, 0.6257, 0.6534, 0.2956, 0.3935, 0.3002])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6242024898529053 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2868, 0.3172, 0.6433, 0.6248, 0.6536, 0.2942, 0.3946, 0.3009]) \n",
      "Test Loss tensor([0.2826, 0.3151, 0.6467, 0.6273, 0.6557, 0.2940, 0.3931, 0.2995])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 532 in 0.6077890396118164 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2815, 0.3134, 0.6484, 0.6288, 0.6565, 0.2935, 0.3930, 0.2990]) \n",
      "Test Loss tensor([0.2798, 0.3142, 0.6489, 0.6298, 0.6577, 0.2930, 0.3929, 0.2983])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6355316638946533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2815, 0.3162, 0.6437, 0.6281, 0.6573, 0.2934, 0.3932, 0.2995]) \n",
      "Test Loss tensor([0.2774, 0.3130, 0.6499, 0.6303, 0.6591, 0.2916, 0.3932, 0.2974])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6271288394927979 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2762, 0.3105, 0.6517, 0.6341, 0.6579, 0.2918, 0.3951, 0.2979]) \n",
      "Test Loss tensor([0.2752, 0.3111, 0.6515, 0.6322, 0.6609, 0.2906, 0.3922, 0.2966])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6674511432647705 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2749, 0.3142, 0.6527, 0.6292, 0.6600, 0.2896, 0.3987, 0.2957]) \n",
      "Test Loss tensor([0.2729, 0.3106, 0.6531, 0.6322, 0.6624, 0.2897, 0.3940, 0.2960])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.636162281036377 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2742, 0.3097, 0.6511, 0.6338, 0.6606, 0.2884, 0.3906, 0.2957]) \n",
      "Test Loss tensor([0.2714, 0.3110, 0.6537, 0.6316, 0.6633, 0.2889, 0.3930, 0.2952])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.9527914524078369 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2703, 0.3091, 0.6539, 0.6329, 0.6628, 0.2890, 0.3928, 0.2956]) \n",
      "Test Loss tensor([0.2689, 0.3104, 0.6548, 0.6329, 0.6645, 0.2879, 0.3924, 0.2950])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.7278871536254883 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2689, 0.3134, 0.6532, 0.6300, 0.6655, 0.2886, 0.3986, 0.2959]) \n",
      "Test Loss tensor([0.2672, 0.3096, 0.6553, 0.6330, 0.6653, 0.2870, 0.3932, 0.2947])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6414940357208252 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2678, 0.3106, 0.6552, 0.6345, 0.6644, 0.2868, 0.3931, 0.2936]) \n",
      "Test Loss tensor([0.2645, 0.3092, 0.6554, 0.6333, 0.6660, 0.2867, 0.3937, 0.2940])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.7105998992919922 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2665, 0.3085, 0.6565, 0.6328, 0.6674, 0.2853, 0.3944, 0.2936]) \n",
      "Test Loss tensor([0.2629, 0.3080, 0.6566, 0.6332, 0.6668, 0.2861, 0.3930, 0.2940])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.7087092399597168 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2620, 0.3082, 0.6575, 0.6349, 0.6670, 0.2856, 0.3989, 0.2939]) \n",
      "Test Loss tensor([0.2603, 0.3086, 0.6568, 0.6330, 0.6672, 0.2851, 0.3930, 0.2937])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6896848678588867 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2623, 0.3094, 0.6558, 0.6340, 0.6661, 0.2853, 0.3916, 0.2942]) \n",
      "Test Loss tensor([0.2581, 0.3067, 0.6575, 0.6337, 0.6678, 0.2851, 0.3937, 0.2943])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6345236301422119 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2581, 0.3083, 0.6576, 0.6338, 0.6681, 0.2854, 0.3940, 0.2940]) \n",
      "Test Loss tensor([0.2571, 0.3072, 0.6573, 0.6327, 0.6683, 0.2847, 0.3944, 0.2943])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.654761791229248 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2558, 0.3074, 0.6565, 0.6337, 0.6681, 0.2848, 0.3963, 0.2947]) \n",
      "Test Loss tensor([0.2541, 0.3070, 0.6587, 0.6329, 0.6691, 0.2847, 0.3927, 0.2940])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.6274242401123047 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2560, 0.3073, 0.6566, 0.6314, 0.6671, 0.2843, 0.3914, 0.2937]) \n",
      "Test Loss tensor([0.2516, 0.3067, 0.6589, 0.6321, 0.6699, 0.2838, 0.3942, 0.2941])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6509101390838623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2524, 0.3081, 0.6575, 0.6306, 0.6686, 0.2829, 0.3911, 0.2949]) \n",
      "Test Loss tensor([0.2488, 0.3055, 0.6592, 0.6327, 0.6706, 0.2838, 0.3935, 0.2938])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6666924953460693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2476, 0.3028, 0.6589, 0.6338, 0.6710, 0.2838, 0.3881, 0.2942]) \n",
      "Test Loss tensor([0.2457, 0.3056, 0.6597, 0.6321, 0.6704, 0.2831, 0.3936, 0.2938])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6286733150482178 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2473, 0.3056, 0.6602, 0.6314, 0.6718, 0.2824, 0.3971, 0.2938]) \n",
      "Test Loss tensor([0.2423, 0.3052, 0.6603, 0.6321, 0.6715, 0.2823, 0.3949, 0.2939])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6307528018951416 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2445, 0.3041, 0.6578, 0.6326, 0.6701, 0.2830, 0.3913, 0.2936]) \n",
      "Test Loss tensor([0.2396, 0.3053, 0.6608, 0.6313, 0.6719, 0.2819, 0.3944, 0.2940])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6377429962158203 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2386, 0.3046, 0.6598, 0.6325, 0.6716, 0.2822, 0.3922, 0.2939]) \n",
      "Test Loss tensor([0.2361, 0.3050, 0.6611, 0.6319, 0.6719, 0.2817, 0.3949, 0.2944])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6221020221710205 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2373, 0.3060, 0.6592, 0.6308, 0.6709, 0.2811, 0.3974, 0.2948]) \n",
      "Test Loss tensor([0.2334, 0.3049, 0.6601, 0.6303, 0.6717, 0.2816, 0.3954, 0.2943])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.624976396560669 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2347, 0.3061, 0.6595, 0.6292, 0.6701, 0.2816, 0.3875, 0.2940]) \n",
      "Test Loss tensor([0.2306, 0.3054, 0.6598, 0.6290, 0.6714, 0.2811, 0.3948, 0.2947])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6209371089935303 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2290, 0.3040, 0.6617, 0.6301, 0.6728, 0.2818, 0.3967, 0.2939]) \n",
      "Test Loss tensor([0.2267, 0.3047, 0.6600, 0.6292, 0.6711, 0.2812, 0.3920, 0.2948])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6060652732849121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2268, 0.3038, 0.6609, 0.6302, 0.6703, 0.2816, 0.3953, 0.2950]) \n",
      "Test Loss tensor([0.2224, 0.3057, 0.6596, 0.6277, 0.6713, 0.2807, 0.3939, 0.2948])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6146929264068604 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2244, 0.3041, 0.6584, 0.6298, 0.6702, 0.2818, 0.3971, 0.2934]) \n",
      "Test Loss tensor([0.2174, 0.3052, 0.6599, 0.6265, 0.6715, 0.2803, 0.3958, 0.2951])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.6374382972717285 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2178, 0.3053, 0.6584, 0.6256, 0.6717, 0.2795, 0.3933, 0.2950]) \n",
      "Test Loss tensor([0.2126, 0.3041, 0.6596, 0.6266, 0.6706, 0.2795, 0.3938, 0.2952])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6152374744415283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2131, 0.3011, 0.6604, 0.6289, 0.6693, 0.2800, 0.3938, 0.2951]) \n",
      "Test Loss tensor([0.2072, 0.3038, 0.6602, 0.6267, 0.6706, 0.2788, 0.3933, 0.2946])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6281533241271973 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2067, 0.3048, 0.6590, 0.6250, 0.6728, 0.2791, 0.3940, 0.2954]) \n",
      "Test Loss tensor([0.2024, 0.3041, 0.6599, 0.6249, 0.6707, 0.2781, 0.3918, 0.2943])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6971907615661621 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.2044, 0.3047, 0.6575, 0.6264, 0.6687, 0.2784, 0.3957, 0.2947]) \n",
      "Test Loss tensor([0.1964, 0.3040, 0.6593, 0.6247, 0.6695, 0.2771, 0.3911, 0.2939])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6520586013793945 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1965, 0.3022, 0.6606, 0.6261, 0.6698, 0.2770, 0.3896, 0.2940]) \n",
      "Test Loss tensor([0.1908, 0.3040, 0.6599, 0.6238, 0.6696, 0.2756, 0.3919, 0.2927])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.7035725116729736 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1904, 0.3064, 0.6576, 0.6223, 0.6682, 0.2737, 0.3932, 0.2930]) \n",
      "Test Loss tensor([0.1828, 0.3035, 0.6605, 0.6238, 0.6688, 0.2739, 0.3918, 0.2921])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6150012016296387 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1831, 0.3012, 0.6609, 0.6264, 0.6708, 0.2746, 0.3883, 0.2921]) \n",
      "Test Loss tensor([0.1754, 0.3040, 0.6610, 0.6230, 0.6682, 0.2721, 0.3911, 0.2907])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6175041198730469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1774, 0.3020, 0.6580, 0.6237, 0.6669, 0.2720, 0.3854, 0.2902]) \n",
      "Test Loss tensor([0.1671, 0.3033, 0.6613, 0.6234, 0.6661, 0.2696, 0.3889, 0.2888])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6207671165466309 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1674, 0.3028, 0.6594, 0.6241, 0.6667, 0.2701, 0.3926, 0.2889]) \n",
      "Test Loss tensor([0.1607, 0.3053, 0.6600, 0.6226, 0.6638, 0.2673, 0.3893, 0.2874])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 664 in 0.6213855743408203 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1576, 0.3011, 0.6601, 0.6245, 0.6634, 0.2682, 0.3873, 0.2871]) \n",
      "Test Loss tensor([0.1512, 0.3043, 0.6600, 0.6230, 0.6605, 0.2640, 0.3878, 0.2845])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6389715671539307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1514, 0.3056, 0.6613, 0.6233, 0.6602, 0.2640, 0.3809, 0.2842]) \n",
      "Test Loss tensor([0.1424, 0.3057, 0.6595, 0.6221, 0.6562, 0.2605, 0.3871, 0.2821])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6204924583435059 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1452, 0.3044, 0.6594, 0.6224, 0.6553, 0.2600, 0.3843, 0.2814]) \n",
      "Test Loss tensor([0.1338, 0.3066, 0.6585, 0.6219, 0.6510, 0.2561, 0.3852, 0.2788])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6294035911560059 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1363, 0.3074, 0.6563, 0.6242, 0.6497, 0.2566, 0.3846, 0.2789]) \n",
      "Test Loss tensor([0.1253, 0.3086, 0.6569, 0.6210, 0.6441, 0.2510, 0.3843, 0.2747])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.656177282333374 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1243, 0.3105, 0.6552, 0.6200, 0.6438, 0.2515, 0.3866, 0.2748]) \n",
      "Test Loss tensor([0.1159, 0.3111, 0.6542, 0.6213, 0.6366, 0.2447, 0.3812, 0.2692])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6682403087615967 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1154, 0.3118, 0.6529, 0.6204, 0.6339, 0.2445, 0.3852, 0.2692]) \n",
      "Test Loss tensor([0.1075, 0.3145, 0.6523, 0.6217, 0.6278, 0.2366, 0.3778, 0.2632])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6979556083679199 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.1039, 0.3138, 0.6555, 0.6227, 0.6297, 0.2370, 0.3788, 0.2627]) \n",
      "Test Loss tensor([0.0950, 0.3154, 0.6525, 0.6245, 0.6196, 0.2272, 0.3757, 0.2547])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.705164909362793 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0945, 0.3158, 0.6525, 0.6222, 0.6187, 0.2270, 0.3761, 0.2539]) \n",
      "Test Loss tensor([0.0852, 0.3179, 0.6503, 0.6263, 0.6111, 0.2157, 0.3716, 0.2451])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7237203121185303 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0847, 0.3170, 0.6499, 0.6253, 0.6107, 0.2162, 0.3729, 0.2433]) \n",
      "Test Loss tensor([0.0768, 0.3196, 0.6483, 0.6278, 0.6024, 0.2020, 0.3688, 0.2330])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.760791540145874 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0762, 0.3201, 0.6490, 0.6301, 0.6013, 0.2022, 0.3686, 0.2322]) \n",
      "Test Loss tensor([0.0669, 0.3192, 0.6463, 0.6324, 0.5956, 0.1870, 0.3647, 0.2188])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6432065963745117 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0610, 0.3203, 0.6472, 0.6338, 0.5957, 0.1858, 0.3696, 0.2184]) \n",
      "Test Loss tensor([0.0584, 0.3164, 0.6440, 0.6379, 0.5890, 0.1695, 0.3579, 0.2025])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6221723556518555 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0551, 0.3130, 0.6462, 0.6403, 0.5890, 0.1697, 0.3543, 0.2030]) \n",
      "Test Loss tensor([0.0512, 0.3097, 0.6409, 0.6427, 0.5841, 0.1514, 0.3551, 0.1843])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6199424266815186 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0503, 0.3116, 0.6405, 0.6400, 0.5833, 0.1508, 0.3577, 0.1842]) \n",
      "Test Loss tensor([0.0437, 0.2962, 0.6385, 0.6503, 0.5809, 0.1319, 0.3457, 0.1642])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6294775009155273 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0424, 0.2972, 0.6400, 0.6496, 0.5791, 0.1318, 0.3479, 0.1644]) \n",
      "Test Loss tensor([0.0404, 0.2787, 0.6357, 0.6564, 0.5789, 0.1124, 0.3392, 0.1430])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6234095096588135 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0410, 0.2804, 0.6357, 0.6571, 0.5778, 0.1128, 0.3358, 0.1432]) \n",
      "Test Loss tensor([0.0354, 0.2570, 0.6339, 0.6631, 0.5777, 0.0941, 0.3301, 0.1216])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6241517066955566 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0385, 0.2583, 0.6317, 0.6621, 0.5764, 0.0934, 0.3300, 0.1211]) \n",
      "Test Loss tensor([0.0334, 0.2339, 0.6302, 0.6668, 0.5759, 0.0772, 0.3203, 0.1009])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6326501369476318 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0346, 0.2326, 0.6310, 0.6692, 0.5761, 0.0770, 0.3195, 0.1005]) \n",
      "Test Loss tensor([0.0320, 0.2115, 0.6248, 0.6704, 0.5704, 0.0618, 0.3085, 0.0818])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6401331424713135 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0289, 0.2094, 0.6245, 0.6733, 0.5711, 0.0613, 0.3069, 0.0823]) \n",
      "Test Loss tensor([0.0321, 0.1910, 0.6169, 0.6731, 0.5616, 0.0482, 0.2971, 0.0652])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6129815578460693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0348, 0.1908, 0.6143, 0.6719, 0.5612, 0.0483, 0.2961, 0.0653]) \n",
      "Test Loss tensor([0.0317, 0.1723, 0.6053, 0.6716, 0.5513, 0.0365, 0.2871, 0.0505])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6145839691162109 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0352, 0.1735, 0.6045, 0.6713, 0.5518, 0.0367, 0.2881, 0.0497]) \n",
      "Test Loss tensor([0.0293, 0.1530, 0.5922, 0.6706, 0.5410, 0.0272, 0.2748, 0.0385])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.615725040435791 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0367, 0.1534, 0.5900, 0.6680, 0.5405, 0.0280, 0.2790, 0.0389]) \n",
      "Test Loss tensor([0.0320, 0.1322, 0.5798, 0.6646, 0.5329, 0.0198, 0.2642, 0.0284])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6132717132568359 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0368, 0.1312, 0.5778, 0.6655, 0.5320, 0.0202, 0.2621, 0.0283]) \n",
      "Test Loss tensor([0.0329, 0.1113, 0.5680, 0.6558, 0.5258, 0.0145, 0.2559, 0.0204])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6163852214813232 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0292, 0.1104, 0.5694, 0.6576, 0.5230, 0.0142, 0.2524, 0.0203]) \n",
      "Test Loss tensor([0.0323, 0.0928, 0.5593, 0.6436, 0.5195, 0.0105, 0.2439, 0.0144])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6125457286834717 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0305, 0.0901, 0.5580, 0.6493, 0.5205, 0.0103, 0.2385, 0.0148]) \n",
      "Test Loss tensor([0.0318, 0.0775, 0.5472, 0.6292, 0.5122, 0.0077, 0.2348, 0.0102])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6267609596252441 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0299, 0.0767, 0.5479, 0.6275, 0.5117, 0.0080, 0.2363, 0.0102]) \n",
      "Test Loss tensor([0.0314, 0.0683, 0.5382, 0.6116, 0.5038, 0.0062, 0.2295, 0.0073])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.616412878036499 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0302, 0.0668, 0.5368, 0.6123, 0.5036, 0.0061, 0.2241, 0.0071]) \n",
      "Test Loss tensor([0.0327, 0.0616, 0.5281, 0.5934, 0.4939, 0.0050, 0.2213, 0.0055])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6088569164276123 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0332, 0.0606, 0.5306, 0.5943, 0.4953, 0.0052, 0.2256, 0.0055]) \n",
      "Test Loss tensor([0.0337, 0.0573, 0.5190, 0.5736, 0.4851, 0.0044, 0.2192, 0.0043])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6147110462188721 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0315, 0.0569, 0.5176, 0.5739, 0.4862, 0.0043, 0.2172, 0.0044]) \n",
      "Test Loss tensor([0.0334, 0.0530, 0.5095, 0.5559, 0.4766, 0.0042, 0.2120, 0.0036])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6237752437591553 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0334, 0.0505, 0.5079, 0.5602, 0.4772, 0.0042, 0.2126, 0.0036]) \n",
      "Test Loss tensor([0.0335, 0.0503, 0.5004, 0.5375, 0.4690, 0.0043, 0.2086, 0.0032])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.617326021194458 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0273, 0.0463, 0.4991, 0.5407, 0.4693, 0.0039, 0.2055, 0.0031]) \n",
      "Test Loss tensor([0.0333, 0.0473, 0.4923, 0.5222, 0.4627, 0.0043, 0.2049, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6419978141784668 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0339, 0.0467, 0.4930, 0.5211, 0.4598, 0.0040, 0.2025, 0.0025]) \n",
      "Test Loss tensor([0.0329, 0.0456, 0.4837, 0.5063, 0.4562, 0.0044, 0.2016, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6296403408050537 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0365, 0.0480, 0.4842, 0.5046, 0.4535, 0.0048, 0.2033, 0.0025]) \n",
      "Test Loss tensor([0.0324, 0.0435, 0.4787, 0.4942, 0.4506, 0.0045, 0.1971, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6244468688964844 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0351, 0.0435, 0.4787, 0.4946, 0.4513, 0.0040, 0.1981, 0.0023]) \n",
      "Test Loss tensor([0.0347, 0.0436, 0.4704, 0.4810, 0.4447, 0.0048, 0.1952, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 796 in 0.6273455619812012 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0414, 0.0435, 0.4655, 0.4811, 0.4461, 0.0053, 0.1940, 0.0029]) \n",
      "Test Loss tensor([0.0335, 0.0425, 0.4622, 0.4705, 0.4399, 0.0050, 0.1922, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6142129898071289 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0313, 0.0435, 0.4633, 0.4724, 0.4395, 0.0054, 0.1928, 0.0026]) \n",
      "Test Loss tensor([0.0316, 0.0404, 0.4560, 0.4624, 0.4356, 0.0054, 0.1877, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6145026683807373 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0308, 0.0398, 0.4533, 0.4626, 0.4347, 0.0053, 0.1872, 0.0029]) \n",
      "Test Loss tensor([0.0331, 0.0411, 0.4493, 0.4517, 0.4310, 0.0056, 0.1864, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6168110370635986 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0369, 0.0443, 0.4490, 0.4479, 0.4306, 0.0054, 0.1895, 0.0023]) \n",
      "Test Loss tensor([0.0326, 0.0404, 0.4417, 0.4436, 0.4273, 0.0059, 0.1844, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6164302825927734 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0325, 0.0390, 0.4424, 0.4468, 0.4264, 0.0060, 0.1791, 0.0028]) \n",
      "Test Loss tensor([0.0337, 0.0398, 0.4366, 0.4366, 0.4227, 0.0060, 0.1823, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6142804622650146 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0367, 0.0412, 0.4372, 0.4339, 0.4234, 0.0057, 0.1832, 0.0023]) \n",
      "Test Loss tensor([0.0328, 0.0392, 0.4316, 0.4308, 0.4196, 0.0063, 0.1809, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6179811954498291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0321, 0.0411, 0.4324, 0.4324, 0.4185, 0.0061, 0.1867, 0.0023]) \n",
      "Test Loss tensor([0.0338, 0.0395, 0.4263, 0.4239, 0.4153, 0.0065, 0.1779, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6256089210510254 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0313, 0.0378, 0.4264, 0.4289, 0.4155, 0.0068, 0.1725, 0.0024]) \n",
      "Test Loss tensor([0.0317, 0.0380, 0.4216, 0.4187, 0.4113, 0.0069, 0.1757, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6293518543243408 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0329, 0.0374, 0.4213, 0.4198, 0.4114, 0.0063, 0.1737, 0.0024]) \n",
      "Test Loss tensor([0.0327, 0.0381, 0.4175, 0.4145, 0.4083, 0.0070, 0.1749, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.618016242980957 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0315, 0.0391, 0.4182, 0.4133, 0.4088, 0.0061, 0.1742, 0.0025]) \n",
      "Test Loss tensor([0.0353, 0.0384, 0.4121, 0.4090, 0.4043, 0.0067, 0.1725, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6159052848815918 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0350, 0.0382, 0.4116, 0.4077, 0.4044, 0.0069, 0.1683, 0.0024]) \n",
      "Test Loss tensor([0.0330, 0.0376, 0.4090, 0.4048, 0.4007, 0.0068, 0.1723, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6171822547912598 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0329, 0.0360, 0.4062, 0.4047, 0.3997, 0.0063, 0.1693, 0.0026]) \n",
      "Test Loss tensor([0.0331, 0.0376, 0.4040, 0.4013, 0.3962, 0.0068, 0.1696, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6183719635009766 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0304, 0.0368, 0.4057, 0.4011, 0.3982, 0.0062, 0.1714, 0.0026]) \n",
      "Test Loss tensor([0.0324, 0.0363, 0.4004, 0.3982, 0.3926, 0.0069, 0.1680, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6809284687042236 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0336, 0.0373, 0.4018, 0.3959, 0.3928, 0.0072, 0.1627, 0.0023]) \n",
      "Test Loss tensor([0.0318, 0.0374, 0.3965, 0.3940, 0.3887, 0.0066, 0.1662, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6517093181610107 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0335, 0.0404, 0.3941, 0.3902, 0.3874, 0.0076, 0.1652, 0.0025]) \n",
      "Test Loss tensor([0.0332, 0.0365, 0.3926, 0.3911, 0.3842, 0.0064, 0.1633, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6138756275177002 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0325, 0.0362, 0.3923, 0.3918, 0.3839, 0.0066, 0.1621, 0.0028]) \n",
      "Test Loss tensor([0.0352, 0.0371, 0.3877, 0.3877, 0.3798, 0.0067, 0.1629, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6269934177398682 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0317, 0.0363, 0.3882, 0.3895, 0.3800, 0.0072, 0.1637, 0.0025]) \n",
      "Test Loss tensor([0.0343, 0.0363, 0.3834, 0.3855, 0.3759, 0.0065, 0.1602, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6170709133148193 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0352, 0.0391, 0.3824, 0.3838, 0.3731, 0.0070, 0.1571, 0.0028]) \n",
      "Test Loss tensor([0.0345, 0.0366, 0.3800, 0.3811, 0.3715, 0.0064, 0.1604, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6165981292724609 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0318, 0.0335, 0.3796, 0.3856, 0.3705, 0.0081, 0.1583, 0.0027]) \n",
      "Test Loss tensor([0.0326, 0.0352, 0.3761, 0.3796, 0.3671, 0.0063, 0.1574, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6270170211791992 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0376, 0.0370, 0.3732, 0.3781, 0.3679, 0.0052, 0.1578, 0.0027]) \n",
      "Test Loss tensor([0.0344, 0.0358, 0.3715, 0.3754, 0.3632, 0.0064, 0.1559, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.7135887145996094 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0258, 0.0274, 0.2794, 0.2787, 0.2725, 0.0047, 0.1146, 0.0022]) \n",
      "Test Loss tensor([0.0335, 0.0357, 0.3675, 0.3732, 0.3592, 0.0058, 0.1540, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7241179943084717 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0344, 0.0368, 0.3676, 0.3702, 0.3583, 0.0050, 0.1567, 0.0026]) \n",
      "Test Loss tensor([0.0354, 0.0357, 0.3633, 0.3704, 0.3554, 0.0055, 0.1544, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.7136225700378418 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0350, 0.0338, 0.3612, 0.3717, 0.3546, 0.0066, 0.1487, 0.0028]) \n",
      "Test Loss tensor([0.0320, 0.0340, 0.3593, 0.3683, 0.3506, 0.0058, 0.1512, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.7551064491271973 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0307, 0.0336, 0.3602, 0.3688, 0.3500, 0.0055, 0.1549, 0.0026]) \n",
      "Test Loss tensor([0.0329, 0.0348, 0.3554, 0.3654, 0.3459, 0.0053, 0.1479, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.7097835540771484 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0313, 0.0354, 0.3568, 0.3639, 0.3457, 0.0050, 0.1499, 0.0027]) \n",
      "Test Loss tensor([0.0338, 0.0348, 0.3517, 0.3623, 0.3413, 0.0054, 0.1477, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.7753076553344727 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0335, 0.0376, 0.3508, 0.3602, 0.3410, 0.0059, 0.1542, 0.0027]) \n",
      "Test Loss tensor([0.0321, 0.0336, 0.3470, 0.3604, 0.3362, 0.0056, 0.1444, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7230954170227051 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0333, 0.0320, 0.3481, 0.3595, 0.3353, 0.0052, 0.1473, 0.0024]) \n",
      "Test Loss tensor([0.0324, 0.0334, 0.3432, 0.3570, 0.3313, 0.0054, 0.1430, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.7123429775238037 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0347, 0.0303, 0.3433, 0.3564, 0.3319, 0.0051, 0.1439, 0.0024]) \n",
      "Test Loss tensor([0.0326, 0.0332, 0.3388, 0.3542, 0.3266, 0.0052, 0.1425, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.7181227207183838 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0314, 0.0358, 0.3376, 0.3513, 0.3264, 0.0062, 0.1435, 0.0028]) \n",
      "Test Loss tensor([0.0339, 0.0323, 0.3348, 0.3516, 0.3213, 0.0053, 0.1403, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.7405879497528076 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0309, 0.0333, 0.3339, 0.3493, 0.3199, 0.0060, 0.1414, 0.0025]) \n",
      "Test Loss tensor([0.0328, 0.0332, 0.3307, 0.3480, 0.3162, 0.0053, 0.1373, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7295742034912109 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0344, 0.0332, 0.3316, 0.3479, 0.3163, 0.0049, 0.1392, 0.0025]) \n",
      "Test Loss tensor([0.0332, 0.0321, 0.3264, 0.3445, 0.3109, 0.0051, 0.1346, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6843805313110352 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0377, 0.0353, 0.3256, 0.3455, 0.3110, 0.0051, 0.1376, 0.0031]) \n",
      "Test Loss tensor([0.0311, 0.0322, 0.3225, 0.3421, 0.3052, 0.0052, 0.1335, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6709520816802979 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0280, 0.0307, 0.3220, 0.3433, 0.3042, 0.0052, 0.1328, 0.0029]) \n",
      "Test Loss tensor([0.0321, 0.0317, 0.3183, 0.3393, 0.2994, 0.0048, 0.1320, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 48 in 0.7196381092071533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0309, 0.0353, 0.3180, 0.3397, 0.2985, 0.0051, 0.1291, 0.0026]) \n",
      "Test Loss tensor([0.0324, 0.0319, 0.3132, 0.3356, 0.2932, 0.0050, 0.1286, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.7834353446960449 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0365, 0.0314, 0.3097, 0.3347, 0.2915, 0.0051, 0.1334, 0.0026]) \n",
      "Test Loss tensor([0.0331, 0.0313, 0.3076, 0.3328, 0.2863, 0.0048, 0.1275, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.8758144378662109 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0396, 0.0327, 0.3066, 0.3318, 0.2864, 0.0057, 0.1247, 0.0027]) \n",
      "Test Loss tensor([0.0319, 0.0311, 0.3026, 0.3297, 0.2798, 0.0050, 0.1224, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.833305835723877 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0312, 0.0282, 0.3015, 0.3307, 0.2801, 0.0057, 0.1237, 0.0028]) \n",
      "Test Loss tensor([0.0338, 0.0307, 0.2979, 0.3267, 0.2727, 0.0049, 0.1219, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.7691078186035156 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0332, 0.0312, 0.2968, 0.3255, 0.2729, 0.0053, 0.1241, 0.0025]) \n",
      "Test Loss tensor([0.0323, 0.0306, 0.2920, 0.3236, 0.2654, 0.0051, 0.1183, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7756359577178955 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0329, 0.0292, 0.2933, 0.3210, 0.2656, 0.0062, 0.1159, 0.0028]) \n",
      "Test Loss tensor([0.0333, 0.0299, 0.2861, 0.3197, 0.2578, 0.0049, 0.1152, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.7722687721252441 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0332, 0.0308, 0.2842, 0.3203, 0.2585, 0.0052, 0.1175, 0.0030]) \n",
      "Test Loss tensor([0.0325, 0.0295, 0.2798, 0.3171, 0.2493, 0.0048, 0.1131, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.7329123020172119 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0326, 0.0294, 0.2812, 0.3176, 0.2486, 0.0049, 0.1135, 0.0024]) \n",
      "Test Loss tensor([0.0329, 0.0294, 0.2736, 0.3140, 0.2405, 0.0050, 0.1100, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7209663391113281 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0342, 0.0284, 0.2715, 0.3123, 0.2407, 0.0046, 0.1087, 0.0026]) \n",
      "Test Loss tensor([0.0326, 0.0281, 0.2658, 0.3108, 0.2312, 0.0050, 0.1055, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7447967529296875 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0379, 0.0294, 0.2673, 0.3098, 0.2316, 0.0057, 0.1075, 0.0025]) \n",
      "Test Loss tensor([0.0339, 0.0289, 0.2586, 0.3073, 0.2221, 0.0049, 0.1031, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.7246954441070557 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0388, 0.0314, 0.2588, 0.3080, 0.2217, 0.0045, 0.1045, 0.0027]) \n",
      "Test Loss tensor([0.0347, 0.0282, 0.2503, 0.3032, 0.2122, 0.0049, 0.0987, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7641360759735107 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0283, 0.0299, 0.2507, 0.3054, 0.2121, 0.0055, 0.0970, 0.0027]) \n",
      "Test Loss tensor([0.0319, 0.0272, 0.2422, 0.3011, 0.2023, 0.0050, 0.0954, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.65224289894104 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0348, 0.0254, 0.2422, 0.3022, 0.2020, 0.0052, 0.0963, 0.0029]) \n",
      "Test Loss tensor([0.0336, 0.0275, 0.2336, 0.2965, 0.1922, 0.0049, 0.0915, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7318477630615234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0329, 0.0288, 0.2351, 0.2975, 0.1911, 0.0047, 0.0902, 0.0026]) \n",
      "Test Loss tensor([0.0323, 0.0255, 0.2242, 0.2944, 0.1827, 0.0048, 0.0881, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.8377230167388916 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0305, 0.0251, 0.2256, 0.2932, 0.1819, 0.0062, 0.0900, 0.0029]) \n",
      "Test Loss tensor([0.0332, 0.0258, 0.2156, 0.2904, 0.1720, 0.0048, 0.0840, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.7811708450317383 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0328, 0.0257, 0.2166, 0.2911, 0.1712, 0.0040, 0.0862, 0.0027]) \n",
      "Test Loss tensor([0.0341, 0.0249, 0.2055, 0.2864, 0.1611, 0.0052, 0.0811, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7294528484344482 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0350, 0.0259, 0.2055, 0.2868, 0.1602, 0.0050, 0.0785, 0.0025]) \n",
      "Test Loss tensor([0.0327, 0.0240, 0.1963, 0.2838, 0.1507, 0.0048, 0.0770, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6612701416015625 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0286, 0.0250, 0.1963, 0.2847, 0.1507, 0.0062, 0.0748, 0.0030]) \n",
      "Test Loss tensor([0.0337, 0.0236, 0.1864, 0.2792, 0.1399, 0.0048, 0.0732, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.679415225982666 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0304, 0.0200, 0.1853, 0.2815, 0.1396, 0.0060, 0.0725, 0.0027]) \n",
      "Test Loss tensor([0.0322, 0.0237, 0.1763, 0.2749, 0.1289, 0.0052, 0.0694, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.7228865623474121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0327, 0.0233, 0.1764, 0.2752, 0.1293, 0.0039, 0.0679, 0.0029]) \n",
      "Test Loss tensor([0.0316, 0.0231, 0.1661, 0.2715, 0.1179, 0.0050, 0.0663, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.8883893489837646 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0357, 0.0237, 0.1665, 0.2699, 0.1181, 0.0052, 0.0647, 0.0027]) \n",
      "Test Loss tensor([0.0320, 0.0219, 0.1563, 0.2665, 0.1074, 0.0048, 0.0621, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.7609267234802246 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0337, 0.0231, 0.1564, 0.2650, 0.1082, 0.0046, 0.0633, 0.0028]) \n",
      "Test Loss tensor([0.0334, 0.0213, 0.1458, 0.2610, 0.0973, 0.0051, 0.0589, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.7382166385650635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0311, 0.0223, 0.1450, 0.2624, 0.0972, 0.0051, 0.0593, 0.0027]) \n",
      "Test Loss tensor([0.0355, 0.0206, 0.1341, 0.2561, 0.0874, 0.0050, 0.0551, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.7634515762329102 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0331, 0.0191, 0.1333, 0.2559, 0.0872, 0.0053, 0.0537, 0.0026]) \n",
      "Test Loss tensor([0.0332, 0.0206, 0.1243, 0.2503, 0.0779, 0.0056, 0.0517, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.8662290573120117 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0311, 0.0201, 0.1241, 0.2498, 0.0776, 0.0045, 0.0530, 0.0026]) \n",
      "Test Loss tensor([0.0329, 0.0195, 0.1147, 0.2456, 0.0688, 0.0054, 0.0495, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7769129276275635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0417, 0.0190, 0.1127, 0.2437, 0.0680, 0.0057, 0.0492, 0.0028]) \n",
      "Test Loss tensor([0.0318, 0.0193, 0.1042, 0.2396, 0.0601, 0.0059, 0.0463, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7160680294036865 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0307, 0.0202, 0.1063, 0.2388, 0.0622, 0.0050, 0.0493, 0.0028]) \n",
      "Test Loss tensor([0.0340, 0.0191, 0.0946, 0.2328, 0.0523, 0.0055, 0.0448, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7495808601379395 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0323, 0.0185, 0.0951, 0.2340, 0.0523, 0.0057, 0.0437, 0.0030]) \n",
      "Test Loss tensor([0.0345, 0.0186, 0.0862, 0.2266, 0.0454, 0.0056, 0.0425, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6756160259246826 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0346, 0.0180, 0.0858, 0.2273, 0.0446, 0.0056, 0.0438, 0.0026]) \n",
      "Test Loss tensor([0.0335, 0.0181, 0.0771, 0.2189, 0.0395, 0.0060, 0.0402, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6449036598205566 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0330, 0.0205, 0.0800, 0.2190, 0.0403, 0.0060, 0.0438, 0.0028]) \n",
      "Test Loss tensor([0.0350, 0.0180, 0.0694, 0.2123, 0.0331, 0.0058, 0.0401, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6267280578613281 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0293, 0.0156, 0.0702, 0.2131, 0.0320, 0.0053, 0.0398, 0.0022]) \n",
      "Test Loss tensor([0.0338, 0.0178, 0.0625, 0.2048, 0.0286, 0.0062, 0.0385, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6270358562469482 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0342, 0.0181, 0.0606, 0.2048, 0.0305, 0.0059, 0.0378, 0.0027]) \n",
      "Test Loss tensor([0.0332, 0.0174, 0.0554, 0.1970, 0.0238, 0.0066, 0.0374, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6376066207885742 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0329, 0.0166, 0.0531, 0.1952, 0.0241, 0.0073, 0.0376, 0.0026]) \n",
      "Test Loss tensor([0.0357, 0.0168, 0.0492, 0.1887, 0.0203, 0.0063, 0.0375, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 180 in 0.6688201427459717 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0344, 0.0163, 0.0494, 0.1891, 0.0219, 0.0056, 0.0375, 0.0028]) \n",
      "Test Loss tensor([0.0327, 0.0172, 0.0439, 0.1806, 0.0170, 0.0064, 0.0375, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.8184061050415039 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0314, 0.0181, 0.0456, 0.1807, 0.0176, 0.0069, 0.0359, 0.0026]) \n",
      "Test Loss tensor([0.0348, 0.0173, 0.0385, 0.1721, 0.0142, 0.0065, 0.0367, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.7257890701293945 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0367, 0.0185, 0.0383, 0.1738, 0.0148, 0.0057, 0.0353, 0.0024]) \n",
      "Test Loss tensor([0.0328, 0.0165, 0.0343, 0.1629, 0.0125, 0.0070, 0.0362, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6203980445861816 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0379, 0.0150, 0.0348, 0.1642, 0.0118, 0.0069, 0.0350, 0.0024]) \n",
      "Test Loss tensor([0.0344, 0.0172, 0.0304, 0.1545, 0.0105, 0.0069, 0.0376, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6224467754364014 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0333, 0.0157, 0.0307, 0.1540, 0.0101, 0.0066, 0.0383, 0.0029]) \n",
      "Test Loss tensor([0.0320, 0.0165, 0.0279, 0.1450, 0.0089, 0.0068, 0.0366, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6325972080230713 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0308, 0.0143, 0.0277, 0.1445, 0.0094, 0.0061, 0.0377, 0.0025]) \n",
      "Test Loss tensor([0.0314, 0.0172, 0.0250, 0.1362, 0.0082, 0.0067, 0.0369, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6204345226287842 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0358, 0.0183, 0.0263, 0.1352, 0.0075, 0.0053, 0.0400, 0.0025]) \n",
      "Test Loss tensor([0.0333, 0.0169, 0.0224, 0.1268, 0.0068, 0.0069, 0.0381, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.675400972366333 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0396, 0.0171, 0.0225, 0.1253, 0.0099, 0.0081, 0.0350, 0.0027]) \n",
      "Test Loss tensor([0.0337, 0.0157, 0.0205, 0.1166, 0.0064, 0.0071, 0.0377, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6286771297454834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0353, 0.0160, 0.0192, 0.1157, 0.0056, 0.0064, 0.0367, 0.0027]) \n",
      "Test Loss tensor([0.0340, 0.0172, 0.0182, 0.1077, 0.0065, 0.0073, 0.0387, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6333489418029785 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0352, 0.0170, 0.0200, 0.1069, 0.0065, 0.0077, 0.0391, 0.0026]) \n",
      "Test Loss tensor([0.0320, 0.0166, 0.0162, 0.0983, 0.0055, 0.0073, 0.0388, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6217615604400635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0317, 0.0176, 0.0149, 0.0984, 0.0058, 0.0080, 0.0383, 0.0026]) \n",
      "Test Loss tensor([0.0327, 0.0159, 0.0153, 0.0897, 0.0052, 0.0073, 0.0397, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6219990253448486 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0366, 0.0184, 0.0141, 0.0907, 0.0056, 0.0060, 0.0409, 0.0026]) \n",
      "Test Loss tensor([0.0339, 0.0178, 0.0151, 0.0811, 0.0049, 0.0069, 0.0391, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6204707622528076 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0396, 0.0132, 0.0136, 0.0792, 0.0064, 0.0064, 0.0400, 0.0025]) \n",
      "Test Loss tensor([0.0323, 0.0172, 0.0133, 0.0730, 0.0054, 0.0075, 0.0395, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6291134357452393 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0294, 0.0176, 0.0136, 0.0724, 0.0045, 0.0065, 0.0404, 0.0025]) \n",
      "Test Loss tensor([0.0341, 0.0170, 0.0130, 0.0652, 0.0050, 0.0079, 0.0400, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6350970268249512 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0287, 0.0177, 0.0135, 0.0661, 0.0064, 0.0078, 0.0389, 0.0027]) \n",
      "Test Loss tensor([0.0332, 0.0171, 0.0123, 0.0581, 0.0044, 0.0079, 0.0407, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6435501575469971 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0273, 0.0187, 0.0126, 0.0582, 0.0048, 0.0088, 0.0377, 0.0024]) \n",
      "Test Loss tensor([0.0322, 0.0170, 0.0118, 0.0513, 0.0042, 0.0082, 0.0412, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6231191158294678 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0381, 0.0146, 0.0108, 0.0487, 0.0051, 0.0067, 0.0402, 0.0025]) \n",
      "Test Loss tensor([0.0328, 0.0169, 0.0110, 0.0446, 0.0045, 0.0082, 0.0414, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6192431449890137 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0303, 0.0173, 0.0105, 0.0446, 0.0056, 0.0075, 0.0421, 0.0024]) \n",
      "Test Loss tensor([0.0333, 0.0173, 0.0110, 0.0386, 0.0048, 0.0079, 0.0416, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6387996673583984 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0332, 0.0154, 0.0098, 0.0376, 0.0074, 0.0071, 0.0412, 0.0026]) \n",
      "Test Loss tensor([0.0307, 0.0174, 0.0105, 0.0338, 0.0054, 0.0073, 0.0422, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6316487789154053 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0299, 0.0183, 0.0092, 0.0326, 0.0057, 0.0083, 0.0443, 0.0025]) \n",
      "Test Loss tensor([0.0326, 0.0176, 0.0103, 0.0290, 0.0049, 0.0075, 0.0442, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6345880031585693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0342, 0.0194, 0.0084, 0.0283, 0.0056, 0.0066, 0.0406, 0.0024]) \n",
      "Test Loss tensor([0.0335, 0.0176, 0.0106, 0.0254, 0.0053, 0.0075, 0.0429, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6390256881713867 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0301, 0.0176, 0.0076, 0.0242, 0.0043, 0.0078, 0.0395, 0.0026]) \n",
      "Test Loss tensor([0.0337, 0.0166, 0.0099, 0.0221, 0.0051, 0.0079, 0.0433, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6232986450195312 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0356, 0.0175, 0.0112, 0.0208, 0.0065, 0.0081, 0.0410, 0.0025]) \n",
      "Test Loss tensor([0.0310, 0.0178, 0.0099, 0.0196, 0.0048, 0.0084, 0.0410, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6174893379211426 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0279, 0.0190, 0.0080, 0.0202, 0.0065, 0.0083, 0.0409, 0.0025]) \n",
      "Test Loss tensor([0.0298, 0.0184, 0.0095, 0.0171, 0.0047, 0.0087, 0.0432, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6191816329956055 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0297, 0.0165, 0.0080, 0.0158, 0.0033, 0.0080, 0.0420, 0.0025]) \n",
      "Test Loss tensor([0.0289, 0.0176, 0.0091, 0.0149, 0.0050, 0.0092, 0.0426, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6226260662078857 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0349, 0.0177, 0.0077, 0.0143, 0.0058, 0.0062, 0.0397, 0.0027]) \n",
      "Test Loss tensor([0.0289, 0.0187, 0.0094, 0.0137, 0.0050, 0.0086, 0.0443, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.710019588470459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0324, 0.0155, 0.0109, 0.0141, 0.0068, 0.0087, 0.0451, 0.0026]) \n",
      "Test Loss tensor([0.0260, 0.0176, 0.0094, 0.0118, 0.0045, 0.0095, 0.0434, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.6303987503051758 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0272, 0.0183, 0.0071, 0.0120, 0.0045, 0.0100, 0.0428, 0.0025]) \n",
      "Test Loss tensor([0.0249, 0.0174, 0.0093, 0.0107, 0.0058, 0.0095, 0.0429, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.619140625 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0250, 0.0193, 0.0075, 0.0091, 0.0073, 0.0108, 0.0468, 0.0022]) \n",
      "Test Loss tensor([0.0215, 0.0175, 0.0085, 0.0092, 0.0056, 0.0095, 0.0442, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6225955486297607 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0270, 0.0147, 0.0080, 0.0097, 0.0064, 0.0099, 0.0419, 0.0026]) \n",
      "Test Loss tensor([0.0228, 0.0181, 0.0090, 0.0083, 0.0051, 0.0094, 0.0427, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6238505840301514 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0212, 0.0206, 0.0085, 0.0108, 0.0050, 0.0072, 0.0458, 0.0025]) \n",
      "Test Loss tensor([0.0224, 0.0176, 0.0087, 0.0076, 0.0052, 0.0090, 0.0423, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6314523220062256 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0221, 0.0186, 0.0084, 0.0072, 0.0062, 0.0101, 0.0408, 0.0027]) \n",
      "Test Loss tensor([0.0222, 0.0167, 0.0086, 0.0069, 0.0051, 0.0078, 0.0432, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.622887372970581 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0193, 0.0172, 0.0097, 0.0064, 0.0057, 0.0078, 0.0477, 0.0028]) \n",
      "Test Loss tensor([0.0214, 0.0182, 0.0093, 0.0072, 0.0051, 0.0088, 0.0436, 0.0026])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 312 in 0.6197528839111328 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0196, 0.0151, 0.0092, 0.0061, 0.0057, 0.0065, 0.0456, 0.0024]) \n",
      "Test Loss tensor([0.0208, 0.0169, 0.0084, 0.0060, 0.0056, 0.0093, 0.0426, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.6343014240264893 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0239, 0.0193, 0.0102, 0.0056, 0.0080, 0.0121, 0.0411, 0.0028]) \n",
      "Test Loss tensor([0.0216, 0.0171, 0.0090, 0.0064, 0.0058, 0.0091, 0.0432, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6229081153869629 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0201, 0.0186, 0.0077, 0.0056, 0.0048, 0.0125, 0.0418, 0.0024]) \n",
      "Test Loss tensor([0.0199, 0.0171, 0.0088, 0.0058, 0.0053, 0.0096, 0.0422, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6232242584228516 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0153, 0.0146, 0.0075, 0.0053, 0.0056, 0.0095, 0.0406, 0.0025]) \n",
      "Test Loss tensor([0.0205, 0.0175, 0.0089, 0.0057, 0.0054, 0.0099, 0.0422, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6549406051635742 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0195, 0.0170, 0.0086, 0.0055, 0.0058, 0.0097, 0.0433, 0.0028]) \n",
      "Test Loss tensor([0.0197, 0.0180, 0.0082, 0.0055, 0.0047, 0.0099, 0.0429, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6268916130065918 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0256, 0.0177, 0.0089, 0.0056, 0.0058, 0.0090, 0.0452, 0.0026]) \n",
      "Test Loss tensor([0.0197, 0.0174, 0.0083, 0.0057, 0.0048, 0.0099, 0.0428, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6307759284973145 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0185, 0.0177, 0.0084, 0.0053, 0.0057, 0.0104, 0.0388, 0.0025]) \n",
      "Test Loss tensor([0.0200, 0.0175, 0.0085, 0.0056, 0.0057, 0.0095, 0.0426, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6272423267364502 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0217, 0.0162, 0.0108, 0.0044, 0.0063, 0.0087, 0.0428, 0.0029]) \n",
      "Test Loss tensor([0.0187, 0.0170, 0.0085, 0.0055, 0.0054, 0.0096, 0.0428, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6354870796203613 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0200, 0.0166, 0.0069, 0.0054, 0.0062, 0.0109, 0.0410, 0.0028]) \n",
      "Test Loss tensor([0.0200, 0.0180, 0.0084, 0.0052, 0.0052, 0.0100, 0.0428, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.636368989944458 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0217, 0.0181, 0.0072, 0.0043, 0.0047, 0.0102, 0.0412, 0.0026]) \n",
      "Test Loss tensor([0.0192, 0.0170, 0.0077, 0.0053, 0.0053, 0.0095, 0.0431, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6276190280914307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0170, 0.0179, 0.0104, 0.0053, 0.0059, 0.0081, 0.0440, 0.0028]) \n",
      "Test Loss tensor([0.0189, 0.0163, 0.0086, 0.0047, 0.0053, 0.0098, 0.0429, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6295783519744873 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0163, 0.0171, 0.0094, 0.0048, 0.0053, 0.0104, 0.0412, 0.0025]) \n",
      "Test Loss tensor([0.0186, 0.0167, 0.0084, 0.0049, 0.0054, 0.0081, 0.0420, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6314315795898438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0189, 0.0200, 0.0079, 0.0034, 0.0066, 0.0093, 0.0431, 0.0025]) \n",
      "Test Loss tensor([0.0188, 0.0172, 0.0080, 0.0049, 0.0051, 0.0084, 0.0423, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.6178662776947021 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0217, 0.0206, 0.0082, 0.0043, 0.0091, 0.0091, 0.0447, 0.0028]) \n",
      "Test Loss tensor([0.0198, 0.0170, 0.0079, 0.0048, 0.0059, 0.0080, 0.0423, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7131748199462891 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0194, 0.0209, 0.0118, 0.0041, 0.0042, 0.0106, 0.0413, 0.0026]) \n",
      "Test Loss tensor([0.0183, 0.0177, 0.0081, 0.0049, 0.0059, 0.0081, 0.0428, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7965672016143799 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0223, 0.0167, 0.0086, 0.0041, 0.0057, 0.0072, 0.0404, 0.0031]) \n",
      "Test Loss tensor([0.0192, 0.0167, 0.0083, 0.0053, 0.0056, 0.0074, 0.0438, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6881723403930664 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0176, 0.0075, 0.0050, 0.0049, 0.0082, 0.0405, 0.0026]) \n",
      "Test Loss tensor([0.0191, 0.0171, 0.0080, 0.0050, 0.0054, 0.0081, 0.0421, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6241278648376465 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0189, 0.0165, 0.0093, 0.0049, 0.0066, 0.0066, 0.0397, 0.0028]) \n",
      "Test Loss tensor([0.0181, 0.0167, 0.0078, 0.0046, 0.0058, 0.0080, 0.0420, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6169393062591553 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0214, 0.0170, 0.0089, 0.0051, 0.0065, 0.0068, 0.0427, 0.0028]) \n",
      "Test Loss tensor([0.0203, 0.0165, 0.0082, 0.0049, 0.0052, 0.0079, 0.0412, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6325016021728516 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0180, 0.0086, 0.0041, 0.0054, 0.0071, 0.0433, 0.0026]) \n",
      "Test Loss tensor([0.0185, 0.0165, 0.0082, 0.0044, 0.0052, 0.0074, 0.0423, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6513621807098389 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0136, 0.0078, 0.0042, 0.0047, 0.0091, 0.0404, 0.0024]) \n",
      "Test Loss tensor([0.0182, 0.0175, 0.0087, 0.0050, 0.0061, 0.0073, 0.0406, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6680209636688232 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0172, 0.0089, 0.0054, 0.0045, 0.0078, 0.0413, 0.0025]) \n",
      "Test Loss tensor([0.0186, 0.0165, 0.0080, 0.0051, 0.0056, 0.0077, 0.0408, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6204259395599365 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0157, 0.0080, 0.0050, 0.0068, 0.0090, 0.0409, 0.0026]) \n",
      "Test Loss tensor([0.0174, 0.0163, 0.0082, 0.0045, 0.0056, 0.0075, 0.0418, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6229584217071533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0203, 0.0089, 0.0052, 0.0052, 0.0092, 0.0407, 0.0026]) \n",
      "Test Loss tensor([0.0198, 0.0166, 0.0082, 0.0052, 0.0055, 0.0074, 0.0416, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6273233890533447 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0168, 0.0072, 0.0053, 0.0048, 0.0077, 0.0419, 0.0026]) \n",
      "Test Loss tensor([0.0179, 0.0163, 0.0080, 0.0046, 0.0064, 0.0069, 0.0416, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6210529804229736 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0203, 0.0165, 0.0075, 0.0043, 0.0064, 0.0079, 0.0446, 0.0025]) \n",
      "Test Loss tensor([0.0175, 0.0173, 0.0076, 0.0047, 0.0049, 0.0066, 0.0413, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.632014274597168 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0152, 0.0064, 0.0063, 0.0065, 0.0084, 0.0437, 0.0026]) \n",
      "Test Loss tensor([0.0182, 0.0161, 0.0078, 0.0051, 0.0051, 0.0070, 0.0402, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6605854034423828 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0157, 0.0159, 0.0079, 0.0047, 0.0049, 0.0053, 0.0402, 0.0025]) \n",
      "Test Loss tensor([0.0185, 0.0164, 0.0083, 0.0047, 0.0056, 0.0065, 0.0408, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.640927791595459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0182, 0.0065, 0.0045, 0.0054, 0.0070, 0.0430, 0.0026]) \n",
      "Test Loss tensor([0.0181, 0.0161, 0.0083, 0.0047, 0.0058, 0.0067, 0.0419, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6221544742584229 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0206, 0.0188, 0.0099, 0.0043, 0.0083, 0.0080, 0.0403, 0.0026]) \n",
      "Test Loss tensor([0.0184, 0.0157, 0.0084, 0.0047, 0.0056, 0.0064, 0.0417, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6295466423034668 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0157, 0.0132, 0.0079, 0.0043, 0.0061, 0.0064, 0.0452, 0.0029]) \n",
      "Test Loss tensor([0.0185, 0.0156, 0.0080, 0.0049, 0.0057, 0.0064, 0.0415, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6224675178527832 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0212, 0.0168, 0.0086, 0.0050, 0.0065, 0.0059, 0.0418, 0.0025]) \n",
      "Test Loss tensor([0.0178, 0.0156, 0.0073, 0.0044, 0.0053, 0.0066, 0.0392, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6218380928039551 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0211, 0.0106, 0.0051, 0.0058, 0.0071, 0.0381, 0.0028]) \n",
      "Test Loss tensor([0.0177, 0.0166, 0.0079, 0.0048, 0.0051, 0.0063, 0.0417, 0.0025])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 444 in 0.6214790344238281 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0192, 0.0163, 0.0078, 0.0050, 0.0071, 0.0064, 0.0382, 0.0029]) \n",
      "Test Loss tensor([0.0183, 0.0162, 0.0078, 0.0049, 0.0051, 0.0071, 0.0400, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6315231323242188 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0166, 0.0172, 0.0089, 0.0041, 0.0046, 0.0060, 0.0405, 0.0028]) \n",
      "Test Loss tensor([0.0186, 0.0164, 0.0077, 0.0049, 0.0051, 0.0071, 0.0406, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.640937328338623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0172, 0.0098, 0.0056, 0.0056, 0.0091, 0.0404, 0.0024]) \n",
      "Test Loss tensor([0.0182, 0.0163, 0.0078, 0.0045, 0.0050, 0.0074, 0.0397, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6837761402130127 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0198, 0.0153, 0.0054, 0.0048, 0.0065, 0.0070, 0.0388, 0.0026]) \n",
      "Test Loss tensor([0.0191, 0.0162, 0.0074, 0.0050, 0.0056, 0.0068, 0.0391, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6942102909088135 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0197, 0.0176, 0.0073, 0.0060, 0.0045, 0.0076, 0.0408, 0.0028]) \n",
      "Test Loss tensor([0.0177, 0.0151, 0.0079, 0.0045, 0.0058, 0.0068, 0.0396, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6269776821136475 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0192, 0.0147, 0.0084, 0.0039, 0.0046, 0.0067, 0.0406, 0.0026]) \n",
      "Test Loss tensor([0.0189, 0.0161, 0.0079, 0.0048, 0.0060, 0.0064, 0.0398, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6738219261169434 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0211, 0.0164, 0.0060, 0.0034, 0.0056, 0.0084, 0.0400, 0.0027]) \n",
      "Test Loss tensor([0.0186, 0.0161, 0.0079, 0.0046, 0.0057, 0.0060, 0.0385, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6696760654449463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0155, 0.0075, 0.0041, 0.0061, 0.0056, 0.0401, 0.0029]) \n",
      "Test Loss tensor([0.0176, 0.0157, 0.0080, 0.0049, 0.0054, 0.0064, 0.0388, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6356813907623291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0164, 0.0169, 0.0076, 0.0045, 0.0052, 0.0062, 0.0371, 0.0027]) \n",
      "Test Loss tensor([0.0186, 0.0159, 0.0077, 0.0052, 0.0056, 0.0058, 0.0407, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6964125633239746 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0138, 0.0097, 0.0035, 0.0063, 0.0057, 0.0345, 0.0024]) \n",
      "Test Loss tensor([0.0170, 0.0154, 0.0075, 0.0047, 0.0052, 0.0058, 0.0392, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.7081859111785889 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0164, 0.0157, 0.0076, 0.0056, 0.0045, 0.0049, 0.0414, 0.0026]) \n",
      "Test Loss tensor([0.0175, 0.0156, 0.0079, 0.0050, 0.0058, 0.0054, 0.0396, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.7061502933502197 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0152, 0.0074, 0.0046, 0.0054, 0.0041, 0.0427, 0.0025]) \n",
      "Test Loss tensor([0.0186, 0.0159, 0.0082, 0.0047, 0.0057, 0.0059, 0.0377, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.8341186046600342 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0160, 0.0054, 0.0044, 0.0048, 0.0063, 0.0374, 0.0024]) \n",
      "Test Loss tensor([0.0179, 0.0161, 0.0077, 0.0050, 0.0056, 0.0055, 0.0376, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7801871299743652 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0152, 0.0062, 0.0059, 0.0059, 0.0057, 0.0391, 0.0027]) \n",
      "Test Loss tensor([0.0181, 0.0164, 0.0078, 0.0049, 0.0056, 0.0060, 0.0371, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6832137107849121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0169, 0.0131, 0.0073, 0.0047, 0.0058, 0.0056, 0.0401, 0.0025]) \n",
      "Test Loss tensor([0.0181, 0.0161, 0.0076, 0.0050, 0.0051, 0.0059, 0.0369, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.695836067199707 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0209, 0.0130, 0.0074, 0.0043, 0.0047, 0.0061, 0.0359, 0.0025]) \n",
      "Test Loss tensor([0.0177, 0.0154, 0.0075, 0.0051, 0.0058, 0.0062, 0.0381, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.753546953201294 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0133, 0.0077, 0.0051, 0.0037, 0.0064, 0.0351, 0.0027]) \n",
      "Test Loss tensor([0.0181, 0.0151, 0.0072, 0.0049, 0.0056, 0.0059, 0.0355, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.8080697059631348 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0163, 0.0061, 0.0040, 0.0038, 0.0075, 0.0342, 0.0024]) \n",
      "Test Loss tensor([0.0179, 0.0150, 0.0077, 0.0049, 0.0052, 0.0056, 0.0360, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.8706748485565186 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0165, 0.0160, 0.0060, 0.0068, 0.0051, 0.0073, 0.0369, 0.0029]) \n",
      "Test Loss tensor([0.0173, 0.0154, 0.0075, 0.0049, 0.0058, 0.0056, 0.0357, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.7007675170898438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0180, 0.0133, 0.0087, 0.0046, 0.0049, 0.0066, 0.0338, 0.0025]) \n",
      "Test Loss tensor([0.0163, 0.0159, 0.0072, 0.0048, 0.0049, 0.0060, 0.0357, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.681513786315918 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0155, 0.0057, 0.0046, 0.0055, 0.0074, 0.0341, 0.0025]) \n",
      "Test Loss tensor([0.0171, 0.0157, 0.0071, 0.0049, 0.0056, 0.0054, 0.0350, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7197000980377197 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0183, 0.0142, 0.0056, 0.0051, 0.0054, 0.0060, 0.0352, 0.0025]) \n",
      "Test Loss tensor([0.0170, 0.0153, 0.0071, 0.0049, 0.0053, 0.0057, 0.0345, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6329421997070312 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0155, 0.0070, 0.0051, 0.0043, 0.0052, 0.0379, 0.0025]) \n",
      "Test Loss tensor([0.0185, 0.0153, 0.0073, 0.0050, 0.0057, 0.0058, 0.0351, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6375243663787842 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0207, 0.0146, 0.0086, 0.0049, 0.0058, 0.0066, 0.0369, 0.0026]) \n",
      "Test Loss tensor([0.0176, 0.0152, 0.0072, 0.0051, 0.0057, 0.0056, 0.0340, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6446771621704102 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0160, 0.0148, 0.0061, 0.0048, 0.0053, 0.0046, 0.0331, 0.0024]) \n",
      "Test Loss tensor([0.0169, 0.0144, 0.0074, 0.0050, 0.0054, 0.0055, 0.0328, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6272294521331787 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0129, 0.0051, 0.0055, 0.0073, 0.0061, 0.0347, 0.0025]) \n",
      "Test Loss tensor([0.0161, 0.0151, 0.0074, 0.0048, 0.0052, 0.0055, 0.0334, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6295232772827148 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0191, 0.0144, 0.0070, 0.0052, 0.0061, 0.0043, 0.0308, 0.0023]) \n",
      "Test Loss tensor([0.0160, 0.0146, 0.0075, 0.0049, 0.0047, 0.0054, 0.0315, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6179561614990234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0161, 0.0137, 0.0079, 0.0042, 0.0057, 0.0062, 0.0299, 0.0024]) \n",
      "Test Loss tensor([0.0176, 0.0144, 0.0072, 0.0052, 0.0055, 0.0060, 0.0316, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6224288940429688 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0177, 0.0175, 0.0070, 0.0063, 0.0046, 0.0066, 0.0302, 0.0023]) \n",
      "Test Loss tensor([0.0163, 0.0136, 0.0068, 0.0051, 0.0056, 0.0058, 0.0321, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6216168403625488 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0149, 0.0044, 0.0062, 0.0056, 0.0068, 0.0323, 0.0024]) \n",
      "Test Loss tensor([0.0174, 0.0137, 0.0064, 0.0054, 0.0053, 0.0066, 0.0304, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6164581775665283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0121, 0.0083, 0.0047, 0.0060, 0.0061, 0.0316, 0.0023]) \n",
      "Test Loss tensor([0.0158, 0.0137, 0.0065, 0.0053, 0.0050, 0.0059, 0.0302, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6943135261535645 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0148, 0.0065, 0.0042, 0.0063, 0.0073, 0.0298, 0.0024]) \n",
      "Test Loss tensor([0.0153, 0.0142, 0.0070, 0.0054, 0.0054, 0.0069, 0.0282, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6946401596069336 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0142, 0.0077, 0.0058, 0.0045, 0.0065, 0.0260, 0.0026]) \n",
      "Test Loss tensor([0.0146, 0.0137, 0.0064, 0.0055, 0.0049, 0.0073, 0.0276, 0.0027])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 576 in 0.6440072059631348 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0154, 0.0073, 0.0051, 0.0062, 0.0068, 0.0270, 0.0027]) \n",
      "Test Loss tensor([0.0155, 0.0137, 0.0062, 0.0055, 0.0054, 0.0070, 0.0271, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6521337032318115 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0146, 0.0084, 0.0050, 0.0081, 0.0064, 0.0266, 0.0029]) \n",
      "Test Loss tensor([0.0153, 0.0153, 0.0066, 0.0059, 0.0059, 0.0073, 0.0284, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.7008585929870605 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0169, 0.0187, 0.0065, 0.0059, 0.0062, 0.0077, 0.0262, 0.0032]) \n",
      "Test Loss tensor([0.0142, 0.0140, 0.0062, 0.0058, 0.0063, 0.0071, 0.0286, 0.0030])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.7423639297485352 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0131, 0.0066, 0.0058, 0.0065, 0.0072, 0.0267, 0.0031]) \n",
      "Test Loss tensor([0.0145, 0.0141, 0.0064, 0.0057, 0.0052, 0.0075, 0.0270, 0.0029])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.8271484375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0139, 0.0065, 0.0055, 0.0050, 0.0069, 0.0269, 0.0028]) \n",
      "Test Loss tensor([0.0151, 0.0135, 0.0068, 0.0056, 0.0055, 0.0068, 0.0271, 0.0028])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6477296352386475 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0110, 0.0059, 0.0054, 0.0048, 0.0066, 0.0259, 0.0027]) \n",
      "Test Loss tensor([0.0146, 0.0139, 0.0072, 0.0056, 0.0053, 0.0063, 0.0268, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.7379176616668701 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0153, 0.0151, 0.0059, 0.0055, 0.0067, 0.0066, 0.0234, 0.0027]) \n",
      "Test Loss tensor([0.0150, 0.0139, 0.0064, 0.0054, 0.0052, 0.0060, 0.0269, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6918330192565918 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0153, 0.0148, 0.0050, 0.0058, 0.0034, 0.0057, 0.0276, 0.0025]) \n",
      "Test Loss tensor([0.0166, 0.0133, 0.0070, 0.0053, 0.0053, 0.0060, 0.0271, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6320409774780273 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0138, 0.0088, 0.0059, 0.0047, 0.0044, 0.0257, 0.0026]) \n",
      "Test Loss tensor([0.0161, 0.0137, 0.0065, 0.0054, 0.0053, 0.0051, 0.0268, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.7605881690979004 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0212, 0.0130, 0.0058, 0.0057, 0.0054, 0.0041, 0.0267, 0.0024]) \n",
      "Test Loss tensor([0.0162, 0.0140, 0.0069, 0.0053, 0.0053, 0.0053, 0.0275, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.8531703948974609 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0143, 0.0061, 0.0046, 0.0046, 0.0053, 0.0271, 0.0024]) \n",
      "Test Loss tensor([0.0156, 0.0135, 0.0071, 0.0051, 0.0058, 0.0051, 0.0280, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6644666194915771 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0177, 0.0161, 0.0073, 0.0058, 0.0049, 0.0057, 0.0296, 0.0024]) \n",
      "Test Loss tensor([0.0172, 0.0144, 0.0070, 0.0054, 0.0057, 0.0051, 0.0272, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6535053253173828 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0147, 0.0063, 0.0044, 0.0078, 0.0043, 0.0256, 0.0023]) \n",
      "Test Loss tensor([0.0158, 0.0134, 0.0066, 0.0049, 0.0058, 0.0053, 0.0271, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.736269474029541 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0182, 0.0150, 0.0078, 0.0051, 0.0062, 0.0055, 0.0276, 0.0024]) \n",
      "Test Loss tensor([0.0154, 0.0142, 0.0073, 0.0050, 0.0059, 0.0046, 0.0268, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6582577228546143 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0181, 0.0103, 0.0065, 0.0036, 0.0053, 0.0058, 0.0270, 0.0023]) \n",
      "Test Loss tensor([0.0151, 0.0144, 0.0070, 0.0053, 0.0057, 0.0051, 0.0263, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.6598649024963379 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0153, 0.0083, 0.0051, 0.0043, 0.0048, 0.0286, 0.0025]) \n",
      "Test Loss tensor([0.0152, 0.0142, 0.0071, 0.0055, 0.0054, 0.0054, 0.0263, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.7670824527740479 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0157, 0.0150, 0.0060, 0.0050, 0.0046, 0.0044, 0.0269, 0.0024]) \n",
      "Test Loss tensor([0.0154, 0.0137, 0.0065, 0.0057, 0.0053, 0.0057, 0.0264, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.804542064666748 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0139, 0.0062, 0.0047, 0.0047, 0.0054, 0.0254, 0.0024]) \n",
      "Test Loss tensor([0.0151, 0.0144, 0.0069, 0.0055, 0.0055, 0.0056, 0.0263, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.7173030376434326 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0171, 0.0137, 0.0060, 0.0049, 0.0050, 0.0066, 0.0266, 0.0026]) \n",
      "Test Loss tensor([0.0158, 0.0136, 0.0070, 0.0056, 0.0054, 0.0061, 0.0255, 0.0027])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6913588047027588 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0144, 0.0073, 0.0046, 0.0057, 0.0061, 0.0256, 0.0026]) \n",
      "Test Loss tensor([0.0168, 0.0136, 0.0065, 0.0055, 0.0055, 0.0061, 0.0250, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6283540725708008 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0138, 0.0056, 0.0050, 0.0072, 0.0052, 0.0245, 0.0027]) \n",
      "Test Loss tensor([0.0159, 0.0132, 0.0065, 0.0053, 0.0058, 0.0061, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6281886100769043 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0181, 0.0127, 0.0061, 0.0046, 0.0074, 0.0053, 0.0249, 0.0027]) \n",
      "Test Loss tensor([0.0160, 0.0140, 0.0065, 0.0054, 0.0054, 0.0059, 0.0259, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6160483360290527 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0149, 0.0058, 0.0052, 0.0046, 0.0051, 0.0237, 0.0029]) \n",
      "Test Loss tensor([0.0151, 0.0136, 0.0065, 0.0054, 0.0051, 0.0056, 0.0247, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6133549213409424 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0184, 0.0137, 0.0071, 0.0055, 0.0066, 0.0038, 0.0228, 0.0026]) \n",
      "Test Loss tensor([0.0160, 0.0137, 0.0067, 0.0054, 0.0055, 0.0058, 0.0252, 0.0026])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6250135898590088 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0111, 0.0067, 0.0050, 0.0051, 0.0052, 0.0244, 0.0026]) \n",
      "Test Loss tensor([0.0156, 0.0129, 0.0066, 0.0050, 0.0056, 0.0055, 0.0243, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6339952945709229 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0136, 0.0061, 0.0058, 0.0054, 0.0051, 0.0244, 0.0023]) \n",
      "Test Loss tensor([0.0154, 0.0133, 0.0065, 0.0053, 0.0065, 0.0055, 0.0249, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6289045810699463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0165, 0.0142, 0.0079, 0.0052, 0.0055, 0.0049, 0.0263, 0.0025]) \n",
      "Test Loss tensor([0.0159, 0.0138, 0.0071, 0.0053, 0.0054, 0.0052, 0.0250, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6351799964904785 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0176, 0.0129, 0.0087, 0.0072, 0.0055, 0.0053, 0.0240, 0.0025]) \n",
      "Test Loss tensor([0.0152, 0.0138, 0.0066, 0.0051, 0.0057, 0.0054, 0.0254, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.617431640625 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0165, 0.0115, 0.0076, 0.0051, 0.0052, 0.0043, 0.0230, 0.0023]) \n",
      "Test Loss tensor([0.0159, 0.0132, 0.0059, 0.0053, 0.0056, 0.0053, 0.0246, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6263866424560547 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0190, 0.0150, 0.0060, 0.0052, 0.0053, 0.0048, 0.0246, 0.0024]) \n",
      "Test Loss tensor([0.0150, 0.0134, 0.0064, 0.0052, 0.0053, 0.0054, 0.0249, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6255018711090088 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0124, 0.0057, 0.0043, 0.0067, 0.0056, 0.0237, 0.0022]) \n",
      "Test Loss tensor([0.0154, 0.0136, 0.0055, 0.0050, 0.0049, 0.0050, 0.0252, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6321234703063965 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0129, 0.0076, 0.0048, 0.0067, 0.0052, 0.0253, 0.0027]) \n",
      "Test Loss tensor([0.0148, 0.0131, 0.0070, 0.0052, 0.0054, 0.0053, 0.0254, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6161980628967285 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0139, 0.0065, 0.0041, 0.0051, 0.0045, 0.0235, 0.0024]) \n",
      "Test Loss tensor([0.0147, 0.0134, 0.0068, 0.0048, 0.0052, 0.0053, 0.0252, 0.0024])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 708 in 0.6145100593566895 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0131, 0.0059, 0.0039, 0.0068, 0.0052, 0.0237, 0.0025]) \n",
      "Test Loss tensor([0.0157, 0.0133, 0.0067, 0.0050, 0.0060, 0.0053, 0.0241, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6188747882843018 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0123, 0.0062, 0.0048, 0.0057, 0.0052, 0.0237, 0.0024]) \n",
      "Test Loss tensor([0.0161, 0.0136, 0.0063, 0.0051, 0.0052, 0.0060, 0.0239, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.6183784008026123 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0166, 0.0154, 0.0056, 0.0044, 0.0059, 0.0062, 0.0256, 0.0026]) \n",
      "Test Loss tensor([0.0155, 0.0131, 0.0062, 0.0052, 0.0053, 0.0061, 0.0241, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6211400032043457 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0139, 0.0051, 0.0052, 0.0066, 0.0066, 0.0241, 0.0024]) \n",
      "Test Loss tensor([0.0149, 0.0131, 0.0064, 0.0053, 0.0049, 0.0057, 0.0237, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6166684627532959 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0156, 0.0141, 0.0055, 0.0049, 0.0054, 0.0065, 0.0254, 0.0024]) \n",
      "Test Loss tensor([0.0160, 0.0133, 0.0062, 0.0054, 0.0051, 0.0058, 0.0244, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6244750022888184 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0129, 0.0077, 0.0048, 0.0059, 0.0057, 0.0250, 0.0024]) \n",
      "Test Loss tensor([0.0153, 0.0138, 0.0063, 0.0052, 0.0054, 0.0050, 0.0242, 0.0025])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6246094703674316 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0166, 0.0136, 0.0052, 0.0049, 0.0064, 0.0063, 0.0219, 0.0028]) \n",
      "Test Loss tensor([0.0144, 0.0121, 0.0064, 0.0049, 0.0055, 0.0049, 0.0245, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.7756152153015137 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0131, 0.0057, 0.0051, 0.0072, 0.0044, 0.0256, 0.0023]) \n",
      "Test Loss tensor([0.0157, 0.0127, 0.0068, 0.0048, 0.0054, 0.0050, 0.0236, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 740 in 1.0991621017456055 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0154, 0.0077, 0.0043, 0.0083, 0.0041, 0.0239, 0.0024]) \n",
      "Test Loss tensor([0.0149, 0.0129, 0.0061, 0.0048, 0.0050, 0.0055, 0.0249, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.8548316955566406 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0132, 0.0080, 0.0058, 0.0058, 0.0054, 0.0230, 0.0025]) \n",
      "Test Loss tensor([0.0153, 0.0138, 0.0062, 0.0050, 0.0052, 0.0054, 0.0240, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7597043514251709 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0159, 0.0066, 0.0052, 0.0057, 0.0049, 0.0231, 0.0023]) \n",
      "Test Loss tensor([0.0148, 0.0135, 0.0062, 0.0049, 0.0052, 0.0054, 0.0248, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.8177597522735596 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0129, 0.0055, 0.0045, 0.0051, 0.0057, 0.0235, 0.0024]) \n",
      "Test Loss tensor([0.0157, 0.0141, 0.0066, 0.0053, 0.0052, 0.0056, 0.0249, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.6814754009246826 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0115, 0.0057, 0.0038, 0.0062, 0.0049, 0.0216, 0.0023]) \n",
      "Test Loss tensor([0.0141, 0.0131, 0.0060, 0.0047, 0.0054, 0.0052, 0.0240, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.7028422355651855 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0124, 0.0073, 0.0040, 0.0063, 0.0052, 0.0206, 0.0024]) \n",
      "Test Loss tensor([0.0152, 0.0130, 0.0060, 0.0049, 0.0057, 0.0048, 0.0232, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.9087798595428467 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0135, 0.0063, 0.0043, 0.0072, 0.0051, 0.0249, 0.0026]) \n",
      "Test Loss tensor([0.0143, 0.0132, 0.0062, 0.0047, 0.0058, 0.0047, 0.0236, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.8585917949676514 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0171, 0.0107, 0.0057, 0.0049, 0.0058, 0.0050, 0.0204, 0.0022]) \n",
      "Test Loss tensor([0.0159, 0.0126, 0.0066, 0.0049, 0.0056, 0.0048, 0.0245, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.8410871028900146 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0163, 0.0148, 0.0084, 0.0039, 0.0076, 0.0059, 0.0250, 0.0023]) \n",
      "Test Loss tensor([0.0150, 0.0128, 0.0060, 0.0046, 0.0061, 0.0048, 0.0235, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7813849449157715 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0114, 0.0057, 0.0055, 0.0062, 0.0039, 0.0241, 0.0026]) \n",
      "Test Loss tensor([0.0151, 0.0134, 0.0065, 0.0048, 0.0055, 0.0051, 0.0230, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 780 in 1.0097064971923828 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0163, 0.0050, 0.0042, 0.0067, 0.0049, 0.0234, 0.0026]) \n",
      "Test Loss tensor([0.0149, 0.0134, 0.0065, 0.0050, 0.0052, 0.0054, 0.0230, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.9058387279510498 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0124, 0.0047, 0.0056, 0.0049, 0.0054, 0.0247, 0.0026]) \n",
      "Test Loss tensor([0.0147, 0.0126, 0.0059, 0.0051, 0.0052, 0.0051, 0.0236, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.990882396697998 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0141, 0.0070, 0.0056, 0.0064, 0.0044, 0.0229, 0.0028]) \n",
      "Test Loss tensor([0.0151, 0.0138, 0.0061, 0.0049, 0.0054, 0.0053, 0.0231, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 792 in 1.0788376331329346 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0137, 0.0062, 0.0049, 0.0049, 0.0058, 0.0222, 0.0024]) \n",
      "Test Loss tensor([0.0149, 0.0131, 0.0064, 0.0047, 0.0058, 0.0052, 0.0223, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 796 in 1.0228796005249023 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0111, 0.0066, 0.0047, 0.0067, 0.0051, 0.0226, 0.0024]) \n",
      "Test Loss tensor([0.0156, 0.0129, 0.0067, 0.0049, 0.0054, 0.0051, 0.0228, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.997525691986084 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0126, 0.0051, 0.0055, 0.0056, 0.0061, 0.0222, 0.0024]) \n",
      "Test Loss tensor([0.0155, 0.0133, 0.0063, 0.0047, 0.0052, 0.0046, 0.0228, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.8253531455993652 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0196, 0.0168, 0.0068, 0.0050, 0.0062, 0.0054, 0.0225, 0.0024]) \n",
      "Test Loss tensor([0.0156, 0.0130, 0.0060, 0.0049, 0.0055, 0.0048, 0.0225, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6938509941101074 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0125, 0.0064, 0.0043, 0.0063, 0.0046, 0.0223, 0.0024]) \n",
      "Test Loss tensor([0.0148, 0.0132, 0.0062, 0.0048, 0.0049, 0.0049, 0.0222, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.729102373123169 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0137, 0.0059, 0.0048, 0.0064, 0.0058, 0.0237, 0.0024]) \n",
      "Test Loss tensor([0.0155, 0.0126, 0.0057, 0.0048, 0.0056, 0.0048, 0.0223, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6726691722869873 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0128, 0.0073, 0.0038, 0.0046, 0.0042, 0.0224, 0.0023]) \n",
      "Test Loss tensor([0.0147, 0.0125, 0.0063, 0.0048, 0.0053, 0.0046, 0.0225, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.7573864459991455 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0137, 0.0058, 0.0049, 0.0049, 0.0061, 0.0250, 0.0023]) \n",
      "Test Loss tensor([0.0148, 0.0129, 0.0064, 0.0049, 0.0052, 0.0051, 0.0230, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.8420836925506592 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0160, 0.0127, 0.0079, 0.0045, 0.0106, 0.0060, 0.0243, 0.0024]) \n",
      "Test Loss tensor([0.0155, 0.0124, 0.0067, 0.0047, 0.0057, 0.0053, 0.0223, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6970365047454834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0122, 0.0080, 0.0045, 0.0044, 0.0057, 0.0242, 0.0024]) \n",
      "Test Loss tensor([0.0144, 0.0127, 0.0062, 0.0048, 0.0053, 0.0050, 0.0222, 0.0024])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7340123653411865 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0119, 0.0065, 0.0045, 0.0062, 0.0051, 0.0221, 0.0023]) \n",
      "Test Loss tensor([0.0145, 0.0134, 0.0061, 0.0047, 0.0051, 0.0045, 0.0223, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.8368184566497803 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0166, 0.0140, 0.0052, 0.0038, 0.0065, 0.0047, 0.0205, 0.0023]) \n",
      "Test Loss tensor([0.0156, 0.0138, 0.0066, 0.0048, 0.0056, 0.0050, 0.0223, 0.0024])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 840 in 0.6729850769042969 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0132, 0.0061, 0.0048, 0.0047, 0.0059, 0.0254, 0.0023]) \n",
      "Test Loss tensor([0.0155, 0.0124, 0.0066, 0.0046, 0.0054, 0.0046, 0.0226, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6973280906677246 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0125, 0.0049, 0.0036, 0.0028, 0.0040, 0.0247, 0.0022]) \n",
      "Test Loss tensor([0.0157, 0.0133, 0.0063, 0.0050, 0.0056, 0.0050, 0.0221, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.8671059608459473 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0115, 0.0058, 0.0044, 0.0045, 0.0039, 0.0227, 0.0023]) \n",
      "Test Loss tensor([0.0154, 0.0132, 0.0064, 0.0046, 0.0058, 0.0049, 0.0216, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.8111348152160645 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0117, 0.0066, 0.0060, 0.0058, 0.0042, 0.0231, 0.0023]) \n",
      "Test Loss tensor([0.0151, 0.0131, 0.0060, 0.0046, 0.0053, 0.0049, 0.0217, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6739215850830078 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0130, 0.0058, 0.0052, 0.0033, 0.0043, 0.0231, 0.0021]) \n",
      "Test Loss tensor([0.0153, 0.0134, 0.0064, 0.0048, 0.0052, 0.0047, 0.0224, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7196507453918457 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0120, 0.0074, 0.0039, 0.0076, 0.0037, 0.0233, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0124, 0.0059, 0.0047, 0.0054, 0.0050, 0.0217, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6902642250061035 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0125, 0.0064, 0.0037, 0.0056, 0.0054, 0.0216, 0.0022]) \n",
      "Test Loss tensor([0.0147, 0.0129, 0.0065, 0.0046, 0.0053, 0.0052, 0.0217, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6628317832946777 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0127, 0.0073, 0.0047, 0.0066, 0.0054, 0.0215, 0.0023]) \n",
      "Test Loss tensor([0.0155, 0.0127, 0.0056, 0.0048, 0.0051, 0.0051, 0.0219, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.7516059875488281 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0175, 0.0100, 0.0052, 0.0050, 0.0068, 0.0050, 0.0215, 0.0025]) \n",
      "Test Loss tensor([0.0145, 0.0128, 0.0064, 0.0049, 0.0053, 0.0049, 0.0221, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6676099300384521 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0078, 0.0044, 0.0043, 0.0037, 0.0039, 0.0179, 0.0015]) \n",
      "Test Loss tensor([0.0156, 0.0130, 0.0062, 0.0049, 0.0054, 0.0048, 0.0213, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7024786472320557 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0163, 0.0116, 0.0050, 0.0046, 0.0062, 0.0048, 0.0215, 0.0025]) \n",
      "Test Loss tensor([0.0147, 0.0126, 0.0060, 0.0046, 0.0058, 0.0047, 0.0223, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.7083306312561035 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0167, 0.0126, 0.0054, 0.0058, 0.0049, 0.0050, 0.0230, 0.0024]) \n",
      "Test Loss tensor([0.0143, 0.0131, 0.0057, 0.0047, 0.0056, 0.0046, 0.0218, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6827676296234131 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0167, 0.0133, 0.0058, 0.0049, 0.0057, 0.0040, 0.0200, 0.0022]) \n",
      "Test Loss tensor([0.0154, 0.0127, 0.0064, 0.0047, 0.0057, 0.0048, 0.0216, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6248316764831543 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0118, 0.0066, 0.0042, 0.0058, 0.0046, 0.0199, 0.0023]) \n",
      "Test Loss tensor([0.0147, 0.0126, 0.0062, 0.0047, 0.0054, 0.0050, 0.0211, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6881897449493408 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0112, 0.0052, 0.0044, 0.0051, 0.0060, 0.0211, 0.0023]) \n",
      "Test Loss tensor([0.0154, 0.0131, 0.0058, 0.0045, 0.0057, 0.0048, 0.0217, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6884875297546387 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0170, 0.0123, 0.0054, 0.0048, 0.0047, 0.0048, 0.0222, 0.0023]) \n",
      "Test Loss tensor([0.0155, 0.0123, 0.0059, 0.0048, 0.0051, 0.0049, 0.0216, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6681280136108398 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0125, 0.0051, 0.0042, 0.0042, 0.0058, 0.0189, 0.0023]) \n",
      "Test Loss tensor([0.0143, 0.0122, 0.0055, 0.0047, 0.0055, 0.0046, 0.0215, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.629382848739624 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0170, 0.0119, 0.0060, 0.0046, 0.0045, 0.0050, 0.0215, 0.0024]) \n",
      "Test Loss tensor([0.0152, 0.0136, 0.0059, 0.0049, 0.0052, 0.0046, 0.0212, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6420516967773438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0171, 0.0138, 0.0060, 0.0051, 0.0053, 0.0046, 0.0211, 0.0021]) \n",
      "Test Loss tensor([0.0142, 0.0127, 0.0059, 0.0045, 0.0053, 0.0046, 0.0215, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.651557207107544 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0129, 0.0052, 0.0049, 0.0064, 0.0046, 0.0210, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0123, 0.0055, 0.0044, 0.0058, 0.0044, 0.0214, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6194248199462891 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0113, 0.0046, 0.0049, 0.0058, 0.0041, 0.0208, 0.0025]) \n",
      "Test Loss tensor([0.0145, 0.0123, 0.0058, 0.0047, 0.0049, 0.0047, 0.0218, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6568002700805664 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0165, 0.0145, 0.0062, 0.0052, 0.0064, 0.0046, 0.0198, 0.0023]) \n",
      "Test Loss tensor([0.0147, 0.0127, 0.0060, 0.0048, 0.0056, 0.0046, 0.0214, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6394999027252197 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0143, 0.0050, 0.0032, 0.0048, 0.0046, 0.0230, 0.0022]) \n",
      "Test Loss tensor([0.0150, 0.0120, 0.0059, 0.0042, 0.0057, 0.0046, 0.0206, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6564173698425293 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0111, 0.0062, 0.0041, 0.0051, 0.0051, 0.0201, 0.0023]) \n",
      "Test Loss tensor([0.0155, 0.0126, 0.0062, 0.0045, 0.0054, 0.0048, 0.0210, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6075129508972168 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0132, 0.0056, 0.0060, 0.0066, 0.0052, 0.0203, 0.0023]) \n",
      "Test Loss tensor([0.0145, 0.0133, 0.0057, 0.0046, 0.0051, 0.0050, 0.0212, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6824257373809814 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0120, 0.0058, 0.0044, 0.0046, 0.0041, 0.0214, 0.0023]) \n",
      "Test Loss tensor([0.0143, 0.0129, 0.0057, 0.0045, 0.0053, 0.0045, 0.0216, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6762526035308838 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0104, 0.0060, 0.0043, 0.0058, 0.0048, 0.0210, 0.0023]) \n",
      "Test Loss tensor([0.0153, 0.0127, 0.0056, 0.0047, 0.0058, 0.0045, 0.0211, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6612200736999512 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0116, 0.0043, 0.0050, 0.0066, 0.0049, 0.0192, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0132, 0.0056, 0.0045, 0.0049, 0.0047, 0.0211, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6114518642425537 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0182, 0.0145, 0.0052, 0.0048, 0.0063, 0.0050, 0.0206, 0.0022]) \n",
      "Test Loss tensor([0.0144, 0.0123, 0.0060, 0.0046, 0.0054, 0.0045, 0.0213, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6600437164306641 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0105, 0.0066, 0.0043, 0.0043, 0.0045, 0.0210, 0.0021]) \n",
      "Test Loss tensor([0.0153, 0.0121, 0.0061, 0.0043, 0.0055, 0.0047, 0.0208, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6500494480133057 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0124, 0.0049, 0.0044, 0.0068, 0.0048, 0.0205, 0.0023]) \n",
      "Test Loss tensor([0.0150, 0.0129, 0.0063, 0.0048, 0.0050, 0.0046, 0.0208, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6543066501617432 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0123, 0.0060, 0.0047, 0.0040, 0.0034, 0.0224, 0.0023]) \n",
      "Test Loss tensor([0.0135, 0.0117, 0.0058, 0.0042, 0.0059, 0.0044, 0.0209, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.629788875579834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0094, 0.0046, 0.0041, 0.0074, 0.0042, 0.0189, 0.0022]) \n",
      "Test Loss tensor([0.0151, 0.0124, 0.0061, 0.0046, 0.0057, 0.0048, 0.0202, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.66595458984375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0115, 0.0052, 0.0041, 0.0060, 0.0038, 0.0228, 0.0023]) \n",
      "Test Loss tensor([0.0146, 0.0119, 0.0062, 0.0044, 0.0053, 0.0046, 0.0212, 0.0022])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 96 in 0.7511820793151855 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0122, 0.0043, 0.0041, 0.0051, 0.0044, 0.0210, 0.0022]) \n",
      "Test Loss tensor([0.0146, 0.0123, 0.0058, 0.0045, 0.0054, 0.0048, 0.0207, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7084476947784424 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0129, 0.0055, 0.0047, 0.0040, 0.0046, 0.0181, 0.0022]) \n",
      "Test Loss tensor([0.0145, 0.0120, 0.0056, 0.0043, 0.0051, 0.0047, 0.0208, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6606624126434326 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0133, 0.0060, 0.0048, 0.0070, 0.0054, 0.0202, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0119, 0.0057, 0.0043, 0.0055, 0.0044, 0.0205, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6458189487457275 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0120, 0.0050, 0.0041, 0.0068, 0.0053, 0.0192, 0.0023]) \n",
      "Test Loss tensor([0.0156, 0.0119, 0.0058, 0.0047, 0.0053, 0.0044, 0.0205, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6495716571807861 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0116, 0.0048, 0.0040, 0.0065, 0.0040, 0.0221, 0.0023]) \n",
      "Test Loss tensor([0.0148, 0.0124, 0.0059, 0.0044, 0.0057, 0.0041, 0.0210, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6570062637329102 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0139, 0.0066, 0.0053, 0.0082, 0.0043, 0.0215, 0.0024]) \n",
      "Test Loss tensor([0.0146, 0.0128, 0.0058, 0.0043, 0.0050, 0.0045, 0.0206, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7825806140899658 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0092, 0.0070, 0.0028, 0.0054, 0.0038, 0.0191, 0.0021]) \n",
      "Test Loss tensor([0.0146, 0.0125, 0.0058, 0.0044, 0.0055, 0.0045, 0.0205, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.7818660736083984 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0114, 0.0054, 0.0043, 0.0060, 0.0035, 0.0197, 0.0022]) \n",
      "Test Loss tensor([0.0150, 0.0122, 0.0061, 0.0041, 0.0051, 0.0046, 0.0204, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6778943538665771 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0167, 0.0134, 0.0054, 0.0037, 0.0049, 0.0044, 0.0210, 0.0024]) \n",
      "Test Loss tensor([0.0151, 0.0125, 0.0058, 0.0045, 0.0052, 0.0048, 0.0208, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.667294979095459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0129, 0.0055, 0.0041, 0.0054, 0.0042, 0.0233, 0.0023]) \n",
      "Test Loss tensor([0.0144, 0.0126, 0.0059, 0.0041, 0.0058, 0.0045, 0.0200, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6765978336334229 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0124, 0.0051, 0.0039, 0.0049, 0.0044, 0.0198, 0.0021]) \n",
      "Test Loss tensor([0.0146, 0.0123, 0.0060, 0.0045, 0.0053, 0.0043, 0.0205, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.606499195098877 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0124, 0.0051, 0.0036, 0.0052, 0.0037, 0.0201, 0.0022]) \n",
      "Test Loss tensor([0.0154, 0.0124, 0.0058, 0.0045, 0.0051, 0.0045, 0.0205, 0.0023])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6521720886230469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0180, 0.0132, 0.0058, 0.0042, 0.0054, 0.0034, 0.0209, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0122, 0.0062, 0.0043, 0.0052, 0.0041, 0.0205, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6416482925415039 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0165, 0.0109, 0.0058, 0.0042, 0.0052, 0.0040, 0.0204, 0.0021]) \n",
      "Test Loss tensor([0.0138, 0.0119, 0.0057, 0.0044, 0.0050, 0.0043, 0.0203, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6727368831634521 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0119, 0.0057, 0.0046, 0.0062, 0.0048, 0.0202, 0.0021]) \n",
      "Test Loss tensor([0.0150, 0.0120, 0.0055, 0.0042, 0.0057, 0.0045, 0.0206, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6622257232666016 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0124, 0.0044, 0.0047, 0.0049, 0.0049, 0.0192, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0120, 0.0053, 0.0044, 0.0046, 0.0048, 0.0214, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6404340267181396 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0116, 0.0067, 0.0033, 0.0048, 0.0040, 0.0200, 0.0022]) \n",
      "Test Loss tensor([0.0141, 0.0123, 0.0057, 0.0043, 0.0051, 0.0048, 0.0202, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6465663909912109 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0125, 0.0052, 0.0044, 0.0041, 0.0043, 0.0207, 0.0022]) \n",
      "Test Loss tensor([0.0147, 0.0125, 0.0059, 0.0045, 0.0051, 0.0048, 0.0202, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6833622455596924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0163, 0.0114, 0.0052, 0.0032, 0.0052, 0.0046, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0124, 0.0058, 0.0047, 0.0048, 0.0048, 0.0201, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6761512756347656 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0099, 0.0044, 0.0044, 0.0058, 0.0046, 0.0210, 0.0023]) \n",
      "Test Loss tensor([0.0138, 0.0124, 0.0053, 0.0040, 0.0051, 0.0043, 0.0205, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6608963012695312 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0141, 0.0059, 0.0041, 0.0050, 0.0044, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0144, 0.0120, 0.0058, 0.0043, 0.0053, 0.0046, 0.0207, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6839122772216797 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0107, 0.0077, 0.0037, 0.0054, 0.0035, 0.0201, 0.0023]) \n",
      "Test Loss tensor([0.0149, 0.0113, 0.0057, 0.0044, 0.0061, 0.0044, 0.0200, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.658083438873291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0171, 0.0109, 0.0067, 0.0045, 0.0061, 0.0048, 0.0199, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0118, 0.0057, 0.0042, 0.0052, 0.0044, 0.0205, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6361062526702881 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0121, 0.0047, 0.0045, 0.0074, 0.0039, 0.0209, 0.0023]) \n",
      "Test Loss tensor([0.0146, 0.0121, 0.0055, 0.0043, 0.0054, 0.0046, 0.0211, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6669864654541016 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0121, 0.0062, 0.0040, 0.0047, 0.0037, 0.0205, 0.0022]) \n",
      "Test Loss tensor([0.0134, 0.0126, 0.0056, 0.0042, 0.0053, 0.0042, 0.0206, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6942520141601562 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0174, 0.0146, 0.0043, 0.0047, 0.0056, 0.0038, 0.0200, 0.0021]) \n",
      "Test Loss tensor([0.0147, 0.0117, 0.0056, 0.0043, 0.0056, 0.0046, 0.0201, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6380033493041992 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0126, 0.0063, 0.0043, 0.0044, 0.0047, 0.0200, 0.0023]) \n",
      "Test Loss tensor([0.0146, 0.0120, 0.0055, 0.0044, 0.0054, 0.0044, 0.0206, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6820554733276367 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0101, 0.0059, 0.0041, 0.0061, 0.0032, 0.0196, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0117, 0.0058, 0.0041, 0.0055, 0.0042, 0.0202, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6611690521240234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0114, 0.0059, 0.0051, 0.0061, 0.0048, 0.0203, 0.0022]) \n",
      "Test Loss tensor([0.0151, 0.0118, 0.0056, 0.0043, 0.0050, 0.0042, 0.0200, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.6612112522125244 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0109, 0.0050, 0.0052, 0.0051, 0.0054, 0.0207, 0.0024]) \n",
      "Test Loss tensor([0.0147, 0.0126, 0.0055, 0.0044, 0.0054, 0.0042, 0.0199, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6841652393341064 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0095, 0.0072, 0.0041, 0.0051, 0.0039, 0.0181, 0.0022]) \n",
      "Test Loss tensor([0.0137, 0.0121, 0.0056, 0.0041, 0.0053, 0.0041, 0.0209, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6649298667907715 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0094, 0.0046, 0.0044, 0.0061, 0.0035, 0.0222, 0.0020]) \n",
      "Test Loss tensor([0.0151, 0.0119, 0.0056, 0.0044, 0.0057, 0.0043, 0.0198, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.6848702430725098 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0154, 0.0055, 0.0036, 0.0048, 0.0051, 0.0225, 0.0022]) \n",
      "Test Loss tensor([0.0146, 0.0118, 0.0053, 0.0042, 0.0051, 0.0045, 0.0200, 0.0022])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 228 in 0.6659982204437256 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0122, 0.0063, 0.0037, 0.0066, 0.0047, 0.0186, 0.0021]) \n",
      "Test Loss tensor([0.0153, 0.0116, 0.0056, 0.0045, 0.0052, 0.0045, 0.0207, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.757554292678833 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0157, 0.0113, 0.0056, 0.0045, 0.0071, 0.0037, 0.0190, 0.0022]) \n",
      "Test Loss tensor([0.0151, 0.0124, 0.0059, 0.0044, 0.0058, 0.0044, 0.0202, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.8003201484680176 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0134, 0.0065, 0.0045, 0.0060, 0.0042, 0.0179, 0.0022]) \n",
      "Test Loss tensor([0.0149, 0.0120, 0.0050, 0.0039, 0.0055, 0.0041, 0.0199, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6523489952087402 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0110, 0.0069, 0.0047, 0.0054, 0.0043, 0.0222, 0.0022]) \n",
      "Test Loss tensor([0.0144, 0.0119, 0.0054, 0.0041, 0.0058, 0.0042, 0.0195, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6468663215637207 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0114, 0.0067, 0.0044, 0.0073, 0.0039, 0.0205, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0122, 0.0054, 0.0042, 0.0056, 0.0042, 0.0203, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.866302490234375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0167, 0.0120, 0.0054, 0.0038, 0.0070, 0.0033, 0.0193, 0.0021]) \n",
      "Test Loss tensor([0.0147, 0.0119, 0.0055, 0.0042, 0.0052, 0.0044, 0.0193, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7532527446746826 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0118, 0.0050, 0.0054, 0.0038, 0.0037, 0.0182, 0.0023]) \n",
      "Test Loss tensor([0.0149, 0.0122, 0.0053, 0.0043, 0.0055, 0.0046, 0.0198, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7987375259399414 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0107, 0.0055, 0.0033, 0.0046, 0.0056, 0.0194, 0.0022]) \n",
      "Test Loss tensor([0.0147, 0.0119, 0.0053, 0.0041, 0.0052, 0.0044, 0.0196, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.769500732421875 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0113, 0.0060, 0.0042, 0.0052, 0.0041, 0.0198, 0.0022]) \n",
      "Test Loss tensor([0.0142, 0.0111, 0.0052, 0.0039, 0.0058, 0.0042, 0.0194, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6768128871917725 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0162, 0.0152, 0.0050, 0.0036, 0.0041, 0.0051, 0.0212, 0.0021]) \n",
      "Test Loss tensor([0.0139, 0.0116, 0.0053, 0.0040, 0.0052, 0.0042, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.7342901229858398 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0103, 0.0050, 0.0037, 0.0066, 0.0043, 0.0201, 0.0022]) \n",
      "Test Loss tensor([0.0143, 0.0117, 0.0054, 0.0042, 0.0052, 0.0044, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.7956368923187256 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0106, 0.0052, 0.0041, 0.0061, 0.0041, 0.0199, 0.0022]) \n",
      "Test Loss tensor([0.0145, 0.0115, 0.0055, 0.0040, 0.0053, 0.0041, 0.0195, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.7514634132385254 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0185, 0.0109, 0.0054, 0.0042, 0.0054, 0.0052, 0.0193, 0.0022]) \n",
      "Test Loss tensor([0.0147, 0.0121, 0.0055, 0.0042, 0.0055, 0.0043, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6804633140563965 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0105, 0.0056, 0.0035, 0.0061, 0.0049, 0.0186, 0.0024]) \n",
      "Test Loss tensor([0.0147, 0.0122, 0.0050, 0.0042, 0.0055, 0.0044, 0.0198, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7015750408172607 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0191, 0.0128, 0.0056, 0.0047, 0.0043, 0.0046, 0.0193, 0.0023]) \n",
      "Test Loss tensor([0.0131, 0.0114, 0.0053, 0.0041, 0.0046, 0.0044, 0.0196, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.7110819816589355 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0117, 0.0049, 0.0037, 0.0051, 0.0049, 0.0187, 0.0021]) \n",
      "Test Loss tensor([0.0141, 0.0122, 0.0051, 0.0040, 0.0050, 0.0043, 0.0200, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.7641341686248779 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0125, 0.0052, 0.0035, 0.0060, 0.0044, 0.0205, 0.0021]) \n",
      "Test Loss tensor([0.0142, 0.0122, 0.0052, 0.0041, 0.0053, 0.0044, 0.0195, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.8180441856384277 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0119, 0.0051, 0.0035, 0.0072, 0.0042, 0.0204, 0.0021]) \n",
      "Test Loss tensor([0.0141, 0.0123, 0.0051, 0.0039, 0.0054, 0.0044, 0.0195, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.7582986354827881 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0168, 0.0115, 0.0060, 0.0040, 0.0044, 0.0041, 0.0191, 0.0025]) \n",
      "Test Loss tensor([0.0136, 0.0117, 0.0050, 0.0039, 0.0056, 0.0040, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.678600549697876 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0123, 0.0047, 0.0045, 0.0086, 0.0034, 0.0204, 0.0022]) \n",
      "Test Loss tensor([0.0141, 0.0114, 0.0052, 0.0039, 0.0058, 0.0039, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6838903427124023 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0124, 0.0058, 0.0048, 0.0076, 0.0037, 0.0184, 0.0023]) \n",
      "Test Loss tensor([0.0146, 0.0114, 0.0054, 0.0041, 0.0055, 0.0041, 0.0195, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7171714305877686 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0111, 0.0061, 0.0044, 0.0059, 0.0046, 0.0195, 0.0022]) \n",
      "Test Loss tensor([0.0141, 0.0117, 0.0051, 0.0040, 0.0057, 0.0039, 0.0194, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.8142030239105225 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0120, 0.0052, 0.0039, 0.0059, 0.0038, 0.0174, 0.0021]) \n",
      "Test Loss tensor([0.0145, 0.0116, 0.0049, 0.0041, 0.0054, 0.0042, 0.0191, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7011516094207764 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0133, 0.0049, 0.0035, 0.0058, 0.0041, 0.0212, 0.0020]) \n",
      "Test Loss tensor([0.0136, 0.0117, 0.0049, 0.0037, 0.0055, 0.0041, 0.0197, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6763656139373779 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0110, 0.0045, 0.0042, 0.0058, 0.0034, 0.0193, 0.0021]) \n",
      "Test Loss tensor([0.0139, 0.0116, 0.0050, 0.0041, 0.0053, 0.0041, 0.0199, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.7130966186523438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0111, 0.0051, 0.0036, 0.0040, 0.0045, 0.0196, 0.0021]) \n",
      "Test Loss tensor([0.0140, 0.0122, 0.0053, 0.0040, 0.0057, 0.0042, 0.0194, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.659306526184082 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0136, 0.0054, 0.0043, 0.0064, 0.0046, 0.0211, 0.0021]) \n",
      "Test Loss tensor([0.0135, 0.0116, 0.0054, 0.0041, 0.0056, 0.0042, 0.0199, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6815178394317627 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0193, 0.0149, 0.0040, 0.0043, 0.0072, 0.0035, 0.0181, 0.0022]) \n",
      "Test Loss tensor([0.0137, 0.0113, 0.0054, 0.0043, 0.0056, 0.0042, 0.0194, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6792745590209961 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0134, 0.0050, 0.0038, 0.0063, 0.0053, 0.0190, 0.0021]) \n",
      "Test Loss tensor([0.0133, 0.0120, 0.0052, 0.0041, 0.0052, 0.0040, 0.0199, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.6938533782958984 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0161, 0.0117, 0.0053, 0.0042, 0.0042, 0.0050, 0.0182, 0.0022]) \n",
      "Test Loss tensor([0.0136, 0.0117, 0.0055, 0.0042, 0.0060, 0.0039, 0.0193, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.6741604804992676 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0098, 0.0060, 0.0048, 0.0055, 0.0031, 0.0207, 0.0023]) \n",
      "Test Loss tensor([0.0139, 0.0120, 0.0052, 0.0039, 0.0051, 0.0038, 0.0200, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.661179780960083 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0106, 0.0058, 0.0043, 0.0066, 0.0047, 0.0185, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0118, 0.0053, 0.0041, 0.0055, 0.0040, 0.0191, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6749482154846191 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0109, 0.0066, 0.0034, 0.0058, 0.0038, 0.0201, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0112, 0.0052, 0.0043, 0.0057, 0.0039, 0.0198, 0.0022])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 360 in 0.7088408470153809 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0160, 0.0101, 0.0064, 0.0039, 0.0066, 0.0050, 0.0189, 0.0022]) \n",
      "Test Loss tensor([0.0136, 0.0118, 0.0049, 0.0041, 0.0055, 0.0042, 0.0187, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7263960838317871 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0116, 0.0048, 0.0034, 0.0034, 0.0037, 0.0184, 0.0021]) \n",
      "Test Loss tensor([0.0142, 0.0116, 0.0052, 0.0041, 0.0052, 0.0042, 0.0194, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7199997901916504 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0131, 0.0056, 0.0043, 0.0053, 0.0049, 0.0179, 0.0023]) \n",
      "Test Loss tensor([0.0148, 0.0117, 0.0055, 0.0043, 0.0058, 0.0039, 0.0191, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.6828725337982178 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0095, 0.0053, 0.0033, 0.0050, 0.0038, 0.0174, 0.0024]) \n",
      "Test Loss tensor([0.0147, 0.0119, 0.0052, 0.0040, 0.0054, 0.0039, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6965756416320801 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0134, 0.0050, 0.0047, 0.0061, 0.0035, 0.0192, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0115, 0.0051, 0.0040, 0.0052, 0.0037, 0.0193, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6855878829956055 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0176, 0.0112, 0.0042, 0.0040, 0.0061, 0.0033, 0.0204, 0.0021]) \n",
      "Test Loss tensor([0.0138, 0.0110, 0.0055, 0.0040, 0.0057, 0.0036, 0.0191, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.663001298904419 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0111, 0.0055, 0.0031, 0.0048, 0.0037, 0.0185, 0.0022]) \n",
      "Test Loss tensor([0.0148, 0.0114, 0.0055, 0.0041, 0.0058, 0.0039, 0.0193, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.6832137107849121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0125, 0.0062, 0.0048, 0.0059, 0.0041, 0.0179, 0.0021]) \n",
      "Test Loss tensor([0.0138, 0.0116, 0.0055, 0.0039, 0.0057, 0.0039, 0.0191, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7174355983734131 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0111, 0.0048, 0.0037, 0.0050, 0.0041, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0113, 0.0056, 0.0040, 0.0047, 0.0037, 0.0194, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6919586658477783 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0112, 0.0050, 0.0037, 0.0049, 0.0045, 0.0186, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0115, 0.0053, 0.0039, 0.0055, 0.0038, 0.0197, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.702350378036499 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0103, 0.0066, 0.0036, 0.0047, 0.0029, 0.0200, 0.0022]) \n",
      "Test Loss tensor([0.0142, 0.0116, 0.0054, 0.0043, 0.0052, 0.0039, 0.0193, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6833450794219971 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0117, 0.0044, 0.0031, 0.0051, 0.0035, 0.0190, 0.0022]) \n",
      "Test Loss tensor([0.0155, 0.0116, 0.0050, 0.0040, 0.0054, 0.0039, 0.0188, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6917238235473633 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0110, 0.0042, 0.0034, 0.0050, 0.0041, 0.0196, 0.0021]) \n",
      "Test Loss tensor([0.0147, 0.0113, 0.0055, 0.0038, 0.0052, 0.0039, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6918795108795166 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0112, 0.0059, 0.0051, 0.0046, 0.0042, 0.0202, 0.0021]) \n",
      "Test Loss tensor([0.0144, 0.0115, 0.0052, 0.0037, 0.0054, 0.0039, 0.0190, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.7122204303741455 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0153, 0.0104, 0.0049, 0.0042, 0.0047, 0.0038, 0.0183, 0.0021]) \n",
      "Test Loss tensor([0.0141, 0.0118, 0.0050, 0.0038, 0.0053, 0.0040, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.6874651908874512 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0153, 0.0124, 0.0056, 0.0043, 0.0058, 0.0041, 0.0197, 0.0024]) \n",
      "Test Loss tensor([0.0149, 0.0116, 0.0052, 0.0039, 0.0054, 0.0039, 0.0188, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.7435431480407715 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0128, 0.0053, 0.0047, 0.0057, 0.0035, 0.0176, 0.0022]) \n",
      "Test Loss tensor([0.0145, 0.0120, 0.0050, 0.0040, 0.0053, 0.0038, 0.0190, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6864669322967529 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0129, 0.0063, 0.0038, 0.0072, 0.0041, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0139, 0.0115, 0.0050, 0.0040, 0.0058, 0.0037, 0.0188, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.6620926856994629 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0121, 0.0046, 0.0032, 0.0061, 0.0032, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0147, 0.0114, 0.0052, 0.0040, 0.0052, 0.0039, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6340949535369873 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0114, 0.0057, 0.0033, 0.0047, 0.0033, 0.0181, 0.0021]) \n",
      "Test Loss tensor([0.0134, 0.0117, 0.0049, 0.0038, 0.0051, 0.0038, 0.0191, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6519680023193359 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0096, 0.0048, 0.0035, 0.0047, 0.0036, 0.0196, 0.0023]) \n",
      "Test Loss tensor([0.0137, 0.0119, 0.0051, 0.0038, 0.0048, 0.0038, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.67618727684021 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0117, 0.0044, 0.0030, 0.0055, 0.0033, 0.0186, 0.0022]) \n",
      "Test Loss tensor([0.0140, 0.0117, 0.0049, 0.0038, 0.0053, 0.0039, 0.0189, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6696653366088867 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0121, 0.0052, 0.0034, 0.0040, 0.0038, 0.0191, 0.0022]) \n",
      "Test Loss tensor([0.0147, 0.0118, 0.0048, 0.0041, 0.0053, 0.0039, 0.0188, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6772556304931641 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0116, 0.0045, 0.0041, 0.0042, 0.0034, 0.0171, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0119, 0.0051, 0.0041, 0.0053, 0.0041, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6879322528839111 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0149, 0.0094, 0.0047, 0.0033, 0.0062, 0.0040, 0.0191, 0.0022]) \n",
      "Test Loss tensor([0.0142, 0.0114, 0.0048, 0.0042, 0.0050, 0.0041, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7605793476104736 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0116, 0.0055, 0.0044, 0.0060, 0.0049, 0.0179, 0.0020]) \n",
      "Test Loss tensor([0.0140, 0.0112, 0.0049, 0.0039, 0.0050, 0.0039, 0.0185, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6871242523193359 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0113, 0.0053, 0.0041, 0.0065, 0.0041, 0.0190, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0109, 0.0049, 0.0039, 0.0053, 0.0039, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6410806179046631 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0120, 0.0053, 0.0040, 0.0046, 0.0034, 0.0186, 0.0022]) \n",
      "Test Loss tensor([0.0140, 0.0113, 0.0053, 0.0039, 0.0050, 0.0039, 0.0185, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.672661304473877 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0114, 0.0053, 0.0036, 0.0046, 0.0030, 0.0185, 0.0021]) \n",
      "Test Loss tensor([0.0139, 0.0116, 0.0051, 0.0043, 0.0049, 0.0039, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6838414669036865 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0130, 0.0054, 0.0030, 0.0074, 0.0049, 0.0197, 0.0022]) \n",
      "Test Loss tensor([0.0141, 0.0115, 0.0050, 0.0039, 0.0053, 0.0039, 0.0189, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6731100082397461 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0173, 0.0105, 0.0068, 0.0036, 0.0068, 0.0045, 0.0185, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0109, 0.0053, 0.0036, 0.0051, 0.0041, 0.0188, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6956586837768555 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0112, 0.0045, 0.0041, 0.0065, 0.0038, 0.0187, 0.0021]) \n",
      "Test Loss tensor([0.0137, 0.0107, 0.0047, 0.0040, 0.0051, 0.0039, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.7407171726226807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0093, 0.0059, 0.0029, 0.0075, 0.0034, 0.0182, 0.0022]) \n",
      "Test Loss tensor([0.0144, 0.0112, 0.0050, 0.0038, 0.0054, 0.0039, 0.0193, 0.0021])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 492 in 0.7094521522521973 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0115, 0.0040, 0.0039, 0.0062, 0.0034, 0.0184, 0.0021]) \n",
      "Test Loss tensor([0.0138, 0.0109, 0.0051, 0.0039, 0.0048, 0.0040, 0.0191, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.6684091091156006 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0097, 0.0050, 0.0029, 0.0054, 0.0035, 0.0188, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0116, 0.0048, 0.0036, 0.0052, 0.0044, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6916224956512451 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0119, 0.0042, 0.0034, 0.0064, 0.0042, 0.0191, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0113, 0.0048, 0.0038, 0.0055, 0.0039, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6524925231933594 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0121, 0.0046, 0.0038, 0.0043, 0.0032, 0.0182, 0.0021]) \n",
      "Test Loss tensor([0.0140, 0.0113, 0.0049, 0.0039, 0.0049, 0.0039, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.649634838104248 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0131, 0.0044, 0.0042, 0.0043, 0.0049, 0.0211, 0.0023]) \n",
      "Test Loss tensor([0.0151, 0.0116, 0.0049, 0.0040, 0.0057, 0.0039, 0.0185, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.7114593982696533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0107, 0.0051, 0.0037, 0.0041, 0.0042, 0.0174, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0118, 0.0046, 0.0040, 0.0052, 0.0038, 0.0191, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.7416026592254639 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0102, 0.0057, 0.0039, 0.0067, 0.0042, 0.0185, 0.0020]) \n",
      "Test Loss tensor([0.0142, 0.0111, 0.0047, 0.0038, 0.0052, 0.0039, 0.0193, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.665283203125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0111, 0.0045, 0.0047, 0.0056, 0.0042, 0.0176, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0115, 0.0047, 0.0037, 0.0049, 0.0038, 0.0194, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.7065143585205078 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0161, 0.0040, 0.0040, 0.0042, 0.0043, 0.0191, 0.0020]) \n",
      "Test Loss tensor([0.0140, 0.0111, 0.0048, 0.0037, 0.0048, 0.0038, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6956636905670166 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0120, 0.0046, 0.0033, 0.0059, 0.0039, 0.0191, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0108, 0.0047, 0.0039, 0.0052, 0.0038, 0.0184, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6390018463134766 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0078, 0.0056, 0.0035, 0.0070, 0.0041, 0.0188, 0.0024]) \n",
      "Test Loss tensor([0.0141, 0.0115, 0.0048, 0.0037, 0.0050, 0.0038, 0.0184, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6847696304321289 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0101, 0.0041, 0.0032, 0.0068, 0.0038, 0.0181, 0.0020]) \n",
      "Test Loss tensor([0.0131, 0.0109, 0.0046, 0.0037, 0.0051, 0.0038, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6816699504852295 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0087, 0.0042, 0.0031, 0.0055, 0.0044, 0.0167, 0.0022]) \n",
      "Test Loss tensor([0.0145, 0.0111, 0.0048, 0.0038, 0.0051, 0.0039, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6962876319885254 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0103, 0.0041, 0.0036, 0.0055, 0.0047, 0.0181, 0.0021]) \n",
      "Test Loss tensor([0.0127, 0.0109, 0.0048, 0.0039, 0.0050, 0.0037, 0.0190, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6829814910888672 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0106, 0.0043, 0.0029, 0.0057, 0.0035, 0.0172, 0.0021]) \n",
      "Test Loss tensor([0.0142, 0.0110, 0.0048, 0.0038, 0.0056, 0.0037, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6717767715454102 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0107, 0.0057, 0.0045, 0.0050, 0.0033, 0.0168, 0.0021]) \n",
      "Test Loss tensor([0.0139, 0.0110, 0.0049, 0.0039, 0.0058, 0.0036, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6974427700042725 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0115, 0.0049, 0.0030, 0.0062, 0.0038, 0.0198, 0.0021]) \n",
      "Test Loss tensor([0.0140, 0.0111, 0.0052, 0.0039, 0.0052, 0.0036, 0.0187, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6640167236328125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0122, 0.0056, 0.0038, 0.0045, 0.0039, 0.0189, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0112, 0.0048, 0.0038, 0.0052, 0.0036, 0.0187, 0.0022])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6295502185821533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0108, 0.0049, 0.0043, 0.0046, 0.0032, 0.0193, 0.0022]) \n",
      "Test Loss tensor([0.0141, 0.0111, 0.0051, 0.0036, 0.0051, 0.0039, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.632171630859375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0164, 0.0099, 0.0062, 0.0038, 0.0068, 0.0038, 0.0179, 0.0021]) \n",
      "Test Loss tensor([0.0135, 0.0113, 0.0049, 0.0038, 0.0051, 0.0036, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6323902606964111 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0119, 0.0044, 0.0037, 0.0049, 0.0038, 0.0209, 0.0020]) \n",
      "Test Loss tensor([0.0147, 0.0109, 0.0047, 0.0037, 0.0056, 0.0036, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6356232166290283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0105, 0.0051, 0.0036, 0.0058, 0.0026, 0.0181, 0.0020]) \n",
      "Test Loss tensor([0.0138, 0.0110, 0.0050, 0.0036, 0.0051, 0.0037, 0.0187, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6181144714355469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0135, 0.0040, 0.0035, 0.0081, 0.0045, 0.0189, 0.0020]) \n",
      "Test Loss tensor([0.0140, 0.0124, 0.0050, 0.0039, 0.0051, 0.0037, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.7138814926147461 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0093, 0.0054, 0.0045, 0.0052, 0.0031, 0.0176, 0.0022]) \n",
      "Test Loss tensor([0.0134, 0.0111, 0.0049, 0.0037, 0.0053, 0.0035, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6891458034515381 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0091, 0.0043, 0.0037, 0.0047, 0.0035, 0.0188, 0.0023]) \n",
      "Test Loss tensor([0.0134, 0.0110, 0.0047, 0.0041, 0.0054, 0.0038, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6863889694213867 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0129, 0.0056, 0.0032, 0.0043, 0.0038, 0.0188, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0110, 0.0048, 0.0037, 0.0054, 0.0036, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.673609733581543 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0087, 0.0034, 0.0033, 0.0061, 0.0032, 0.0192, 0.0020]) \n",
      "Test Loss tensor([0.0137, 0.0109, 0.0048, 0.0038, 0.0049, 0.0038, 0.0181, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.706871747970581 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0105, 0.0055, 0.0036, 0.0059, 0.0035, 0.0182, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0109, 0.0049, 0.0036, 0.0053, 0.0038, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6965196132659912 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0092, 0.0039, 0.0034, 0.0071, 0.0044, 0.0181, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0115, 0.0046, 0.0038, 0.0053, 0.0036, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.704749584197998 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0122, 0.0032, 0.0033, 0.0050, 0.0036, 0.0187, 0.0022]) \n",
      "Test Loss tensor([0.0136, 0.0119, 0.0047, 0.0042, 0.0051, 0.0039, 0.0194, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.6816353797912598 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0102, 0.0043, 0.0035, 0.0065, 0.0046, 0.0175, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0117, 0.0050, 0.0040, 0.0052, 0.0037, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6766090393066406 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0104, 0.0050, 0.0039, 0.0046, 0.0036, 0.0184, 0.0021]) \n",
      "Test Loss tensor([0.0125, 0.0108, 0.0043, 0.0036, 0.0054, 0.0038, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6719684600830078 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0088, 0.0052, 0.0036, 0.0056, 0.0031, 0.0188, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0112, 0.0052, 0.0037, 0.0055, 0.0040, 0.0181, 0.0021])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 624 in 0.6718113422393799 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0146, 0.0108, 0.0059, 0.0032, 0.0071, 0.0038, 0.0185, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0108, 0.0049, 0.0038, 0.0054, 0.0036, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.664348840713501 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0119, 0.0039, 0.0038, 0.0063, 0.0035, 0.0192, 0.0022]) \n",
      "Test Loss tensor([0.0137, 0.0109, 0.0046, 0.0037, 0.0060, 0.0035, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6626358032226562 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0131, 0.0048, 0.0029, 0.0059, 0.0036, 0.0190, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0108, 0.0051, 0.0038, 0.0048, 0.0037, 0.0181, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.671527624130249 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0100, 0.0039, 0.0033, 0.0055, 0.0040, 0.0206, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0107, 0.0049, 0.0035, 0.0051, 0.0036, 0.0185, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6481878757476807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0096, 0.0042, 0.0033, 0.0078, 0.0037, 0.0184, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0108, 0.0045, 0.0034, 0.0054, 0.0038, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.65716552734375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0111, 0.0048, 0.0045, 0.0064, 0.0036, 0.0192, 0.0021]) \n",
      "Test Loss tensor([0.0137, 0.0105, 0.0046, 0.0038, 0.0045, 0.0038, 0.0178, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6530482769012451 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0137, 0.0041, 0.0033, 0.0042, 0.0033, 0.0194, 0.0021]) \n",
      "Test Loss tensor([0.0148, 0.0115, 0.0054, 0.0039, 0.0056, 0.0038, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6481618881225586 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0105, 0.0048, 0.0038, 0.0073, 0.0033, 0.0178, 0.0022]) \n",
      "Test Loss tensor([0.0133, 0.0114, 0.0051, 0.0037, 0.0049, 0.0035, 0.0185, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6916942596435547 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0116, 0.0049, 0.0044, 0.0045, 0.0039, 0.0179, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0112, 0.0047, 0.0034, 0.0048, 0.0037, 0.0185, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.649040937423706 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0113, 0.0050, 0.0030, 0.0067, 0.0034, 0.0198, 0.0022]) \n",
      "Test Loss tensor([0.0140, 0.0106, 0.0050, 0.0036, 0.0056, 0.0035, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6611204147338867 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0107, 0.0047, 0.0036, 0.0065, 0.0036, 0.0171, 0.0020]) \n",
      "Test Loss tensor([0.0130, 0.0114, 0.0046, 0.0035, 0.0050, 0.0035, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6628472805023193 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0109, 0.0055, 0.0042, 0.0056, 0.0034, 0.0187, 0.0021]) \n",
      "Test Loss tensor([0.0130, 0.0119, 0.0046, 0.0038, 0.0052, 0.0036, 0.0189, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6705210208892822 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0118, 0.0054, 0.0031, 0.0066, 0.0038, 0.0179, 0.0020]) \n",
      "Test Loss tensor([0.0130, 0.0111, 0.0046, 0.0037, 0.0052, 0.0038, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6676938533782959 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0101, 0.0041, 0.0031, 0.0058, 0.0031, 0.0188, 0.0021]) \n",
      "Test Loss tensor([0.0143, 0.0111, 0.0048, 0.0036, 0.0058, 0.0036, 0.0178, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6856579780578613 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0101, 0.0055, 0.0038, 0.0056, 0.0035, 0.0185, 0.0021]) \n",
      "Test Loss tensor([0.0133, 0.0113, 0.0051, 0.0036, 0.0056, 0.0035, 0.0179, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.701359748840332 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0172, 0.0099, 0.0048, 0.0032, 0.0073, 0.0037, 0.0176, 0.0021]) \n",
      "Test Loss tensor([0.0135, 0.0110, 0.0048, 0.0039, 0.0052, 0.0036, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6835870742797852 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0163, 0.0119, 0.0055, 0.0031, 0.0065, 0.0030, 0.0178, 0.0020]) \n",
      "Test Loss tensor([0.0140, 0.0110, 0.0048, 0.0036, 0.0058, 0.0039, 0.0176, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6859855651855469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0107, 0.0042, 0.0029, 0.0050, 0.0040, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0137, 0.0111, 0.0048, 0.0035, 0.0054, 0.0036, 0.0181, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.7332723140716553 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0152, 0.0083, 0.0047, 0.0032, 0.0056, 0.0030, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0107, 0.0046, 0.0039, 0.0052, 0.0037, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6707725524902344 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0090, 0.0049, 0.0035, 0.0054, 0.0035, 0.0170, 0.0021]) \n",
      "Test Loss tensor([0.0142, 0.0115, 0.0042, 0.0039, 0.0049, 0.0037, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6592483520507812 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0124, 0.0041, 0.0033, 0.0056, 0.0040, 0.0195, 0.0019]) \n",
      "Test Loss tensor([0.0136, 0.0107, 0.0044, 0.0036, 0.0052, 0.0038, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.7369441986083984 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0115, 0.0038, 0.0028, 0.0065, 0.0038, 0.0185, 0.0022]) \n",
      "Test Loss tensor([0.0132, 0.0117, 0.0045, 0.0036, 0.0051, 0.0036, 0.0181, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.7544558048248291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0125, 0.0037, 0.0026, 0.0059, 0.0040, 0.0185, 0.0019]) \n",
      "Test Loss tensor([0.0135, 0.0116, 0.0049, 0.0039, 0.0054, 0.0033, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.7410953044891357 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0168, 0.0119, 0.0044, 0.0035, 0.0045, 0.0047, 0.0190, 0.0020]) \n",
      "Test Loss tensor([0.0142, 0.0111, 0.0048, 0.0037, 0.0055, 0.0037, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.7084600925445557 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0101, 0.0044, 0.0034, 0.0051, 0.0031, 0.0196, 0.0020]) \n",
      "Test Loss tensor([0.0143, 0.0115, 0.0050, 0.0039, 0.0053, 0.0037, 0.0179, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.696274995803833 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0118, 0.0049, 0.0039, 0.0061, 0.0035, 0.0185, 0.0020]) \n",
      "Test Loss tensor([0.0137, 0.0110, 0.0048, 0.0036, 0.0051, 0.0036, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.6671736240386963 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0106, 0.0042, 0.0030, 0.0051, 0.0041, 0.0175, 0.0020]) \n",
      "Test Loss tensor([0.0132, 0.0111, 0.0045, 0.0034, 0.0055, 0.0036, 0.0181, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.7445335388183594 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0123, 0.0056, 0.0044, 0.0058, 0.0033, 0.0197, 0.0020]) \n",
      "Test Loss tensor([0.0130, 0.0110, 0.0044, 0.0036, 0.0053, 0.0036, 0.0179, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.8725423812866211 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0105, 0.0035, 0.0034, 0.0060, 0.0037, 0.0160, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0112, 0.0047, 0.0036, 0.0053, 0.0035, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.7195515632629395 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0127, 0.0042, 0.0033, 0.0061, 0.0043, 0.0178, 0.0021]) \n",
      "Test Loss tensor([0.0131, 0.0105, 0.0048, 0.0037, 0.0059, 0.0036, 0.0175, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6782920360565186 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0109, 0.0057, 0.0042, 0.0047, 0.0031, 0.0175, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0110, 0.0046, 0.0035, 0.0054, 0.0034, 0.0175, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.7252771854400635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0107, 0.0045, 0.0043, 0.0065, 0.0028, 0.0174, 0.0020]) \n",
      "Test Loss tensor([0.0138, 0.0106, 0.0049, 0.0036, 0.0057, 0.0034, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6878516674041748 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0129, 0.0057, 0.0033, 0.0062, 0.0025, 0.0177, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0107, 0.0049, 0.0033, 0.0052, 0.0032, 0.0180, 0.0021])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 756 in 0.7142331600189209 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0102, 0.0040, 0.0033, 0.0052, 0.0033, 0.0186, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0107, 0.0048, 0.0037, 0.0051, 0.0034, 0.0182, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6552095413208008 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0147, 0.0113, 0.0047, 0.0041, 0.0066, 0.0032, 0.0175, 0.0022]) \n",
      "Test Loss tensor([0.0136, 0.0105, 0.0048, 0.0038, 0.0052, 0.0035, 0.0186, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6524217128753662 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0095, 0.0051, 0.0026, 0.0042, 0.0038, 0.0178, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0108, 0.0048, 0.0038, 0.0050, 0.0035, 0.0175, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6795346736907959 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0135, 0.0044, 0.0032, 0.0061, 0.0032, 0.0189, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0113, 0.0046, 0.0036, 0.0047, 0.0036, 0.0179, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6678650379180908 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0166, 0.0090, 0.0048, 0.0036, 0.0051, 0.0045, 0.0179, 0.0020]) \n",
      "Test Loss tensor([0.0138, 0.0107, 0.0048, 0.0034, 0.0054, 0.0035, 0.0181, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7186224460601807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0107, 0.0052, 0.0036, 0.0046, 0.0034, 0.0197, 0.0021]) \n",
      "Test Loss tensor([0.0133, 0.0107, 0.0051, 0.0036, 0.0052, 0.0031, 0.0183, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.687359094619751 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0100, 0.0049, 0.0036, 0.0043, 0.0032, 0.0177, 0.0020]) \n",
      "Test Loss tensor([0.0127, 0.0113, 0.0045, 0.0037, 0.0052, 0.0034, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6669821739196777 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0097, 0.0046, 0.0039, 0.0042, 0.0030, 0.0185, 0.0020]) \n",
      "Test Loss tensor([0.0132, 0.0106, 0.0048, 0.0034, 0.0053, 0.0034, 0.0174, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6760385036468506 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0120, 0.0050, 0.0042, 0.0060, 0.0038, 0.0182, 0.0021]) \n",
      "Test Loss tensor([0.0141, 0.0110, 0.0045, 0.0034, 0.0054, 0.0036, 0.0171, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.782158613204956 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0089, 0.0042, 0.0032, 0.0072, 0.0036, 0.0165, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0106, 0.0044, 0.0036, 0.0048, 0.0038, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6777565479278564 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0104, 0.0042, 0.0041, 0.0045, 0.0027, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0113, 0.0045, 0.0034, 0.0052, 0.0036, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.7074778079986572 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0100, 0.0061, 0.0042, 0.0045, 0.0030, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0106, 0.0048, 0.0037, 0.0053, 0.0034, 0.0179, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6681909561157227 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0091, 0.0049, 0.0037, 0.0041, 0.0030, 0.0165, 0.0021]) \n",
      "Test Loss tensor([0.0133, 0.0114, 0.0045, 0.0034, 0.0050, 0.0036, 0.0175, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6655535697937012 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0103, 0.0045, 0.0043, 0.0057, 0.0032, 0.0171, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0106, 0.0048, 0.0037, 0.0050, 0.0033, 0.0185, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6798999309539795 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0102, 0.0050, 0.0035, 0.0054, 0.0027, 0.0175, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0112, 0.0046, 0.0034, 0.0049, 0.0035, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.663646936416626 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0093, 0.0044, 0.0041, 0.0047, 0.0033, 0.0165, 0.0020]) \n",
      "Test Loss tensor([0.0130, 0.0106, 0.0046, 0.0033, 0.0052, 0.0034, 0.0180, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6668946743011475 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0112, 0.0043, 0.0033, 0.0061, 0.0033, 0.0193, 0.0021]) \n",
      "Test Loss tensor([0.0133, 0.0107, 0.0045, 0.0039, 0.0050, 0.0038, 0.0175, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6850976943969727 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0106, 0.0048, 0.0032, 0.0056, 0.0039, 0.0187, 0.0021]) \n",
      "Test Loss tensor([0.0130, 0.0115, 0.0043, 0.0037, 0.0046, 0.0037, 0.0178, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6453852653503418 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0096, 0.0046, 0.0037, 0.0050, 0.0039, 0.0168, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0115, 0.0044, 0.0034, 0.0052, 0.0036, 0.0167, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.7050235271453857 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0108, 0.0056, 0.0030, 0.0055, 0.0031, 0.0174, 0.0022]) \n",
      "Test Loss tensor([0.0135, 0.0114, 0.0047, 0.0035, 0.0058, 0.0034, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6847105026245117 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0083, 0.0039, 0.0024, 0.0055, 0.0033, 0.0174, 0.0020]) \n",
      "Test Loss tensor([0.0139, 0.0106, 0.0047, 0.0034, 0.0052, 0.0034, 0.0178, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6629853248596191 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0121, 0.0036, 0.0034, 0.0055, 0.0038, 0.0180, 0.0020]) \n",
      "Test Loss tensor([0.0132, 0.0109, 0.0044, 0.0033, 0.0051, 0.0031, 0.0180, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6828467845916748 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0087, 0.0051, 0.0032, 0.0052, 0.0036, 0.0173, 0.0020]) \n",
      "Test Loss tensor([0.0138, 0.0106, 0.0046, 0.0034, 0.0052, 0.0034, 0.0180, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.6664156913757324 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0109, 0.0056, 0.0026, 0.0065, 0.0030, 0.0180, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0108, 0.0049, 0.0038, 0.0052, 0.0035, 0.0178, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.691162109375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0096, 0.0041, 0.0032, 0.0051, 0.0040, 0.0162, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0111, 0.0046, 0.0038, 0.0048, 0.0035, 0.0176, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6673033237457275 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0127, 0.0054, 0.0042, 0.0054, 0.0029, 0.0182, 0.0022]) \n",
      "Test Loss tensor([0.0139, 0.0110, 0.0044, 0.0032, 0.0051, 0.0034, 0.0174, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6760444641113281 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0108, 0.0053, 0.0039, 0.0071, 0.0035, 0.0198, 0.0020]) \n",
      "Test Loss tensor([0.0136, 0.0107, 0.0049, 0.0036, 0.0051, 0.0034, 0.0175, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.6620175838470459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0138, 0.0043, 0.0039, 0.0051, 0.0034, 0.0177, 0.0021]) \n",
      "Test Loss tensor([0.0134, 0.0116, 0.0045, 0.0036, 0.0050, 0.0034, 0.0184, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6898174285888672 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0088, 0.0040, 0.0037, 0.0038, 0.0036, 0.0175, 0.0021]) \n",
      "Test Loss tensor([0.0131, 0.0108, 0.0044, 0.0036, 0.0055, 0.0036, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.656125545501709 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0115, 0.0049, 0.0035, 0.0044, 0.0035, 0.0181, 0.0020]) \n",
      "Test Loss tensor([0.0130, 0.0106, 0.0047, 0.0036, 0.0052, 0.0032, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6689462661743164 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0102, 0.0032, 0.0025, 0.0039, 0.0034, 0.0121, 0.0015]) \n",
      "Test Loss tensor([0.0130, 0.0104, 0.0046, 0.0035, 0.0052, 0.0035, 0.0179, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.712932825088501 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0122, 0.0035, 0.0032, 0.0044, 0.0040, 0.0191, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0113, 0.0044, 0.0035, 0.0050, 0.0035, 0.0178, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.682354211807251 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0155, 0.0115, 0.0046, 0.0038, 0.0042, 0.0029, 0.0163, 0.0020]) \n",
      "Test Loss tensor([0.0141, 0.0104, 0.0047, 0.0034, 0.0052, 0.0035, 0.0170, 0.0021])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 8 in 0.6810195446014404 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0101, 0.0047, 0.0030, 0.0050, 0.0027, 0.0175, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0113, 0.0044, 0.0036, 0.0048, 0.0033, 0.0179, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6931633949279785 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0113, 0.0041, 0.0031, 0.0058, 0.0029, 0.0184, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0108, 0.0047, 0.0034, 0.0052, 0.0034, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6835088729858398 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0111, 0.0047, 0.0035, 0.0066, 0.0034, 0.0183, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0109, 0.0044, 0.0036, 0.0051, 0.0033, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7222437858581543 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0104, 0.0047, 0.0039, 0.0063, 0.0028, 0.0193, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0115, 0.0045, 0.0035, 0.0048, 0.0034, 0.0180, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6737630367279053 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0113, 0.0041, 0.0032, 0.0069, 0.0042, 0.0183, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0106, 0.0044, 0.0036, 0.0046, 0.0034, 0.0182, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.7684376239776611 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0114, 0.0050, 0.0042, 0.0048, 0.0031, 0.0176, 0.0021]) \n",
      "Test Loss tensor([0.0125, 0.0113, 0.0044, 0.0034, 0.0048, 0.0032, 0.0178, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.7321555614471436 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0117, 0.0047, 0.0034, 0.0058, 0.0029, 0.0168, 0.0022]) \n",
      "Test Loss tensor([0.0134, 0.0106, 0.0046, 0.0035, 0.0054, 0.0034, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.7170448303222656 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0096, 0.0045, 0.0036, 0.0071, 0.0035, 0.0201, 0.0021]) \n",
      "Test Loss tensor([0.0130, 0.0109, 0.0046, 0.0035, 0.0047, 0.0033, 0.0174, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6746034622192383 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0100, 0.0050, 0.0032, 0.0063, 0.0026, 0.0190, 0.0019]) \n",
      "Test Loss tensor([0.0128, 0.0103, 0.0047, 0.0036, 0.0047, 0.0034, 0.0174, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7060501575469971 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0091, 0.0039, 0.0027, 0.0049, 0.0036, 0.0160, 0.0020]) \n",
      "Test Loss tensor([0.0137, 0.0111, 0.0044, 0.0034, 0.0050, 0.0035, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.6858408451080322 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0150, 0.0116, 0.0046, 0.0031, 0.0047, 0.0037, 0.0189, 0.0021]) \n",
      "Test Loss tensor([0.0137, 0.0104, 0.0045, 0.0034, 0.0056, 0.0034, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.673513650894165 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0093, 0.0048, 0.0032, 0.0051, 0.0033, 0.0165, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0108, 0.0047, 0.0034, 0.0048, 0.0034, 0.0175, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6963882446289062 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0101, 0.0050, 0.0030, 0.0051, 0.0031, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0102, 0.0045, 0.0036, 0.0052, 0.0034, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6921441555023193 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0103, 0.0044, 0.0035, 0.0047, 0.0039, 0.0171, 0.0020]) \n",
      "Test Loss tensor([0.0134, 0.0111, 0.0046, 0.0036, 0.0052, 0.0037, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.670459508895874 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0118, 0.0044, 0.0029, 0.0072, 0.0028, 0.0180, 0.0021]) \n",
      "Test Loss tensor([0.0124, 0.0107, 0.0045, 0.0034, 0.0054, 0.0033, 0.0177, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.715456485748291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0122, 0.0042, 0.0037, 0.0052, 0.0033, 0.0164, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0104, 0.0046, 0.0034, 0.0053, 0.0033, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6372404098510742 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0113, 0.0044, 0.0045, 0.0063, 0.0040, 0.0189, 0.0020]) \n",
      "Test Loss tensor([0.0144, 0.0109, 0.0047, 0.0035, 0.0053, 0.0036, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6312453746795654 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0076, 0.0038, 0.0033, 0.0032, 0.0028, 0.0154, 0.0019]) \n",
      "Test Loss tensor([0.0133, 0.0108, 0.0045, 0.0033, 0.0052, 0.0036, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6670377254486084 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0120, 0.0048, 0.0038, 0.0053, 0.0042, 0.0183, 0.0023]) \n",
      "Test Loss tensor([0.0136, 0.0109, 0.0046, 0.0033, 0.0055, 0.0035, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7132730484008789 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0128, 0.0057, 0.0041, 0.0069, 0.0034, 0.0161, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0109, 0.0045, 0.0036, 0.0048, 0.0033, 0.0177, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.7978334426879883 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0098, 0.0048, 0.0027, 0.0066, 0.0035, 0.0176, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0102, 0.0048, 0.0035, 0.0055, 0.0034, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.7765824794769287 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0095, 0.0039, 0.0027, 0.0044, 0.0029, 0.0169, 0.0021]) \n",
      "Test Loss tensor([0.0121, 0.0108, 0.0044, 0.0036, 0.0050, 0.0033, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7369318008422852 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0101, 0.0048, 0.0036, 0.0058, 0.0026, 0.0169, 0.0019]) \n",
      "Test Loss tensor([0.0135, 0.0111, 0.0048, 0.0037, 0.0050, 0.0034, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.7500481605529785 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0100, 0.0046, 0.0032, 0.0035, 0.0033, 0.0173, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0111, 0.0047, 0.0036, 0.0053, 0.0034, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.6792662143707275 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0121, 0.0056, 0.0034, 0.0059, 0.0040, 0.0194, 0.0021]) \n",
      "Test Loss tensor([0.0132, 0.0111, 0.0049, 0.0035, 0.0051, 0.0031, 0.0172, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6881358623504639 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0097, 0.0041, 0.0030, 0.0052, 0.0036, 0.0174, 0.0018]) \n",
      "Test Loss tensor([0.0132, 0.0103, 0.0047, 0.0034, 0.0057, 0.0032, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7621548175811768 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0110, 0.0037, 0.0035, 0.0040, 0.0027, 0.0178, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0106, 0.0046, 0.0034, 0.0050, 0.0033, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6857626438140869 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0125, 0.0042, 0.0031, 0.0031, 0.0028, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0102, 0.0049, 0.0035, 0.0054, 0.0032, 0.0175, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.649228572845459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0145, 0.0101, 0.0058, 0.0032, 0.0073, 0.0027, 0.0176, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0107, 0.0044, 0.0034, 0.0053, 0.0033, 0.0177, 0.0021])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6765730381011963 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0116, 0.0043, 0.0033, 0.0054, 0.0039, 0.0174, 0.0021]) \n",
      "Test Loss tensor([0.0116, 0.0104, 0.0047, 0.0034, 0.0051, 0.0032, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.72920823097229 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0110, 0.0040, 0.0035, 0.0048, 0.0027, 0.0187, 0.0019]) \n",
      "Test Loss tensor([0.0128, 0.0104, 0.0046, 0.0036, 0.0053, 0.0034, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.6596291065216064 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0109, 0.0051, 0.0027, 0.0055, 0.0029, 0.0187, 0.0019]) \n",
      "Test Loss tensor([0.0130, 0.0106, 0.0046, 0.0035, 0.0049, 0.0032, 0.0175, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6603395938873291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0109, 0.0044, 0.0029, 0.0050, 0.0033, 0.0168, 0.0020]) \n",
      "Test Loss tensor([0.0138, 0.0106, 0.0046, 0.0035, 0.0052, 0.0032, 0.0177, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6400718688964844 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0107, 0.0055, 0.0038, 0.0060, 0.0032, 0.0170, 0.0018]) \n",
      "Test Loss tensor([0.0128, 0.0106, 0.0045, 0.0036, 0.0052, 0.0033, 0.0177, 0.0020])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 144 in 0.644406795501709 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0139, 0.0100, 0.0043, 0.0046, 0.0062, 0.0032, 0.0158, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0105, 0.0045, 0.0034, 0.0050, 0.0033, 0.0171, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6401963233947754 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0088, 0.0052, 0.0035, 0.0051, 0.0036, 0.0164, 0.0021]) \n",
      "Test Loss tensor([0.0121, 0.0107, 0.0046, 0.0034, 0.0048, 0.0034, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6360697746276855 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0106, 0.0056, 0.0032, 0.0054, 0.0027, 0.0181, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0102, 0.0045, 0.0035, 0.0057, 0.0035, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6607778072357178 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0105, 0.0047, 0.0028, 0.0045, 0.0036, 0.0158, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0106, 0.0045, 0.0037, 0.0054, 0.0033, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6353967189788818 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0136, 0.0086, 0.0042, 0.0037, 0.0045, 0.0028, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0118, 0.0105, 0.0046, 0.0034, 0.0054, 0.0033, 0.0173, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.6378898620605469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0143, 0.0101, 0.0041, 0.0037, 0.0066, 0.0032, 0.0166, 0.0019]) \n",
      "Test Loss tensor([0.0123, 0.0110, 0.0044, 0.0034, 0.0049, 0.0034, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6524519920349121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0089, 0.0047, 0.0030, 0.0043, 0.0025, 0.0172, 0.0020]) \n",
      "Test Loss tensor([0.0127, 0.0105, 0.0045, 0.0034, 0.0054, 0.0035, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6895127296447754 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0093, 0.0052, 0.0029, 0.0064, 0.0033, 0.0171, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0106, 0.0046, 0.0036, 0.0048, 0.0034, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.6722562313079834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0085, 0.0049, 0.0033, 0.0057, 0.0035, 0.0166, 0.0019]) \n",
      "Test Loss tensor([0.0132, 0.0110, 0.0043, 0.0035, 0.0052, 0.0035, 0.0173, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6774182319641113 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0094, 0.0044, 0.0037, 0.0062, 0.0031, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0125, 0.0106, 0.0045, 0.0033, 0.0047, 0.0034, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.679833173751831 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0114, 0.0035, 0.0032, 0.0046, 0.0030, 0.0184, 0.0020]) \n",
      "Test Loss tensor([0.0135, 0.0111, 0.0046, 0.0036, 0.0057, 0.0037, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.7026262283325195 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0092, 0.0041, 0.0032, 0.0045, 0.0031, 0.0177, 0.0021]) \n",
      "Test Loss tensor([0.0136, 0.0103, 0.0044, 0.0037, 0.0052, 0.0035, 0.0173, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.6665143966674805 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0156, 0.0094, 0.0045, 0.0029, 0.0050, 0.0035, 0.0170, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0102, 0.0043, 0.0033, 0.0048, 0.0036, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6749844551086426 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0118, 0.0047, 0.0045, 0.0048, 0.0032, 0.0172, 0.0019]) \n",
      "Test Loss tensor([0.0122, 0.0107, 0.0046, 0.0033, 0.0045, 0.0035, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.6847169399261475 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0093, 0.0051, 0.0037, 0.0051, 0.0032, 0.0164, 0.0020]) \n",
      "Test Loss tensor([0.0133, 0.0111, 0.0045, 0.0037, 0.0046, 0.0035, 0.0171, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.708794355392456 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0133, 0.0106, 0.0040, 0.0031, 0.0061, 0.0039, 0.0170, 0.0021]) \n",
      "Test Loss tensor([0.0121, 0.0107, 0.0044, 0.0034, 0.0048, 0.0033, 0.0171, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.7347815036773682 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0100, 0.0046, 0.0035, 0.0047, 0.0034, 0.0169, 0.0021]) \n",
      "Test Loss tensor([0.0130, 0.0105, 0.0046, 0.0036, 0.0051, 0.0035, 0.0171, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.695784330368042 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0106, 0.0044, 0.0038, 0.0062, 0.0031, 0.0150, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0110, 0.0043, 0.0035, 0.0050, 0.0033, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.6817986965179443 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0115, 0.0044, 0.0036, 0.0046, 0.0029, 0.0169, 0.0021]) \n",
      "Test Loss tensor([0.0119, 0.0105, 0.0042, 0.0034, 0.0049, 0.0032, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.6983227729797363 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0090, 0.0044, 0.0027, 0.0066, 0.0032, 0.0169, 0.0020]) \n",
      "Test Loss tensor([0.0121, 0.0099, 0.0046, 0.0033, 0.0046, 0.0031, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.674187183380127 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0096, 0.0040, 0.0031, 0.0050, 0.0032, 0.0173, 0.0019]) \n",
      "Test Loss tensor([0.0126, 0.0103, 0.0047, 0.0033, 0.0051, 0.0033, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6633255481719971 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0088, 0.0051, 0.0038, 0.0046, 0.0037, 0.0148, 0.0022]) \n",
      "Test Loss tensor([0.0127, 0.0110, 0.0046, 0.0034, 0.0051, 0.0033, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.7060179710388184 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0106, 0.0042, 0.0027, 0.0049, 0.0040, 0.0160, 0.0020]) \n",
      "Test Loss tensor([0.0131, 0.0106, 0.0048, 0.0036, 0.0049, 0.0033, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6666045188903809 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0111, 0.0036, 0.0028, 0.0063, 0.0032, 0.0150, 0.0021]) \n",
      "Test Loss tensor([0.0123, 0.0108, 0.0045, 0.0035, 0.0050, 0.0034, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6660478115081787 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0144, 0.0104, 0.0041, 0.0029, 0.0058, 0.0038, 0.0154, 0.0019]) \n",
      "Test Loss tensor([0.0124, 0.0107, 0.0046, 0.0034, 0.0045, 0.0033, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6604585647583008 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0097, 0.0037, 0.0026, 0.0049, 0.0037, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0129, 0.0106, 0.0043, 0.0034, 0.0046, 0.0034, 0.0173, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.6610281467437744 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0103, 0.0053, 0.0033, 0.0044, 0.0029, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0122, 0.0101, 0.0044, 0.0036, 0.0048, 0.0032, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.6568169593811035 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0096, 0.0041, 0.0030, 0.0046, 0.0036, 0.0157, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0099, 0.0047, 0.0032, 0.0057, 0.0030, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.7157979011535645 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0093, 0.0038, 0.0031, 0.0056, 0.0029, 0.0165, 0.0021]) \n",
      "Test Loss tensor([0.0125, 0.0101, 0.0044, 0.0034, 0.0046, 0.0031, 0.0179, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.7024714946746826 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0103, 0.0045, 0.0025, 0.0070, 0.0030, 0.0169, 0.0020]) \n",
      "Test Loss tensor([0.0125, 0.0101, 0.0044, 0.0034, 0.0048, 0.0031, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.6996464729309082 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0098, 0.0045, 0.0034, 0.0049, 0.0028, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0125, 0.0101, 0.0045, 0.0033, 0.0047, 0.0031, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6941876411437988 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0083, 0.0050, 0.0034, 0.0058, 0.0029, 0.0186, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0108, 0.0045, 0.0033, 0.0050, 0.0035, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6673626899719238 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0083, 0.0052, 0.0029, 0.0040, 0.0039, 0.0179, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0106, 0.0047, 0.0033, 0.0047, 0.0033, 0.0173, 0.0020])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 276 in 0.6744122505187988 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0099, 0.0042, 0.0039, 0.0062, 0.0031, 0.0155, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0103, 0.0046, 0.0034, 0.0051, 0.0033, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.6554956436157227 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0106, 0.0050, 0.0030, 0.0037, 0.0028, 0.0162, 0.0019]) \n",
      "Test Loss tensor([0.0128, 0.0103, 0.0045, 0.0034, 0.0053, 0.0030, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.6713016033172607 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0108, 0.0036, 0.0032, 0.0052, 0.0027, 0.0172, 0.0021]) \n",
      "Test Loss tensor([0.0122, 0.0102, 0.0046, 0.0033, 0.0052, 0.0031, 0.0176, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.660463809967041 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0097, 0.0041, 0.0034, 0.0069, 0.0029, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0126, 0.0108, 0.0044, 0.0035, 0.0049, 0.0030, 0.0174, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.6621434688568115 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0119, 0.0045, 0.0036, 0.0057, 0.0034, 0.0171, 0.0021]) \n",
      "Test Loss tensor([0.0123, 0.0105, 0.0043, 0.0032, 0.0049, 0.0034, 0.0166, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.6825628280639648 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0131, 0.0109, 0.0044, 0.0030, 0.0053, 0.0031, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0103, 0.0040, 0.0033, 0.0050, 0.0034, 0.0166, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.6887621879577637 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0105, 0.0043, 0.0034, 0.0048, 0.0033, 0.0167, 0.0019]) \n",
      "Test Loss tensor([0.0134, 0.0104, 0.0045, 0.0034, 0.0046, 0.0033, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6776580810546875 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0098, 0.0043, 0.0031, 0.0047, 0.0027, 0.0159, 0.0020]) \n",
      "Test Loss tensor([0.0125, 0.0105, 0.0042, 0.0033, 0.0051, 0.0033, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6833369731903076 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0083, 0.0039, 0.0033, 0.0047, 0.0031, 0.0173, 0.0019]) \n",
      "Test Loss tensor([0.0127, 0.0102, 0.0043, 0.0035, 0.0048, 0.0033, 0.0161, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.6969754695892334 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0097, 0.0053, 0.0030, 0.0056, 0.0031, 0.0161, 0.0021]) \n",
      "Test Loss tensor([0.0126, 0.0107, 0.0045, 0.0034, 0.0045, 0.0033, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7454793453216553 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0098, 0.0054, 0.0035, 0.0051, 0.0034, 0.0171, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0103, 0.0047, 0.0036, 0.0051, 0.0030, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.7828800678253174 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0107, 0.0053, 0.0031, 0.0068, 0.0027, 0.0176, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0099, 0.0047, 0.0033, 0.0052, 0.0031, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.7685244083404541 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0151, 0.0135, 0.0054, 0.0036, 0.0065, 0.0038, 0.0162, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0103, 0.0044, 0.0034, 0.0050, 0.0032, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6665072441101074 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0129, 0.0047, 0.0035, 0.0051, 0.0035, 0.0176, 0.0020]) \n",
      "Test Loss tensor([0.0125, 0.0101, 0.0046, 0.0034, 0.0053, 0.0031, 0.0160, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6511213779449463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0106, 0.0045, 0.0029, 0.0050, 0.0038, 0.0186, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0102, 0.0045, 0.0035, 0.0046, 0.0033, 0.0160, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6329655647277832 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0090, 0.0037, 0.0037, 0.0070, 0.0034, 0.0171, 0.0019]) \n",
      "Test Loss tensor([0.0130, 0.0098, 0.0046, 0.0032, 0.0054, 0.0032, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.618300199508667 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0127, 0.0032, 0.0035, 0.0055, 0.0038, 0.0157, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0099, 0.0045, 0.0034, 0.0054, 0.0031, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.7969851493835449 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0108, 0.0042, 0.0037, 0.0052, 0.0038, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0104, 0.0045, 0.0033, 0.0052, 0.0032, 0.0172, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.679398775100708 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0109, 0.0041, 0.0036, 0.0045, 0.0030, 0.0148, 0.0020]) \n",
      "Test Loss tensor([0.0126, 0.0110, 0.0044, 0.0034, 0.0049, 0.0033, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.6483025550842285 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0104, 0.0038, 0.0033, 0.0057, 0.0028, 0.0156, 0.0019]) \n",
      "Test Loss tensor([0.0115, 0.0105, 0.0043, 0.0034, 0.0045, 0.0031, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.6301016807556152 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0104, 0.0041, 0.0034, 0.0055, 0.0035, 0.0167, 0.0021]) \n",
      "Test Loss tensor([0.0122, 0.0101, 0.0043, 0.0034, 0.0050, 0.0034, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.6200144290924072 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0117, 0.0041, 0.0035, 0.0051, 0.0033, 0.0173, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0104, 0.0044, 0.0033, 0.0047, 0.0031, 0.0173, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.709540843963623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0070, 0.0047, 0.0028, 0.0065, 0.0034, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0126, 0.0107, 0.0045, 0.0036, 0.0051, 0.0032, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.7604751586914062 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0110, 0.0053, 0.0028, 0.0060, 0.0035, 0.0175, 0.0020]) \n",
      "Test Loss tensor([0.0120, 0.0101, 0.0047, 0.0033, 0.0051, 0.0030, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.668006181716919 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0087, 0.0044, 0.0036, 0.0038, 0.0036, 0.0177, 0.0021]) \n",
      "Test Loss tensor([0.0129, 0.0106, 0.0043, 0.0035, 0.0052, 0.0033, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7694625854492188 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0160, 0.0089, 0.0042, 0.0029, 0.0061, 0.0034, 0.0178, 0.0020]) \n",
      "Test Loss tensor([0.0120, 0.0101, 0.0044, 0.0032, 0.0050, 0.0033, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.7284176349639893 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0090, 0.0043, 0.0027, 0.0037, 0.0028, 0.0173, 0.0018]) \n",
      "Test Loss tensor([0.0124, 0.0100, 0.0045, 0.0036, 0.0052, 0.0031, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6955113410949707 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0105, 0.0041, 0.0033, 0.0062, 0.0029, 0.0161, 0.0019]) \n",
      "Test Loss tensor([0.0120, 0.0099, 0.0045, 0.0034, 0.0046, 0.0033, 0.0165, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7265405654907227 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0110, 0.0048, 0.0032, 0.0070, 0.0034, 0.0167, 0.0022]) \n",
      "Test Loss tensor([0.0117, 0.0104, 0.0046, 0.0034, 0.0047, 0.0031, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.6366040706634521 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0106, 0.0039, 0.0037, 0.0048, 0.0032, 0.0165, 0.0020]) \n",
      "Test Loss tensor([0.0126, 0.0107, 0.0045, 0.0035, 0.0050, 0.0032, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.6121177673339844 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0101, 0.0040, 0.0027, 0.0043, 0.0035, 0.0165, 0.0019]) \n",
      "Test Loss tensor([0.0125, 0.0100, 0.0045, 0.0034, 0.0049, 0.0032, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6148650646209717 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0090, 0.0044, 0.0028, 0.0051, 0.0026, 0.0161, 0.0020]) \n",
      "Test Loss tensor([0.0119, 0.0105, 0.0045, 0.0033, 0.0045, 0.0032, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6268677711486816 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0080, 0.0040, 0.0031, 0.0038, 0.0028, 0.0174, 0.0020]) \n",
      "Test Loss tensor([0.0117, 0.0099, 0.0043, 0.0031, 0.0049, 0.0032, 0.0165, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 408 in 0.6248791217803955 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0102, 0.0037, 0.0028, 0.0055, 0.0030, 0.0168, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0105, 0.0044, 0.0034, 0.0049, 0.0032, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6255574226379395 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0079, 0.0036, 0.0028, 0.0038, 0.0031, 0.0149, 0.0019]) \n",
      "Test Loss tensor([0.0116, 0.0101, 0.0044, 0.0033, 0.0052, 0.0032, 0.0162, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.7146201133728027 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0097, 0.0064, 0.0034, 0.0063, 0.0032, 0.0166, 0.0021]) \n",
      "Test Loss tensor([0.0124, 0.0104, 0.0043, 0.0035, 0.0050, 0.0034, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7841775417327881 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0107, 0.0048, 0.0034, 0.0056, 0.0031, 0.0180, 0.0019]) \n",
      "Test Loss tensor([0.0126, 0.0108, 0.0043, 0.0033, 0.0045, 0.0033, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6809639930725098 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0084, 0.0043, 0.0034, 0.0049, 0.0030, 0.0157, 0.0020]) \n",
      "Test Loss tensor([0.0123, 0.0103, 0.0043, 0.0034, 0.0053, 0.0032, 0.0165, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.8619635105133057 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0098, 0.0038, 0.0029, 0.0061, 0.0027, 0.0180, 0.0020]) \n",
      "Test Loss tensor([0.0125, 0.0100, 0.0043, 0.0034, 0.0051, 0.0031, 0.0166, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.7853162288665771 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0105, 0.0039, 0.0034, 0.0061, 0.0031, 0.0161, 0.0018]) \n",
      "Test Loss tensor([0.0128, 0.0104, 0.0042, 0.0035, 0.0048, 0.0033, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.7382609844207764 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0126, 0.0044, 0.0035, 0.0049, 0.0039, 0.0170, 0.0021]) \n",
      "Test Loss tensor([0.0120, 0.0098, 0.0044, 0.0031, 0.0049, 0.0032, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6896390914916992 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0095, 0.0044, 0.0027, 0.0046, 0.0025, 0.0183, 0.0017]) \n",
      "Test Loss tensor([0.0121, 0.0104, 0.0042, 0.0034, 0.0050, 0.0031, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6835958957672119 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0158, 0.0109, 0.0048, 0.0034, 0.0065, 0.0029, 0.0163, 0.0021]) \n",
      "Test Loss tensor([0.0123, 0.0106, 0.0044, 0.0032, 0.0048, 0.0033, 0.0163, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6580841541290283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0100, 0.0039, 0.0032, 0.0051, 0.0037, 0.0156, 0.0019]) \n",
      "Test Loss tensor([0.0123, 0.0102, 0.0043, 0.0033, 0.0045, 0.0031, 0.0159, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6793723106384277 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0115, 0.0042, 0.0035, 0.0056, 0.0035, 0.0166, 0.0020]) \n",
      "Test Loss tensor([0.0115, 0.0101, 0.0043, 0.0033, 0.0047, 0.0029, 0.0160, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.7005248069763184 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0084, 0.0044, 0.0032, 0.0058, 0.0032, 0.0176, 0.0019]) \n",
      "Test Loss tensor([0.0131, 0.0105, 0.0044, 0.0033, 0.0050, 0.0032, 0.0159, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7420082092285156 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0110, 0.0034, 0.0037, 0.0057, 0.0034, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0120, 0.0101, 0.0045, 0.0033, 0.0050, 0.0030, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7172737121582031 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0124, 0.0045, 0.0038, 0.0041, 0.0035, 0.0167, 0.0019]) \n",
      "Test Loss tensor([0.0124, 0.0105, 0.0047, 0.0034, 0.0050, 0.0031, 0.0159, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.7097384929656982 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0118, 0.0046, 0.0032, 0.0052, 0.0028, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0099, 0.0042, 0.0032, 0.0048, 0.0031, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.7221887111663818 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0092, 0.0050, 0.0025, 0.0054, 0.0029, 0.0158, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0107, 0.0047, 0.0034, 0.0046, 0.0030, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.656853437423706 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0110, 0.0033, 0.0029, 0.0047, 0.0034, 0.0157, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0102, 0.0044, 0.0032, 0.0050, 0.0029, 0.0166, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.7088782787322998 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0099, 0.0048, 0.0037, 0.0037, 0.0028, 0.0151, 0.0020]) \n",
      "Test Loss tensor([0.0121, 0.0100, 0.0044, 0.0033, 0.0051, 0.0030, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6309762001037598 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0106, 0.0039, 0.0027, 0.0053, 0.0034, 0.0159, 0.0020]) \n",
      "Test Loss tensor([0.0121, 0.0097, 0.0044, 0.0033, 0.0052, 0.0030, 0.0162, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6218111515045166 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0099, 0.0053, 0.0028, 0.0047, 0.0030, 0.0159, 0.0018]) \n",
      "Test Loss tensor([0.0118, 0.0099, 0.0044, 0.0031, 0.0051, 0.0031, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6373410224914551 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0105, 0.0041, 0.0039, 0.0048, 0.0029, 0.0166, 0.0020]) \n",
      "Test Loss tensor([0.0119, 0.0100, 0.0044, 0.0033, 0.0052, 0.0030, 0.0166, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.8071045875549316 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0078, 0.0040, 0.0025, 0.0042, 0.0033, 0.0163, 0.0018]) \n",
      "Test Loss tensor([0.0119, 0.0102, 0.0043, 0.0031, 0.0047, 0.0030, 0.0165, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.7002832889556885 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0111, 0.0057, 0.0033, 0.0043, 0.0029, 0.0168, 0.0018]) \n",
      "Test Loss tensor([0.0123, 0.0106, 0.0045, 0.0034, 0.0046, 0.0032, 0.0166, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6648275852203369 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0112, 0.0046, 0.0028, 0.0048, 0.0030, 0.0168, 0.0020]) \n",
      "Test Loss tensor([0.0115, 0.0100, 0.0042, 0.0033, 0.0050, 0.0029, 0.0171, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6611833572387695 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0094, 0.0041, 0.0032, 0.0047, 0.0026, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0131, 0.0103, 0.0045, 0.0034, 0.0049, 0.0030, 0.0168, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6293537616729736 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0113, 0.0044, 0.0040, 0.0040, 0.0025, 0.0146, 0.0018]) \n",
      "Test Loss tensor([0.0119, 0.0100, 0.0042, 0.0033, 0.0045, 0.0031, 0.0165, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6472797393798828 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0096, 0.0050, 0.0025, 0.0044, 0.0026, 0.0171, 0.0019]) \n",
      "Test Loss tensor([0.0119, 0.0097, 0.0042, 0.0034, 0.0044, 0.0031, 0.0167, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6694378852844238 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0098, 0.0042, 0.0032, 0.0036, 0.0027, 0.0174, 0.0020]) \n",
      "Test Loss tensor([0.0120, 0.0101, 0.0041, 0.0034, 0.0045, 0.0031, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6360819339752197 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0106, 0.0046, 0.0037, 0.0055, 0.0032, 0.0168, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0102, 0.0041, 0.0034, 0.0055, 0.0031, 0.0164, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.6733901500701904 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0106, 0.0043, 0.0030, 0.0047, 0.0029, 0.0155, 0.0021]) \n",
      "Test Loss tensor([0.0121, 0.0100, 0.0046, 0.0034, 0.0051, 0.0031, 0.0165, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.9018795490264893 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0090, 0.0038, 0.0029, 0.0054, 0.0033, 0.0167, 0.0019]) \n",
      "Test Loss tensor([0.0121, 0.0103, 0.0046, 0.0033, 0.0054, 0.0030, 0.0164, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.8122756481170654 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0137, 0.0115, 0.0058, 0.0030, 0.0040, 0.0029, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0114, 0.0100, 0.0043, 0.0033, 0.0055, 0.0030, 0.0164, 0.0020])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 540 in 0.7208759784698486 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0098, 0.0044, 0.0048, 0.0075, 0.0029, 0.0159, 0.0020]) \n",
      "Test Loss tensor([0.0122, 0.0102, 0.0045, 0.0032, 0.0049, 0.0032, 0.0159, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.7990591526031494 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0082, 0.0037, 0.0040, 0.0047, 0.0030, 0.0162, 0.0021]) \n",
      "Test Loss tensor([0.0118, 0.0102, 0.0044, 0.0032, 0.0052, 0.0031, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6961579322814941 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0097, 0.0047, 0.0032, 0.0061, 0.0035, 0.0169, 0.0019]) \n",
      "Test Loss tensor([0.0127, 0.0099, 0.0045, 0.0033, 0.0046, 0.0030, 0.0163, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6449782848358154 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0107, 0.0039, 0.0035, 0.0041, 0.0037, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0114, 0.0097, 0.0045, 0.0031, 0.0052, 0.0031, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6422131061553955 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0107, 0.0036, 0.0030, 0.0050, 0.0038, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0100, 0.0043, 0.0032, 0.0048, 0.0027, 0.0166, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6173486709594727 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0098, 0.0050, 0.0033, 0.0039, 0.0034, 0.0170, 0.0019]) \n",
      "Test Loss tensor([0.0119, 0.0102, 0.0045, 0.0032, 0.0052, 0.0031, 0.0170, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6452949047088623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0085, 0.0049, 0.0035, 0.0056, 0.0026, 0.0136, 0.0018]) \n",
      "Test Loss tensor([0.0117, 0.0099, 0.0045, 0.0033, 0.0048, 0.0030, 0.0164, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.624171257019043 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0102, 0.0038, 0.0028, 0.0059, 0.0037, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0120, 0.0097, 0.0044, 0.0032, 0.0049, 0.0030, 0.0162, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6271436214447021 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0094, 0.0043, 0.0037, 0.0065, 0.0034, 0.0165, 0.0021]) \n",
      "Test Loss tensor([0.0116, 0.0099, 0.0043, 0.0031, 0.0049, 0.0032, 0.0164, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.6428322792053223 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0101, 0.0050, 0.0028, 0.0050, 0.0039, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0122, 0.0105, 0.0042, 0.0034, 0.0052, 0.0032, 0.0157, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6833755970001221 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0125, 0.0051, 0.0037, 0.0045, 0.0028, 0.0162, 0.0020]) \n",
      "Test Loss tensor([0.0115, 0.0097, 0.0042, 0.0032, 0.0054, 0.0030, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 584 in 0.8937356472015381 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0141, 0.0095, 0.0039, 0.0031, 0.0056, 0.0028, 0.0168, 0.0018]) \n",
      "Test Loss tensor([0.0119, 0.0101, 0.0044, 0.0031, 0.0054, 0.0033, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.8161306381225586 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0096, 0.0037, 0.0032, 0.0054, 0.0027, 0.0158, 0.0020]) \n",
      "Test Loss tensor([0.0119, 0.0107, 0.0042, 0.0034, 0.0046, 0.0030, 0.0169, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.8033559322357178 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0105, 0.0046, 0.0035, 0.0050, 0.0035, 0.0185, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0101, 0.0043, 0.0031, 0.0048, 0.0031, 0.0163, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.7089455127716064 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0084, 0.0035, 0.0035, 0.0066, 0.0029, 0.0164, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0102, 0.0042, 0.0032, 0.0049, 0.0031, 0.0160, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6512274742126465 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0089, 0.0033, 0.0030, 0.0053, 0.0038, 0.0153, 0.0020]) \n",
      "Test Loss tensor([0.0117, 0.0099, 0.0042, 0.0032, 0.0047, 0.0032, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.8248162269592285 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0113, 0.0037, 0.0024, 0.0045, 0.0024, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0120, 0.0097, 0.0041, 0.0031, 0.0045, 0.0031, 0.0160, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.8148281574249268 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0109, 0.0049, 0.0036, 0.0062, 0.0034, 0.0164, 0.0021]) \n",
      "Test Loss tensor([0.0120, 0.0099, 0.0044, 0.0035, 0.0049, 0.0030, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.7548680305480957 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0087, 0.0046, 0.0032, 0.0062, 0.0030, 0.0153, 0.0018]) \n",
      "Test Loss tensor([0.0117, 0.0100, 0.0044, 0.0032, 0.0048, 0.0031, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6455855369567871 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0097, 0.0039, 0.0040, 0.0062, 0.0028, 0.0175, 0.0019]) \n",
      "Test Loss tensor([0.0125, 0.0104, 0.0044, 0.0033, 0.0047, 0.0031, 0.0158, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.7978940010070801 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0140, 0.0115, 0.0040, 0.0039, 0.0049, 0.0028, 0.0184, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0098, 0.0043, 0.0031, 0.0047, 0.0029, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.7531569004058838 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0087, 0.0046, 0.0030, 0.0057, 0.0029, 0.0151, 0.0018]) \n",
      "Test Loss tensor([0.0116, 0.0101, 0.0042, 0.0033, 0.0052, 0.0031, 0.0162, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.8157131671905518 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0154, 0.0110, 0.0045, 0.0033, 0.0049, 0.0036, 0.0168, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0106, 0.0043, 0.0036, 0.0054, 0.0032, 0.0156, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6886115074157715 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0092, 0.0048, 0.0037, 0.0065, 0.0032, 0.0163, 0.0018]) \n",
      "Test Loss tensor([0.0117, 0.0097, 0.0044, 0.0033, 0.0050, 0.0029, 0.0162, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.7365643978118896 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0108, 0.0039, 0.0034, 0.0051, 0.0027, 0.0149, 0.0018]) \n",
      "Test Loss tensor([0.0119, 0.0098, 0.0044, 0.0035, 0.0046, 0.0031, 0.0164, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.8594019412994385 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0081, 0.0043, 0.0034, 0.0063, 0.0024, 0.0161, 0.0020]) \n",
      "Test Loss tensor([0.0128, 0.0103, 0.0043, 0.0035, 0.0047, 0.0032, 0.0156, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.7038614749908447 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0098, 0.0041, 0.0031, 0.0051, 0.0026, 0.0154, 0.0019]) \n",
      "Test Loss tensor([0.0121, 0.0102, 0.0043, 0.0032, 0.0043, 0.0032, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.766554594039917 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0098, 0.0045, 0.0031, 0.0062, 0.0033, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0103, 0.0043, 0.0033, 0.0052, 0.0032, 0.0159, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.82834792137146 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0114, 0.0042, 0.0031, 0.0033, 0.0036, 0.0159, 0.0020]) \n",
      "Test Loss tensor([0.0114, 0.0101, 0.0044, 0.0033, 0.0052, 0.0030, 0.0157, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.7301218509674072 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0121, 0.0048, 0.0033, 0.0049, 0.0034, 0.0157, 0.0020]) \n",
      "Test Loss tensor([0.0124, 0.0100, 0.0042, 0.0032, 0.0053, 0.0030, 0.0158, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.7755498886108398 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0097, 0.0045, 0.0039, 0.0040, 0.0035, 0.0185, 0.0018]) \n",
      "Test Loss tensor([0.0113, 0.0098, 0.0042, 0.0034, 0.0047, 0.0031, 0.0158, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.6999406814575195 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0108, 0.0037, 0.0029, 0.0042, 0.0022, 0.0163, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0096, 0.0045, 0.0030, 0.0048, 0.0030, 0.0159, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.8292350769042969 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0095, 0.0034, 0.0028, 0.0049, 0.0024, 0.0176, 0.0019]) \n",
      "Test Loss tensor([0.0121, 0.0101, 0.0043, 0.0034, 0.0053, 0.0030, 0.0160, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 672 in 0.765214204788208 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0109, 0.0034, 0.0031, 0.0061, 0.0029, 0.0164, 0.0019]) \n",
      "Test Loss tensor([0.0115, 0.0096, 0.0043, 0.0032, 0.0046, 0.0031, 0.0155, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.7690212726593018 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0097, 0.0041, 0.0032, 0.0049, 0.0034, 0.0152, 0.0020]) \n",
      "Test Loss tensor([0.0123, 0.0095, 0.0041, 0.0033, 0.0047, 0.0032, 0.0158, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.7024762630462646 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0101, 0.0037, 0.0038, 0.0050, 0.0029, 0.0158, 0.0020]) \n",
      "Test Loss tensor([0.0115, 0.0100, 0.0042, 0.0031, 0.0047, 0.0030, 0.0163, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.6889448165893555 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0093, 0.0034, 0.0031, 0.0055, 0.0030, 0.0165, 0.0018]) \n",
      "Test Loss tensor([0.0120, 0.0095, 0.0040, 0.0032, 0.0054, 0.0030, 0.0160, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.7885580062866211 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0082, 0.0049, 0.0033, 0.0042, 0.0031, 0.0137, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0103, 0.0044, 0.0031, 0.0046, 0.0031, 0.0159, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.7407865524291992 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0085, 0.0036, 0.0029, 0.0065, 0.0027, 0.0159, 0.0021]) \n",
      "Test Loss tensor([0.0117, 0.0096, 0.0045, 0.0029, 0.0048, 0.0030, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6914260387420654 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0115, 0.0046, 0.0028, 0.0040, 0.0036, 0.0165, 0.0019]) \n",
      "Test Loss tensor([0.0118, 0.0106, 0.0041, 0.0031, 0.0045, 0.0032, 0.0159, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.6534397602081299 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0107, 0.0045, 0.0027, 0.0054, 0.0029, 0.0158, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0095, 0.0044, 0.0032, 0.0048, 0.0029, 0.0160, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.732642412185669 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0125, 0.0086, 0.0046, 0.0029, 0.0044, 0.0027, 0.0167, 0.0019]) \n",
      "Test Loss tensor([0.0109, 0.0100, 0.0043, 0.0034, 0.0046, 0.0030, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6683006286621094 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0113, 0.0043, 0.0035, 0.0053, 0.0029, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0119, 0.0103, 0.0044, 0.0033, 0.0044, 0.0030, 0.0164, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.7301151752471924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0096, 0.0037, 0.0037, 0.0045, 0.0038, 0.0163, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0100, 0.0046, 0.0032, 0.0049, 0.0029, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 716 in 0.7453393936157227 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0097, 0.0047, 0.0028, 0.0053, 0.0033, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0100, 0.0045, 0.0030, 0.0048, 0.0030, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.803962230682373 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0103, 0.0038, 0.0038, 0.0048, 0.0032, 0.0175, 0.0021]) \n",
      "Test Loss tensor([0.0116, 0.0098, 0.0046, 0.0029, 0.0049, 0.0029, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.7491936683654785 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0090, 0.0047, 0.0040, 0.0052, 0.0035, 0.0152, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0104, 0.0043, 0.0032, 0.0048, 0.0030, 0.0157, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.7077682018280029 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0092, 0.0038, 0.0043, 0.0064, 0.0032, 0.0171, 0.0021]) \n",
      "Test Loss tensor([0.0111, 0.0099, 0.0043, 0.0035, 0.0044, 0.0030, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.7029922008514404 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0073, 0.0042, 0.0026, 0.0067, 0.0025, 0.0148, 0.0020]) \n",
      "Test Loss tensor([0.0115, 0.0101, 0.0043, 0.0032, 0.0047, 0.0029, 0.0161, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.676062822341919 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0108, 0.0048, 0.0036, 0.0053, 0.0028, 0.0154, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0102, 0.0046, 0.0030, 0.0048, 0.0030, 0.0163, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.7570316791534424 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0089, 0.0036, 0.0031, 0.0043, 0.0032, 0.0152, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0097, 0.0047, 0.0030, 0.0053, 0.0028, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6590437889099121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0102, 0.0051, 0.0031, 0.0066, 0.0029, 0.0157, 0.0019]) \n",
      "Test Loss tensor([0.0116, 0.0096, 0.0047, 0.0033, 0.0053, 0.0027, 0.0163, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.89101243019104 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0086, 0.0053, 0.0034, 0.0041, 0.0028, 0.0155, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0101, 0.0045, 0.0031, 0.0049, 0.0028, 0.0157, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.7574498653411865 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0092, 0.0052, 0.0030, 0.0055, 0.0030, 0.0164, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0099, 0.0041, 0.0034, 0.0048, 0.0030, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.7081139087677002 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0079, 0.0090, 0.0048, 0.0026, 0.0038, 0.0031, 0.0167, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0101, 0.0043, 0.0034, 0.0046, 0.0033, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.8736333847045898 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0103, 0.0046, 0.0030, 0.0040, 0.0028, 0.0156, 0.0021]) \n",
      "Test Loss tensor([0.0116, 0.0102, 0.0042, 0.0034, 0.0048, 0.0030, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.7265467643737793 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0101, 0.0039, 0.0026, 0.0046, 0.0024, 0.0165, 0.0019]) \n",
      "Test Loss tensor([0.0116, 0.0100, 0.0042, 0.0033, 0.0051, 0.0030, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.7132840156555176 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0103, 0.0036, 0.0030, 0.0040, 0.0026, 0.0158, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0097, 0.0043, 0.0032, 0.0044, 0.0030, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.7882130146026611 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0082, 0.0048, 0.0032, 0.0047, 0.0026, 0.0161, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0101, 0.0044, 0.0034, 0.0049, 0.0030, 0.0162, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.7450854778289795 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0115, 0.0037, 0.0027, 0.0062, 0.0026, 0.0164, 0.0018]) \n",
      "Test Loss tensor([0.0108, 0.0102, 0.0041, 0.0033, 0.0050, 0.0029, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.7435877323150635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0089, 0.0033, 0.0029, 0.0054, 0.0030, 0.0163, 0.0020]) \n",
      "Test Loss tensor([0.0121, 0.0103, 0.0042, 0.0033, 0.0049, 0.0031, 0.0159, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.6654136180877686 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0083, 0.0040, 0.0025, 0.0054, 0.0029, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0119, 0.0101, 0.0044, 0.0033, 0.0047, 0.0031, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6706633567810059 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0093, 0.0045, 0.0030, 0.0048, 0.0026, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0096, 0.0042, 0.0032, 0.0046, 0.0031, 0.0166, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6815357208251953 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0106, 0.0046, 0.0031, 0.0076, 0.0027, 0.0155, 0.0020]) \n",
      "Test Loss tensor([0.0118, 0.0098, 0.0043, 0.0033, 0.0048, 0.0030, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6950042247772217 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0090, 0.0035, 0.0029, 0.0073, 0.0025, 0.0153, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0094, 0.0040, 0.0030, 0.0046, 0.0029, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6875381469726562 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0091, 0.0043, 0.0037, 0.0061, 0.0030, 0.0160, 0.0020]) \n",
      "Test Loss tensor([0.0111, 0.0099, 0.0043, 0.0031, 0.0046, 0.0030, 0.0156, 0.0020])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 804 in 0.7226464748382568 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0095, 0.0034, 0.0037, 0.0053, 0.0027, 0.0149, 0.0019]) \n",
      "Test Loss tensor([0.0119, 0.0098, 0.0041, 0.0034, 0.0051, 0.0029, 0.0155, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.8107037544250488 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0097, 0.0040, 0.0029, 0.0027, 0.0030, 0.0150, 0.0019]) \n",
      "Test Loss tensor([0.0117, 0.0095, 0.0043, 0.0033, 0.0052, 0.0031, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.7084012031555176 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0099, 0.0040, 0.0030, 0.0050, 0.0028, 0.0162, 0.0017]) \n",
      "Test Loss tensor([0.0117, 0.0096, 0.0043, 0.0033, 0.0046, 0.0032, 0.0156, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6271812915802002 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0104, 0.0050, 0.0029, 0.0040, 0.0034, 0.0156, 0.0018]) \n",
      "Test Loss tensor([0.0113, 0.0097, 0.0044, 0.0031, 0.0049, 0.0030, 0.0155, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6187987327575684 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0117, 0.0038, 0.0030, 0.0058, 0.0027, 0.0170, 0.0018]) \n",
      "Test Loss tensor([0.0117, 0.0096, 0.0042, 0.0032, 0.0051, 0.0031, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6334373950958252 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0083, 0.0048, 0.0034, 0.0058, 0.0031, 0.0150, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0092, 0.0044, 0.0033, 0.0048, 0.0030, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6307077407836914 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0094, 0.0040, 0.0041, 0.0039, 0.0030, 0.0154, 0.0020]) \n",
      "Test Loss tensor([0.0105, 0.0095, 0.0043, 0.0033, 0.0043, 0.0029, 0.0156, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6257767677307129 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0108, 0.0032, 0.0026, 0.0048, 0.0030, 0.0155, 0.0019]) \n",
      "Test Loss tensor([0.0115, 0.0102, 0.0042, 0.0032, 0.0050, 0.0031, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6255035400390625 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0077, 0.0051, 0.0031, 0.0055, 0.0035, 0.0155, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0100, 0.0044, 0.0033, 0.0049, 0.0029, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.6492965221405029 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0099, 0.0043, 0.0029, 0.0056, 0.0028, 0.0144, 0.0019]) \n",
      "Test Loss tensor([0.0107, 0.0096, 0.0043, 0.0033, 0.0045, 0.0029, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6226511001586914 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0080, 0.0035, 0.0024, 0.0050, 0.0026, 0.0139, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0098, 0.0043, 0.0032, 0.0046, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 848 in 0.7279114723205566 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0093, 0.0041, 0.0034, 0.0041, 0.0029, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0115, 0.0098, 0.0043, 0.0031, 0.0049, 0.0030, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6855838298797607 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0120, 0.0092, 0.0045, 0.0023, 0.0054, 0.0027, 0.0146, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0098, 0.0044, 0.0033, 0.0049, 0.0029, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6587262153625488 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0094, 0.0041, 0.0026, 0.0062, 0.0033, 0.0149, 0.0020]) \n",
      "Test Loss tensor([0.0116, 0.0100, 0.0045, 0.0032, 0.0055, 0.0029, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.7236673831939697 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0105, 0.0036, 0.0036, 0.0053, 0.0033, 0.0164, 0.0020]) \n",
      "Test Loss tensor([0.0120, 0.0098, 0.0044, 0.0031, 0.0052, 0.0030, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.693687915802002 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0103, 0.0042, 0.0032, 0.0044, 0.0031, 0.0150, 0.0020]) \n",
      "Test Loss tensor([0.0110, 0.0101, 0.0044, 0.0031, 0.0042, 0.0029, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.6490347385406494 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0142, 0.0094, 0.0050, 0.0041, 0.0037, 0.0027, 0.0145, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0096, 0.0044, 0.0033, 0.0044, 0.0029, 0.0152, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.7160532474517822 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0104, 0.0044, 0.0028, 0.0050, 0.0024, 0.0146, 0.0020]) \n",
      "Test Loss tensor([0.0113, 0.0094, 0.0043, 0.0032, 0.0046, 0.0029, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6726622581481934 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0067, 0.0063, 0.0030, 0.0021, 0.0045, 0.0020, 0.0110, 0.0014]) \n",
      "Test Loss tensor([0.0113, 0.0096, 0.0045, 0.0031, 0.0044, 0.0029, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.8383915424346924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0102, 0.0050, 0.0032, 0.0042, 0.0025, 0.0131, 0.0019]) \n",
      "Test Loss tensor([0.0112, 0.0097, 0.0046, 0.0032, 0.0046, 0.0030, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.674790620803833 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0092, 0.0050, 0.0031, 0.0066, 0.0029, 0.0161, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0098, 0.0044, 0.0032, 0.0045, 0.0026, 0.0161, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.6561775207519531 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0083, 0.0044, 0.0043, 0.0047, 0.0025, 0.0161, 0.0019]) \n",
      "Test Loss tensor([0.0115, 0.0097, 0.0042, 0.0033, 0.0048, 0.0028, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.673051118850708 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0087, 0.0044, 0.0031, 0.0044, 0.0027, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0114, 0.0103, 0.0042, 0.0032, 0.0048, 0.0030, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.720757007598877 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0098, 0.0045, 0.0034, 0.0052, 0.0027, 0.0149, 0.0018]) \n",
      "Test Loss tensor([0.0115, 0.0096, 0.0042, 0.0034, 0.0045, 0.0030, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.7686541080474854 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0104, 0.0029, 0.0030, 0.0047, 0.0031, 0.0162, 0.0017]) \n",
      "Test Loss tensor([0.0111, 0.0103, 0.0042, 0.0032, 0.0049, 0.0029, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6629137992858887 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0104, 0.0049, 0.0038, 0.0042, 0.0027, 0.0148, 0.0018]) \n",
      "Test Loss tensor([0.0107, 0.0094, 0.0042, 0.0032, 0.0046, 0.0030, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.8099014759063721 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0102, 0.0051, 0.0032, 0.0049, 0.0026, 0.0144, 0.0018]) \n",
      "Test Loss tensor([0.0121, 0.0097, 0.0041, 0.0032, 0.0044, 0.0031, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.7323391437530518 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0097, 0.0031, 0.0029, 0.0061, 0.0033, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0094, 0.0042, 0.0029, 0.0045, 0.0027, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6595275402069092 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0124, 0.0092, 0.0043, 0.0031, 0.0033, 0.0028, 0.0141, 0.0021]) \n",
      "Test Loss tensor([0.0114, 0.0097, 0.0041, 0.0033, 0.0047, 0.0030, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.8500938415527344 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0117, 0.0038, 0.0032, 0.0056, 0.0032, 0.0169, 0.0018]) \n",
      "Test Loss tensor([0.0113, 0.0098, 0.0042, 0.0030, 0.0047, 0.0031, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.7702529430389404 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0083, 0.0048, 0.0029, 0.0050, 0.0027, 0.0156, 0.0018]) \n",
      "Test Loss tensor([0.0106, 0.0096, 0.0043, 0.0030, 0.0049, 0.0027, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7333846092224121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0138, 0.0088, 0.0044, 0.0030, 0.0037, 0.0028, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0111, 0.0096, 0.0045, 0.0031, 0.0048, 0.0027, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6603131294250488 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0087, 0.0045, 0.0031, 0.0047, 0.0022, 0.0145, 0.0019]) \n",
      "Test Loss tensor([0.0116, 0.0095, 0.0041, 0.0032, 0.0050, 0.0029, 0.0156, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 56 in 0.6825113296508789 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0123, 0.0070, 0.0044, 0.0042, 0.0044, 0.0032, 0.0139, 0.0020]) \n",
      "Test Loss tensor([0.0110, 0.0101, 0.0042, 0.0031, 0.0041, 0.0029, 0.0158, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.700631856918335 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0082, 0.0049, 0.0041, 0.0051, 0.0032, 0.0154, 0.0020]) \n",
      "Test Loss tensor([0.0106, 0.0089, 0.0042, 0.0032, 0.0043, 0.0028, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.6803197860717773 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0107, 0.0053, 0.0033, 0.0045, 0.0036, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0106, 0.0099, 0.0043, 0.0031, 0.0048, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.6621232032775879 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0077, 0.0040, 0.0029, 0.0061, 0.0027, 0.0161, 0.0019]) \n",
      "Test Loss tensor([0.0103, 0.0097, 0.0044, 0.0032, 0.0047, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.7430365085601807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0076, 0.0053, 0.0029, 0.0055, 0.0025, 0.0150, 0.0018]) \n",
      "Test Loss tensor([0.0114, 0.0091, 0.0045, 0.0032, 0.0047, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.8071475028991699 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0098, 0.0039, 0.0025, 0.0066, 0.0030, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0098, 0.0042, 0.0033, 0.0049, 0.0030, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.7783706188201904 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0101, 0.0040, 0.0029, 0.0053, 0.0038, 0.0157, 0.0019]) \n",
      "Test Loss tensor([0.0105, 0.0096, 0.0042, 0.0028, 0.0052, 0.0029, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.6637973785400391 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0094, 0.0050, 0.0031, 0.0063, 0.0033, 0.0138, 0.0018]) \n",
      "Test Loss tensor([0.0108, 0.0095, 0.0043, 0.0030, 0.0046, 0.0030, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6964833736419678 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0092, 0.0035, 0.0031, 0.0046, 0.0031, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0107, 0.0098, 0.0043, 0.0033, 0.0044, 0.0029, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.787358283996582 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0129, 0.0104, 0.0046, 0.0033, 0.0051, 0.0028, 0.0153, 0.0018]) \n",
      "Test Loss tensor([0.0109, 0.0098, 0.0046, 0.0031, 0.0046, 0.0028, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7608718872070312 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0081, 0.0036, 0.0025, 0.0039, 0.0029, 0.0154, 0.0020]) \n",
      "Test Loss tensor([0.0108, 0.0096, 0.0044, 0.0030, 0.0046, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.773484468460083 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0089, 0.0035, 0.0030, 0.0052, 0.0027, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0095, 0.0043, 0.0034, 0.0048, 0.0028, 0.0157, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 104 in 0.7385380268096924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0093, 0.0045, 0.0027, 0.0044, 0.0025, 0.0142, 0.0020]) \n",
      "Test Loss tensor([0.0112, 0.0097, 0.0044, 0.0032, 0.0049, 0.0029, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6381800174713135 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0092, 0.0037, 0.0029, 0.0050, 0.0034, 0.0157, 0.0018]) \n",
      "Test Loss tensor([0.0104, 0.0097, 0.0044, 0.0032, 0.0044, 0.0029, 0.0149, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.7283973693847656 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0083, 0.0041, 0.0030, 0.0043, 0.0036, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0110, 0.0096, 0.0043, 0.0033, 0.0045, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6711940765380859 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0089, 0.0041, 0.0031, 0.0052, 0.0033, 0.0157, 0.0019]) \n",
      "Test Loss tensor([0.0113, 0.0097, 0.0042, 0.0032, 0.0044, 0.0029, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.7113373279571533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0106, 0.0037, 0.0031, 0.0047, 0.0032, 0.0165, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0097, 0.0045, 0.0032, 0.0050, 0.0028, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6589422225952148 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0090, 0.0039, 0.0030, 0.0047, 0.0027, 0.0125, 0.0019]) \n",
      "Test Loss tensor([0.0119, 0.0096, 0.0041, 0.0033, 0.0048, 0.0029, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.7742385864257812 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0089, 0.0044, 0.0030, 0.0050, 0.0021, 0.0166, 0.0019]) \n",
      "Test Loss tensor([0.0112, 0.0095, 0.0045, 0.0031, 0.0048, 0.0027, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.8506851196289062 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0071, 0.0043, 0.0028, 0.0051, 0.0030, 0.0154, 0.0019]) \n",
      "Test Loss tensor([0.0109, 0.0097, 0.0045, 0.0031, 0.0050, 0.0029, 0.0156, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.711888313293457 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0121, 0.0102, 0.0054, 0.0029, 0.0057, 0.0032, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0110, 0.0097, 0.0041, 0.0032, 0.0046, 0.0030, 0.0148, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.6528835296630859 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0089, 0.0041, 0.0036, 0.0039, 0.0028, 0.0156, 0.0019]) \n",
      "Test Loss tensor([0.0114, 0.0094, 0.0043, 0.0033, 0.0046, 0.0028, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6295123100280762 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0132, 0.0102, 0.0045, 0.0036, 0.0060, 0.0029, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0113, 0.0097, 0.0042, 0.0034, 0.0049, 0.0030, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.7534410953521729 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0083, 0.0040, 0.0032, 0.0048, 0.0027, 0.0144, 0.0018]) \n",
      "Test Loss tensor([0.0107, 0.0099, 0.0043, 0.0032, 0.0047, 0.0028, 0.0149, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.7096881866455078 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0104, 0.0042, 0.0025, 0.0059, 0.0027, 0.0151, 0.0019]) \n",
      "Test Loss tensor([0.0105, 0.0094, 0.0042, 0.0033, 0.0044, 0.0028, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.7200233936309814 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0088, 0.0050, 0.0027, 0.0035, 0.0026, 0.0136, 0.0019]) \n",
      "Test Loss tensor([0.0108, 0.0097, 0.0044, 0.0034, 0.0048, 0.0030, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.7023236751556396 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0159, 0.0109, 0.0043, 0.0036, 0.0041, 0.0024, 0.0146, 0.0018]) \n",
      "Test Loss tensor([0.0110, 0.0096, 0.0043, 0.0034, 0.0043, 0.0029, 0.0149, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.7477648258209229 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0099, 0.0036, 0.0023, 0.0047, 0.0031, 0.0158, 0.0019]) \n",
      "Test Loss tensor([0.0108, 0.0097, 0.0041, 0.0032, 0.0044, 0.0030, 0.0158, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.8124680519104004 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0148, 0.0095, 0.0041, 0.0030, 0.0066, 0.0027, 0.0156, 0.0019]) \n",
      "Test Loss tensor([0.0102, 0.0094, 0.0045, 0.0032, 0.0046, 0.0028, 0.0155, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.7204122543334961 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0093, 0.0046, 0.0026, 0.0048, 0.0025, 0.0144, 0.0021]) \n",
      "Test Loss tensor([0.0117, 0.0097, 0.0043, 0.0034, 0.0047, 0.0029, 0.0156, 0.0020])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7408456802368164 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0086, 0.0041, 0.0029, 0.0039, 0.0027, 0.0168, 0.0021]) \n",
      "Test Loss tensor([0.0112, 0.0090, 0.0041, 0.0032, 0.0044, 0.0029, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.8365781307220459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0088, 0.0044, 0.0031, 0.0062, 0.0031, 0.0153, 0.0020]) \n",
      "Test Loss tensor([0.0102, 0.0097, 0.0042, 0.0028, 0.0048, 0.0029, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7623779773712158 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0106, 0.0039, 0.0034, 0.0037, 0.0023, 0.0151, 0.0019]) \n",
      "Test Loss tensor([0.0106, 0.0098, 0.0041, 0.0031, 0.0048, 0.0029, 0.0149, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 188 in 0.8519203662872314 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0099, 0.0043, 0.0034, 0.0036, 0.0034, 0.0158, 0.0018]) \n",
      "Test Loss tensor([0.0105, 0.0098, 0.0041, 0.0031, 0.0046, 0.0030, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.68727707862854 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0088, 0.0049, 0.0031, 0.0070, 0.0028, 0.0156, 0.0020]) \n",
      "Test Loss tensor([0.0099, 0.0100, 0.0043, 0.0033, 0.0046, 0.0028, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.6516823768615723 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0103, 0.0040, 0.0036, 0.0056, 0.0034, 0.0158, 0.0018]) \n",
      "Test Loss tensor([0.0116, 0.0097, 0.0043, 0.0032, 0.0049, 0.0028, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.7121872901916504 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0072, 0.0038, 0.0030, 0.0052, 0.0025, 0.0151, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0090, 0.0044, 0.0030, 0.0046, 0.0028, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.6754043102264404 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0083, 0.0040, 0.0032, 0.0054, 0.0024, 0.0163, 0.0018]) \n",
      "Test Loss tensor([0.0105, 0.0091, 0.0042, 0.0030, 0.0044, 0.0028, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.6662917137145996 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0083, 0.0036, 0.0028, 0.0059, 0.0030, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0097, 0.0095, 0.0043, 0.0031, 0.0040, 0.0028, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.7347245216369629 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0134, 0.0089, 0.0044, 0.0028, 0.0052, 0.0027, 0.0149, 0.0018]) \n",
      "Test Loss tensor([0.0109, 0.0093, 0.0042, 0.0033, 0.0051, 0.0030, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7678329944610596 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0090, 0.0049, 0.0030, 0.0062, 0.0032, 0.0159, 0.0020]) \n",
      "Test Loss tensor([0.0100, 0.0096, 0.0044, 0.0032, 0.0045, 0.0028, 0.0149, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.9144890308380127 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0104, 0.0041, 0.0025, 0.0050, 0.0024, 0.0142, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0094, 0.0043, 0.0032, 0.0045, 0.0027, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.8546175956726074 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0113, 0.0088, 0.0039, 0.0039, 0.0058, 0.0031, 0.0159, 0.0019]) \n",
      "Test Loss tensor([0.0102, 0.0094, 0.0042, 0.0028, 0.0043, 0.0027, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.7250914573669434 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0081, 0.0038, 0.0029, 0.0048, 0.0025, 0.0155, 0.0018]) \n",
      "Test Loss tensor([0.0109, 0.0093, 0.0044, 0.0030, 0.0043, 0.0027, 0.0154, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.677276611328125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0095, 0.0040, 0.0036, 0.0037, 0.0025, 0.0144, 0.0020]) \n",
      "Test Loss tensor([0.0105, 0.0088, 0.0044, 0.0032, 0.0045, 0.0027, 0.0152, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 236 in 0.6994035243988037 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0097, 0.0045, 0.0025, 0.0074, 0.0024, 0.0132, 0.0019]) \n",
      "Test Loss tensor([0.0109, 0.0098, 0.0042, 0.0033, 0.0042, 0.0030, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.64400315284729 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0081, 0.0042, 0.0033, 0.0050, 0.0031, 0.0153, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0094, 0.0041, 0.0032, 0.0047, 0.0029, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.7274200916290283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0080, 0.0039, 0.0033, 0.0042, 0.0021, 0.0148, 0.0019]) \n",
      "Test Loss tensor([0.0106, 0.0087, 0.0041, 0.0031, 0.0047, 0.0028, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.8080699443817139 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0089, 0.0032, 0.0022, 0.0052, 0.0025, 0.0160, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0094, 0.0041, 0.0029, 0.0046, 0.0027, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7885715961456299 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0088, 0.0033, 0.0029, 0.0034, 0.0031, 0.0137, 0.0017]) \n",
      "Test Loss tensor([0.0107, 0.0092, 0.0043, 0.0032, 0.0046, 0.0028, 0.0149, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.6720695495605469 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0089, 0.0050, 0.0031, 0.0035, 0.0022, 0.0147, 0.0020]) \n",
      "Test Loss tensor([0.0105, 0.0087, 0.0043, 0.0031, 0.0043, 0.0029, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.6306948661804199 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0094, 0.0037, 0.0026, 0.0046, 0.0023, 0.0146, 0.0017]) \n",
      "Test Loss tensor([0.0106, 0.0093, 0.0041, 0.0032, 0.0047, 0.0029, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.64359450340271 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0100, 0.0040, 0.0034, 0.0041, 0.0030, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0106, 0.0086, 0.0041, 0.0029, 0.0049, 0.0027, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.6794016361236572 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0100, 0.0043, 0.0034, 0.0065, 0.0025, 0.0162, 0.0018]) \n",
      "Test Loss tensor([0.0106, 0.0093, 0.0043, 0.0034, 0.0049, 0.0028, 0.0149, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.6636333465576172 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0114, 0.0042, 0.0043, 0.0059, 0.0029, 0.0162, 0.0019]) \n",
      "Test Loss tensor([0.0104, 0.0091, 0.0044, 0.0032, 0.0045, 0.0026, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.6319024562835693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0093, 0.0034, 0.0026, 0.0042, 0.0033, 0.0140, 0.0020]) \n",
      "Test Loss tensor([0.0107, 0.0093, 0.0045, 0.0032, 0.0048, 0.0026, 0.0151, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.7203459739685059 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0135, 0.0082, 0.0053, 0.0029, 0.0057, 0.0021, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0107, 0.0090, 0.0042, 0.0033, 0.0048, 0.0029, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.7567799091339111 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0097, 0.0038, 0.0029, 0.0043, 0.0025, 0.0137, 0.0019]) \n",
      "Test Loss tensor([0.0111, 0.0095, 0.0042, 0.0032, 0.0052, 0.0028, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.7339191436767578 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0091, 0.0034, 0.0030, 0.0050, 0.0025, 0.0152, 0.0018]) \n",
      "Test Loss tensor([0.0104, 0.0098, 0.0044, 0.0032, 0.0044, 0.0030, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.698199987411499 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0091, 0.0040, 0.0030, 0.0070, 0.0032, 0.0150, 0.0020]) \n",
      "Test Loss tensor([0.0101, 0.0090, 0.0043, 0.0032, 0.0046, 0.0029, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 296 in 0.655573844909668 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0081, 0.0038, 0.0031, 0.0045, 0.0024, 0.0152, 0.0019]) \n",
      "Test Loss tensor([0.0107, 0.0093, 0.0044, 0.0031, 0.0045, 0.0030, 0.0153, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.650932788848877 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0116, 0.0043, 0.0027, 0.0073, 0.0034, 0.0139, 0.0020]) \n",
      "Test Loss tensor([0.0110, 0.0092, 0.0043, 0.0032, 0.0049, 0.0029, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.6264505386352539 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0087, 0.0053, 0.0034, 0.0049, 0.0032, 0.0144, 0.0020]) \n",
      "Test Loss tensor([0.0104, 0.0094, 0.0044, 0.0032, 0.0048, 0.0029, 0.0148, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.6246280670166016 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0090, 0.0042, 0.0026, 0.0056, 0.0031, 0.0143, 0.0019]) \n",
      "Test Loss tensor([0.0100, 0.0091, 0.0045, 0.0030, 0.0047, 0.0027, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.7541790008544922 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0093, 0.0043, 0.0029, 0.0042, 0.0028, 0.0137, 0.0019]) \n",
      "Test Loss tensor([0.0106, 0.0092, 0.0043, 0.0030, 0.0048, 0.0027, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.8280024528503418 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0090, 0.0035, 0.0028, 0.0044, 0.0025, 0.0148, 0.0020]) \n",
      "Test Loss tensor([0.0106, 0.0089, 0.0045, 0.0032, 0.0044, 0.0029, 0.0140, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 320 in 0.8189442157745361 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0130, 0.0081, 0.0044, 0.0039, 0.0055, 0.0027, 0.0138, 0.0018]) \n",
      "Test Loss tensor([0.0103, 0.0093, 0.0043, 0.0033, 0.0045, 0.0030, 0.0144, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.753648042678833 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0089, 0.0037, 0.0029, 0.0041, 0.0025, 0.0158, 0.0017]) \n",
      "Test Loss tensor([0.0102, 0.0094, 0.0043, 0.0035, 0.0051, 0.0030, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.696270227432251 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0081, 0.0039, 0.0031, 0.0047, 0.0032, 0.0143, 0.0019]) \n",
      "Test Loss tensor([0.0101, 0.0091, 0.0043, 0.0030, 0.0044, 0.0028, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6799182891845703 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0107, 0.0042, 0.0029, 0.0047, 0.0025, 0.0156, 0.0018]) \n",
      "Test Loss tensor([0.0102, 0.0093, 0.0042, 0.0031, 0.0044, 0.0027, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.7092070579528809 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0089, 0.0039, 0.0022, 0.0059, 0.0026, 0.0135, 0.0018]) \n",
      "Test Loss tensor([0.0099, 0.0091, 0.0045, 0.0031, 0.0047, 0.0027, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.7317657470703125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0090, 0.0039, 0.0030, 0.0042, 0.0030, 0.0146, 0.0020]) \n",
      "Test Loss tensor([0.0096, 0.0098, 0.0043, 0.0032, 0.0046, 0.0029, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.655536413192749 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0083, 0.0090, 0.0035, 0.0029, 0.0053, 0.0031, 0.0148, 0.0019]) \n",
      "Test Loss tensor([0.0097, 0.0098, 0.0043, 0.0031, 0.0046, 0.0030, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.7321641445159912 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0079, 0.0046, 0.0030, 0.0072, 0.0033, 0.0154, 0.0021]) \n",
      "Test Loss tensor([0.0100, 0.0092, 0.0045, 0.0029, 0.0050, 0.0028, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7051889896392822 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0112, 0.0057, 0.0035, 0.0038, 0.0024, 0.0142, 0.0022]) \n",
      "Test Loss tensor([0.0102, 0.0093, 0.0044, 0.0031, 0.0046, 0.0027, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.7403953075408936 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0102, 0.0035, 0.0032, 0.0046, 0.0026, 0.0162, 0.0018]) \n",
      "Test Loss tensor([0.0108, 0.0090, 0.0044, 0.0031, 0.0047, 0.0027, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.7851526737213135 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0078, 0.0101, 0.0044, 0.0034, 0.0039, 0.0031, 0.0160, 0.0020]) \n",
      "Test Loss tensor([0.0103, 0.0089, 0.0043, 0.0032, 0.0047, 0.0028, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7330605983734131 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0119, 0.0088, 0.0039, 0.0025, 0.0047, 0.0027, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0101, 0.0093, 0.0044, 0.0030, 0.0043, 0.0027, 0.0150, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 368 in 0.6742637157440186 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0102, 0.0041, 0.0023, 0.0051, 0.0026, 0.0141, 0.0020]) \n",
      "Test Loss tensor([0.0106, 0.0091, 0.0044, 0.0032, 0.0046, 0.0029, 0.0148, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7202703952789307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0095, 0.0042, 0.0037, 0.0042, 0.0024, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0102, 0.0088, 0.0042, 0.0032, 0.0043, 0.0028, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.7012858390808105 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0114, 0.0087, 0.0043, 0.0036, 0.0069, 0.0036, 0.0162, 0.0019]) \n",
      "Test Loss tensor([0.0098, 0.0087, 0.0043, 0.0031, 0.0048, 0.0027, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.7226016521453857 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0087, 0.0044, 0.0027, 0.0054, 0.0032, 0.0150, 0.0019]) \n",
      "Test Loss tensor([0.0105, 0.0089, 0.0043, 0.0029, 0.0047, 0.0028, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.7583978176116943 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0087, 0.0054, 0.0027, 0.0039, 0.0023, 0.0132, 0.0018]) \n",
      "Test Loss tensor([0.0099, 0.0087, 0.0043, 0.0032, 0.0045, 0.0028, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7288405895233154 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0068, 0.0035, 0.0026, 0.0058, 0.0026, 0.0152, 0.0018]) \n",
      "Test Loss tensor([0.0104, 0.0093, 0.0043, 0.0033, 0.0041, 0.0029, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7757370471954346 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0097, 0.0041, 0.0032, 0.0048, 0.0028, 0.0143, 0.0020]) \n",
      "Test Loss tensor([0.0091, 0.0092, 0.0042, 0.0030, 0.0045, 0.0029, 0.0147, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.7170400619506836 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0092, 0.0036, 0.0031, 0.0044, 0.0021, 0.0141, 0.0018]) \n",
      "Test Loss tensor([0.0093, 0.0086, 0.0042, 0.0030, 0.0048, 0.0027, 0.0144, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.6903903484344482 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0062, 0.0037, 0.0036, 0.0058, 0.0026, 0.0136, 0.0018]) \n",
      "Test Loss tensor([0.0101, 0.0088, 0.0044, 0.0030, 0.0041, 0.0029, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.6531922817230225 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0111, 0.0041, 0.0028, 0.0042, 0.0023, 0.0148, 0.0019]) \n",
      "Test Loss tensor([0.0099, 0.0088, 0.0043, 0.0030, 0.0047, 0.0028, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6390080451965332 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0085, 0.0044, 0.0029, 0.0053, 0.0026, 0.0142, 0.0020]) \n",
      "Test Loss tensor([0.0102, 0.0092, 0.0042, 0.0031, 0.0044, 0.0028, 0.0144, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6981797218322754 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0109, 0.0042, 0.0032, 0.0035, 0.0030, 0.0141, 0.0020]) \n",
      "Test Loss tensor([0.0097, 0.0089, 0.0044, 0.0030, 0.0046, 0.0027, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.7353987693786621 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0089, 0.0053, 0.0029, 0.0049, 0.0031, 0.0130, 0.0019]) \n",
      "Test Loss tensor([0.0098, 0.0095, 0.0041, 0.0032, 0.0044, 0.0028, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7063324451446533 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0086, 0.0035, 0.0029, 0.0054, 0.0025, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0104, 0.0089, 0.0040, 0.0033, 0.0044, 0.0030, 0.0141, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.6672728061676025 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0101, 0.0042, 0.0040, 0.0044, 0.0029, 0.0146, 0.0019]) \n",
      "Test Loss tensor([0.0102, 0.0090, 0.0043, 0.0030, 0.0046, 0.0028, 0.0144, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6947166919708252 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0093, 0.0043, 0.0031, 0.0056, 0.0027, 0.0143, 0.0018]) \n",
      "Test Loss tensor([0.0101, 0.0092, 0.0045, 0.0030, 0.0048, 0.0027, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.7034258842468262 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0093, 0.0048, 0.0033, 0.0046, 0.0026, 0.0147, 0.0021]) \n",
      "Test Loss tensor([0.0104, 0.0095, 0.0044, 0.0030, 0.0045, 0.0027, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.720001220703125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0127, 0.0086, 0.0042, 0.0030, 0.0037, 0.0025, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0108, 0.0094, 0.0044, 0.0033, 0.0049, 0.0027, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.6885604858398438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0111, 0.0036, 0.0031, 0.0056, 0.0024, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0099, 0.0090, 0.0041, 0.0032, 0.0049, 0.0028, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6319863796234131 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0086, 0.0042, 0.0028, 0.0034, 0.0028, 0.0136, 0.0019]) \n",
      "Test Loss tensor([0.0100, 0.0092, 0.0043, 0.0031, 0.0045, 0.0027, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6801581382751465 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0098, 0.0040, 0.0032, 0.0048, 0.0025, 0.0161, 0.0020]) \n",
      "Test Loss tensor([0.0096, 0.0093, 0.0045, 0.0032, 0.0049, 0.0028, 0.0146, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 452 in 0.6400091648101807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0111, 0.0088, 0.0032, 0.0040, 0.0045, 0.0028, 0.0140, 0.0019]) \n",
      "Test Loss tensor([0.0096, 0.0093, 0.0043, 0.0030, 0.0044, 0.0028, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.7207145690917969 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0079, 0.0034, 0.0026, 0.0055, 0.0030, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0098, 0.0094, 0.0042, 0.0031, 0.0040, 0.0029, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.7266788482666016 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0081, 0.0043, 0.0025, 0.0035, 0.0029, 0.0157, 0.0018]) \n",
      "Test Loss tensor([0.0099, 0.0093, 0.0044, 0.0032, 0.0047, 0.0027, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.6779463291168213 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0094, 0.0042, 0.0031, 0.0057, 0.0024, 0.0144, 0.0018]) \n",
      "Test Loss tensor([0.0092, 0.0093, 0.0043, 0.0030, 0.0048, 0.0029, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.6849396228790283 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0094, 0.0045, 0.0031, 0.0036, 0.0026, 0.0140, 0.0018]) \n",
      "Test Loss tensor([0.0099, 0.0093, 0.0041, 0.0031, 0.0044, 0.0028, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.6684043407440186 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0086, 0.0049, 0.0029, 0.0053, 0.0027, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0091, 0.0042, 0.0030, 0.0043, 0.0026, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.6259994506835938 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0085, 0.0040, 0.0028, 0.0036, 0.0024, 0.0146, 0.0019]) \n",
      "Test Loss tensor([0.0097, 0.0092, 0.0044, 0.0029, 0.0051, 0.0026, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6231825351715088 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0083, 0.0041, 0.0027, 0.0041, 0.0027, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0103, 0.0092, 0.0042, 0.0030, 0.0045, 0.0027, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6189596652984619 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0094, 0.0043, 0.0025, 0.0056, 0.0023, 0.0132, 0.0018]) \n",
      "Test Loss tensor([0.0099, 0.0088, 0.0043, 0.0032, 0.0040, 0.0027, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.6188075542449951 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0092, 0.0048, 0.0027, 0.0049, 0.0025, 0.0147, 0.0019]) \n",
      "Test Loss tensor([0.0095, 0.0093, 0.0043, 0.0031, 0.0045, 0.0028, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.6175029277801514 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0104, 0.0036, 0.0028, 0.0055, 0.0027, 0.0150, 0.0019]) \n",
      "Test Loss tensor([0.0097, 0.0094, 0.0043, 0.0029, 0.0047, 0.0029, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.614171028137207 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0099, 0.0046, 0.0037, 0.0042, 0.0026, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0102, 0.0093, 0.0039, 0.0033, 0.0048, 0.0030, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 500 in 0.6195328235626221 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0122, 0.0091, 0.0044, 0.0030, 0.0049, 0.0040, 0.0151, 0.0018]) \n",
      "Test Loss tensor([0.0098, 0.0095, 0.0040, 0.0031, 0.0042, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.6220347881317139 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0092, 0.0035, 0.0027, 0.0063, 0.0030, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0103, 0.0088, 0.0042, 0.0031, 0.0055, 0.0026, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.6200919151306152 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0117, 0.0097, 0.0042, 0.0031, 0.0047, 0.0028, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0103, 0.0094, 0.0040, 0.0031, 0.0045, 0.0028, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.6199817657470703 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0089, 0.0041, 0.0026, 0.0043, 0.0022, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0101, 0.0091, 0.0041, 0.0029, 0.0046, 0.0028, 0.0146, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6134467124938965 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0090, 0.0042, 0.0027, 0.0052, 0.0026, 0.0122, 0.0019]) \n",
      "Test Loss tensor([0.0097, 0.0088, 0.0043, 0.0029, 0.0046, 0.0027, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.6152074337005615 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0115, 0.0076, 0.0041, 0.0027, 0.0032, 0.0023, 0.0129, 0.0019]) \n",
      "Test Loss tensor([0.0101, 0.0097, 0.0043, 0.0031, 0.0044, 0.0029, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.6111812591552734 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0102, 0.0032, 0.0029, 0.0068, 0.0035, 0.0131, 0.0019]) \n",
      "Test Loss tensor([0.0098, 0.0097, 0.0041, 0.0031, 0.0041, 0.0027, 0.0145, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.620715856552124 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0073, 0.0108, 0.0047, 0.0029, 0.0063, 0.0022, 0.0144, 0.0019]) \n",
      "Test Loss tensor([0.0097, 0.0091, 0.0042, 0.0031, 0.0045, 0.0029, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.6138617992401123 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0076, 0.0059, 0.0027, 0.0052, 0.0029, 0.0144, 0.0018]) \n",
      "Test Loss tensor([0.0103, 0.0089, 0.0042, 0.0031, 0.0046, 0.0027, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6119916439056396 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0095, 0.0036, 0.0029, 0.0054, 0.0022, 0.0135, 0.0018]) \n",
      "Test Loss tensor([0.0095, 0.0089, 0.0042, 0.0034, 0.0044, 0.0026, 0.0144, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.6131453514099121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0095, 0.0047, 0.0032, 0.0061, 0.0023, 0.0129, 0.0017]) \n",
      "Test Loss tensor([0.0099, 0.0087, 0.0040, 0.0033, 0.0046, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6203930377960205 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0101, 0.0042, 0.0028, 0.0047, 0.0023, 0.0150, 0.0020]) \n",
      "Test Loss tensor([0.0099, 0.0089, 0.0041, 0.0030, 0.0044, 0.0028, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.6159124374389648 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0090, 0.0050, 0.0044, 0.0049, 0.0031, 0.0123, 0.0021]) \n",
      "Test Loss tensor([0.0094, 0.0094, 0.0040, 0.0030, 0.0043, 0.0028, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6315200328826904 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0083, 0.0083, 0.0032, 0.0033, 0.0040, 0.0026, 0.0141, 0.0018]) \n",
      "Test Loss tensor([0.0098, 0.0092, 0.0044, 0.0031, 0.0048, 0.0027, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 556 in 0.6177568435668945 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0091, 0.0037, 0.0034, 0.0040, 0.0021, 0.0130, 0.0019]) \n",
      "Test Loss tensor([0.0093, 0.0090, 0.0042, 0.0032, 0.0037, 0.0026, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 560 in 0.6119246482849121 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0097, 0.0041, 0.0027, 0.0046, 0.0023, 0.0164, 0.0019]) \n",
      "Test Loss tensor([0.0101, 0.0090, 0.0040, 0.0029, 0.0045, 0.0026, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 564 in 0.6140291690826416 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0098, 0.0044, 0.0031, 0.0063, 0.0028, 0.0153, 0.0020]) \n",
      "Test Loss tensor([0.0099, 0.0092, 0.0042, 0.0029, 0.0045, 0.0027, 0.0144, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 568 in 0.6073968410491943 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0099, 0.0040, 0.0022, 0.0050, 0.0027, 0.0140, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0093, 0.0043, 0.0030, 0.0043, 0.0026, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 572 in 0.6094298362731934 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0095, 0.0047, 0.0035, 0.0051, 0.0024, 0.0136, 0.0020]) \n",
      "Test Loss tensor([0.0092, 0.0088, 0.0042, 0.0031, 0.0045, 0.0026, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 576 in 0.7099676132202148 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0126, 0.0108, 0.0044, 0.0033, 0.0042, 0.0020, 0.0152, 0.0018]) \n",
      "Test Loss tensor([0.0097, 0.0090, 0.0046, 0.0031, 0.0046, 0.0029, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 580 in 0.6228427886962891 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0072, 0.0047, 0.0032, 0.0037, 0.0025, 0.0145, 0.0019]) \n",
      "Test Loss tensor([0.0096, 0.0085, 0.0043, 0.0030, 0.0044, 0.0028, 0.0137, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 584 in 0.618119478225708 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0078, 0.0050, 0.0030, 0.0051, 0.0034, 0.0141, 0.0019]) \n",
      "Test Loss tensor([0.0101, 0.0091, 0.0041, 0.0032, 0.0041, 0.0029, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 588 in 0.6138627529144287 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0089, 0.0051, 0.0027, 0.0041, 0.0027, 0.0120, 0.0019]) \n",
      "Test Loss tensor([0.0090, 0.0091, 0.0040, 0.0031, 0.0040, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 592 in 0.6190676689147949 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0086, 0.0037, 0.0026, 0.0045, 0.0029, 0.0134, 0.0020]) \n",
      "Test Loss tensor([0.0094, 0.0090, 0.0041, 0.0030, 0.0046, 0.0028, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 596 in 0.6218836307525635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0093, 0.0041, 0.0023, 0.0036, 0.0027, 0.0143, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0089, 0.0039, 0.0031, 0.0041, 0.0029, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 600 in 0.6189212799072266 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0089, 0.0039, 0.0028, 0.0041, 0.0027, 0.0133, 0.0020]) \n",
      "Test Loss tensor([0.0102, 0.0092, 0.0043, 0.0032, 0.0045, 0.0029, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 604 in 0.6130218505859375 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0075, 0.0039, 0.0026, 0.0072, 0.0033, 0.0136, 0.0019]) \n",
      "Test Loss tensor([0.0095, 0.0089, 0.0042, 0.0030, 0.0047, 0.0026, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 608 in 0.6111204624176025 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0083, 0.0040, 0.0039, 0.0047, 0.0030, 0.0127, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0092, 0.0042, 0.0033, 0.0043, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 612 in 0.616952657699585 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0099, 0.0044, 0.0035, 0.0048, 0.0027, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0092, 0.0041, 0.0029, 0.0047, 0.0027, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 616 in 0.6498472690582275 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0071, 0.0042, 0.0026, 0.0035, 0.0022, 0.0137, 0.0019]) \n",
      "Test Loss tensor([0.0099, 0.0090, 0.0042, 0.0030, 0.0044, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 620 in 0.6122701168060303 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0075, 0.0041, 0.0026, 0.0051, 0.0030, 0.0146, 0.0019]) \n",
      "Test Loss tensor([0.0090, 0.0096, 0.0041, 0.0028, 0.0043, 0.0029, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 624 in 0.6097362041473389 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0107, 0.0081, 0.0039, 0.0026, 0.0043, 0.0032, 0.0144, 0.0023]) \n",
      "Test Loss tensor([0.0091, 0.0084, 0.0042, 0.0029, 0.0039, 0.0029, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 628 in 0.613349437713623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0083, 0.0090, 0.0034, 0.0031, 0.0050, 0.0039, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0095, 0.0087, 0.0042, 0.0030, 0.0045, 0.0028, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 632 in 0.6083674430847168 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0088, 0.0043, 0.0037, 0.0055, 0.0030, 0.0139, 0.0019]) \n",
      "Test Loss tensor([0.0098, 0.0090, 0.0042, 0.0030, 0.0042, 0.0029, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 636 in 0.632962703704834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0090, 0.0047, 0.0029, 0.0043, 0.0027, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0093, 0.0088, 0.0043, 0.0030, 0.0042, 0.0028, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 640 in 0.6243906021118164 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0096, 0.0045, 0.0028, 0.0047, 0.0034, 0.0146, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0090, 0.0042, 0.0029, 0.0044, 0.0026, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 644 in 0.6188108921051025 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0077, 0.0034, 0.0029, 0.0039, 0.0022, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0092, 0.0091, 0.0042, 0.0030, 0.0041, 0.0027, 0.0143, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 648 in 0.6132442951202393 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0081, 0.0043, 0.0030, 0.0048, 0.0029, 0.0140, 0.0019]) \n",
      "Test Loss tensor([0.0085, 0.0085, 0.0044, 0.0031, 0.0045, 0.0030, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 652 in 0.6101593971252441 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0085, 0.0052, 0.0028, 0.0044, 0.0033, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0094, 0.0087, 0.0044, 0.0031, 0.0043, 0.0027, 0.0142, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 656 in 0.6129710674285889 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0087, 0.0043, 0.0031, 0.0047, 0.0024, 0.0141, 0.0020]) \n",
      "Test Loss tensor([0.0094, 0.0087, 0.0043, 0.0033, 0.0052, 0.0028, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 660 in 0.6103155612945557 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0078, 0.0088, 0.0038, 0.0032, 0.0049, 0.0025, 0.0142, 0.0018]) \n",
      "Test Loss tensor([0.0094, 0.0088, 0.0044, 0.0029, 0.0047, 0.0028, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 664 in 0.610344409942627 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0084, 0.0081, 0.0039, 0.0031, 0.0046, 0.0025, 0.0143, 0.0018]) \n",
      "Test Loss tensor([0.0094, 0.0093, 0.0042, 0.0029, 0.0045, 0.0028, 0.0136, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 668 in 0.6238577365875244 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0108, 0.0095, 0.0047, 0.0034, 0.0037, 0.0024, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0086, 0.0040, 0.0030, 0.0043, 0.0027, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 672 in 0.6124234199523926 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0110, 0.0079, 0.0037, 0.0029, 0.0062, 0.0022, 0.0136, 0.0020]) \n",
      "Test Loss tensor([0.0092, 0.0092, 0.0042, 0.0031, 0.0046, 0.0029, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 676 in 0.6269485950469971 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0118, 0.0095, 0.0030, 0.0043, 0.0051, 0.0037, 0.0140, 0.0018]) \n",
      "Test Loss tensor([0.0091, 0.0092, 0.0041, 0.0032, 0.0045, 0.0029, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 680 in 0.6270198822021484 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0071, 0.0041, 0.0028, 0.0043, 0.0027, 0.0138, 0.0018]) \n",
      "Test Loss tensor([0.0088, 0.0081, 0.0042, 0.0029, 0.0044, 0.0026, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 684 in 0.614795446395874 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0083, 0.0083, 0.0039, 0.0032, 0.0042, 0.0028, 0.0143, 0.0018]) \n",
      "Test Loss tensor([0.0094, 0.0087, 0.0041, 0.0030, 0.0049, 0.0027, 0.0140, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 688 in 0.6108641624450684 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0087, 0.0037, 0.0036, 0.0033, 0.0030, 0.0138, 0.0020]) \n",
      "Test Loss tensor([0.0092, 0.0094, 0.0043, 0.0031, 0.0053, 0.0028, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 692 in 0.6081693172454834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0081, 0.0036, 0.0035, 0.0058, 0.0026, 0.0132, 0.0019]) \n",
      "Test Loss tensor([0.0095, 0.0092, 0.0040, 0.0030, 0.0044, 0.0027, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 696 in 0.6301908493041992 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0096, 0.0044, 0.0025, 0.0047, 0.0032, 0.0149, 0.0020]) \n",
      "Test Loss tensor([0.0092, 0.0089, 0.0041, 0.0030, 0.0046, 0.0028, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 700 in 0.7176840305328369 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0078, 0.0035, 0.0031, 0.0047, 0.0023, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0090, 0.0041, 0.0030, 0.0049, 0.0028, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 704 in 0.6113290786743164 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0064, 0.0080, 0.0032, 0.0028, 0.0055, 0.0023, 0.0142, 0.0018]) \n",
      "Test Loss tensor([0.0098, 0.0087, 0.0042, 0.0030, 0.0047, 0.0026, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 708 in 0.6121296882629395 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0091, 0.0042, 0.0033, 0.0053, 0.0031, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0090, 0.0041, 0.0030, 0.0043, 0.0027, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 712 in 0.6136002540588379 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0095, 0.0043, 0.0034, 0.0037, 0.0025, 0.0136, 0.0018]) \n",
      "Test Loss tensor([0.0093, 0.0085, 0.0041, 0.0031, 0.0047, 0.0028, 0.0135, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 716 in 0.6200826168060303 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0079, 0.0043, 0.0031, 0.0054, 0.0024, 0.0139, 0.0020]) \n",
      "Test Loss tensor([0.0089, 0.0088, 0.0042, 0.0030, 0.0042, 0.0027, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 720 in 0.6206181049346924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0082, 0.0041, 0.0030, 0.0048, 0.0023, 0.0136, 0.0018]) \n",
      "Test Loss tensor([0.0086, 0.0090, 0.0042, 0.0032, 0.0041, 0.0027, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 724 in 0.6095762252807617 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0087, 0.0041, 0.0035, 0.0063, 0.0025, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0086, 0.0040, 0.0030, 0.0042, 0.0028, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 728 in 0.612091064453125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0082, 0.0042, 0.0023, 0.0045, 0.0023, 0.0132, 0.0019]) \n",
      "Test Loss tensor([0.0093, 0.0087, 0.0041, 0.0034, 0.0041, 0.0029, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 732 in 0.6113491058349609 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0087, 0.0039, 0.0035, 0.0058, 0.0021, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0089, 0.0041, 0.0030, 0.0044, 0.0028, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 736 in 0.6082916259765625 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0083, 0.0038, 0.0024, 0.0044, 0.0027, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0087, 0.0094, 0.0040, 0.0030, 0.0041, 0.0028, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 740 in 0.6156351566314697 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0086, 0.0033, 0.0028, 0.0035, 0.0026, 0.0154, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0097, 0.0038, 0.0029, 0.0041, 0.0030, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 744 in 0.6063368320465088 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0082, 0.0039, 0.0026, 0.0051, 0.0022, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0089, 0.0042, 0.0033, 0.0042, 0.0027, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 748 in 0.6073780059814453 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0084, 0.0083, 0.0039, 0.0026, 0.0040, 0.0021, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0092, 0.0083, 0.0040, 0.0031, 0.0043, 0.0028, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 752 in 0.6131730079650879 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0070, 0.0051, 0.0025, 0.0047, 0.0032, 0.0128, 0.0021]) \n",
      "Test Loss tensor([0.0093, 0.0085, 0.0040, 0.0030, 0.0044, 0.0025, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 756 in 0.607255220413208 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0082, 0.0039, 0.0031, 0.0046, 0.0027, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0092, 0.0088, 0.0042, 0.0031, 0.0047, 0.0027, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 760 in 0.6119468212127686 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0106, 0.0106, 0.0045, 0.0027, 0.0048, 0.0022, 0.0137, 0.0018]) \n",
      "Test Loss tensor([0.0095, 0.0081, 0.0041, 0.0031, 0.0041, 0.0028, 0.0137, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 764 in 0.6114809513092041 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0109, 0.0103, 0.0039, 0.0033, 0.0052, 0.0025, 0.0148, 0.0019]) \n",
      "Test Loss tensor([0.0095, 0.0085, 0.0040, 0.0031, 0.0041, 0.0028, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 768 in 0.6125216484069824 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0083, 0.0078, 0.0049, 0.0030, 0.0047, 0.0026, 0.0137, 0.0018]) \n",
      "Test Loss tensor([0.0095, 0.0088, 0.0041, 0.0032, 0.0048, 0.0026, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 772 in 0.6111147403717041 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0072, 0.0065, 0.0044, 0.0032, 0.0039, 0.0032, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0089, 0.0087, 0.0041, 0.0029, 0.0045, 0.0027, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 776 in 0.6182169914245605 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0095, 0.0048, 0.0024, 0.0050, 0.0021, 0.0138, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0084, 0.0046, 0.0030, 0.0047, 0.0026, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 780 in 0.6135272979736328 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0097, 0.0052, 0.0028, 0.0053, 0.0028, 0.0148, 0.0019]) \n",
      "Test Loss tensor([0.0091, 0.0095, 0.0041, 0.0030, 0.0042, 0.0028, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 784 in 0.616908073425293 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0079, 0.0042, 0.0032, 0.0041, 0.0025, 0.0130, 0.0019]) \n",
      "Test Loss tensor([0.0090, 0.0093, 0.0041, 0.0029, 0.0044, 0.0027, 0.0138, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 788 in 0.6134927272796631 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0079, 0.0070, 0.0033, 0.0038, 0.0037, 0.0026, 0.0116, 0.0020]) \n",
      "Test Loss tensor([0.0087, 0.0089, 0.0042, 0.0030, 0.0050, 0.0028, 0.0139, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 792 in 0.6122663021087646 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0079, 0.0032, 0.0024, 0.0044, 0.0030, 0.0131, 0.0019]) \n",
      "Test Loss tensor([0.0086, 0.0089, 0.0041, 0.0031, 0.0046, 0.0028, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 796 in 0.6125912666320801 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0066, 0.0033, 0.0027, 0.0049, 0.0027, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0087, 0.0083, 0.0044, 0.0029, 0.0043, 0.0027, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 800 in 0.6125526428222656 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0097, 0.0050, 0.0038, 0.0042, 0.0028, 0.0130, 0.0020]) \n",
      "Test Loss tensor([0.0085, 0.0087, 0.0042, 0.0028, 0.0042, 0.0027, 0.0141, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 804 in 0.6209852695465088 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0089, 0.0041, 0.0026, 0.0045, 0.0028, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0090, 0.0040, 0.0033, 0.0042, 0.0026, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 808 in 0.6164658069610596 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0071, 0.0049, 0.0026, 0.0055, 0.0024, 0.0142, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0087, 0.0043, 0.0031, 0.0046, 0.0026, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 812 in 0.6223468780517578 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0084, 0.0080, 0.0043, 0.0030, 0.0047, 0.0027, 0.0130, 0.0019]) \n",
      "Test Loss tensor([0.0093, 0.0084, 0.0042, 0.0030, 0.0045, 0.0026, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 816 in 0.6129095554351807 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0092, 0.0040, 0.0028, 0.0043, 0.0031, 0.0144, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0091, 0.0043, 0.0028, 0.0041, 0.0026, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 820 in 0.6113286018371582 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0074, 0.0047, 0.0023, 0.0061, 0.0025, 0.0132, 0.0019]) \n",
      "Test Loss tensor([0.0085, 0.0086, 0.0043, 0.0030, 0.0045, 0.0026, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 824 in 0.6477651596069336 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0097, 0.0057, 0.0028, 0.0040, 0.0024, 0.0124, 0.0022]) \n",
      "Test Loss tensor([0.0084, 0.0090, 0.0043, 0.0028, 0.0045, 0.0025, 0.0133, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 828 in 0.6159536838531494 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0065, 0.0093, 0.0036, 0.0032, 0.0037, 0.0026, 0.0149, 0.0018]) \n",
      "Test Loss tensor([0.0088, 0.0086, 0.0042, 0.0032, 0.0041, 0.0026, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 832 in 0.6159400939941406 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0074, 0.0075, 0.0040, 0.0023, 0.0055, 0.0021, 0.0123, 0.0018]) \n",
      "Test Loss tensor([0.0093, 0.0082, 0.0042, 0.0030, 0.0045, 0.0026, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 836 in 0.6225969791412354 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0074, 0.0095, 0.0042, 0.0038, 0.0057, 0.0026, 0.0138, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0089, 0.0042, 0.0031, 0.0047, 0.0026, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 840 in 0.617401123046875 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0085, 0.0046, 0.0033, 0.0038, 0.0028, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0094, 0.0086, 0.0043, 0.0030, 0.0051, 0.0026, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 844 in 0.6165242195129395 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0100, 0.0038, 0.0028, 0.0050, 0.0028, 0.0129, 0.0022]) \n",
      "Test Loss tensor([0.0092, 0.0085, 0.0041, 0.0031, 0.0046, 0.0025, 0.0137, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 848 in 0.6168467998504639 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0078, 0.0036, 0.0028, 0.0044, 0.0022, 0.0124, 0.0019]) \n",
      "Test Loss tensor([0.0081, 0.0091, 0.0041, 0.0031, 0.0045, 0.0027, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 852 in 0.6405305862426758 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0071, 0.0046, 0.0030, 0.0035, 0.0022, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0081, 0.0041, 0.0031, 0.0044, 0.0025, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 856 in 0.6187949180603027 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0128, 0.0075, 0.0032, 0.0028, 0.0062, 0.0028, 0.0143, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0087, 0.0040, 0.0029, 0.0042, 0.0027, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 860 in 0.6355078220367432 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0095, 0.0036, 0.0030, 0.0035, 0.0023, 0.0123, 0.0019]) \n",
      "Test Loss tensor([0.0081, 0.0082, 0.0039, 0.0030, 0.0043, 0.0026, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 864 in 0.631788969039917 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0080, 0.0041, 0.0023, 0.0037, 0.0022, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0088, 0.0090, 0.0037, 0.0032, 0.0045, 0.0028, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 868 in 0.7074949741363525 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0085, 0.0050, 0.0028, 0.0033, 0.0028, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0079, 0.0090, 0.0040, 0.0031, 0.0038, 0.0027, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 872 in 0.6748676300048828 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0084, 0.0038, 0.0032, 0.0052, 0.0023, 0.0133, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0089, 0.0042, 0.0026, 0.0041, 0.0027, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 876 in 0.6855597496032715 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0057, 0.0023, 0.0022, 0.0055, 0.0022, 0.0103, 0.0014]) \n",
      "Test Loss tensor([0.0090, 0.0092, 0.0041, 0.0030, 0.0045, 0.0028, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 0 in 0.7157368659973145 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0073, 0.0038, 0.0025, 0.0049, 0.0024, 0.0135, 0.0017]) \n",
      "Test Loss tensor([0.0092, 0.0086, 0.0043, 0.0030, 0.0043, 0.0027, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 4 in 0.769951343536377 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0085, 0.0040, 0.0026, 0.0063, 0.0028, 0.0153, 0.0018]) \n",
      "Test Loss tensor([0.0087, 0.0083, 0.0039, 0.0031, 0.0045, 0.0028, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.681556224822998 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0071, 0.0041, 0.0029, 0.0045, 0.0027, 0.0130, 0.0019]) \n",
      "Test Loss tensor([0.0085, 0.0088, 0.0038, 0.0031, 0.0045, 0.0028, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.6141033172607422 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0087, 0.0043, 0.0032, 0.0052, 0.0025, 0.0127, 0.0020]) \n",
      "Test Loss tensor([0.0077, 0.0085, 0.0041, 0.0029, 0.0044, 0.0026, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.6172506809234619 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0083, 0.0041, 0.0026, 0.0052, 0.0032, 0.0140, 0.0019]) \n",
      "Test Loss tensor([0.0088, 0.0092, 0.0042, 0.0031, 0.0043, 0.0025, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.6582658290863037 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0084, 0.0080, 0.0042, 0.0027, 0.0043, 0.0026, 0.0145, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0085, 0.0041, 0.0031, 0.0048, 0.0025, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 24 in 0.6288468837738037 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0081, 0.0038, 0.0023, 0.0071, 0.0025, 0.0146, 0.0019]) \n",
      "Test Loss tensor([0.0088, 0.0081, 0.0040, 0.0029, 0.0045, 0.0025, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.6662693023681641 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0088, 0.0037, 0.0028, 0.0042, 0.0026, 0.0120, 0.0018]) \n",
      "Test Loss tensor([0.0092, 0.0083, 0.0043, 0.0030, 0.0044, 0.0026, 0.0136, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.6575329303741455 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0062, 0.0082, 0.0037, 0.0027, 0.0034, 0.0027, 0.0119, 0.0019]) \n",
      "Test Loss tensor([0.0092, 0.0085, 0.0040, 0.0031, 0.0044, 0.0028, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.6259329319000244 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0087, 0.0043, 0.0032, 0.0048, 0.0029, 0.0130, 0.0018]) \n",
      "Test Loss tensor([0.0091, 0.0088, 0.0041, 0.0030, 0.0046, 0.0027, 0.0134, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 40 in 0.6713659763336182 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0092, 0.0046, 0.0027, 0.0047, 0.0022, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0086, 0.0085, 0.0044, 0.0030, 0.0044, 0.0025, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 44 in 0.6978890895843506 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0075, 0.0038, 0.0028, 0.0038, 0.0023, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0086, 0.0083, 0.0042, 0.0029, 0.0045, 0.0025, 0.0135, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 48 in 0.7500033378601074 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0096, 0.0036, 0.0036, 0.0050, 0.0022, 0.0132, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0086, 0.0042, 0.0030, 0.0046, 0.0026, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 52 in 0.6806430816650391 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0081, 0.0040, 0.0024, 0.0040, 0.0024, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0089, 0.0085, 0.0041, 0.0029, 0.0046, 0.0026, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 56 in 0.6377353668212891 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0082, 0.0046, 0.0025, 0.0027, 0.0019, 0.0134, 0.0018]) \n",
      "Test Loss tensor([0.0082, 0.0083, 0.0042, 0.0030, 0.0049, 0.0026, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 60 in 0.6667320728302002 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0086, 0.0041, 0.0023, 0.0044, 0.0026, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0085, 0.0041, 0.0030, 0.0043, 0.0026, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 64 in 0.723759651184082 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0100, 0.0035, 0.0028, 0.0045, 0.0026, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0082, 0.0038, 0.0031, 0.0043, 0.0028, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 68 in 0.7419559955596924 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0068, 0.0074, 0.0036, 0.0030, 0.0052, 0.0022, 0.0133, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0089, 0.0043, 0.0029, 0.0041, 0.0028, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 72 in 0.6621265411376953 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0084, 0.0040, 0.0025, 0.0044, 0.0026, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0083, 0.0040, 0.0028, 0.0044, 0.0026, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 76 in 0.6713361740112305 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0081, 0.0041, 0.0030, 0.0066, 0.0026, 0.0139, 0.0020]) \n",
      "Test Loss tensor([0.0086, 0.0084, 0.0040, 0.0032, 0.0046, 0.0026, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 80 in 0.6207852363586426 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0069, 0.0049, 0.0026, 0.0031, 0.0021, 0.0133, 0.0018]) \n",
      "Test Loss tensor([0.0088, 0.0082, 0.0041, 0.0028, 0.0044, 0.0027, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 84 in 0.7267851829528809 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0067, 0.0031, 0.0025, 0.0054, 0.0024, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0090, 0.0085, 0.0037, 0.0030, 0.0044, 0.0027, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 88 in 0.6393134593963623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0064, 0.0076, 0.0035, 0.0025, 0.0042, 0.0026, 0.0118, 0.0020]) \n",
      "Test Loss tensor([0.0088, 0.0092, 0.0041, 0.0028, 0.0043, 0.0028, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 92 in 0.620830774307251 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0062, 0.0096, 0.0045, 0.0031, 0.0050, 0.0031, 0.0118, 0.0021]) \n",
      "Test Loss tensor([0.0083, 0.0088, 0.0039, 0.0030, 0.0042, 0.0028, 0.0130, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 96 in 0.7200467586517334 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0074, 0.0084, 0.0036, 0.0033, 0.0033, 0.0031, 0.0136, 0.0019]) \n",
      "Test Loss tensor([0.0083, 0.0084, 0.0041, 0.0031, 0.0042, 0.0028, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 100 in 0.6824162006378174 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0103, 0.0035, 0.0036, 0.0065, 0.0025, 0.0125, 0.0021]) \n",
      "Test Loss tensor([0.0089, 0.0089, 0.0040, 0.0029, 0.0041, 0.0028, 0.0131, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 104 in 0.6956427097320557 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0079, 0.0033, 0.0029, 0.0042, 0.0024, 0.0143, 0.0018]) \n",
      "Test Loss tensor([0.0089, 0.0081, 0.0041, 0.0030, 0.0049, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 108 in 0.6181044578552246 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0065, 0.0045, 0.0028, 0.0049, 0.0020, 0.0133, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0086, 0.0039, 0.0028, 0.0038, 0.0027, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 112 in 0.6345789432525635 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0056, 0.0035, 0.0029, 0.0046, 0.0032, 0.0126, 0.0020]) \n",
      "Test Loss tensor([0.0085, 0.0082, 0.0042, 0.0030, 0.0047, 0.0026, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 116 in 0.6735174655914307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0073, 0.0036, 0.0026, 0.0056, 0.0027, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0086, 0.0084, 0.0042, 0.0030, 0.0041, 0.0027, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 120 in 0.6338191032409668 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0101, 0.0036, 0.0028, 0.0043, 0.0023, 0.0131, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0086, 0.0039, 0.0030, 0.0046, 0.0028, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 124 in 0.6219854354858398 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0067, 0.0043, 0.0022, 0.0053, 0.0026, 0.0124, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0087, 0.0041, 0.0029, 0.0050, 0.0026, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 128 in 0.6120967864990234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0100, 0.0077, 0.0040, 0.0025, 0.0058, 0.0031, 0.0115, 0.0020]) \n",
      "Test Loss tensor([0.0085, 0.0088, 0.0044, 0.0031, 0.0049, 0.0026, 0.0127, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 132 in 0.611793041229248 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0079, 0.0041, 0.0022, 0.0042, 0.0024, 0.0122, 0.0021]) \n",
      "Test Loss tensor([0.0088, 0.0083, 0.0041, 0.0029, 0.0041, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 136 in 0.6744885444641113 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0066, 0.0089, 0.0030, 0.0029, 0.0041, 0.0025, 0.0130, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0086, 0.0041, 0.0030, 0.0044, 0.0029, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 140 in 0.8387558460235596 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0088, 0.0034, 0.0028, 0.0044, 0.0025, 0.0132, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0082, 0.0040, 0.0029, 0.0042, 0.0026, 0.0132, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 144 in 0.6756131649017334 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0112, 0.0075, 0.0042, 0.0035, 0.0056, 0.0022, 0.0126, 0.0019]) \n",
      "Test Loss tensor([0.0084, 0.0087, 0.0040, 0.0033, 0.0045, 0.0026, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 148 in 0.6250097751617432 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0067, 0.0048, 0.0030, 0.0054, 0.0024, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0082, 0.0041, 0.0029, 0.0045, 0.0025, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 152 in 0.6346235275268555 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0089, 0.0046, 0.0034, 0.0036, 0.0024, 0.0145, 0.0018]) \n",
      "Test Loss tensor([0.0086, 0.0080, 0.0042, 0.0030, 0.0040, 0.0026, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 156 in 0.6407551765441895 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0082, 0.0042, 0.0029, 0.0046, 0.0031, 0.0139, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0085, 0.0041, 0.0031, 0.0042, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 160 in 0.6368885040283203 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0067, 0.0055, 0.0023, 0.0055, 0.0025, 0.0127, 0.0019]) \n",
      "Test Loss tensor([0.0081, 0.0082, 0.0043, 0.0028, 0.0040, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 164 in 0.7025296688079834 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0102, 0.0092, 0.0037, 0.0026, 0.0052, 0.0028, 0.0126, 0.0021]) \n",
      "Test Loss tensor([0.0089, 0.0086, 0.0041, 0.0031, 0.0044, 0.0025, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 168 in 0.6710953712463379 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0081, 0.0044, 0.0026, 0.0052, 0.0020, 0.0111, 0.0020]) \n",
      "Test Loss tensor([0.0087, 0.0081, 0.0043, 0.0029, 0.0045, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 172 in 0.6716892719268799 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0078, 0.0045, 0.0025, 0.0040, 0.0023, 0.0124, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0092, 0.0042, 0.0028, 0.0045, 0.0027, 0.0125, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 176 in 0.7237637042999268 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0082, 0.0049, 0.0030, 0.0041, 0.0024, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0088, 0.0040, 0.0031, 0.0045, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 180 in 0.6541516780853271 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0063, 0.0096, 0.0037, 0.0022, 0.0043, 0.0028, 0.0129, 0.0018]) \n",
      "Test Loss tensor([0.0075, 0.0082, 0.0041, 0.0029, 0.0040, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 184 in 0.7125508785247803 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0072, 0.0044, 0.0032, 0.0043, 0.0029, 0.0126, 0.0019]) \n",
      "Test Loss tensor([0.0083, 0.0084, 0.0041, 0.0029, 0.0043, 0.0027, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 188 in 0.6606757640838623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0092, 0.0053, 0.0026, 0.0034, 0.0033, 0.0128, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0087, 0.0044, 0.0030, 0.0042, 0.0028, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 192 in 0.7018146514892578 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0109, 0.0046, 0.0034, 0.0032, 0.0031, 0.0133, 0.0018]) \n",
      "Test Loss tensor([0.0081, 0.0084, 0.0040, 0.0031, 0.0040, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 196 in 0.723808765411377 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0098, 0.0045, 0.0031, 0.0046, 0.0032, 0.0135, 0.0019]) \n",
      "Test Loss tensor([0.0084, 0.0085, 0.0041, 0.0030, 0.0042, 0.0028, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 200 in 0.7853100299835205 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0090, 0.0043, 0.0024, 0.0049, 0.0023, 0.0131, 0.0018]) \n",
      "Test Loss tensor([0.0082, 0.0087, 0.0040, 0.0032, 0.0044, 0.0027, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 204 in 0.9260599613189697 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0095, 0.0051, 0.0035, 0.0043, 0.0024, 0.0129, 0.0019]) \n",
      "Test Loss tensor([0.0077, 0.0082, 0.0038, 0.0030, 0.0044, 0.0025, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 208 in 0.9894223213195801 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0097, 0.0075, 0.0040, 0.0033, 0.0070, 0.0021, 0.0128, 0.0021]) \n",
      "Test Loss tensor([0.0083, 0.0090, 0.0042, 0.0029, 0.0042, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 212 in 0.9962997436523438 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0092, 0.0040, 0.0026, 0.0056, 0.0027, 0.0118, 0.0018]) \n",
      "Test Loss tensor([0.0090, 0.0092, 0.0040, 0.0029, 0.0042, 0.0029, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 216 in 0.7493107318878174 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0078, 0.0064, 0.0040, 0.0022, 0.0044, 0.0024, 0.0125, 0.0017]) \n",
      "Test Loss tensor([0.0085, 0.0086, 0.0042, 0.0030, 0.0040, 0.0026, 0.0137, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 220 in 0.7066354751586914 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0059, 0.0084, 0.0031, 0.0029, 0.0053, 0.0025, 0.0134, 0.0019]) \n",
      "Test Loss tensor([0.0086, 0.0088, 0.0039, 0.0029, 0.0046, 0.0029, 0.0128, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 224 in 0.683826208114624 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0079, 0.0073, 0.0035, 0.0031, 0.0048, 0.0023, 0.0131, 0.0018]) \n",
      "Test Loss tensor([0.0082, 0.0083, 0.0042, 0.0028, 0.0043, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 228 in 0.6466126441955566 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0085, 0.0045, 0.0029, 0.0057, 0.0021, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0078, 0.0042, 0.0029, 0.0046, 0.0025, 0.0127, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 232 in 0.6590070724487305 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0065, 0.0040, 0.0026, 0.0045, 0.0022, 0.0124, 0.0019]) \n",
      "Test Loss tensor([0.0085, 0.0083, 0.0041, 0.0029, 0.0039, 0.0027, 0.0130, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 236 in 0.6802682876586914 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0093, 0.0043, 0.0029, 0.0048, 0.0021, 0.0125, 0.0018]) \n",
      "Test Loss tensor([0.0081, 0.0081, 0.0038, 0.0028, 0.0039, 0.0027, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 240 in 0.6562473773956299 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0074, 0.0040, 0.0023, 0.0039, 0.0032, 0.0129, 0.0019]) \n",
      "Test Loss tensor([0.0088, 0.0087, 0.0038, 0.0029, 0.0042, 0.0027, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 244 in 0.6515331268310547 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0085, 0.0040, 0.0033, 0.0029, 0.0034, 0.0123, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0087, 0.0039, 0.0030, 0.0047, 0.0027, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 248 in 0.7715508937835693 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0072, 0.0071, 0.0043, 0.0029, 0.0052, 0.0028, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0086, 0.0040, 0.0030, 0.0042, 0.0026, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 252 in 0.7295899391174316 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0095, 0.0090, 0.0040, 0.0031, 0.0059, 0.0028, 0.0133, 0.0019]) \n",
      "Test Loss tensor([0.0087, 0.0087, 0.0041, 0.0030, 0.0046, 0.0026, 0.0133, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 256 in 0.834918737411499 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0091, 0.0036, 0.0033, 0.0044, 0.0030, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0083, 0.0086, 0.0040, 0.0028, 0.0045, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 260 in 0.9191422462463379 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0083, 0.0046, 0.0024, 0.0035, 0.0022, 0.0132, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0085, 0.0040, 0.0030, 0.0043, 0.0026, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 264 in 0.9775750637054443 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0060, 0.0073, 0.0040, 0.0031, 0.0046, 0.0027, 0.0119, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0084, 0.0040, 0.0029, 0.0043, 0.0026, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 268 in 0.8934752941131592 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0068, 0.0037, 0.0030, 0.0051, 0.0025, 0.0128, 0.0019]) \n",
      "Test Loss tensor([0.0085, 0.0081, 0.0038, 0.0029, 0.0039, 0.0026, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 272 in 0.82012939453125 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0090, 0.0078, 0.0048, 0.0033, 0.0042, 0.0025, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0088, 0.0041, 0.0028, 0.0042, 0.0025, 0.0129, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 276 in 0.8604340553283691 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0086, 0.0042, 0.0025, 0.0032, 0.0028, 0.0109, 0.0018]) \n",
      "Test Loss tensor([0.0088, 0.0081, 0.0041, 0.0029, 0.0044, 0.0025, 0.0124, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 280 in 0.8983564376831055 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0098, 0.0089, 0.0038, 0.0036, 0.0049, 0.0027, 0.0119, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0083, 0.0040, 0.0030, 0.0043, 0.0025, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 284 in 0.9143869876861572 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0116, 0.0071, 0.0039, 0.0036, 0.0056, 0.0024, 0.0128, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0086, 0.0042, 0.0027, 0.0036, 0.0023, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 288 in 0.8675105571746826 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0061, 0.0083, 0.0040, 0.0028, 0.0049, 0.0029, 0.0122, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0091, 0.0040, 0.0030, 0.0048, 0.0027, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 292 in 0.9979736804962158 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0079, 0.0075, 0.0039, 0.0029, 0.0033, 0.0024, 0.0126, 0.0021]) \n",
      "Test Loss tensor([0.0086, 0.0082, 0.0038, 0.0028, 0.0041, 0.0025, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 296 in 1.0884370803833008 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0091, 0.0095, 0.0041, 0.0025, 0.0064, 0.0024, 0.0136, 0.0022]) \n",
      "Test Loss tensor([0.0084, 0.0088, 0.0038, 0.0030, 0.0041, 0.0027, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 300 in 0.9856357574462891 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0075, 0.0027, 0.0027, 0.0040, 0.0027, 0.0118, 0.0018]) \n",
      "Test Loss tensor([0.0083, 0.0083, 0.0038, 0.0031, 0.0044, 0.0025, 0.0128, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 304 in 0.7701530456542969 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0069, 0.0041, 0.0027, 0.0065, 0.0026, 0.0108, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0083, 0.0039, 0.0028, 0.0039, 0.0026, 0.0122, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 308 in 0.7298986911773682 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0089, 0.0038, 0.0023, 0.0054, 0.0026, 0.0120, 0.0020]) \n",
      "Test Loss tensor([0.0086, 0.0083, 0.0042, 0.0028, 0.0043, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 312 in 0.771841287612915 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0075, 0.0036, 0.0032, 0.0045, 0.0023, 0.0121, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0084, 0.0039, 0.0028, 0.0040, 0.0026, 0.0123, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 316 in 0.7705914974212646 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0063, 0.0082, 0.0045, 0.0024, 0.0044, 0.0025, 0.0117, 0.0019]) \n",
      "Test Loss tensor([0.0082, 0.0080, 0.0037, 0.0028, 0.0040, 0.0026, 0.0127, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 320 in 0.6465668678283691 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0101, 0.0043, 0.0037, 0.0049, 0.0033, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0084, 0.0036, 0.0029, 0.0043, 0.0024, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 324 in 0.6497786045074463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0089, 0.0073, 0.0036, 0.0027, 0.0034, 0.0022, 0.0126, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0080, 0.0038, 0.0029, 0.0044, 0.0026, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 328 in 0.6449859142303467 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0078, 0.0036, 0.0031, 0.0063, 0.0025, 0.0111, 0.0019]) \n",
      "Test Loss tensor([0.0090, 0.0079, 0.0038, 0.0030, 0.0045, 0.0025, 0.0122, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 332 in 0.6467173099517822 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0068, 0.0039, 0.0029, 0.0058, 0.0023, 0.0127, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0078, 0.0038, 0.0030, 0.0042, 0.0026, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 336 in 0.6317276954650879 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0084, 0.0093, 0.0035, 0.0027, 0.0043, 0.0026, 0.0118, 0.0017]) \n",
      "Test Loss tensor([0.0080, 0.0080, 0.0039, 0.0029, 0.0040, 0.0027, 0.0124, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 340 in 0.6586744785308838 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0064, 0.0076, 0.0039, 0.0025, 0.0052, 0.0022, 0.0111, 0.0019]) \n",
      "Test Loss tensor([0.0079, 0.0085, 0.0037, 0.0028, 0.0046, 0.0027, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 344 in 0.694443941116333 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0081, 0.0044, 0.0028, 0.0052, 0.0028, 0.0120, 0.0018]) \n",
      "Test Loss tensor([0.0086, 0.0086, 0.0041, 0.0029, 0.0042, 0.0026, 0.0126, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 348 in 0.7302300930023193 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0099, 0.0088, 0.0051, 0.0032, 0.0047, 0.0026, 0.0127, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0080, 0.0041, 0.0031, 0.0054, 0.0026, 0.0122, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 352 in 0.7597968578338623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0070, 0.0085, 0.0033, 0.0024, 0.0044, 0.0024, 0.0116, 0.0018]) \n",
      "Test Loss tensor([0.0075, 0.0080, 0.0040, 0.0029, 0.0044, 0.0025, 0.0123, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 356 in 0.8644120693206787 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0105, 0.0066, 0.0040, 0.0029, 0.0043, 0.0024, 0.0126, 0.0019]) \n",
      "Test Loss tensor([0.0083, 0.0077, 0.0039, 0.0029, 0.0043, 0.0026, 0.0123, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 360 in 0.822634220123291 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0091, 0.0046, 0.0028, 0.0039, 0.0027, 0.0124, 0.0017]) \n",
      "Test Loss tensor([0.0081, 0.0079, 0.0041, 0.0029, 0.0046, 0.0025, 0.0124, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 364 in 0.7341816425323486 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0057, 0.0083, 0.0041, 0.0029, 0.0037, 0.0024, 0.0129, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0085, 0.0036, 0.0028, 0.0043, 0.0027, 0.0123, 0.0019])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 368 in 0.710437536239624 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0101, 0.0097, 0.0040, 0.0031, 0.0048, 0.0025, 0.0122, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0088, 0.0039, 0.0028, 0.0042, 0.0028, 0.0123, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 372 in 0.7312572002410889 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0070, 0.0039, 0.0029, 0.0048, 0.0024, 0.0122, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0086, 0.0044, 0.0028, 0.0044, 0.0025, 0.0129, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 376 in 0.6486151218414307 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0083, 0.0051, 0.0028, 0.0047, 0.0025, 0.0124, 0.0019]) \n",
      "Test Loss tensor([0.0089, 0.0086, 0.0040, 0.0029, 0.0042, 0.0025, 0.0125, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 380 in 0.6882579326629639 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0081, 0.0049, 0.0029, 0.0049, 0.0024, 0.0117, 0.0018]) \n",
      "Test Loss tensor([0.0082, 0.0084, 0.0041, 0.0027, 0.0049, 0.0026, 0.0126, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 384 in 0.6625494956970215 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0069, 0.0066, 0.0037, 0.0027, 0.0064, 0.0025, 0.0127, 0.0019]) \n",
      "Test Loss tensor([0.0079, 0.0080, 0.0039, 0.0030, 0.0038, 0.0027, 0.0122, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 388 in 0.7582323551177979 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0084, 0.0036, 0.0032, 0.0047, 0.0026, 0.0126, 0.0020]) \n",
      "Test Loss tensor([0.0088, 0.0085, 0.0040, 0.0029, 0.0040, 0.0025, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 392 in 0.7390224933624268 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0073, 0.0070, 0.0037, 0.0030, 0.0049, 0.0024, 0.0128, 0.0021]) \n",
      "Test Loss tensor([0.0081, 0.0082, 0.0042, 0.0031, 0.0044, 0.0025, 0.0124, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 396 in 0.8071110248565674 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0076, 0.0040, 0.0036, 0.0034, 0.0025, 0.0114, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0081, 0.0040, 0.0030, 0.0038, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 400 in 0.7886800765991211 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0070, 0.0082, 0.0036, 0.0026, 0.0052, 0.0024, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0077, 0.0085, 0.0040, 0.0030, 0.0042, 0.0024, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 404 in 0.7637696266174316 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0082, 0.0037, 0.0025, 0.0025, 0.0021, 0.0118, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0079, 0.0041, 0.0029, 0.0044, 0.0026, 0.0127, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 408 in 0.6225423812866211 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0082, 0.0034, 0.0033, 0.0036, 0.0022, 0.0114, 0.0018]) \n",
      "Test Loss tensor([0.0081, 0.0083, 0.0039, 0.0030, 0.0041, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 412 in 0.6453533172607422 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0080, 0.0076, 0.0045, 0.0027, 0.0038, 0.0026, 0.0120, 0.0019]) \n",
      "Test Loss tensor([0.0078, 0.0085, 0.0037, 0.0030, 0.0039, 0.0027, 0.0131, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 416 in 0.6924455165863037 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0095, 0.0033, 0.0033, 0.0048, 0.0023, 0.0126, 0.0021]) \n",
      "Test Loss tensor([0.0080, 0.0081, 0.0039, 0.0030, 0.0042, 0.0026, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 420 in 0.7029931545257568 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0103, 0.0075, 0.0039, 0.0031, 0.0041, 0.0022, 0.0114, 0.0020]) \n",
      "Test Loss tensor([0.0086, 0.0079, 0.0041, 0.0028, 0.0046, 0.0026, 0.0124, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 424 in 0.637082576751709 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0104, 0.0102, 0.0044, 0.0031, 0.0038, 0.0031, 0.0127, 0.0020]) \n",
      "Test Loss tensor([0.0085, 0.0079, 0.0040, 0.0030, 0.0045, 0.0026, 0.0122, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 428 in 0.6540839672088623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0086, 0.0039, 0.0026, 0.0039, 0.0028, 0.0120, 0.0019]) \n",
      "Test Loss tensor([0.0079, 0.0085, 0.0037, 0.0030, 0.0042, 0.0027, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 432 in 0.7041900157928467 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0087, 0.0085, 0.0036, 0.0024, 0.0052, 0.0028, 0.0138, 0.0019]) \n",
      "Test Loss tensor([0.0077, 0.0083, 0.0037, 0.0029, 0.0041, 0.0026, 0.0126, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 436 in 0.6933741569519043 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0084, 0.0034, 0.0032, 0.0040, 0.0022, 0.0119, 0.0017]) \n",
      "Test Loss tensor([0.0075, 0.0081, 0.0039, 0.0029, 0.0041, 0.0024, 0.0121, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 440 in 0.7005858421325684 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0088, 0.0071, 0.0048, 0.0036, 0.0050, 0.0030, 0.0120, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0084, 0.0039, 0.0030, 0.0043, 0.0029, 0.0128, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 444 in 0.6770367622375488 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0066, 0.0094, 0.0044, 0.0036, 0.0031, 0.0020, 0.0121, 0.0019]) \n",
      "Test Loss tensor([0.0086, 0.0084, 0.0039, 0.0027, 0.0046, 0.0027, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 448 in 0.6889681816101074 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0079, 0.0083, 0.0041, 0.0026, 0.0045, 0.0029, 0.0106, 0.0019]) \n",
      "Test Loss tensor([0.0078, 0.0080, 0.0038, 0.0028, 0.0044, 0.0026, 0.0125, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 452 in 0.6749467849731445 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0093, 0.0081, 0.0042, 0.0030, 0.0044, 0.0027, 0.0124, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0081, 0.0040, 0.0030, 0.0047, 0.0025, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 456 in 0.6732378005981445 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0072, 0.0070, 0.0034, 0.0033, 0.0044, 0.0026, 0.0128, 0.0021]) \n",
      "Test Loss tensor([0.0078, 0.0078, 0.0040, 0.0027, 0.0049, 0.0024, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 460 in 0.6575136184692383 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0071, 0.0033, 0.0026, 0.0040, 0.0023, 0.0125, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0082, 0.0039, 0.0028, 0.0043, 0.0025, 0.0122, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 464 in 0.7074594497680664 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0085, 0.0074, 0.0040, 0.0032, 0.0045, 0.0023, 0.0126, 0.0018]) \n",
      "Test Loss tensor([0.0078, 0.0082, 0.0036, 0.0030, 0.0041, 0.0027, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 468 in 0.7110579013824463 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0056, 0.0079, 0.0037, 0.0028, 0.0036, 0.0027, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0082, 0.0039, 0.0031, 0.0044, 0.0026, 0.0120, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 472 in 0.8104829788208008 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0074, 0.0084, 0.0036, 0.0027, 0.0036, 0.0027, 0.0118, 0.0018]) \n",
      "Test Loss tensor([0.0076, 0.0082, 0.0040, 0.0027, 0.0044, 0.0026, 0.0125, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 476 in 0.8864374160766602 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0077, 0.0080, 0.0042, 0.0030, 0.0033, 0.0020, 0.0113, 0.0020]) \n",
      "Test Loss tensor([0.0077, 0.0080, 0.0041, 0.0029, 0.0045, 0.0025, 0.0123, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 480 in 0.6750173568725586 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0068, 0.0083, 0.0034, 0.0031, 0.0060, 0.0026, 0.0137, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0083, 0.0043, 0.0027, 0.0043, 0.0027, 0.0125, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 484 in 0.6702213287353516 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0089, 0.0048, 0.0022, 0.0039, 0.0022, 0.0123, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0075, 0.0037, 0.0029, 0.0047, 0.0025, 0.0120, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 488 in 0.9195859432220459 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0062, 0.0077, 0.0031, 0.0037, 0.0055, 0.0021, 0.0127, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0079, 0.0042, 0.0030, 0.0047, 0.0026, 0.0125, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 492 in 0.7935681343078613 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0065, 0.0079, 0.0044, 0.0025, 0.0054, 0.0020, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0085, 0.0082, 0.0041, 0.0028, 0.0048, 0.0026, 0.0123, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 496 in 0.7530879974365234 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0075, 0.0080, 0.0045, 0.0026, 0.0043, 0.0021, 0.0122, 0.0018]) \n",
      "Test Loss tensor([0.0078, 0.0078, 0.0041, 0.0028, 0.0044, 0.0026, 0.0123, 0.0018])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 500 in 0.6263623237609863 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0096, 0.0078, 0.0039, 0.0028, 0.0055, 0.0024, 0.0117, 0.0018]) \n",
      "Test Loss tensor([0.0089, 0.0083, 0.0039, 0.0031, 0.0044, 0.0025, 0.0126, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 504 in 0.642627477645874 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0070, 0.0090, 0.0050, 0.0036, 0.0058, 0.0022, 0.0124, 0.0019]) \n",
      "Test Loss tensor([0.0080, 0.0083, 0.0041, 0.0030, 0.0041, 0.0025, 0.0122, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 508 in 0.7397828102111816 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0069, 0.0039, 0.0027, 0.0037, 0.0025, 0.0112, 0.0019]) \n",
      "Test Loss tensor([0.0083, 0.0088, 0.0039, 0.0029, 0.0039, 0.0026, 0.0127, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 512 in 0.7227902412414551 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0060, 0.0102, 0.0038, 0.0030, 0.0052, 0.0024, 0.0120, 0.0018]) \n",
      "Test Loss tensor([0.0080, 0.0082, 0.0038, 0.0030, 0.0046, 0.0026, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 516 in 0.6851944923400879 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0059, 0.0096, 0.0044, 0.0028, 0.0047, 0.0022, 0.0128, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0083, 0.0038, 0.0029, 0.0045, 0.0027, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 520 in 0.7091403007507324 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0102, 0.0034, 0.0029, 0.0040, 0.0023, 0.0118, 0.0018]) \n",
      "Test Loss tensor([0.0084, 0.0082, 0.0039, 0.0028, 0.0044, 0.0024, 0.0123, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 524 in 0.7146291732788086 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0081, 0.0084, 0.0043, 0.0030, 0.0047, 0.0027, 0.0123, 0.0017]) \n",
      "Test Loss tensor([0.0085, 0.0076, 0.0038, 0.0028, 0.0045, 0.0026, 0.0122, 0.0018])\n",
      "\n",
      "\n",
      "************** Batch 528 in 0.7043309211730957 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0092, 0.0078, 0.0037, 0.0037, 0.0050, 0.0031, 0.0125, 0.0018]) \n",
      "Test Loss tensor([0.0079, 0.0082, 0.0037, 0.0030, 0.0041, 0.0026, 0.0117, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 532 in 0.7907743453979492 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0094, 0.0077, 0.0046, 0.0024, 0.0049, 0.0026, 0.0114, 0.0018]) \n",
      "Test Loss tensor([0.0081, 0.0080, 0.0039, 0.0028, 0.0041, 0.0025, 0.0121, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 536 in 0.6905503273010254 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0083, 0.0036, 0.0026, 0.0043, 0.0027, 0.0121, 0.0018]) \n",
      "Test Loss tensor([0.0077, 0.0070, 0.0040, 0.0029, 0.0041, 0.0024, 0.0119, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 540 in 0.7111735343933105 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0071, 0.0080, 0.0033, 0.0023, 0.0041, 0.0019, 0.0123, 0.0017]) \n",
      "Test Loss tensor([0.0081, 0.0079, 0.0039, 0.0028, 0.0042, 0.0024, 0.0122, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 544 in 0.6623783111572266 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0086, 0.0080, 0.0048, 0.0024, 0.0056, 0.0030, 0.0114, 0.0018]) \n",
      "Test Loss tensor([0.0078, 0.0084, 0.0041, 0.0030, 0.0045, 0.0026, 0.0120, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 548 in 0.7473535537719727 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0082, 0.0082, 0.0034, 0.0030, 0.0062, 0.0024, 0.0114, 0.0019]) \n",
      "Test Loss tensor([0.0077, 0.0077, 0.0041, 0.0028, 0.0045, 0.0023, 0.0119, 0.0019])\n",
      "\n",
      "\n",
      "************** Batch 552 in 0.6853339672088623 **************\n",
      "\n",
      "Training Idx 6 \n",
      "Train Loss tensor([0.0076, 0.0089, 0.0047, 0.0030, 0.0042, 0.0031, 0.0136, 0.0017]) \n",
      "Test Loss tensor([0.0086, 0.0078, 0.0041, 0.0028, 0.0042, 0.0024, 0.0120, 0.0019])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ac85611aee6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mtestLosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a5ec9ccb498e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, state)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithInputNetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmessagePassingIteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumMessagePassingIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mapply_nodes\u001b[0;34m(self, func, v, ntype, inplace)\u001b[0m\n\u001b[1;32m   4015\u001b[0m         \u001b[0mntype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4017\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4018\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ntype)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"\"\"Return the nodes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mntid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typeid_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         return F.copy_to(F.arange(0, self._graph._graph.number_of_nodes(ntid),\n\u001b[0m\u001b[1;32m     44\u001b[0m                                   dtype=self._graph.idtype),\n\u001b[1;32m     45\u001b[0m                          self._graph.device)\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_to\u001b[0;34m(input, ctx, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "validLosses = {}\n",
    "trainingIdxs = []\n",
    "validationIdxs = []\n",
    "\n",
    "inputNetworkGradients = []\n",
    "messageNetworkGradients = []\n",
    "updateNetworkGradients = []\n",
    "outputNetworkGradients = []\n",
    "\n",
    "\n",
    "for morphIdx in range(7):\n",
    "    trainLosses[morphIdx] = []\n",
    "    testLosses[morphIdx] = []\n",
    "    validLosses[morphIdx] = []\n",
    "\n",
    "for index in [1, 2, 3, 4, 5, 6]:\n",
    "    \n",
    "    inputNetwork = Network(inputSize, stateSize, hidden_sizes, batch_size, with_batch_norm)\n",
    "    messageNetwork = Network(stateSize + 1, messageSize, hidden_sizes, batch_size, with_batch_norm, nn.Tanh)\n",
    "    updateNetwork = Network(stateSize + messageSize, stateSize, hidden_sizes, batch_size, with_batch_norm)\n",
    "    outputNetwork = Network(stateSize, outputSize, hidden_sizes, batch_size, with_batch_norm, nn.Tanh)\n",
    "\n",
    "    gnn = GraphNeuralNetwork(inputNetwork, messageNetwork, updateNetwork, outputNetwork, numMessagePassingIterations).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(itertools.chain(inputNetwork.parameters(), messageNetwork.parameters(), updateNetwork.parameters(), outputNetwork.parameters())\n",
    "                           , lr, weight_decay=1e-5)\n",
    "    \n",
    "    trainingIdxs = [index]\n",
    "    \n",
    "    for epoch in range(10):\n",
    "\n",
    "        for morphIdx in trainingIdxs:\n",
    "            permutation = np.random.permutation(X_train[morphIdx].shape[0])\n",
    "            X_train[morphIdx] = X_train[morphIdx][permutation]\n",
    "            Y_train[morphIdx] = Y_train[morphIdx][permutation]\n",
    "\n",
    "        stepLoss = None\n",
    "        graphs = []\n",
    "        numAggregatedBatches = 0\n",
    "\n",
    "        for batch in range(0, numTrainingBatches, numBatchesPerTrainingStep):\n",
    "\n",
    "            inputNetwork.train()\n",
    "            messageNetwork.train()\n",
    "            updateNetwork.train()\n",
    "            outputNetwork.train()\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            for morphIdx in trainingIdxs:\n",
    "                numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "                trainLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "\n",
    "            for batchOffset in range(numBatchesPerTrainingStep):\n",
    "\n",
    "                if batch + batchOffset >= numTrainingBatches:\n",
    "                    break\n",
    "\n",
    "                for morphIdx in trainingIdxs:\n",
    "                    graphs.append(env[morphIdx].get_graph()._get_dgl_graph())\n",
    "                    x = X_train[morphIdx][(batch+batchOffset) * batch_size:(batch+batchOffset+1)*batch_size].to(device)\n",
    "                    y = Y_train[morphIdx][(batch+batchOffset) * batch_size:(batch+batchOffset+1)*batch_size].to(device)\n",
    "\n",
    "                    y_hat = gnn.forward(graphs[-1], x)\n",
    "\n",
    "                    loss_tmp = criterion(y, y_hat).mean(dim=0)\n",
    "\n",
    "                    trainLosses[morphIdx][-1] += loss_tmp.cpu().detach() / numBatchesPerTrainingStep\n",
    "\n",
    "                    if stepLoss is None:\n",
    "                        stepLoss = loss_tmp.mean()\n",
    "\n",
    "                    else:\n",
    "                        stepLoss += loss_tmp.mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            stepLoss.backward()\n",
    "\n",
    "\n",
    "            s = 0\n",
    "            for parameter in inputNetwork.parameters():\n",
    "                s += torch.abs(parameter.grad).mean()\n",
    "            inputNetworkGradients.append(s.item())\n",
    "\n",
    "            s = 0\n",
    "            for parameter in messageNetwork.parameters():\n",
    "                s += torch.abs(parameter.grad).mean()\n",
    "            messageNetworkGradients.append(s.item())\n",
    "\n",
    "            s = 0        \n",
    "            for parameter in updateNetwork.parameters():\n",
    "                s += torch.abs(parameter.grad).mean()\n",
    "            updateNetworkGradients.append(s.item())\n",
    "\n",
    "            s = 0        \n",
    "            for parameter in outputNetwork.parameters():\n",
    "                s += torch.abs(parameter.grad).mean()\n",
    "            outputNetworkGradients.append(s.item())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            stepLoss = None\n",
    "            graphs = []\n",
    "\n",
    "            inputNetwork.eval()\n",
    "            messageNetwork.eval()\n",
    "            updateNetwork.eval()\n",
    "            outputNetwork.eval()\n",
    "\n",
    "            numBatchesForExectution = 50\n",
    "            for morphIdx in trainingIdxs:\n",
    "                numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "                testLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "                for batch_ in np.random.choice(np.arange(numTestingBatches-1), numBatchesForExectution):\n",
    "                    g = env[morphIdx].get_graph()._get_dgl_graph()\n",
    "                    x = X_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                    y = Y_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                    y_hat = gnn.forward(g, x)\n",
    "                    loss = criterion(y, y_hat).mean(dim=0)\n",
    "                    testLosses[morphIdx][-1] += loss.cpu().detach()\n",
    "                testLosses[morphIdx][-1] /= numBatchesForExectution\n",
    "\n",
    "            for morphIdx in validationIdxs:\n",
    "                numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "                validLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "                for batch_ in np.random.choice(np.arange(numTestingBatches-1), numBatchesForExectution):\n",
    "\n",
    "                    g = env[morphIdx].get_graph()._get_dgl_graph()\n",
    "                    x = X_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                    y = Y_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "\n",
    "                    y_hat = gnn.forward(g, x)\n",
    "                    loss = criterion(y, y_hat).mean(dim=0)\n",
    "\n",
    "                    validLosses[morphIdx][-1] += loss.cpu().detach()\n",
    "                validLosses[morphIdx][-1] /= numBatchesForExectution\n",
    "\n",
    "            print('\\n************** Batch {} in {} **************\\n'.format(batch, time.time() - t0))\n",
    "            for morphIdx in trainingIdxs:\n",
    "                print('Training Idx {} \\nTrain Loss {} \\nTest Loss {}\\n'.format(morphIdx, trainLosses[morphIdx][-1], testLosses[morphIdx][-1]))\n",
    "            for morphIdx in validationIdxs:\n",
    "                print('Valid Idx {} | Loss {}'.format(morphIdx, validLosses[morphIdx][-1]))\n",
    "                \n",
    "    lossArr = torch.stack(testLosses[index]).T\n",
    "    fig, ax = plt.subplots(1, sharex=True)\n",
    "    for i in range(lossArr.shape[0]):\n",
    "        ax.plot(range(lossArr.shape[1]), torch.log10(lossArr[i]))\n",
    "    plt.legend(range(lossArr.shape[0]))\n",
    "    plt.xlabel('Training Step')\n",
    "    plt.grid()\n",
    "    plt.ylabel('Smooth L1 Loss')\n",
    "    plt.title('Per Node Loss Morphology {}'.format(index))\n",
    "    plt.savefig('per-node-loss-{}.jpg'.format(morphIdx))\n",
    "    plt.show()\n",
    "\n",
    "#             if batch % 20 ==0:\n",
    "#                 print('Gradients: Input {} | Message {} | Update {} | Output {}'.format(\n",
    "#                     inputNetworkGradients[-1], messageNetworkGradients[-1], updateNetworkGradients[-1], outputNetworkGradients[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Batch 0 in 0.5357680320739746 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0168, 0.0028, 0.0044, 0.0249, 0.0152, 0.0075]) \n",
      "Test Loss tensor([0.0138, 0.0028, 0.0051, 0.0222, 0.0151, 0.0088])\n",
      "\n",
      "Gradients: Input 0.09093064069747925 | Message 0.0723920464515686 | Update 0.10797195136547089 | Output 0.013019801117479801\n",
      "\n",
      "************** Batch 4 in 0.5407388210296631 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0134, 0.0035, 0.0052, 0.0223, 0.0142, 0.0085]) \n",
      "Test Loss tensor([0.0137, 0.0029, 0.0051, 0.0226, 0.0153, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 8 in 0.5462749004364014 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0139, 0.0026, 0.0041, 0.0205, 0.0149, 0.0069]) \n",
      "Test Loss tensor([0.0138, 0.0029, 0.0052, 0.0219, 0.0154, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 12 in 0.583775520324707 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0149, 0.0027, 0.0049, 0.0236, 0.0147, 0.0079]) \n",
      "Test Loss tensor([0.0134, 0.0031, 0.0052, 0.0223, 0.0157, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 16 in 0.52911376953125 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0151, 0.0033, 0.0044, 0.0232, 0.0162, 0.0101]) \n",
      "Test Loss tensor([0.0136, 0.0030, 0.0050, 0.0219, 0.0156, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 20 in 0.5395047664642334 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0149, 0.0031, 0.0049, 0.0247, 0.0155, 0.0078]) \n",
      "Test Loss tensor([0.0136, 0.0030, 0.0050, 0.0218, 0.0154, 0.0087])\n",
      "\n",
      "Gradients: Input 0.046766191720962524 | Message 0.034481123089790344 | Update 0.05236717313528061 | Output 0.006140363402664661\n",
      "\n",
      "************** Batch 24 in 0.50681471824646 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0142, 0.0034, 0.0048, 0.0211, 0.0154, 0.0092]) \n",
      "Test Loss tensor([0.0134, 0.0032, 0.0052, 0.0214, 0.0156, 0.0087])\n",
      "\n",
      "\n",
      "************** Batch 28 in 0.511594295501709 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0152, 0.0027, 0.0052, 0.0230, 0.0147, 0.0069]) \n",
      "Test Loss tensor([0.0137, 0.0031, 0.0052, 0.0218, 0.0148, 0.0089])\n",
      "\n",
      "\n",
      "************** Batch 32 in 0.5782902240753174 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0125, 0.0026, 0.0041, 0.0242, 0.0128, 0.0100]) \n",
      "Test Loss tensor([0.0134, 0.0033, 0.0051, 0.0216, 0.0152, 0.0088])\n",
      "\n",
      "\n",
      "************** Batch 36 in 0.5342671871185303 **************\n",
      "\n",
      "Training Idx 0 \n",
      "Train Loss tensor([0.0123, 0.0029, 0.0046, 0.0204, 0.0170, 0.0075]) \n",
      "Test Loss tensor([0.0127, 0.0030, 0.0050, 0.0220, 0.0158, 0.0093])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4a860ba61091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtestLosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a5ec9ccb498e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, state)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmessagePassingIteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumMessagePassingIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessageFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm_hat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4498\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4499\u001b[0;31m         \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4500\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_gspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsgdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_gspmm\u001b[0;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_field\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_field\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/ops/spmm.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(g, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'copy_lhs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'copy_rhs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/ops/spmm.py\u001b[0m in \u001b[0;36mgspmm\u001b[0;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mrhs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_rhs_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# With max and min reducers infinity will be returned for zero degree nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     ret = gspmm_internal(g._graph, op,\n\u001b[0m\u001b[1;32m     63\u001b[0m                          \u001b[0;34m'sum'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduce_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                          lhs_data, rhs_data)\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py\u001b[0m in \u001b[0;36mgspmm\u001b[0;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGSpMM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/sparse.py\u001b[0m in \u001b[0;36m_gspmm\u001b[0;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_etypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"We only support gspmm on graph with one edge type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0muse_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'copy_rhs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mnumber_of_etypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumber_of_etypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;34m\"\"\"Return number of edge types.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_relation_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mmetagraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroGetMetaGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumber_of_ntypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.make_ret\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./object.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.make_ret_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/honors-project/lib/python3.8/site-packages/dgl/graph_index.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_coo\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# python-side cache of the flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "validLosses = {}\n",
    "trainingIdxs = [0]\n",
    "validationIdxs = []\n",
    "\n",
    "inputNetworkGradients = []\n",
    "messageNetworkGradients = []\n",
    "updateNetworkGradients = []\n",
    "outputNetworkGradients = []\n",
    "\n",
    "\n",
    "for morphIdx in range(7):\n",
    "    trainLosses[morphIdx] = []\n",
    "    testLosses[morphIdx] = []\n",
    "    validLosses[morphIdx] = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    \n",
    "    for morphIdx in trainingIdxs:\n",
    "        permutation = np.random.permutation(X_train[morphIdx].shape[0])\n",
    "        X_train[morphIdx] = X_train[morphIdx][permutation]\n",
    "        Y_train[morphIdx] = Y_train[morphIdx][permutation]\n",
    "        \n",
    "    stepLoss = None\n",
    "    graphs = []\n",
    "    numAggregatedBatches = 0\n",
    "\n",
    "    for batch in range(0, numTrainingBatches, numBatchesPerTrainingStep):\n",
    "        \n",
    "        inputNetwork.train()\n",
    "        messageNetwork.train()\n",
    "        updateNetwork.train()\n",
    "        outputNetwork.train()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        for morphIdx in trainingIdxs:\n",
    "            numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "            trainLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "\n",
    "        for batchOffset in range(numBatchesPerTrainingStep):\n",
    "            \n",
    "            if batch + batchOffset >= numTrainingBatches:\n",
    "                break\n",
    "                \n",
    "            for morphIdx in trainingIdxs:\n",
    "                graphs.append(env[morphIdx].get_graph()._get_dgl_graph())\n",
    "                x = X_train[morphIdx][(batch+batchOffset) * batch_size:(batch+batchOffset+1)*batch_size].to(device)\n",
    "                y = Y_train[morphIdx][(batch+batchOffset) * batch_size:(batch+batchOffset+1)*batch_size].to(device)\n",
    "\n",
    "                y_hat = gnn.forward(graphs[-1], x)\n",
    "\n",
    "                loss_tmp = criterion(y, y_hat).mean(dim=0)\n",
    "\n",
    "                trainLosses[morphIdx][-1] += loss_tmp.cpu().detach() / numBatchesPerTrainingStep\n",
    "\n",
    "                if stepLoss is None:\n",
    "                    stepLoss = loss_tmp.mean()\n",
    "\n",
    "                else:\n",
    "                    stepLoss += loss_tmp.mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        stepLoss.backward()\n",
    "        \n",
    "        \n",
    "        s = 0\n",
    "        for parameter in inputNetwork.parameters():\n",
    "            s += torch.abs(parameter.grad).mean()\n",
    "        inputNetworkGradients.append(s.item())\n",
    "\n",
    "        s = 0\n",
    "        for parameter in messageNetwork.parameters():\n",
    "            s += torch.abs(parameter.grad).mean()\n",
    "        messageNetworkGradients.append(s.item())\n",
    "\n",
    "        s = 0        \n",
    "        for parameter in updateNetwork.parameters():\n",
    "            s += torch.abs(parameter.grad).mean()\n",
    "        updateNetworkGradients.append(s.item())\n",
    "\n",
    "        s = 0        \n",
    "        for parameter in outputNetwork.parameters():\n",
    "            s += torch.abs(parameter.grad).mean()\n",
    "        outputNetworkGradients.append(s.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        stepLoss = None\n",
    "        graphs = []\n",
    "        \n",
    "        inputNetwork.eval()\n",
    "        messageNetwork.eval()\n",
    "        updateNetwork.eval()\n",
    "        outputNetwork.eval()\n",
    "\n",
    "        numBatchesForExectution = 50\n",
    "        for morphIdx in trainingIdxs:\n",
    "            numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "            testLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "            for batch_ in np.random.choice(np.arange(numTestingBatches-1), numBatchesForExectution):\n",
    "                g = env[morphIdx].get_graph()._get_dgl_graph()\n",
    "                x = X_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                y = Y_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                y_hat = gnn.forward(g, x)\n",
    "                loss = criterion(y, y_hat).mean(dim=0)\n",
    "                testLosses[morphIdx][-1] += loss.cpu().detach()\n",
    "            testLosses[morphIdx][-1] /= numBatchesForExectution\n",
    "        \n",
    "        for morphIdx in validationIdxs:\n",
    "            numNodes = (X_train[morphIdx].shape[1] // 2 - 5) // 2\n",
    "            validLosses[morphIdx].append(torch.zeros(numNodes))\n",
    "            for batch_ in np.random.choice(np.arange(numTestingBatches-1), numBatchesForExectution):\n",
    "\n",
    "                g = env[morphIdx].get_graph()._get_dgl_graph()\n",
    "                x = X_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "                y = Y_test[morphIdx][batch_ * batch_size:(batch_+1)*batch_size].to(device)\n",
    "\n",
    "                y_hat = gnn.forward(g, x)\n",
    "                loss = criterion(y, y_hat).mean(dim=0)\n",
    "\n",
    "                validLosses[morphIdx][-1] += loss.cpu().detach()\n",
    "            validLosses[morphIdx][-1] /= numBatchesForExectution\n",
    "\n",
    "        print('\\n************** Batch {} in {} **************\\n'.format(batch, time.time() - t0))\n",
    "        for morphIdx in trainingIdxs:\n",
    "            print('Training Idx {} \\nTrain Loss {} \\nTest Loss {}\\n'.format(morphIdx, trainLosses[morphIdx][-1], testLosses[morphIdx][-1]))\n",
    "        for morphIdx in validationIdxs:\n",
    "            print('Valid Idx {} | Loss {}'.format(morphIdx, validLosses[morphIdx][-1]))\n",
    "            \n",
    "        if batch % 20 ==0:\n",
    "            print('Gradients: Input {} | Message {} | Update {} | Output {}'.format(\n",
    "                inputNetworkGradients[-1], messageNetworkGradients[-1], updateNetworkGradients[-1], outputNetworkGradients[-1]))    \n",
    "#         if batch % 100 == 99:\n",
    "#             lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "morphIdx = 0\n",
    "lossArr = torch.stack(testLosses[morphIdx]).T\n",
    "fig, ax = plt.subplots(1, sharex=True)\n",
    "for i in range(lossArr.shape[0]):\n",
    "    ax.plot(range(lossArr.shape[1]), torch.log10(lossArr[i]))\n",
    "plt.legend(range(lossArr.shape[0]))\n",
    "plt.xlabel('Training Step')\n",
    "plt.grid()\n",
    "plt.ylabel('Smooth L1 Loss')\n",
    "plt.title('Per Node Loss Morphology {}, Train = {}'.format(morphIdx, morphIdx in trainingIdxs))\n",
    "plt.savefig('per-node-loss-{}.jpg'.format(morphIdx))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainigIdxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b47ad76e4004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorphIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmorphIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainigIdxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlossArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorphIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainigIdxs' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell for producing Per Node Loss for each Morphology\n",
    "\n",
    "for morphIdx in range(7):\n",
    "    if morphIdx in trainigIdxs:\n",
    "        lossArr = torch.stack(testLosses[morphIdx]).T\n",
    "    else:\n",
    "        lossArr = torch.stack(validLosses[morphIdx]).T\n",
    "    \n",
    "    fig, ax = plt.subplots(1, sharex=True)\n",
    "    for i in range(lossArr.shape[0]):\n",
    "        ax.plot(range(lossArr.shape[1]), lossArr[i])\n",
    "    plt.legend(range(lossArr.shape[0]))\n",
    "    plt.xlabel('Training Step')\n",
    "    plt.grid()\n",
    "    plt.ylabel('Smooth L1 Loss')\n",
    "    plt.title('Per Node Loss Morphology {}, Train = {}'.format(morphIdx, morphIdx in trainingIdxs))\n",
    "    plt.savefig('per-node-loss-{}.jpg'.format(morphIdx))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, sharex=True)\n",
    "for morphIdx in trainingIdxs:\n",
    "    lossArr = torch.stack(testLosses[morphIdx]).mean(dim=1)\n",
    "    ax.plot(range(lossArr.shape[0]), lossArr)\n",
    "for morphIdx in validationIdxs:\n",
    "    lossArr = torch.stack(validLosses[morphIdx]).mean(dim=1)\n",
    "    ax.plot(range(lossArr.shape[0]), lossArr)\n",
    "\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Smooth L1 Loss')\n",
    "plt.title('Mean Node Loss per Morphology')\n",
    "plt.legend(trainingIdxs + validationIdxs)\n",
    "plt.savefig('mean-node-losses.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, sharex=True)\n",
    "ax.plot(range(len(inputNetworkGradients)), np.log10(inputNetworkGradients))\n",
    "ax.plot(range(len(messageNetworkGradients)), np.log10(messageNetworkGradients))\n",
    "ax.plot(range(len(updateNetworkGradients)), np.log10(updateNetworkGradients))\n",
    "ax.plot(range(len(outputNetworkGradients)), np.log10(outputNetworkGradients))\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Mean Absolute Gradient (Log 10)')\n",
    "plt.title('Gradient Magnitudes Over Time')\n",
    "plt.legend(['Input Network', 'Message Network', 'Update Network', ' Output Network'])\n",
    "plt.savefig('gradients.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../models/mix/'\n",
    "\n",
    "testLossesArr = np.array(testLosses)\n",
    "trainLossesArr = np.array(trainLosses)\n",
    "validLossesArr = np.array(validLosses)\n",
    "learningRatesArr = np.array(learningRates)\n",
    "\n",
    "np.save(prefix + 'testLosses', testLossesArr)\n",
    "np.save(prefix + 'trainLosses', trainLossesArr)\n",
    "np.save(prefix + 'validLosses', validLossesArr)\n",
    "np.save(prefix + 'learningRates', learningRatesArr)\n",
    "\n",
    "# torch.save(inputNetwork, prefix + 'inputNetwork.pt')\n",
    "# torch.save(outputNetwork, prefix + 'outputNetwork.pt')\n",
    "# torch.save(messageNetwork, prefix + 'messageNetwork.pt')\n",
    "# torch.save(updateNetwork, prefix + 'updateNetwork.pt')\n",
    "\n",
    "fig, ax = plt.subplots(1, sharex=True)\n",
    "ax.plot(range(len(testLossesArr)), testLossesArr)\n",
    "ax.plot(range(len(trainLossesArr)), trainLossesArr, 'b')\n",
    "ax.plot(range(len(validLossesArr)), validLossesArr)\n",
    "ax.set(ylabel='Smooth L1 Loss')\n",
    "# ax[1].plot(range(len(learningRates)), learningRatesArr)\n",
    "# ax[1].set(ylabel='Learning Rate')\n",
    "ax.legend([\"Testing\", \"Training\", \"Valid\"])\n",
    "plt.xlabel('Batch')\n",
    "plt.savefig(prefix + 'valid-0.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../models/mix/'\n",
    "\n",
    "inputNetwork = torch.load(prefix + 'inputNetwork.pt')\n",
    "messageNetwork = torch.load(prefix + 'messageNetwork.pt')\n",
    "updateNetwork = torch.load(prefix + 'updateNetwork.pt')\n",
    "outputNetwork = torch.load(prefix + 'outputNetwork.pt')\n",
    "\n",
    "gnn = GraphNeuralNetwork(inputNetwork, messageNetwork, updateNetwork, outputNetwork, numMessagePassingIterations=3).to(device)\n",
    "\n",
    "testLoss = 0\n",
    "for morphIdx in [0]:\n",
    "    \n",
    "    for batch in range(numTestingBatches):\n",
    "\n",
    "        g = env[morphIdx].get_graph()._get_dgl_graph()\n",
    "        x = X_test[morphIdx][batch * batch_size:(batch+1)*batch_size].to(device)\n",
    "        y = Y_test[morphIdx][batch * batch_size:(batch+1)*batch_size].to(device)\n",
    "\n",
    "        y_hat = gnn.forward(g, x)\n",
    "        loss = criterion(y, y_hat)\n",
    "        testLoss += loss.item()\n",
    "        \n",
    "print(testLoss / X_test[morphIdx].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
