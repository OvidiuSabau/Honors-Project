{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import torch.autograd\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pybullet as p \n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pybullet \n",
    "import pybullet_envs.gym_pendulum_envs \n",
    "import pybullet_envs.gym_locomotion_envs\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "import networkx as nx\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "prefix = '../datasets/doubleInvertedPendulum'\n",
    "statesDoubleInverted = np.load(prefix + 'Dataset/states_array.npy')[:1000]\n",
    "prefix = '../datasets/invertedPendulum'\n",
    "statesSingleInverted = np.load(prefix + 'Dataset/states_array.npy')[:1000]\n",
    "print(statesDoubleInverted.shape)\n",
    "print(statesSingleInverted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = torch.tensor([0, 1]).to(device), torch.tensor([1, 0]).to(device)\n",
    "g = dgl.graph((u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since the actual graph is undirected, we convert it for visualization\n",
    "# purpose.\n",
    "nx_g = g.cpu().to_networkx().to_undirected()\n",
    "# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
    "pos = nx.kamada_kawai_layout(nx_g)\n",
    "nx.draw(nx_g, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_states_in_graph(state, graph):\n",
    "    \n",
    "    if len(state.shape) == 1:\n",
    "        state = state[np.newaxis, ...]\n",
    "    \n",
    "    firstNode = state[:, 0:6][np.newaxis, ...]\n",
    "    secondNode = np.concatenate((state[:, 0:3], state[:, 6:]), -1)[np.newaxis, ...]\n",
    "    nodeData = torch.tensor(np.concatenate((firstNode, secondNode), 0), dtype=torch.float32).to(device)\n",
    "    graph.ndata['state'] = nodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        hidden_sizes\n",
    "    ):\n",
    "        super(Network, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(self.input_size, hidden_sizes[0]))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_sizes[len(hidden_sizes) - 1], self.output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messageNetwork = Network(6, 10, [16, 32, 16]).to(device)\n",
    "updateNetwork = Network(16, 6, [16, 32, 16]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMessage(edges):\n",
    "    return {'m' : messageNetwork(edges.src['state'])}\n",
    "\n",
    "def updateFunction(nodes):\n",
    "    return {'state': updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.update_all(computeMessage, dgl.function.max('m', 'm_hat'), updateFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_states_in_graph(statesDoubleInverted, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000, 6])\n"
     ]
    }
   ],
   "source": [
    "print(g.nodes[0].data['state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphNeuralNetwork():\n",
    "    def __init__(\n",
    "        graph,\n",
    "        messageNetwork,\n",
    "        updateNetwork\n",
    "    ):\n",
    "        self.graph = dgl.graph()\n",
    "        self.messageNetwork = messageNetwork\n",
    "        self.updateNetwork = updateNetwork\n",
    "    \n",
    "    def messageFunction(self, edges):\n",
    "        return {'m' : self.messageNetwork(edges.src['state'])}\n",
    "    \n",
    "    def updateFunction(self, nodes):\n",
    "        return {'state': self.updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}\n",
    "    \n",
    "    def forward(self, state):\n",
    "        self.update_states_in_graph(state)\n",
    "        \n",
    "        self.graph.update_all(self.sendMessage, dgl.function.max('m', 'm_hat'), updateFunction)\n",
    "        \n",
    "    def update_states_in_graph(self, state):\n",
    "        if len(state.shape) == 1:\n",
    "            state = state[np.newaxis, ...]\n",
    "\n",
    "        firstNode = state[:, 0:6][np.newaxis, ...]\n",
    "        secondNode = np.concatenate((state[:, 0:3], state[:, 6:]), -1)[np.newaxis, ...]\n",
    "        nodeData = torch.tensor(np.concatenate((firstNode, secondNode), 0), dtype=torch.float32).to(device)\n",
    "        self.graph.ndata['state'] = nodeData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
