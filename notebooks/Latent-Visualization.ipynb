{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import torch.autograd\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pybullet as p \n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "#     print(\"Running on the GPU\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"Running on the CPU\")\n",
    "device = torch.device(\"cpu\")\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import dgl\n",
    "import morphsim as m\n",
    "from graphenvs import HalfCheetahGraphEnv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        hidden_sizes,\n",
    "        batch_size=256, # Needed only for batch norm\n",
    "        with_batch_norm=False,\n",
    "        activation=None\n",
    "    ):\n",
    "        super(Network, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Linear(self.input_size, hidden_sizes[0]))\n",
    "        if with_batch_norm:\n",
    "#             self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "            self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[0])))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            if with_batch_norm:\n",
    "#                 self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "                self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[i+1])))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_sizes[len(hidden_sizes) - 1], self.output_size))\n",
    "        \n",
    "        if activation is not None:\n",
    "            self.layers.append(activation())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputNetwork,\n",
    "        messageNetwork,\n",
    "        updateNetwork,\n",
    "        outputNetwork,\n",
    "        numMessagePassingIterations,\n",
    "        encoder = True\n",
    "    ):\n",
    "        \n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "                \n",
    "        self.inputNetwork = inputNetwork\n",
    "        self.messageNetwork = messageNetwork\n",
    "        self.updateNetwork = updateNetwork\n",
    "        self.outputNetwork = outputNetwork\n",
    "        \n",
    "        self.numMessagePassingIterations = numMessagePassingIterations\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def inputFunction(self, nodes):\n",
    "        return {'state' : self.inputNetwork(nodes.data['input'])}\n",
    "    \n",
    "    def messageFunction(self, edges):\n",
    "        \n",
    "        batchSize = edges.src['state'].shape[1]\n",
    "        edgeData = edges.data['feature'].repeat(batchSize, 1).T.unsqueeze(-1)\n",
    "        nodeInput = edges.src['input']\n",
    "        \n",
    "#         print(edges.src['state'].shape)\n",
    "#         print(nodeInput.shape)\n",
    "        return {'m' : self.messageNetwork(torch.cat((edges.src['state'], edgeData, nodeInput), -1))}\n",
    "        \n",
    "\n",
    "    def updateFunction(self, nodes):\n",
    "        return {'state': self.updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}\n",
    "    \n",
    "    def outputFunction(self, nodes):\n",
    "        \n",
    "#         numNodes, batchSize, stateSize = graph.ndata['state'].shape\n",
    "#         return self.outputNetwork.forward(graph.ndata['state'])\n",
    "        return {'output': self.outputNetwork(nodes.data['state'])}\n",
    "\n",
    "\n",
    "    def forward(self, graph, state):\n",
    "        \n",
    "        self.update_states_in_graph(graph, state)\n",
    "        \n",
    "        graph.apply_nodes(self.inputFunction)\n",
    "        \n",
    "        for messagePassingIteration in range(self.numMessagePassingIterations):\n",
    "            graph.update_all(self.messageFunction, dgl.function.max('m', 'm_hat'), self.updateFunction)\n",
    "        \n",
    "        graph.apply_nodes(self.outputFunction)\n",
    "        \n",
    "        output = graph.ndata['output']\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def update_states_in_graph(self, graph, state):\n",
    "        \n",
    "        if self.encoder:\n",
    "            if len(state.shape) == 1:\n",
    "                state = state.unsqueeze(0)\n",
    "\n",
    "            numGraphFeature = 6\n",
    "            numGlobalStateInformation = 5\n",
    "            numLocalStateInformation = 2\n",
    "            numStateVar = state.shape[1]\n",
    "            globalInformation = state[:, 0:5]\n",
    "            batch_size = state.shape[0]\n",
    "            numNodes = (numStateVar - 5) // 2\n",
    "\n",
    "            nodeData = torch.empty((numNodes, batch_size, numGraphFeature + numGlobalStateInformation + numLocalStateInformation)).to(device)\n",
    "\n",
    "            nodeData[:, :, 0:numGlobalStateInformation] = globalInformation            \n",
    "            for nodeIdx in range(numNodes):\n",
    "                # Assign local state information\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation] = state[:, 5 + nodeIdx]\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation + 1] = state[:, 5 + numNodes + nodeIdx]\n",
    "                # Assign global features from graph\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation + 2 : numGlobalStateInformation + 2 + numGraphFeature] = graph.ndata['feature'][nodeIdx]\n",
    "\n",
    "            graph.ndata['input'] = nodeData\n",
    "        \n",
    "        else:\n",
    "            numNodes, batchSize, inputSize = state.shape\n",
    "            nodeData = torch.empty((numNodes, batchSize, inputSize + 6)).to(device)\n",
    "            nodeData[:, :, :inputSize] = state\n",
    "            nodeData[:, :, inputSize : inputSize + 6] = graph.ndata['feature'].unsqueeze(dim=1).repeat_interleave(batchSize, dim=1)\n",
    "#             for nodeIdx in range(numNodes):\n",
    "#                 nodeData[nodeIdx, :, inputSize : inputSize + 6] = graph.ndata['feature'][nodeIdx]\n",
    "            \n",
    "            graph.ndata['input'] = nodeData\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovi/anaconda3/envs/honors-project/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n",
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoneType: None\n"
     ]
    }
   ],
   "source": [
    "states = {}\n",
    "actions = {}\n",
    "rewards = {}\n",
    "next_states = {}\n",
    "dones = {}\n",
    "env = {}\n",
    "\n",
    "for morphIdx in range(7):\n",
    "\n",
    "    prefix = '../datasets/{}/'.format(morphIdx)\n",
    "    \n",
    "    states[morphIdx] = np.load(prefix + 'states_array.npy')[:500]\n",
    "    actions[morphIdx] = np.load(prefix + 'actions_array.npy')[:500]\n",
    "    rewards[morphIdx] = np.load(prefix + 'rewards_array.npy')[:500]\n",
    "    next_states[morphIdx] = np.load(prefix + 'next_states_array.npy')[:500]\n",
    "    dones[morphIdx] = np.load(prefix + 'dones_array.npy')[:500]\n",
    "    \n",
    "    env[morphIdx] = HalfCheetahGraphEnv(None)\n",
    "    env[morphIdx].set_morphology(morphIdx)\n",
    "    env[morphIdx].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [256, 256]\n",
    "\n",
    "inputSize = 13\n",
    "stateSize = 64\n",
    "messageSize = 64\n",
    "latentSize = 2\n",
    "numMessagePassingIterations = 4\n",
    "batch_size = 1024\n",
    "numBatchesPerTrainingStep = 1\n",
    "minRandomDistance = 1\n",
    "maxSequentialDistance = 0.04\n",
    "with_batch_norm = True\n",
    "\n",
    "# # Encoder Networks \n",
    "encoderInputNetwork = Network(inputSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "encoderMessageNetwork = Network(stateSize + inputSize + 1, messageSize, hidden_sizes, with_batch_norm=with_batch_norm, activation=nn.Tanh)\n",
    "encoderUpdateNetwork = Network(stateSize + messageSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "encoderOutputNetwork = Network(stateSize, latentSize, hidden_sizes, with_batch_norm=with_batch_norm, activation=nn.Tanh)\n",
    "encoderGNN = GraphNeuralNetwork(encoderInputNetwork, encoderMessageNetwork, encoderUpdateNetwork, encoderOutputNetwork, numMessagePassingIterations, encoder=True).to(device)\n",
    "\n",
    "# # Decoder Networks\n",
    "decoderInputNetwork = Network(latentSize + 6, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderMessageNetwork = Network(stateSize + latentSize + 7, messageSize, hidden_sizes, with_batch_norm=with_batch_norm, activation=nn.Tanh)\n",
    "decoderUpdateNetwork = Network(stateSize + messageSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderOutputNetwork = Network(stateSize, 7, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderGNN = GraphNeuralNetwork(decoderInputNetwork, decoderMessageNetwork, decoderUpdateNetwork, decoderOutputNetwork, numMessagePassingIterations, encoder=False).to(device)\n",
    "\n",
    "\n",
    "encoderGNN.load_state_dict(torch.load('encoderGNN.pt'))\n",
    "decoderGNN.load_state_dict(torch.load('decoderGNN.pt'))\n",
    "\n",
    "# Optimizer\n",
    "lr =  1e-5\n",
    "optimizer = optim.Adam(itertools.chain(\n",
    "                    encoderInputNetwork.parameters(), encoderMessageNetwork.parameters(), \n",
    "                    encoderUpdateNetwork.parameters(), encoderOutputNetwork.parameters(),\n",
    "                    decoderInputNetwork.parameters(), decoderMessageNetwork.parameters(), \n",
    "                    decoderUpdateNetwork.parameters(), decoderOutputNetwork.parameters()),\n",
    "                    lr, weight_decay=0)\n",
    "\n",
    "lr_lambda = lambda epoch: 0.7\n",
    "lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda)\n",
    "criterion  = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'multitask-'\n",
    "numMessagePassingIterations = 4\n",
    "\n",
    "encoderInputNetwork.load_state_dict(torch.load(prefix + 'encoderInputNetwork' + '.pt'))\n",
    "encoderMessageNetwork.load_state_dict(torch.load(prefix + 'encoderMessageNetwork' + '.pt'))\n",
    "encoderUpdateNetwork.load_state_dict(torch.load(prefix + 'encoderUpdateNetwork' + '.pt'))\n",
    "encoderOutputNetwork.load_state_dict(torch.load(prefix + 'encoderOutputNetwork' + '.pt'))\n",
    "encoderGNN = GraphNeuralNetwork(encoderInputNetwork, encoderMessageNetwork, encoderUpdateNetwork, encoderOutputNetwork, numMessagePassingIterations, encoder=True).to(device)\n",
    "\n",
    "decoderInputNetwork.load_state_dict(torch.load(prefix + 'decoderInputNetwork' + '.pt'))\n",
    "decoderMessageNetwork.load_state_dict(torch.load(prefix + 'decoderMessageNetwork' + '.pt'))\n",
    "decoderUpdateNetwork.load_state_dict(torch.load(prefix + 'decoderUpdateNetwork' + '.pt'))\n",
    "decoderOutputNetwork.load_state_dict(torch.load(prefix + 'decoderOutputNetwork' + '.pt'))\n",
    "decoderGNN = GraphNeuralNetwork(decoderInputNetwork, decoderMessageNetwork, decoderUpdateNetwork, decoderOutputNetwork, numMessagePassingIterations, encoder=False).to(device)\n",
    "\n",
    "encoderInputNetwork.eval()\n",
    "encoderMessageNetwork.eval()\n",
    "encoderUpdateNetwork.eval()\n",
    "encoderOutputNetwork.eval()\n",
    "\n",
    "decoderInputNetwork.eval()\n",
    "decoderMessageNetwork.eval()\n",
    "decoderUpdateNetwork.eval()\n",
    "decoderOutputNetwork.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphIdx = 4\n",
    "\n",
    "with torch.no_grad():\n",
    "    g1 = env[morphIdx].get_graph()._get_dgl_graph().to('cpu')\n",
    "    \n",
    "    latentEncodings = encoderGNN(g1, a)\n",
    "    originalInput = g1.ndata['input'][:, :, :7]\n",
    "\n",
    "    g2 = env[morphIdx].get_graph()._get_dgl_graph().to('cpu')\n",
    "    stateReconstruction = decoderGNN(g2, latentEncodings)\n",
    "    stateReconstruction[:, :, 0:5] = stateReconstruction[:, :, 0:5].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5000,  0.0000,  0.0000,  0.3000,  0.0000,  0.7000],\n",
      "        [-0.5000,  0.0000, -0.3000,  0.2000,  0.0000,  0.7000],\n",
      "        [-0.5000,  0.0000, -0.5000,  0.2000,  0.0000,  0.7000],\n",
      "        [-0.5000,  0.0000, -0.7000,  0.1500, -1.5700,  0.7000],\n",
      "        [ 0.5000,  0.0000,  0.0000,  0.3000,  0.0000,  0.7000],\n",
      "        [ 0.5000,  0.0000, -0.3000,  0.2000,  0.0000,  0.7000],\n",
      "        [ 0.5000,  0.0000, -0.5000,  0.1500, -1.5700,  0.7000]])\n"
     ]
    }
   ],
   "source": [
    "print(g2.ndata['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4082, 0.6828, 0.1377, 0.3356, 0.3284, 0.2448, 0.6077, 0.8391, 0.9633,\n",
      "         0.3126, 0.0998, 0.7740, 0.5747, 0.2868, 0.4104, 0.0566, 0.5307, 0.4024,\n",
      "         0.2544],\n",
      "        [0.9969, 0.3216, 0.0069, 0.1808, 0.1510, 0.5144, 0.7217, 0.0204, 0.6995,\n",
      "         0.8897, 0.2783, 0.8410, 0.9073, 0.0085, 0.3420, 0.1271, 0.6714, 0.5995,\n",
      "         0.4799]])\n",
      "tensor([[[-0.9305,  0.9545],\n",
      "         [-0.9174,  0.9401]],\n",
      "\n",
      "        [[-0.8990,  0.9438],\n",
      "         [-0.8871,  0.9327]],\n",
      "\n",
      "        [[-0.8137,  0.9071],\n",
      "         [-0.8146,  0.8944]],\n",
      "\n",
      "        [[-0.9405,  0.9658],\n",
      "         [-0.9433,  0.9636]],\n",
      "\n",
      "        [[-0.9150,  0.9417],\n",
      "         [-0.9072,  0.9360]],\n",
      "\n",
      "        [[-0.9005,  0.9560],\n",
      "         [-0.8909,  0.9458]],\n",
      "\n",
      "        [[-0.9325,  0.9459],\n",
      "         [-0.9363,  0.9530]]])\n",
      "tensor([[[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  0.5489,  1.5153],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  0.5659,  1.5150]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  1.8745,  1.6689],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  1.8437,  1.6567]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  0.5148,  1.3584],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  0.4776,  1.3476]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  6.7979,  1.7637],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  6.6830,  1.7393]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  0.5943,  1.6000],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  0.6012,  1.6021]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  1.5225,  1.7359],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  1.5205,  1.7318]],\n",
      "\n",
      "        [[-0.4061,  6.7473,  0.6282,  0.1058,  2.1843,  6.4630,  2.1837],\n",
      "         [-0.4112,  6.7795,  0.6402,  0.0977,  2.1788,  6.4596,  2.1814]]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(latentEncodings)\n",
    "print(stateReconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.338685989379883\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.MSELoss(reduction='none')(stateReconstruction, originalInput).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('inputNetwork.layers.0.weight',\n",
       "              tensor([[-0.2555, -0.1739,  0.1580,  ...,  0.0895,  0.0754,  0.0935],\n",
       "                      [ 0.2648, -0.1616,  0.0540,  ...,  0.1292, -0.3203,  0.2862],\n",
       "                      [ 0.1270, -0.1272,  0.1431,  ..., -0.1147,  0.2002, -0.1269],\n",
       "                      ...,\n",
       "                      [ 0.2968,  0.1648,  0.2995,  ..., -0.2269,  0.0887,  0.1168],\n",
       "                      [-0.2694, -0.4318,  0.0039,  ..., -0.0209, -0.2338, -0.0135],\n",
       "                      [-0.0488, -0.0623, -0.2562,  ...,  0.1377,  0.3263, -0.0899]])),\n",
       "             ('inputNetwork.layers.0.bias',\n",
       "              tensor([ 0.1060, -0.3399, -0.0059,  0.2553,  0.0247,  0.1560,  0.3391,  0.0981,\n",
       "                       0.1841, -0.2273,  0.2045, -0.3481, -0.0547,  0.2828, -0.0760, -0.1732,\n",
       "                      -0.2082, -0.0143,  0.2593, -0.2022, -0.2030, -0.1152, -0.1895, -0.2356,\n",
       "                       0.1740, -0.1269, -0.3403, -0.0389, -0.1594,  0.1803,  0.1764, -0.0820,\n",
       "                       0.1787, -0.3159,  0.0569, -0.0637,  0.0024,  0.2503,  0.0961,  0.2300,\n",
       "                      -0.1149, -0.0589, -0.2740,  0.0514,  0.0389, -0.2780, -0.2621, -0.3334,\n",
       "                      -0.0944, -0.2967, -0.1784,  0.2383,  0.2094, -0.1477,  0.0145,  0.1254,\n",
       "                       0.2087, -0.0167,  0.1489, -0.1864, -0.0131, -0.2730, -0.2768, -0.1444,\n",
       "                       0.1945, -0.2339, -0.1799,  0.3398,  0.0731,  0.1446,  0.2303, -0.1658,\n",
       "                       0.1077,  0.0350, -0.2029, -0.2277, -0.1653, -0.2659,  0.1332, -0.1420,\n",
       "                       0.0483, -0.3157, -0.1820,  0.0456,  0.0789, -0.0539,  0.0457, -0.0740,\n",
       "                      -0.0722,  0.1949,  0.0361,  0.3615, -0.1252,  0.1145,  0.0553, -0.3182,\n",
       "                      -0.3343, -0.1000,  0.1699, -0.0759,  0.1300, -0.0493,  0.2361,  0.0693,\n",
       "                      -0.0475, -0.0152, -0.0156, -0.2014, -0.0132, -0.1749, -0.2232, -0.0629,\n",
       "                       0.1167,  0.1407, -0.3073, -0.3033,  0.2701,  0.0633,  0.0655,  0.1507,\n",
       "                      -0.0673, -0.0078, -0.2721,  0.2771, -0.1046, -0.2359, -0.0305, -0.0083,\n",
       "                      -0.3169, -0.0968,  0.2544,  0.2622, -0.1053, -0.2920, -0.1471, -0.3013,\n",
       "                       0.1533, -0.0736,  0.1445,  0.0529,  0.2511,  0.1392, -0.1102,  0.1784,\n",
       "                      -0.2868,  0.0269, -0.1829, -0.1333, -0.0921, -0.1616,  0.2912, -0.0393,\n",
       "                      -0.1455,  0.1305,  0.2403,  0.3375,  0.3310,  0.1312,  0.2608,  0.0595,\n",
       "                      -0.2940, -0.2280, -0.2497, -0.1719, -0.2111, -0.0552,  0.3227,  0.3165,\n",
       "                       0.1028, -0.0236, -0.2118, -0.0957, -0.0033, -0.1961,  0.1358, -0.1400,\n",
       "                      -0.3671,  0.2187, -0.0442,  0.2993,  0.0739,  0.0422, -0.1760,  0.1696,\n",
       "                      -0.1032,  0.0298, -0.1768, -0.2320, -0.0352, -0.2631,  0.2613, -0.1236,\n",
       "                      -0.0497,  0.2174, -0.2044, -0.2258,  0.2489, -0.0146,  0.0504, -0.2595,\n",
       "                      -0.0901, -0.0017, -0.3109,  0.3401,  0.0628,  0.2551,  0.0813, -0.2753,\n",
       "                       0.0325,  0.0823, -0.0134,  0.1547,  0.1442,  0.1737,  0.2899, -0.2666,\n",
       "                      -0.2900,  0.0118,  0.1547,  0.0658,  0.1052,  0.3001,  0.0935,  0.0080,\n",
       "                      -0.2203,  0.2708, -0.1556, -0.0902, -0.2561,  0.3316, -0.0490, -0.2749,\n",
       "                      -0.0462, -0.0103, -0.0943,  0.0645,  0.3095, -0.2682,  0.2523,  0.1636,\n",
       "                      -0.1894, -0.0245, -0.0124, -0.1086, -0.3314,  0.0313, -0.2060, -0.1958,\n",
       "                      -0.2482,  0.2426,  0.0550, -0.1833,  0.2874, -0.0479, -0.0600,  0.3422])),\n",
       "             ('inputNetwork.layers.1.weight',\n",
       "              tensor([1.0155, 1.0155, 0.9682, 0.9914, 0.9822, 0.9450, 0.9724, 0.9874, 1.0140,\n",
       "                      1.0516, 0.9501, 1.0177, 0.9601, 0.9836, 1.0074, 1.0374, 0.9412, 0.9672,\n",
       "                      0.9903, 0.9043, 1.0063, 0.9423, 0.9323, 1.1223, 0.9854, 1.0317, 0.9697,\n",
       "                      1.0389, 1.0851, 0.9970, 0.9302, 0.9260, 1.0168, 0.9941, 1.1699, 0.9953,\n",
       "                      0.9303, 1.0085, 1.0455, 0.9804, 1.0527, 1.0042, 1.0304, 1.0812, 0.9864,\n",
       "                      1.0250, 1.0047, 0.9967, 0.9431, 0.9769, 1.0586, 0.9786, 1.0265, 0.8798,\n",
       "                      0.9556, 0.9227, 0.9971, 1.0398, 1.0185, 1.0000, 0.9962, 1.1258, 1.1247,\n",
       "                      1.0505, 0.9361, 1.0342, 0.9807, 0.9492, 1.0131, 0.9348, 0.9815, 1.0368,\n",
       "                      0.9659, 0.9610, 1.0545, 1.0888, 1.0405, 0.9696, 0.9482, 0.9934, 0.9431,\n",
       "                      1.0041, 1.0477, 0.9627, 0.9963, 1.0811, 1.0313, 1.0074, 1.0393, 0.9310,\n",
       "                      1.0447, 1.0221, 0.9779, 0.9505, 1.0011, 1.1443, 0.9444, 0.9514, 0.9576,\n",
       "                      1.1613, 0.9419, 1.0219, 0.9544, 1.0179, 0.9604, 0.9895, 0.9739, 1.1937,\n",
       "                      0.9494, 0.9789, 0.9296, 0.9477, 1.0398, 0.9630, 1.0732, 1.1135, 1.0140,\n",
       "                      1.1381, 1.0470, 1.0252, 1.0073, 0.9426, 0.9932, 0.9707, 1.4119, 1.1155,\n",
       "                      0.9774, 1.0054, 1.0578, 1.0054, 0.9865, 0.9834, 0.9982, 1.3584, 0.9886,\n",
       "                      1.0203, 1.0242, 1.0817, 0.9873, 0.9280, 0.9764, 0.9763, 1.0680, 1.0028,\n",
       "                      0.9821, 1.0277, 0.9865, 1.0788, 1.1586, 0.9606, 0.9516, 1.2300, 0.9785,\n",
       "                      0.9690, 1.0466, 0.9750, 1.0038, 0.9716, 0.9560, 1.0481, 0.9655, 0.9861,\n",
       "                      0.9833, 1.0726, 1.0053, 0.9596, 0.9501, 0.9912, 0.9662, 1.1401, 1.0441,\n",
       "                      1.1123, 1.0209, 0.9006, 0.9725, 0.9074, 0.9611, 1.0219, 0.9979, 0.9949,\n",
       "                      0.9833, 0.9314, 1.0572, 0.9532, 0.9877, 0.9998, 0.8467, 0.8866, 1.0722,\n",
       "                      1.0788, 0.9907, 1.1198, 0.8750, 1.0121, 1.0789, 1.1137, 0.9311, 1.0096,\n",
       "                      1.0188, 1.0229, 0.9868, 1.0160, 1.1357, 1.0042, 1.0006, 1.0221, 0.9920,\n",
       "                      1.5521, 0.9861, 1.0188, 0.9785, 1.0027, 0.9985, 0.9988, 1.0125, 0.9374,\n",
       "                      1.0189, 1.1142, 0.9843, 0.9822, 0.9646, 0.9369, 0.9285, 1.0202, 0.9415,\n",
       "                      0.9345, 1.1530, 1.0036, 1.0882, 0.9956, 0.9856, 1.1364, 1.0033, 0.9151,\n",
       "                      0.9242, 0.9540, 0.9726, 1.0016, 1.0340, 0.9829, 1.1335, 0.9824, 1.0984,\n",
       "                      0.9808, 1.0046, 0.9643, 1.0451, 0.9844, 1.0208, 0.9006, 1.0606, 1.0149,\n",
       "                      0.9579, 1.0081, 1.2242, 0.9918])),\n",
       "             ('inputNetwork.layers.1.bias',\n",
       "              tensor([ 9.2858e-03, -3.4651e-02, -3.4063e-02, -1.1076e-02, -1.8993e-02,\n",
       "                      -5.1291e-02, -4.4861e-02, -1.1085e-02, -8.5600e-03,  5.4659e-04,\n",
       "                      -6.8155e-02, -6.7889e-03, -5.6264e-02, -2.8478e-02, -2.8310e-02,\n",
       "                       1.3999e-02, -5.5793e-02, -7.2129e-02, -2.6161e-02, -5.5464e-02,\n",
       "                       1.3603e-01, -5.9318e-02, -4.5073e-02,  1.4972e-02, -2.9256e-02,\n",
       "                       7.0693e-04, -7.5415e-02,  1.4007e-02,  2.9207e-02, -2.3814e-02,\n",
       "                      -6.6267e-02, -5.2877e-02, -5.2850e-03, -2.7758e-02,  7.6344e-02,\n",
       "                      -7.6886e-02, -5.5399e-02, -1.3370e-02,  2.5235e-02, -3.7176e-02,\n",
       "                      -1.4941e-02,  7.6883e-03, -2.1282e-03,  5.3641e-02, -2.7161e-02,\n",
       "                      -1.4891e-02, -1.2178e-02, -3.3891e-02, -5.3215e-02, -7.0915e-02,\n",
       "                       1.5338e-02, -3.0122e-02, -1.1285e-03, -1.3657e-01, -3.2983e-02,\n",
       "                      -4.2655e-02, -2.3750e-02,  6.2548e-03,  1.1729e-02,  0.0000e+00,\n",
       "                      -1.4599e-02,  7.2270e-03,  2.2511e-02,  9.9143e-03, -6.5889e-02,\n",
       "                      -2.1060e-02, -2.6290e-02, -5.2900e-02,  2.4544e-02, -5.2282e-02,\n",
       "                      -3.1987e-02,  1.5537e-02, -3.2357e-02, -2.7583e-02,  6.9774e-02,\n",
       "                       2.1438e-01,  4.0550e-03, -8.0099e-03, -4.6975e-02, -1.0896e-02,\n",
       "                      -4.3415e-02, -2.0500e-02, -6.3585e-03, -3.8866e-02, -1.0615e-02,\n",
       "                       4.1456e-02, -3.4342e-03, -1.3111e-03,  9.4389e-03, -6.9387e-02,\n",
       "                       2.9741e-02,  7.2122e-03, -3.4128e-02, -4.4377e-02, -2.3143e-02,\n",
       "                       1.5039e-02, -3.1194e-02, -5.4186e-02, -4.4042e-02,  9.0020e-02,\n",
       "                      -6.2303e-02, -4.9913e-03, -4.7200e-02, -1.2096e-02, -3.0206e-02,\n",
       "                      -1.7572e-02, -1.0790e-02,  7.9692e-02, -6.3586e-02, -4.9067e-02,\n",
       "                      -4.3123e-02, -5.5331e-02, -5.4276e-03, -3.1779e-02,  3.4382e-02,\n",
       "                       3.1314e-02,  1.5571e-03,  8.2992e-02,  2.0092e-02,  9.5366e-03,\n",
       "                      -2.7545e-02, -6.1549e-02, -1.6452e-02, -2.3654e-02,  9.9546e-02,\n",
       "                       5.8478e-02, -2.6026e-02, -1.7701e-02,  2.2824e-02, -1.2870e-02,\n",
       "                      -2.1478e-02, -1.5040e-02, -3.0019e-02,  4.4063e-02, -2.1922e-02,\n",
       "                      -5.6422e-03,  7.4362e-04,  2.8709e-02, -1.6081e-02, -7.6769e-02,\n",
       "                      -2.2872e-02, -2.5347e-02,  9.0954e-03,  2.2165e-04, -5.3982e-02,\n",
       "                      -9.4236e-03, -1.7569e-02,  2.8620e-02,  9.3165e-02, -2.6533e-02,\n",
       "                      -5.0333e-02,  4.7049e-02, -2.7717e-02, -4.2827e-02,  9.5403e-03,\n",
       "                      -2.1098e-02,  2.6964e-03, -3.0510e-02, -4.3435e-02,  1.5392e-02,\n",
       "                      -3.4248e-02, -1.5036e-02, -3.7719e-02, -4.1954e-03, -9.6804e-03,\n",
       "                      -3.1883e-02, -4.9874e-02, -1.6995e-02, -3.8522e-02,  1.9941e-02,\n",
       "                      -1.9592e-02,  6.3574e-03,  2.9715e-03, -4.2695e-02, -3.8618e-02,\n",
       "                      -7.1462e-02, -5.4482e-02, -6.3456e-03, -2.1617e-02, -1.3767e-02,\n",
       "                       1.9573e-02, -4.2199e-02, -1.5559e-02, -4.8174e-02, -2.1865e-02,\n",
       "                      -5.0847e-04, -1.4533e-01, -9.2964e-02,  2.7339e-02,  3.6356e-02,\n",
       "                      -2.0718e-02,  6.3311e-03, -8.1519e-02, -1.7072e-02,  6.5073e-02,\n",
       "                       6.6307e-03, -6.0015e-02, -4.0694e-04,  1.0290e-03,  6.5427e-03,\n",
       "                      -2.9867e-02, -2.9450e-03,  1.6699e-02, -5.9883e-03, -2.1825e-03,\n",
       "                       4.5310e-03, -1.9724e-02,  1.4717e-02, -2.7863e-02,  1.6054e-02,\n",
       "                      -2.4406e-02, -1.3710e-02, -1.4580e-02,  2.7155e-03, -5.2607e-03,\n",
       "                      -6.5714e-02, -1.5008e-03,  4.7970e-02, -1.7917e-02, -3.9139e-02,\n",
       "                      -3.3033e-02, -7.3719e-02, -8.8244e-02,  6.0167e-03, -7.0056e-02,\n",
       "                      -5.6251e-02,  9.6928e-02, -1.8276e-02, -6.1262e-05, -1.9313e-02,\n",
       "                       1.7874e-02,  6.6616e-02, -7.0789e-03, -9.7833e-02, -8.2080e-02,\n",
       "                      -2.3146e-02, -3.1404e-02, -1.2819e-02,  2.2320e-02, -1.1998e-02,\n",
       "                       5.7734e-02, -2.2875e-04,  2.7876e-02, -2.6756e-02, -2.8233e-02,\n",
       "                      -1.8630e-02,  6.4276e-02, -1.7508e-02, -1.5608e-02, -7.1793e-02,\n",
       "                       1.9065e-02, -1.4070e-03, -4.8006e-02, -3.0552e-02,  1.0124e-01,\n",
       "                      -2.1368e-02])),\n",
       "             ('inputNetwork.layers.3.weight',\n",
       "              tensor([[ 0.0128,  0.0921, -0.0381,  ..., -0.0076,  0.0957,  0.0344],\n",
       "                      [ 0.0222, -0.0207, -0.0157,  ..., -0.0132, -0.0428, -0.0256],\n",
       "                      [-0.0482,  0.0061, -0.0249,  ...,  0.0932, -0.1990,  0.0070],\n",
       "                      ...,\n",
       "                      [-0.0014,  0.0393,  0.0447,  ...,  0.0119, -0.0037, -0.0048],\n",
       "                      [ 0.0252,  0.0946,  0.0495,  ...,  0.0616,  0.0096, -0.0061],\n",
       "                      [-0.0267,  0.0802,  0.0646,  ..., -0.0077,  0.1332,  0.0230]])),\n",
       "             ('inputNetwork.layers.3.bias',\n",
       "              tensor([-0.0599,  0.0596, -0.0390, -0.0081, -0.0412, -0.0152, -0.0010, -0.0548,\n",
       "                       0.0002, -0.0394,  0.0010, -0.0487, -0.0641, -0.0308,  0.0029, -0.0408,\n",
       "                      -0.0375,  0.0536,  0.0075, -0.0583, -0.0420, -0.0053, -0.0604, -0.0648,\n",
       "                       0.0437, -0.0417,  0.0449,  0.0474, -0.0456,  0.0525, -0.0005,  0.0472,\n",
       "                      -0.0490,  0.0594, -0.0333, -0.0544, -0.0042,  0.0137, -0.0039,  0.0268,\n",
       "                      -0.0064, -0.0382,  0.0022, -0.0561,  0.0423, -0.0050, -0.0469, -0.0351,\n",
       "                       0.0110, -0.0210, -0.0091,  0.0232,  0.0230,  0.0131,  0.0468,  0.0069,\n",
       "                       0.0187, -0.0499, -0.0303, -0.0159, -0.0036,  0.0204,  0.0526,  0.0190,\n",
       "                      -0.0184, -0.0044,  0.0552,  0.0289, -0.0376, -0.0564, -0.0580, -0.0296,\n",
       "                      -0.0275, -0.0473,  0.0230,  0.0089, -0.0162, -0.0015,  0.0392, -0.0383,\n",
       "                      -0.0383, -0.0604,  0.0335, -0.0121, -0.0173,  0.0624, -0.0364,  0.0286,\n",
       "                      -0.0442, -0.0521, -0.0385, -0.0039,  0.0156,  0.0465,  0.0069, -0.0675,\n",
       "                      -0.0158,  0.0147,  0.0198, -0.0526,  0.0203,  0.0707, -0.0198, -0.0236,\n",
       "                       0.0509,  0.0528, -0.0415,  0.0171,  0.0613, -0.0067, -0.0406, -0.0513,\n",
       "                      -0.0564,  0.0511,  0.0553,  0.0535,  0.0478,  0.0301, -0.0511,  0.0398,\n",
       "                      -0.0391, -0.0453,  0.0666, -0.0009, -0.0558, -0.0437,  0.0283,  0.0549,\n",
       "                       0.0177,  0.0632, -0.0353, -0.0410, -0.0415,  0.0076,  0.0698,  0.0014,\n",
       "                       0.0410, -0.0296,  0.0245,  0.0242,  0.0405, -0.0096,  0.0074,  0.0554,\n",
       "                      -0.0270, -0.0493,  0.0401, -0.0448, -0.0295,  0.0124,  0.0398,  0.0289,\n",
       "                       0.0084, -0.0423,  0.0242,  0.0259, -0.0370,  0.0410, -0.0089,  0.0661,\n",
       "                      -0.0119,  0.0263,  0.0704, -0.0442,  0.0385,  0.0512, -0.0452,  0.0265,\n",
       "                       0.0062, -0.0305,  0.0357,  0.0386,  0.0025, -0.0073,  0.0208,  0.0439,\n",
       "                       0.0112,  0.0588,  0.0150, -0.0523, -0.0586, -0.0506,  0.0424, -0.0041,\n",
       "                       0.0102, -0.0034, -0.0067,  0.0129,  0.0076,  0.0513,  0.0199,  0.0418,\n",
       "                       0.0525, -0.0602,  0.0155, -0.0477,  0.0238,  0.0448, -0.0104, -0.0209,\n",
       "                       0.0643, -0.0370, -0.0042,  0.0460, -0.0217, -0.0005, -0.0498, -0.0320,\n",
       "                       0.0402,  0.0114, -0.0668,  0.0461, -0.0421, -0.0252, -0.0406,  0.0284,\n",
       "                      -0.0177, -0.0148, -0.0585, -0.0326,  0.0424, -0.0352, -0.0053,  0.0513,\n",
       "                       0.0121, -0.0042,  0.0141, -0.0287, -0.0446,  0.0735, -0.0569,  0.0189,\n",
       "                       0.0351,  0.0254,  0.0347, -0.0198, -0.0401, -0.0282, -0.0338,  0.0235,\n",
       "                       0.0106, -0.0361, -0.0509, -0.0096, -0.0636, -0.0132, -0.0506, -0.0115,\n",
       "                      -0.0054,  0.0545, -0.0477, -0.0149,  0.0576,  0.0177, -0.0472, -0.0336])),\n",
       "             ('inputNetwork.layers.4.weight',\n",
       "              tensor([0.9654, 0.9815, 1.0314, 0.9552, 0.9742, 0.9694, 0.9031, 0.9729, 1.0886,\n",
       "                      0.9240, 0.9879, 0.8670, 0.9285, 0.8980, 0.8482, 0.9967, 0.9578, 1.0611,\n",
       "                      0.9817, 1.0068, 0.9183, 1.0315, 0.8987, 0.7574, 0.9763, 1.0469, 0.9696,\n",
       "                      0.9591, 1.0316, 0.9536, 0.9779, 0.8298, 0.8476, 1.0107, 0.9323, 0.9248,\n",
       "                      1.0494, 1.0797, 0.7474, 0.9796, 1.0644, 1.0572, 1.0394, 0.8933, 1.0024,\n",
       "                      1.0496, 1.0261, 0.9210, 0.8066, 1.0078, 0.9327, 1.0291, 0.9904, 0.9410,\n",
       "                      1.0482, 0.9575, 0.9758, 0.7258, 0.9869, 1.0625, 1.0535, 0.6696, 1.0125,\n",
       "                      0.9301, 0.9953, 0.9965, 0.9592, 0.8205, 0.8826, 0.9558, 1.0244, 0.9712,\n",
       "                      0.8723, 0.9386, 0.9525, 0.9463, 0.9076, 1.0448, 0.8588, 1.0664, 0.9377,\n",
       "                      0.8480, 1.0164, 0.9837, 0.9474, 0.9668, 1.0644, 0.9635, 1.0143, 0.9608,\n",
       "                      1.0200, 1.0738, 0.9242, 0.9664, 0.9202, 0.9366, 0.9669, 1.0094, 0.9258,\n",
       "                      0.9392, 0.9273, 1.0142, 0.9733, 0.9230, 0.9632, 1.0926, 0.9435, 0.9976,\n",
       "                      1.0177, 0.9939, 0.9281, 0.9847, 0.8230, 0.9014, 1.0473, 0.9395, 0.9165,\n",
       "                      0.9823, 1.0193, 1.0630, 1.0183, 0.8453, 0.9759, 0.9919, 0.9555, 0.9899,\n",
       "                      1.0278, 1.0009, 0.9744, 1.0461, 1.0265, 0.9984, 0.9265, 1.0492, 1.0320,\n",
       "                      0.9002, 0.9234, 0.9421, 1.0035, 0.9763, 0.9343, 1.0555, 1.0328, 1.0249,\n",
       "                      0.9068, 1.0104, 0.9965, 0.9022, 1.0057, 0.9547, 0.9459, 1.0330, 0.9716,\n",
       "                      1.1144, 0.9831, 0.9608, 0.9315, 0.9486, 1.0543, 1.0509, 1.0525, 0.9547,\n",
       "                      0.9314, 0.9841, 0.9804, 0.9804, 1.0285, 0.6085, 1.0808, 0.9494, 0.9372,\n",
       "                      1.0317, 0.9976, 0.9470, 0.8806, 1.0053, 1.0906, 1.0151, 1.0138, 0.9751,\n",
       "                      0.9470, 1.0171, 1.0000, 0.9547, 1.0550, 0.9435, 0.9724, 0.9688, 1.0039,\n",
       "                      0.9454, 0.6057, 0.9998, 0.9720, 0.9772, 0.8556, 0.9389, 0.9603, 0.9400,\n",
       "                      0.9961, 1.0905, 0.9781, 0.9301, 0.9580, 1.0061, 0.9674, 0.9945, 0.9836,\n",
       "                      0.9693, 0.9176, 1.0041, 0.9609, 0.9249, 0.9037, 0.9531, 0.9469, 0.9798,\n",
       "                      0.9432, 1.0757, 0.9719, 1.0347, 0.9322, 0.9396, 0.8893, 0.9154, 0.9791,\n",
       "                      1.0247, 0.9534, 0.9873, 0.8227, 1.0881, 0.8688, 1.0040, 1.0151, 1.0036,\n",
       "                      0.9923, 0.9407, 0.9208, 0.9939, 1.0515, 0.9998, 0.9757, 0.9238, 0.9920,\n",
       "                      0.9657, 0.9856, 0.9540, 0.9386, 0.9737, 0.9028, 0.8583, 0.9424, 0.9409,\n",
       "                      0.9306, 0.9795, 1.0808, 1.1322])),\n",
       "             ('inputNetwork.layers.4.bias',\n",
       "              tensor([-5.5019e-02, -2.6841e-02,  2.1712e-02, -4.5778e-02, -1.9332e-02,\n",
       "                      -2.8194e-02, -1.0550e-01, -5.7226e-02, -3.9071e-03, -6.0288e-02,\n",
       "                      -2.2087e-02, -1.3515e-01, -3.5210e-02, -5.8211e-02, -1.5701e-01,\n",
       "                      -9.4452e-03, -2.1468e-02,  3.7056e-02, -1.6342e-02, -2.9070e-02,\n",
       "                      -3.8413e-02, -3.7061e-03, -6.6725e-02, -1.5794e-01, -2.1891e-02,\n",
       "                      -2.6117e-02, -2.6082e-02, -4.5032e-02, -2.0320e-03, -4.3881e-02,\n",
       "                      -1.9292e-02, -1.3857e-01, -1.0998e-01,  4.3212e-03, -7.3405e-02,\n",
       "                      -3.4025e-02, -8.4321e-03, -1.1758e-02, -2.2421e-01, -3.7534e-02,\n",
       "                       2.5665e-02, -1.2603e-02, -3.2018e-02, -5.3844e-02, -1.3365e-02,\n",
       "                       9.4176e-03, -1.6716e-02, -8.6380e-02, -1.1244e-01, -3.0818e-03,\n",
       "                      -1.0494e-01, -1.2568e-02, -4.6291e-02, -5.7356e-02, -1.2894e-02,\n",
       "                      -2.4477e-02, -3.9054e-02, -1.5622e-01, -3.2577e-03,  3.1395e-02,\n",
       "                       1.5930e-02, -2.4068e-01, -1.6888e-02, -9.5431e-02, -3.1887e-02,\n",
       "                      -1.0604e-02, -2.2718e-02, -1.8189e-01, -1.2551e-01, -7.0922e-02,\n",
       "                       2.4023e-04, -1.9087e-02, -1.2300e-01, -6.8384e-02, -2.5062e-02,\n",
       "                      -6.9410e-02, -5.3171e-02,  1.6344e-02, -1.4173e-01,  2.7084e-02,\n",
       "                      -4.0919e-02, -1.0638e-01, -1.7746e-03, -6.1478e-03, -7.2293e-02,\n",
       "                      -4.0494e-02,  2.4639e-02, -7.1773e-02,  8.4092e-03, -6.1761e-02,\n",
       "                      -1.9273e-02,  4.8378e-02, -2.6912e-02, -2.2070e-02, -6.8299e-02,\n",
       "                      -9.5206e-02, -2.3880e-02, -1.0334e-02, -5.0894e-02, -5.0096e-02,\n",
       "                      -5.5621e-02, -1.3452e-03, -1.2829e-02, -1.3821e-01, -6.1286e-03,\n",
       "                       2.6021e-02, -9.4901e-02, -4.2935e-02, -1.1434e-02, -8.6117e-04,\n",
       "                      -7.7455e-02,  7.1364e-04, -1.6783e-01, -6.2428e-02,  1.5891e-02,\n",
       "                      -8.3623e-02, -8.7873e-02, -2.2196e-02, -5.8521e-03,  4.4649e-02,\n",
       "                      -2.1064e-02, -8.9243e-02, -1.4956e-02, -6.1230e-04, -4.0047e-02,\n",
       "                       9.9895e-04,  3.0030e-02, -1.2149e-02, -6.4388e-02,  7.2573e-04,\n",
       "                      -6.7162e-02, -2.4776e-02, -5.5030e-02,  4.4366e-02, -1.2339e-02,\n",
       "                      -8.3849e-02, -8.1234e-02, -1.7022e-02,  1.0495e-02, -2.9988e-02,\n",
       "                      -3.7592e-02,  2.7547e-02,  7.2269e-04,  2.4978e-02, -1.1409e-01,\n",
       "                      -1.1990e-02, -4.1109e-03, -6.0767e-02, -6.1025e-03, -7.1392e-03,\n",
       "                      -1.1803e-01,  4.0857e-03, -2.7988e-02,  9.7199e-03, -1.0372e-02,\n",
       "                      -4.8599e-02, -9.6960e-02, -4.4081e-02, -7.7540e-03,  2.2045e-02,\n",
       "                       1.4829e-02, -4.3058e-02, -5.0053e-02, -2.5147e-02, -2.7995e-02,\n",
       "                      -1.5332e-02, -7.9188e-03, -2.6029e-01,  5.1000e-02, -4.1191e-02,\n",
       "                      -8.3446e-02,  1.3851e-02, -8.0870e-04, -2.2285e-02, -1.3620e-01,\n",
       "                      -5.4616e-02, -1.4853e-02, -5.2587e-02, -1.7430e-03, -1.7050e-02,\n",
       "                      -5.5561e-02, -2.0695e-02,  6.5417e-03, -1.8301e-02,  1.1623e-02,\n",
       "                      -6.9438e-02, -6.1163e-02, -2.6522e-02, -4.5333e-02, -9.3759e-02,\n",
       "                      -3.1324e-01, -3.4979e-02, -3.8342e-02, -5.0313e-02, -1.1381e-01,\n",
       "                      -1.8958e-02, -5.0209e-02, -6.9671e-02, -7.5916e-02,  2.4812e-02,\n",
       "                      -1.2850e-02, -4.6066e-02, -3.7352e-02, -3.0118e-03, -1.5189e-02,\n",
       "                      -1.7772e-02, -1.5039e-02, -3.7669e-02, -4.2381e-02, -1.5521e-02,\n",
       "                      -4.3626e-02, -7.5067e-02, -9.3589e-02, -2.9374e-02, -1.4549e-02,\n",
       "                      -4.0490e-02, -7.5308e-02,  1.4520e-02, -2.4677e-02,  3.0946e-02,\n",
       "                      -1.1001e-01, -3.8343e-02, -3.9957e-02, -7.9025e-02, -2.9640e-02,\n",
       "                       1.7375e-02, -4.6886e-02, -9.3436e-03, -1.6190e-01,  2.6513e-02,\n",
       "                      -1.0332e-01,  4.5835e-03, -5.7695e-03, -2.1344e-02, -5.6900e-03,\n",
       "                      -7.3543e-02, -5.1797e-02,  7.6990e-04, -4.2993e-03, -2.2583e-02,\n",
       "                      -4.8433e-02, -1.1421e-01, -1.9011e-02, -2.1803e-02, -9.5863e-02,\n",
       "                      -3.1305e-02, -4.1010e-02, -7.9991e-03, -1.3890e-01, -1.4327e-01,\n",
       "                      -1.0418e-01, -8.3910e-02, -5.4613e-02, -1.5642e-02,  5.6405e-02,\n",
       "                       1.0329e-03])),\n",
       "             ('inputNetwork.layers.6.weight',\n",
       "              tensor([[-0.0319, -0.0721,  0.0030,  ..., -0.0385, -0.1134, -0.0424],\n",
       "                      [ 0.0175, -0.0682, -0.0231,  ..., -0.0481, -0.0079, -0.0017],\n",
       "                      [-0.0507, -0.0665, -0.0936,  ..., -0.0475, -0.1201, -0.0784],\n",
       "                      ...,\n",
       "                      [ 0.0128, -0.0953,  0.0112,  ...,  0.0484, -0.0550, -0.0995],\n",
       "                      [-0.0558,  0.0398,  0.0160,  ...,  0.0397,  0.0244,  0.0108],\n",
       "                      [-0.0589,  0.0265,  0.0239,  ...,  0.0670, -0.0224, -0.0411]])),\n",
       "             ('inputNetwork.layers.6.bias',\n",
       "              tensor([-0.0024,  0.0420, -0.0199, -0.0580,  0.0214,  0.0259,  0.0459, -0.0071,\n",
       "                      -0.0351, -0.0099, -0.0403, -0.0584,  0.0393, -0.0221,  0.0029, -0.0086,\n",
       "                      -0.0332, -0.0078, -0.0177, -0.0326,  0.0302,  0.0575, -0.0566,  0.0480,\n",
       "                      -0.0265,  0.0364,  0.0366, -0.0320,  0.0380, -0.0539,  0.0601, -0.0115,\n",
       "                       0.0416,  0.0579,  0.0115,  0.0322, -0.0270,  0.0654,  0.0033,  0.0259,\n",
       "                      -0.0106, -0.0280, -0.0216, -0.0478, -0.0521,  0.0177,  0.0147, -0.0652,\n",
       "                       0.0049,  0.0359, -0.0372, -0.0022, -0.0357,  0.0596, -0.0549, -0.0268,\n",
       "                       0.0232,  0.0076, -0.0108, -0.0333,  0.0085, -0.0153, -0.0048, -0.0344])),\n",
       "             ('messageNetwork.layers.0.weight',\n",
       "              tensor([[ 0.0886,  0.0444, -0.0119,  ..., -0.0200,  0.1184,  0.0027],\n",
       "                      [ 0.0556,  0.0024, -0.0551,  ..., -0.0388, -0.1167,  0.1001],\n",
       "                      [ 0.0934, -0.0111,  0.1058,  ...,  0.0316, -0.1285, -0.0353],\n",
       "                      ...,\n",
       "                      [ 0.0363, -0.0496, -0.0275,  ...,  0.1052,  0.0378, -0.0133],\n",
       "                      [-0.1288, -0.1066, -0.0568,  ...,  0.0852,  0.0734, -0.0348],\n",
       "                      [ 0.0529, -0.0747,  0.0212,  ...,  0.0066,  0.0896,  0.0004]])),\n",
       "             ('messageNetwork.layers.0.bias',\n",
       "              tensor([ 0.0431,  0.1027, -0.1254,  0.0939, -0.0045, -0.0124,  0.0497, -0.0397,\n",
       "                      -0.0087, -0.0298, -0.0546,  0.0535,  0.1080, -0.0725, -0.0045,  0.0855,\n",
       "                      -0.0776, -0.0227,  0.0399,  0.0144,  0.1342,  0.0811, -0.1003, -0.0573,\n",
       "                       0.0482,  0.0193, -0.0011, -0.0197,  0.0706,  0.1109,  0.0885,  0.0206,\n",
       "                      -0.0031,  0.0203,  0.1117, -0.0437, -0.0590,  0.0218,  0.0384, -0.0898,\n",
       "                       0.0872,  0.0411, -0.0663, -0.0900,  0.0707, -0.1035, -0.1014, -0.0267,\n",
       "                       0.0866, -0.0662,  0.0483, -0.0841,  0.0095,  0.0217,  0.1115, -0.0849,\n",
       "                      -0.0395,  0.0257, -0.0566,  0.0391,  0.0831,  0.0327,  0.0135, -0.0162,\n",
       "                       0.0268,  0.0705,  0.0779,  0.0079, -0.1004, -0.0570,  0.0529,  0.0516,\n",
       "                       0.0742, -0.1003,  0.0279,  0.0112,  0.0653, -0.0500, -0.0953, -0.0075,\n",
       "                       0.0207,  0.0281,  0.0712,  0.1085, -0.0477,  0.1216,  0.0877, -0.0813,\n",
       "                       0.0986, -0.0344, -0.0601, -0.0473, -0.0202, -0.0073,  0.0731, -0.0532,\n",
       "                       0.0328,  0.0538,  0.0660, -0.0309,  0.0387,  0.0956, -0.0691,  0.0607,\n",
       "                       0.0961,  0.0579, -0.0822,  0.0616,  0.0411,  0.0970,  0.0065,  0.0630,\n",
       "                       0.0419, -0.0575, -0.0194, -0.0877, -0.0093,  0.0759,  0.0354, -0.0573,\n",
       "                       0.0559,  0.0954,  0.0246,  0.0869,  0.0714, -0.0579,  0.0136, -0.0474,\n",
       "                      -0.0091, -0.0832,  0.0176, -0.0772,  0.0672, -0.0888, -0.0145, -0.0983,\n",
       "                       0.0154, -0.0088,  0.0648,  0.0552, -0.0046, -0.0060, -0.0108, -0.0301,\n",
       "                      -0.0811, -0.0858, -0.0880, -0.0038, -0.0983,  0.0405, -0.0935,  0.1029,\n",
       "                      -0.0823, -0.0350,  0.0162,  0.1142, -0.0614, -0.0141,  0.0250,  0.0294,\n",
       "                       0.0917, -0.0531,  0.0995, -0.0557, -0.0316,  0.0386, -0.1199,  0.1203,\n",
       "                      -0.0977, -0.0596, -0.0198, -0.0350, -0.1011, -0.0788,  0.0236,  0.0446,\n",
       "                      -0.0364, -0.1286,  0.0228,  0.0069, -0.0498,  0.0298,  0.0723, -0.0993,\n",
       "                       0.0281, -0.0968, -0.1101,  0.0102,  0.0344,  0.0262, -0.0207,  0.0553,\n",
       "                       0.0547, -0.0550, -0.0273,  0.0690,  0.0161, -0.0615,  0.0385,  0.0218,\n",
       "                      -0.0770,  0.0685, -0.0299,  0.0098, -0.0772, -0.0242,  0.0988,  0.0348,\n",
       "                      -0.1398,  0.0540,  0.0621,  0.0434, -0.0014,  0.0538, -0.0116, -0.0016,\n",
       "                       0.0981, -0.0500, -0.0112, -0.0819,  0.0693,  0.0353, -0.0204, -0.0269,\n",
       "                       0.0529, -0.1112,  0.0909,  0.0780, -0.0902,  0.0500, -0.0698,  0.0775,\n",
       "                       0.0040, -0.0640, -0.0140, -0.0026, -0.0817, -0.0646,  0.0420, -0.0817,\n",
       "                      -0.0846,  0.0222, -0.0817,  0.0836,  0.0572, -0.0123, -0.0709,  0.0345,\n",
       "                      -0.0907, -0.1189, -0.0807, -0.0332,  0.0342, -0.0845,  0.0716,  0.0269])),\n",
       "             ('messageNetwork.layers.1.weight',\n",
       "              tensor([1.0117, 0.9975, 1.0418, 0.9843, 0.9979, 1.0023, 1.0023, 1.0093, 1.0337,\n",
       "                      0.9853, 1.0260, 0.9842, 0.9929, 1.0011, 0.9983, 1.0215, 1.0100, 1.0703,\n",
       "                      0.9969, 0.9817, 1.0155, 1.0133, 1.0095, 1.0264, 1.0155, 0.9729, 1.0102,\n",
       "                      1.0181, 1.0211, 1.0273, 1.0308, 1.0086, 1.0272, 1.0124, 1.0034, 1.0290,\n",
       "                      1.0043, 1.0169, 1.0054, 1.0233, 1.0155, 0.9861, 0.9970, 0.9873, 1.0084,\n",
       "                      1.0034, 0.9967, 1.0336, 0.9777, 0.9834, 1.0470, 1.0009, 1.0320, 1.0033,\n",
       "                      0.9850, 1.0076, 0.9611, 1.0009, 1.0126, 1.0096, 1.0105, 0.9756, 0.9563,\n",
       "                      0.9866, 0.9948, 0.9957, 0.9701, 0.9983, 1.0524, 1.0288, 1.0046, 1.0012,\n",
       "                      0.9637, 1.0122, 0.9536, 1.0142, 0.9709, 1.0811, 1.0368, 0.9966, 1.0264,\n",
       "                      1.0307, 1.0057, 0.9721, 0.9506, 1.0127, 1.0005, 0.9840, 1.0401, 0.9861,\n",
       "                      1.0109, 0.9841, 1.0048, 1.0188, 1.0108, 1.0046, 1.0363, 1.0220, 0.9888,\n",
       "                      1.0179, 0.9754, 1.0414, 0.9892, 1.0055, 0.9958, 0.9641, 0.9974, 1.0002,\n",
       "                      1.0316, 0.9823, 1.0034, 1.0001, 1.0144, 0.9970, 1.0247, 1.0348, 1.0558,\n",
       "                      1.0114, 1.0077, 0.9599, 0.9945, 1.0040, 1.0396, 1.0268, 0.9283, 1.0104,\n",
       "                      1.0129, 0.9934, 0.9926, 0.9911, 0.9778, 1.0720, 0.9873, 1.0348, 0.9965,\n",
       "                      1.0131, 1.0155, 0.9776, 0.9969, 1.0008, 0.9651, 0.9857, 1.0269, 0.9955,\n",
       "                      1.0088, 1.0261, 1.0103, 0.9997, 1.0132, 1.0116, 1.0103, 1.0034, 1.0344,\n",
       "                      1.0422, 0.9947, 1.0515, 0.9852, 1.0239, 1.0089, 0.9992, 0.9637, 1.0211,\n",
       "                      1.0082, 0.9780, 0.9862, 1.0124, 1.0088, 0.9954, 0.9885, 1.0111, 1.0036,\n",
       "                      0.9650, 0.9971, 1.0162, 0.9914, 1.0165, 1.0309, 0.9871, 1.0197, 1.0570,\n",
       "                      1.0375, 0.9809, 1.0274, 1.0291, 1.0043, 1.0057, 1.0020, 0.9832, 0.9852,\n",
       "                      0.9901, 0.9785, 0.9888, 1.0338, 0.9953, 0.9898, 0.9693, 0.9750, 0.9823,\n",
       "                      1.0080, 1.0003, 1.0099, 0.9997, 1.0018, 1.0462, 0.9876, 0.9781, 1.0099,\n",
       "                      1.0285, 1.0364, 0.9718, 0.9885, 0.9913, 1.0545, 0.9740, 0.9865, 1.0081,\n",
       "                      0.9569, 0.9911, 1.0024, 0.9837, 0.9839, 1.0218, 1.0059, 1.0147, 1.0424,\n",
       "                      0.9919, 1.0128, 1.0135, 0.9748, 0.9652, 1.0148, 1.0038, 1.0200, 1.0126,\n",
       "                      0.9667, 1.0021, 1.0099, 1.0212, 0.9840, 1.0066, 0.9896, 0.9971, 1.0050,\n",
       "                      0.9856, 0.9820, 0.9982, 0.9946, 1.0114, 1.0486, 0.9462, 0.9915, 1.1062,\n",
       "                      1.0017, 1.0551, 1.0310, 1.0072])),\n",
       "             ('messageNetwork.layers.1.bias',\n",
       "              tensor([-7.0409e-03, -1.3708e-02, -1.3915e-02, -1.5629e-02, -1.4443e-02,\n",
       "                      -3.4691e-02, -3.0538e-02, -2.5898e-02, -3.2568e-02, -1.9405e-02,\n",
       "                      -3.2917e-02, -1.2576e-02,  6.6949e-03, -2.5890e-02,  4.8629e-04,\n",
       "                      -1.2314e-02,  9.7014e-03, -6.3648e-02, -4.1338e-02, -1.8871e-02,\n",
       "                       1.1910e-02, -1.4764e-03, -2.3104e-02,  1.7233e-02, -2.2822e-03,\n",
       "                      -9.6921e-03,  8.6612e-03, -3.1091e-02,  1.6704e-03, -5.1327e-03,\n",
       "                       4.8661e-03, -3.5160e-03, -2.6897e-04, -1.0880e-02, -1.4412e-02,\n",
       "                       1.8462e-02, -2.8231e-04,  9.0324e-03, -5.5253e-02, -7.2216e-03,\n",
       "                      -2.2403e-03, -2.0005e-02,  2.5887e-02,  1.0123e-02, -1.3398e-02,\n",
       "                      -3.1203e-02, -2.1870e-03,  8.1517e-03, -3.3987e-02, -2.5169e-02,\n",
       "                      -5.6509e-02, -1.7559e-02, -6.0214e-02, -2.4475e-02, -2.7601e-03,\n",
       "                       1.3495e-03, -5.0132e-02, -1.1875e-02,  7.4769e-03, -1.6465e-02,\n",
       "                      -2.9199e-03, -1.1252e-02, -3.6245e-02, -4.6700e-03, -3.4440e-02,\n",
       "                      -1.4599e-02, -4.6666e-02, -3.7611e-02,  3.0074e-03,  2.4938e-02,\n",
       "                      -9.4759e-03, -6.4034e-03, -2.5148e-02, -6.2926e-03, -5.1671e-02,\n",
       "                       2.1939e-03, -3.7769e-02, -2.1946e-02, -4.6418e-02, -2.4459e-02,\n",
       "                       7.0055e-03,  1.9751e-02, -2.3621e-02, -1.8248e-02, -5.4697e-02,\n",
       "                      -2.3952e-02, -1.7044e-02, -6.2780e-02,  1.6390e-02, -4.4205e-02,\n",
       "                      -4.9967e-02,  4.8373e-04, -2.2068e-02,  1.0421e-02, -8.4676e-03,\n",
       "                      -3.2063e-03, -1.7089e-02,  2.9210e-02, -4.3892e-02,  1.7862e-03,\n",
       "                      -4.8520e-02, -9.2361e-03, -8.7272e-03, -5.9627e-02, -2.6512e-02,\n",
       "                      -1.7903e-02, -3.2032e-02, -3.9290e-02, -3.6974e-02, -1.3799e-02,\n",
       "                      -3.3943e-02,  6.8128e-03,  7.8910e-04, -1.7054e-02, -2.1884e-02,\n",
       "                      -7.2142e-02, -6.4302e-04, -5.1225e-04, -5.2815e-02, -6.2356e-02,\n",
       "                      -2.8574e-02, -3.0636e-02,  4.2271e-03,  3.4465e-03, -8.3977e-02,\n",
       "                      -2.7678e-03, -2.0449e-02, -3.9034e-02, -3.1196e-02, -4.8695e-02,\n",
       "                      -2.2872e-02, -4.4130e-02, -2.6832e-02,  2.0523e-02, -1.1135e-02,\n",
       "                      -2.3523e-02, -2.8902e-03, -2.9812e-02, -5.0105e-02, -7.1547e-04,\n",
       "                      -5.6298e-02, -1.7305e-02, -8.7885e-03, -4.1440e-03,  1.8352e-02,\n",
       "                       1.3792e-02, -6.1283e-03, -1.8658e-02, -3.9618e-02,  1.0851e-02,\n",
       "                      -2.6214e-02,  6.1570e-03,  1.6606e-02, -9.3773e-04, -6.7474e-05,\n",
       "                      -1.8947e-02, -3.1887e-02, -1.0153e-02,  7.1663e-03, -2.1445e-02,\n",
       "                      -4.0513e-02,  3.5569e-03, -1.2667e-02, -1.9823e-02, -2.3900e-03,\n",
       "                       5.7364e-03, -6.3691e-03, -1.9509e-03, -3.1199e-02, -1.0356e-02,\n",
       "                       2.9733e-03, -3.7765e-02, -3.2920e-02, -4.1283e-02, -5.0880e-02,\n",
       "                      -5.9276e-03, -1.5136e-02, -3.5978e-02, -3.6485e-02, -1.2992e-02,\n",
       "                       2.4697e-02, -3.1617e-02, -4.9484e-02, -5.9509e-03,  1.6313e-02,\n",
       "                      -3.2561e-02, -3.8202e-02, -2.8720e-02, -8.9581e-03,  1.2798e-02,\n",
       "                      -1.0072e-02,  1.2587e-02, -1.8161e-02,  3.3674e-03, -3.7334e-02,\n",
       "                      -3.2762e-02, -2.3709e-02, -5.5919e-03, -1.0824e-02, -1.0300e-02,\n",
       "                       1.2398e-02,  1.0443e-03, -2.4337e-02, -2.2393e-02, -4.7448e-02,\n",
       "                      -2.1539e-02,  1.1437e-03,  2.1943e-02, -8.4898e-02, -9.5477e-03,\n",
       "                      -2.9555e-02, -4.1406e-02, -1.5003e-02, -4.0594e-02, -1.5343e-02,\n",
       "                      -1.0265e-02, -3.8055e-02, -2.2369e-02, -2.3164e-02, -2.1553e-02,\n",
       "                      -1.6022e-02, -2.1999e-02, -4.7364e-03, -3.5914e-02,  2.8921e-03,\n",
       "                      -3.4897e-02, -1.3080e-02,  2.2820e-03, -4.1812e-02, -6.4345e-02,\n",
       "                       2.9297e-02, -1.4613e-02, -1.2957e-02,  5.4445e-03, -4.1049e-02,\n",
       "                      -3.9632e-02,  3.7063e-03, -1.4900e-02, -9.3134e-03,  3.6570e-03,\n",
       "                      -9.9842e-03, -1.7191e-02, -2.5624e-02, -2.1952e-02, -4.2947e-02,\n",
       "                       2.1529e-02, -1.7647e-02, -2.8475e-03,  1.6311e-02, -7.7982e-02,\n",
       "                      -2.0283e-02,  3.8939e-02,  1.8808e-03,  2.4670e-03,  1.3614e-03,\n",
       "                      -7.0387e-03])),\n",
       "             ('messageNetwork.layers.3.weight',\n",
       "              tensor([[ 0.0671,  0.0185, -0.0022,  ..., -0.0817,  0.0815,  0.0505],\n",
       "                      [-0.0599, -0.0008, -0.0048,  ..., -0.1067,  0.0016, -0.0513],\n",
       "                      [-0.0061,  0.0071, -0.0143,  ..., -0.0854, -0.0412,  0.0184],\n",
       "                      ...,\n",
       "                      [ 0.0069,  0.0070, -0.0450,  ...,  0.0166, -0.0741, -0.0466],\n",
       "                      [-0.0622, -0.0572, -0.0373,  ..., -0.0036, -0.0838,  0.0176],\n",
       "                      [-0.0139, -0.0312,  0.0256,  ...,  0.0247, -0.0025, -0.0371]])),\n",
       "             ('messageNetwork.layers.3.bias',\n",
       "              tensor([ 0.0061,  0.0458, -0.0414, -0.0033, -0.0199, -0.0380, -0.0161,  0.0355,\n",
       "                       0.0492,  0.0401, -0.0160,  0.0251, -0.0349, -0.0527,  0.0283,  0.0057,\n",
       "                       0.0085, -0.0289, -0.0151, -0.0105, -0.0448,  0.0259,  0.0325, -0.0003,\n",
       "                      -0.0264, -0.0496,  0.0046, -0.0180, -0.0227, -0.0492, -0.0280,  0.0354,\n",
       "                       0.0451,  0.0412, -0.0366, -0.0423, -0.0547, -0.0351,  0.0048,  0.0283,\n",
       "                      -0.0106, -0.0541,  0.0413,  0.0320, -0.0001,  0.0131, -0.0164, -0.0627,\n",
       "                       0.0424, -0.0189,  0.0404,  0.0156,  0.0553, -0.0030,  0.0211,  0.0494,\n",
       "                       0.0618,  0.0172, -0.0358,  0.0438,  0.0134, -0.0312,  0.0676, -0.0332,\n",
       "                       0.0411, -0.0139,  0.0327,  0.0775,  0.0277, -0.0484,  0.0666,  0.0466,\n",
       "                       0.0082,  0.0608, -0.0556, -0.0211, -0.0331, -0.0450,  0.0436,  0.0320,\n",
       "                       0.0330, -0.0012,  0.0447, -0.0769, -0.0461, -0.0003, -0.0185,  0.0307,\n",
       "                       0.0251,  0.0138, -0.0105,  0.0353,  0.0512,  0.0189,  0.0348,  0.0593,\n",
       "                       0.0589,  0.0319, -0.0089, -0.0582, -0.0579,  0.0551,  0.0588,  0.0054,\n",
       "                       0.0417,  0.0324, -0.0042, -0.0728,  0.0058, -0.0526,  0.0478, -0.0467,\n",
       "                       0.0736,  0.0234, -0.0424,  0.0449,  0.0071,  0.0166,  0.0223, -0.0313,\n",
       "                       0.0415, -0.0173,  0.0370,  0.0669, -0.0073, -0.0002, -0.0547, -0.0601,\n",
       "                      -0.0346,  0.0631, -0.0114,  0.0128, -0.0191, -0.0237, -0.0154, -0.0382,\n",
       "                       0.0146, -0.0090, -0.0155, -0.0402,  0.0124, -0.0334, -0.0364,  0.0363,\n",
       "                      -0.0242,  0.0722,  0.0686, -0.0093,  0.0746,  0.0581, -0.0099,  0.0234,\n",
       "                      -0.0103, -0.0205, -0.0145,  0.0359,  0.0629,  0.0416, -0.0478, -0.0490,\n",
       "                       0.0360, -0.0711,  0.0490, -0.0153, -0.0474,  0.0034,  0.0322,  0.0389,\n",
       "                       0.0085, -0.0035, -0.0096, -0.0547,  0.0591,  0.0597,  0.0385, -0.0066,\n",
       "                      -0.0036,  0.0169,  0.0303,  0.0462,  0.0005, -0.0459,  0.0160,  0.0516,\n",
       "                      -0.0193, -0.0446,  0.0469,  0.0042,  0.0059, -0.0565,  0.0288,  0.0007,\n",
       "                       0.0225,  0.0564, -0.0763, -0.0126,  0.0297,  0.0546, -0.0119, -0.0035,\n",
       "                       0.0386,  0.0443,  0.0580, -0.0665, -0.0478, -0.0558,  0.0602,  0.0559,\n",
       "                      -0.0162,  0.0293, -0.0399, -0.0535, -0.0163,  0.0655, -0.0229,  0.0208,\n",
       "                       0.0146,  0.0168, -0.0166, -0.0122,  0.0517, -0.0622,  0.0353,  0.0176,\n",
       "                       0.0290,  0.0076, -0.0111,  0.0016,  0.0564, -0.0715,  0.0318, -0.0324,\n",
       "                      -0.0571,  0.0058,  0.0007,  0.0096,  0.0324, -0.0537, -0.0054, -0.0194,\n",
       "                       0.0361,  0.0263, -0.0677,  0.0459, -0.0537,  0.0351, -0.0286,  0.0774,\n",
       "                      -0.0375, -0.0036, -0.0253, -0.0576, -0.0418,  0.0177, -0.0227,  0.0438])),\n",
       "             ('messageNetwork.layers.4.weight',\n",
       "              tensor([1.0525, 1.0446, 1.0084, 0.9973, 0.9899, 0.9968, 1.0198, 1.0518, 0.9946,\n",
       "                      1.0405, 1.0234, 1.0149, 1.0183, 0.9887, 0.9968, 1.0222, 1.0294, 1.0864,\n",
       "                      0.9897, 0.9956, 1.0136, 1.0313, 1.0093, 0.9769, 1.0009, 1.0033, 1.0181,\n",
       "                      0.9986, 0.9821, 1.0673, 1.0011, 1.1077, 1.0055, 1.0096, 1.1015, 1.0029,\n",
       "                      1.0211, 1.1151, 0.9986, 1.0114, 1.0650, 1.0582, 1.0051, 1.0105, 0.9906,\n",
       "                      0.9959, 1.0475, 1.0044, 0.9816, 0.9886, 1.0234, 1.0074, 1.0507, 0.9826,\n",
       "                      1.1222, 1.0177, 1.0484, 0.9903, 0.9933, 1.0128, 0.9941, 0.9858, 1.0401,\n",
       "                      1.0201, 1.0019, 1.0285, 0.9930, 0.9888, 1.0147, 1.0142, 1.0462, 1.0000,\n",
       "                      1.0597, 1.0203, 1.0646, 0.9931, 1.0538, 1.0486, 1.1123, 0.9962, 1.0261,\n",
       "                      1.0024, 1.0191, 1.0235, 1.0387, 0.9627, 1.0499, 1.0112, 1.0065, 1.0203,\n",
       "                      0.9873, 1.0419, 1.0111, 1.0773, 0.9893, 1.0163, 1.0003, 0.9971, 1.0085,\n",
       "                      1.0224, 1.0026, 1.0010, 0.9933, 1.0302, 0.9745, 1.0202, 1.1190, 1.0539,\n",
       "                      0.9835, 0.9557, 0.9835, 1.0090, 1.0380, 1.0034, 0.9715, 1.1103, 1.0138,\n",
       "                      1.0537, 1.0029, 1.0153, 0.9906, 1.0206, 1.0339, 1.0086, 1.0283, 1.0468,\n",
       "                      0.9998, 1.0408, 1.0588, 1.0283, 1.0331, 1.0319, 0.9884, 1.0633, 1.0436,\n",
       "                      1.0263, 1.0277, 1.0861, 1.0411, 1.0138, 1.0547, 1.0048, 1.0078, 1.0384,\n",
       "                      1.0097, 1.0545, 1.0090, 0.9818, 1.0273, 1.0207, 1.0416, 1.0014, 1.0924,\n",
       "                      1.0087, 1.0374, 1.0198, 1.0195, 1.0342, 1.0054, 1.0100, 0.9802, 1.0652,\n",
       "                      1.0401, 1.0199, 1.0477, 1.0349, 0.9989, 1.0049, 0.9716, 1.0139, 1.0257,\n",
       "                      0.9919, 1.0438, 1.0332, 0.9944, 1.0175, 1.0158, 1.0283, 1.0769, 1.0219,\n",
       "                      1.0705, 1.0472, 0.9966, 0.9965, 1.0346, 1.0203, 1.0028, 1.0241, 1.0000,\n",
       "                      1.0591, 0.9942, 1.0228, 1.0062, 1.0151, 0.9863, 0.9712, 1.0285, 1.0000,\n",
       "                      1.0422, 1.0339, 0.9747, 1.0187, 1.0236, 1.0017, 1.0028, 0.9671, 1.0256,\n",
       "                      0.9976, 1.0206, 1.0176, 1.0316, 1.0937, 0.9933, 1.0156, 1.0105, 1.0069,\n",
       "                      0.9945, 1.1068, 1.0101, 1.0038, 0.9874, 1.0155, 1.0268, 1.0409, 1.0822,\n",
       "                      1.0051, 1.0095, 1.0021, 0.9937, 0.9894, 0.9939, 1.0125, 1.0370, 1.0073,\n",
       "                      1.0506, 1.0462, 1.0508, 0.9848, 1.0085, 0.9969, 1.0121, 1.0024, 1.1505,\n",
       "                      0.9991, 0.9920, 0.9852, 0.9998, 1.0164, 1.0360, 1.0658, 1.0080, 1.0125,\n",
       "                      0.9849, 1.0193, 0.9861, 1.0366])),\n",
       "             ('messageNetwork.layers.4.bias',\n",
       "              tensor([-3.6605e-03, -4.8639e-02, -3.2810e-02, -2.1461e-02, -2.4439e-02,\n",
       "                      -1.3974e-02, -5.9072e-02, -2.5584e-02, -1.8982e-02,  4.3298e-03,\n",
       "                      -1.5058e-02, -6.1540e-02, -1.5574e-03, -2.0575e-02, -1.0141e-03,\n",
       "                      -2.6757e-02,  6.6302e-03, -5.9722e-02, -3.5954e-03, -6.7769e-03,\n",
       "                       1.4779e-03,  1.0854e-02, -1.1013e-02, -2.1594e-02, -1.3276e-02,\n",
       "                      -3.3823e-02, -2.8610e-03, -4.9236e-02,  4.7187e-03, -2.5208e-02,\n",
       "                      -1.7878e-03, -6.5832e-02, -1.8746e-02, -7.8488e-03, -3.4136e-02,\n",
       "                      -3.8303e-03, -4.5437e-02, -2.4638e-03, -1.7258e-02, -2.4394e-02,\n",
       "                      -1.7078e-02, -4.7958e-02, -6.5104e-02, -9.4027e-04, -2.2229e-02,\n",
       "                      -7.2638e-02, -6.2073e-02, -2.8763e-02, -2.9271e-02, -2.9610e-03,\n",
       "                      -1.3164e-02, -2.0642e-02, -2.0045e-02, -4.3827e-02, -1.7323e-02,\n",
       "                       2.1978e-03, -3.2676e-02,  2.7708e-03, -1.3564e-02, -1.3691e-02,\n",
       "                      -2.2957e-02, -3.8793e-02,  6.4623e-04, -4.7776e-03, -7.1270e-03,\n",
       "                       1.6216e-02, -2.0043e-02, -4.2073e-03, -5.9447e-02, -3.7287e-02,\n",
       "                      -1.7140e-02, -1.1158e-02, -1.5261e-02, -1.4377e-02, -1.1858e-02,\n",
       "                      -1.9773e-02, -4.7700e-02, -5.9733e-02, -7.4956e-02, -3.6015e-02,\n",
       "                      -4.4482e-03, -1.9954e-02, -4.4584e-02, -3.8765e-02, -5.2385e-02,\n",
       "                      -4.1124e-02, -1.6218e-02, -1.6647e-02, -1.4696e-02, -2.7177e-02,\n",
       "                      -1.1930e-02, -2.6430e-02, -2.1996e-02, -4.4245e-02, -1.8413e-02,\n",
       "                      -2.2481e-02, -2.0587e-02, -1.5984e-02, -2.1515e-02, -2.6471e-02,\n",
       "                      -1.8720e-02, -2.2371e-02, -2.6646e-02, -9.1537e-03, -3.5076e-02,\n",
       "                      -4.6782e-02, -4.4143e-02, -3.1210e-02,  5.0955e-04, -6.5268e-02,\n",
       "                      -2.7093e-02,  1.2539e-03, -5.0244e-03, -1.6039e-02, -9.4190e-02,\n",
       "                      -2.8178e-02, -1.0645e-02, -3.3199e-02, -8.3363e-03, -2.0308e-02,\n",
       "                      -1.8444e-02, -4.3733e-02, -3.4625e-02,  3.9663e-03,  1.0347e-02,\n",
       "                      -1.1523e-02, -5.4898e-02, -3.1653e-02, -3.4180e-02,  1.3617e-02,\n",
       "                      -5.7470e-02, -1.9628e-02, -6.3707e-02, -5.7301e-02, -5.9475e-02,\n",
       "                      -1.0306e-02,  1.3404e-04, -6.1937e-02, -4.9194e-02, -1.8062e-02,\n",
       "                      -1.5560e-02, -2.6508e-03, -5.6430e-02, -1.7247e-02, -1.4214e-02,\n",
       "                      -1.4631e-02, -1.6072e-02, -1.8155e-02, -9.8310e-03, -1.6546e-02,\n",
       "                       6.6380e-03, -1.2818e-02, -2.3207e-02, -2.7064e-02,  2.9938e-02,\n",
       "                      -1.2531e-02, -1.4576e-02,  1.8879e-02, -2.1294e-02,  1.5686e-05,\n",
       "                      -6.5404e-03, -3.5828e-02,  1.2275e-02, -3.1308e-02, -3.2567e-02,\n",
       "                      -2.1296e-02, -3.0331e-02, -1.2485e-02, -2.6610e-02, -4.5610e-02,\n",
       "                      -1.1797e-02, -3.1331e-02, -3.3769e-02, -1.7392e-02, -2.4861e-02,\n",
       "                      -2.4721e-02, -2.2183e-02,  1.4295e-02, -4.3731e-02, -1.3400e-02,\n",
       "                      -3.6152e-02, -3.7191e-02, -2.7155e-02, -1.7702e-02, -2.4584e-02,\n",
       "                      -1.7814e-02,  3.8236e-03, -1.6510e-02, -3.4340e-02, -2.0523e-02,\n",
       "                      -1.2927e-02,  7.1414e-03, -1.2553e-02, -2.3017e-02, -4.0530e-02,\n",
       "                      -1.7709e-02, -8.2440e-03, -2.0389e-03, -2.9508e-02, -4.9093e-05,\n",
       "                      -1.3972e-02, -2.4881e-02, -8.8686e-03, -3.2308e-02, -1.0229e-02,\n",
       "                      -4.0871e-02, -8.1325e-03, -6.5201e-03, -9.3242e-03, -1.9174e-02,\n",
       "                      -5.7274e-02, -3.3809e-02, -3.2398e-02,  1.5497e-03, -1.4188e-02,\n",
       "                      -2.4534e-03, -2.9377e-02, -4.8675e-02, -1.0860e-02, -6.0163e-03,\n",
       "                      -1.4456e-02, -1.0238e-02, -1.5565e-03, -1.0822e-02, -3.3689e-02,\n",
       "                      -8.7921e-03, -9.4661e-03, -5.3857e-03, -2.0142e-02, -2.7496e-02,\n",
       "                       4.2227e-03, -1.3952e-02, -2.4922e-02,  6.1611e-03, -2.8957e-02,\n",
       "                      -5.9698e-02, -5.5486e-03, -1.7812e-02, -1.4351e-02, -2.2534e-02,\n",
       "                      -3.4565e-03, -1.3179e-02, -3.4548e-02,  7.9029e-04, -2.2032e-02,\n",
       "                      -4.1446e-02, -1.9070e-02,  6.8122e-03, -1.8359e-02, -4.6856e-03,\n",
       "                      -5.9798e-03, -3.5879e-03, -7.6638e-03, -2.4584e-03, -4.0740e-02,\n",
       "                      -1.9394e-04])),\n",
       "             ('messageNetwork.layers.6.weight',\n",
       "              tensor([[-0.0729,  0.0020,  0.0349,  ...,  0.0732,  0.0030,  0.0609],\n",
       "                      [ 0.0288,  0.0105, -0.0030,  ...,  0.0299, -0.0266, -0.0750],\n",
       "                      [-0.0022,  0.0482, -0.0723,  ...,  0.0574, -0.0157,  0.0383],\n",
       "                      ...,\n",
       "                      [ 0.0354,  0.0505,  0.0452,  ..., -0.0961, -0.1048,  0.0036],\n",
       "                      [ 0.0386,  0.0019,  0.0133,  ..., -0.0902, -0.0185, -0.0112],\n",
       "                      [-0.1037, -0.1283, -0.0486,  ..., -0.0225,  0.0315, -0.0179]])),\n",
       "             ('messageNetwork.layers.6.bias',\n",
       "              tensor([-0.0487,  0.0018,  0.0430, -0.0331,  0.0562,  0.0116, -0.0679,  0.0318,\n",
       "                      -0.0097, -0.0408, -0.0503,  0.0143, -0.0386, -0.0382, -0.0514,  0.0643,\n",
       "                       0.0127, -0.0625, -0.0343,  0.0328,  0.0354,  0.0152,  0.0486, -0.0582,\n",
       "                       0.0428, -0.0076,  0.0496, -0.0506, -0.0116, -0.0081, -0.0420, -0.0531,\n",
       "                       0.0218, -0.0595,  0.0587, -0.0039, -0.0190,  0.0073, -0.0419, -0.0479,\n",
       "                       0.0460, -0.0575, -0.0551, -0.0255, -0.0470,  0.0043,  0.0329, -0.0069,\n",
       "                       0.0170,  0.0222, -0.0101, -0.0635,  0.0117,  0.0590,  0.0546,  0.0369,\n",
       "                       0.0662,  0.0288,  0.0108,  0.0209, -0.0542, -0.0290, -0.0108,  0.0046])),\n",
       "             ('updateNetwork.layers.0.weight',\n",
       "              tensor([[-0.0010, -0.0154, -0.0384,  ...,  0.0322,  0.0262, -0.0805],\n",
       "                      [ 0.0008,  0.0658, -0.0628,  ...,  0.0669,  0.0011,  0.0006],\n",
       "                      [ 0.0276, -0.0711, -0.1060,  ...,  0.0372, -0.0649, -0.0609],\n",
       "                      ...,\n",
       "                      [-0.0296, -0.0730, -0.0975,  ..., -0.0285,  0.0796, -0.0173],\n",
       "                      [-0.0600, -0.0980,  0.1053,  ..., -0.0878,  0.0763, -0.0472],\n",
       "                      [ 0.0003, -0.0513,  0.0623,  ...,  0.0723,  0.0588,  0.0604]])),\n",
       "             ('updateNetwork.layers.0.bias',\n",
       "              tensor([-0.0320, -0.0137, -0.0139,  0.0366,  0.0066, -0.0520, -0.0343, -0.0371,\n",
       "                       0.0807, -0.0950,  0.0378,  0.0075, -0.0342, -0.0770,  0.0253, -0.0984,\n",
       "                       0.0038, -0.0844, -0.0177, -0.0451,  0.0649,  0.0541, -0.0368, -0.0540,\n",
       "                       0.0394,  0.0629, -0.0850,  0.0723, -0.0807, -0.0575,  0.0336,  0.0602,\n",
       "                       0.0379, -0.0231, -0.0325, -0.0183,  0.0744,  0.0845, -0.0090,  0.0431,\n",
       "                       0.0175, -0.0502, -0.0571, -0.0492, -0.0710,  0.0160, -0.0966, -0.0652,\n",
       "                       0.0028,  0.0557, -0.0334, -0.0067, -0.0046, -0.0217, -0.0493,  0.0239,\n",
       "                       0.0513, -0.0257,  0.0799,  0.0027,  0.0449,  0.0118, -0.0746, -0.0540,\n",
       "                       0.0298, -0.0668,  0.0263,  0.0596,  0.0715,  0.0656,  0.0191, -0.0116,\n",
       "                       0.0522,  0.0312, -0.0637,  0.0425,  0.0124, -0.0475, -0.0232, -0.0830,\n",
       "                       0.0580, -0.0076,  0.0700, -0.0530,  0.0008, -0.0143, -0.0230, -0.0472,\n",
       "                       0.0128,  0.0165, -0.0359,  0.0070, -0.0434, -0.0073,  0.0821, -0.0657,\n",
       "                       0.0614, -0.0459, -0.0384, -0.0225, -0.0504, -0.0507, -0.1113, -0.0269,\n",
       "                       0.0030, -0.0110,  0.0417, -0.0678,  0.0219,  0.0639, -0.0259, -0.0343,\n",
       "                       0.0853, -0.0291,  0.0762,  0.0011, -0.0612,  0.0508,  0.0188,  0.0225,\n",
       "                      -0.0809, -0.0224, -0.0751, -0.0890, -0.0606, -0.0456, -0.0883, -0.0243,\n",
       "                       0.0955,  0.0387,  0.0363,  0.0807, -0.0499, -0.0363, -0.0178, -0.0195,\n",
       "                       0.0833,  0.0276, -0.0266, -0.0741, -0.0485, -0.0268, -0.0525,  0.0054,\n",
       "                       0.0145, -0.0449,  0.0300,  0.0451, -0.0371,  0.0451,  0.0088, -0.0131,\n",
       "                       0.0631,  0.0494, -0.0188,  0.0138, -0.0271, -0.0012, -0.0367, -0.0929,\n",
       "                       0.0748, -0.0037, -0.0301,  0.0036,  0.0283, -0.0476, -0.0513,  0.0557,\n",
       "                       0.0695, -0.0134, -0.0140,  0.0402, -0.0004,  0.0237, -0.0604, -0.0576,\n",
       "                      -0.0796, -0.0977,  0.0582, -0.0469,  0.0389, -0.0707,  0.0232, -0.0647,\n",
       "                       0.0558,  0.0586, -0.0460, -0.0546, -0.0436, -0.0159, -0.0456, -0.0360,\n",
       "                       0.0640, -0.0802, -0.0108,  0.0455,  0.0436,  0.0907, -0.0831, -0.0409,\n",
       "                      -0.0436, -0.0546, -0.0062,  0.0115, -0.0519, -0.0501,  0.0593, -0.0619,\n",
       "                       0.0827,  0.0540,  0.0407,  0.0149,  0.0532, -0.0122,  0.0343,  0.0314,\n",
       "                       0.0489,  0.0650, -0.0722,  0.0037,  0.0644,  0.0477,  0.0628, -0.0500,\n",
       "                       0.0168, -0.0295, -0.0609, -0.0589, -0.0038,  0.1024, -0.0949,  0.0449,\n",
       "                       0.0472,  0.0411, -0.0239, -0.0724, -0.0399,  0.0270, -0.0336,  0.0853,\n",
       "                       0.0473, -0.0708,  0.0238, -0.0410, -0.0255, -0.0436,  0.0452, -0.0156,\n",
       "                      -0.0002, -0.0266, -0.0159, -0.0067,  0.0107, -0.0245,  0.0505,  0.0299])),\n",
       "             ('updateNetwork.layers.1.weight',\n",
       "              tensor([1.0234, 1.0175, 1.0050, 1.0142, 1.0083, 0.9979, 1.1202, 1.0035, 1.0378,\n",
       "                      1.0161, 0.9887, 1.0257, 0.9938, 1.0281, 1.0172, 1.0324, 0.9907, 1.0196,\n",
       "                      1.0342, 1.0421, 1.0372, 1.0519, 0.9763, 0.9670, 1.0143, 0.9810, 1.0672,\n",
       "                      0.9647, 1.0433, 1.0365, 1.0080, 0.9765, 1.0039, 1.0241, 1.0008, 1.0913,\n",
       "                      0.9849, 1.0098, 0.9979, 0.9943, 1.0576, 1.0150, 1.0781, 1.0191, 0.9985,\n",
       "                      0.9812, 0.9904, 1.0085, 1.0531, 0.9805, 1.0237, 0.9853, 1.0096, 1.0384,\n",
       "                      1.0243, 1.0499, 0.9971, 1.0936, 1.0301, 0.9821, 0.9782, 0.9879, 1.0015,\n",
       "                      1.0726, 1.0475, 1.0185, 0.9645, 1.0098, 1.0089, 0.9910, 1.0021, 1.0004,\n",
       "                      1.0037, 1.0170, 0.9904, 1.0018, 1.0056, 1.0281, 0.9871, 1.0334, 1.0357,\n",
       "                      1.0038, 0.9709, 1.0066, 1.0065, 0.9733, 1.0917, 1.0388, 1.0254, 1.0066,\n",
       "                      1.0211, 0.9998, 1.0041, 0.9976, 1.0032, 0.9975, 1.0126, 0.9910, 1.0428,\n",
       "                      1.0094, 1.0335, 0.9831, 1.1060, 1.0354, 0.9959, 1.0188, 1.0045, 1.0220,\n",
       "                      1.0063, 0.9882, 1.0123, 0.9970, 1.0216, 1.0265, 1.0006, 1.0119, 1.0060,\n",
       "                      1.0483, 0.9923, 1.0083, 1.0153, 1.0015, 1.0093, 1.0218, 1.0000, 1.0829,\n",
       "                      1.0420, 1.0184, 1.0069, 1.0148, 0.9881, 0.9880, 1.0541, 1.0186, 1.0262,\n",
       "                      1.0317, 0.9980, 0.9856, 0.9987, 1.0024, 1.0311, 1.0274, 1.0369, 1.0084,\n",
       "                      0.9910, 1.0189, 0.9692, 1.0116, 1.0394, 1.0214, 1.0176, 0.9890, 0.9782,\n",
       "                      0.9875, 1.0109, 1.0333, 1.0152, 1.0098, 1.0208, 0.9648, 0.9956, 1.0399,\n",
       "                      1.0206, 1.0252, 1.0016, 0.9943, 1.0010, 0.9854, 0.9831, 0.9936, 1.0303,\n",
       "                      1.0121, 1.0125, 1.0664, 1.0173, 1.0034, 1.0463, 1.0621, 0.9790, 1.0229,\n",
       "                      1.0122, 1.0335, 1.0223, 1.0044, 1.0142, 1.0096, 1.0036, 1.0108, 1.0295,\n",
       "                      0.9680, 1.0205, 1.0010, 0.9971, 1.0118, 1.0410, 1.0373, 1.0341, 1.0183,\n",
       "                      0.9867, 0.9956, 0.9970, 1.0510, 1.0115, 0.9831, 1.0294, 0.9858, 1.0622,\n",
       "                      1.0282, 0.9985, 0.9962, 1.0115, 1.0193, 1.0026, 1.0073, 1.0260, 0.9839,\n",
       "                      1.0584, 0.9797, 1.0295, 0.9911, 1.0365, 0.9880, 1.0389, 0.9946, 1.0370,\n",
       "                      1.0066, 1.0075, 1.0092, 1.0529, 1.0105, 1.0016, 1.0194, 1.0282, 1.0005,\n",
       "                      1.0120, 1.0247, 1.0131, 1.0645, 1.0257, 0.9906, 1.0498, 1.0277, 1.0195,\n",
       "                      0.9830, 1.0459, 1.0353, 0.9981, 0.9850, 1.0099, 0.9851, 1.0212, 0.9928,\n",
       "                      0.9874, 1.0238, 1.0171, 0.9974])),\n",
       "             ('updateNetwork.layers.1.bias',\n",
       "              tensor([-0.0542,  0.0023, -0.0208, -0.0097, -0.0081, -0.0040, -0.0164,  0.0016,\n",
       "                       0.0005, -0.0288, -0.0329, -0.0389, -0.0144, -0.0233, -0.0367, -0.0220,\n",
       "                      -0.0095, -0.0100, -0.0819, -0.0193, -0.0300, -0.0049, -0.0296, -0.0584,\n",
       "                      -0.0251, -0.0225, -0.0246, -0.0289, -0.0194,  0.0020, -0.0363, -0.0006,\n",
       "                      -0.0015, -0.0289, -0.0393, -0.0237, -0.0238, -0.0113, -0.0141, -0.0278,\n",
       "                      -0.0422, -0.0188, -0.0331, -0.0277, -0.0091, -0.0501, -0.0200,  0.0016,\n",
       "                      -0.0492, -0.0341, -0.0171, -0.0222, -0.0608, -0.0221,  0.0199, -0.0157,\n",
       "                      -0.0088, -0.0428, -0.0236, -0.0735, -0.0228, -0.0197, -0.0158, -0.0114,\n",
       "                      -0.0216, -0.0275, -0.0163,  0.0289, -0.0214, -0.0096, -0.0189, -0.0356,\n",
       "                      -0.0237, -0.0167, -0.0232, -0.0356,  0.0067, -0.0364, -0.0009, -0.0216,\n",
       "                      -0.0288, -0.0279, -0.0388, -0.0324, -0.0371, -0.0372, -0.0248, -0.0045,\n",
       "                       0.0308, -0.0331,  0.0027, -0.0421, -0.0167, -0.0330, -0.0039, -0.0381,\n",
       "                      -0.0324, -0.0246, -0.0379, -0.0051, -0.0204,  0.0147, -0.0571,  0.0109,\n",
       "                      -0.0469, -0.0658,  0.0032, -0.0152, -0.0194, -0.0242,  0.0109,  0.0121,\n",
       "                      -0.0094, -0.0204, -0.0125, -0.0148, -0.0737,  0.0325, -0.0150, -0.0195,\n",
       "                      -0.0036, -0.0409, -0.0142, -0.0832, -0.0072, -0.0299, -0.0502, -0.0873,\n",
       "                      -0.0069, -0.0146, -0.0326,  0.0026, -0.0037, -0.0182, -0.0454, -0.0491,\n",
       "                      -0.0057, -0.0114, -0.0272, -0.0168, -0.0374,  0.0104, -0.0168, -0.0789,\n",
       "                      -0.0078, -0.0156, -0.0110, -0.0172, -0.0208, -0.0155, -0.0240, -0.0378,\n",
       "                      -0.0234, -0.0056, -0.0287, -0.0260, -0.0005, -0.0137,  0.0165, -0.0382,\n",
       "                      -0.0210, -0.0582, -0.0103,  0.0145, -0.0270,  0.0116, -0.0376, -0.0219,\n",
       "                      -0.0250, -0.0124, -0.0570,  0.0053,  0.0050, -0.0165, -0.0197, -0.0003,\n",
       "                      -0.0397, -0.0264, -0.0249, -0.0271, -0.0147, -0.0308, -0.0424,  0.0004,\n",
       "                      -0.0228, -0.0022, -0.0261, -0.0245, -0.0159, -0.0365, -0.0097, -0.0520,\n",
       "                      -0.0173, -0.0152, -0.0136, -0.0237,  0.0134,  0.0206, -0.0503,  0.0025,\n",
       "                       0.0047, -0.0547, -0.0432, -0.0353, -0.0414, -0.0206, -0.0403,  0.0248,\n",
       "                      -0.0168, -0.0062,  0.0079, -0.0123, -0.0633, -0.0002,  0.0108, -0.0054,\n",
       "                      -0.0141, -0.0263, -0.0464, -0.0222, -0.0279, -0.0336, -0.0300, -0.0484,\n",
       "                      -0.0426, -0.0270,  0.0185, -0.0417, -0.0238,  0.0110, -0.0192, -0.0398,\n",
       "                      -0.0349, -0.0142, -0.0136, -0.0069, -0.0074, -0.0029,  0.0105, -0.0263,\n",
       "                      -0.0152, -0.0172, -0.0212, -0.0191, -0.0362, -0.0730, -0.0083, -0.0436,\n",
       "                      -0.0100, -0.0469, -0.0099,  0.0088, -0.0262, -0.0295,  0.0182, -0.0102])),\n",
       "             ('updateNetwork.layers.3.weight',\n",
       "              tensor([[ 0.0444, -0.0132,  0.0112,  ..., -0.0256,  0.0511,  0.0173],\n",
       "                      [ 0.0782, -0.0429,  0.0436,  ..., -0.0575, -0.0291,  0.0342],\n",
       "                      [ 0.0568, -0.0404, -0.0619,  ...,  0.0035,  0.0908, -0.0519],\n",
       "                      ...,\n",
       "                      [ 0.0129,  0.0090,  0.0023,  ..., -0.0272, -0.0265,  0.0188],\n",
       "                      [ 0.0658, -0.0044, -0.0652,  ..., -0.0235,  0.1030, -0.0136],\n",
       "                      [ 0.0860, -0.0382, -0.0463,  ..., -0.0353,  0.0795,  0.0064]])),\n",
       "             ('updateNetwork.layers.3.bias',\n",
       "              tensor([-5.3062e-02,  3.2644e-02, -1.9237e-02, -6.0141e-02,  3.2083e-02,\n",
       "                      -3.0403e-02, -1.8899e-02,  5.7059e-02,  4.9917e-02, -4.8473e-03,\n",
       "                       6.6289e-02, -2.7819e-02,  4.6831e-02,  5.9363e-02,  4.9554e-02,\n",
       "                       3.9032e-02,  7.4453e-02, -3.9993e-03,  8.4013e-03,  1.2180e-02,\n",
       "                       5.4865e-02, -3.9633e-02, -3.4061e-02,  6.5520e-02,  1.1072e-02,\n",
       "                       1.8260e-02, -6.2680e-03, -4.1248e-02,  5.6456e-02,  7.4039e-03,\n",
       "                      -1.5317e-02, -2.1268e-02, -3.3738e-02, -2.0204e-02, -1.5796e-02,\n",
       "                      -4.6803e-02, -8.9659e-03, -3.7312e-02,  5.9393e-02,  3.1162e-02,\n",
       "                       4.6135e-02,  2.5373e-02, -5.6192e-02, -1.6243e-01,  8.2817e-02,\n",
       "                      -3.4310e-02,  6.9227e-02,  4.4974e-03, -5.7389e-03, -1.0184e-02,\n",
       "                      -1.1862e-02, -3.7776e-02,  5.7867e-02,  8.9239e-03, -5.3296e-04,\n",
       "                       9.3497e-03, -4.9145e-02, -1.0010e-02,  8.1813e-03,  6.0193e-02,\n",
       "                      -6.4164e-02, -3.5792e-02,  5.0012e-02, -5.9881e-02,  5.5016e-02,\n",
       "                       3.9230e-02, -1.3740e-02, -4.8066e-02, -9.3590e-02, -5.6220e-02,\n",
       "                       2.2573e-02, -5.8659e-02,  2.1607e-02, -6.7039e-02, -1.1162e-02,\n",
       "                      -2.8072e-02,  6.6152e-02, -4.8639e-02, -1.4050e-02,  5.3360e-02,\n",
       "                      -1.1500e-02,  4.8623e-02, -3.9568e-02,  2.0407e-02, -2.3566e-02,\n",
       "                       5.8412e-02,  1.1128e-02,  4.0051e-02,  3.2257e-02,  1.4642e-02,\n",
       "                      -7.3170e-02,  4.6875e-02, -4.9175e-02,  4.1115e-02,  4.7485e-02,\n",
       "                      -5.6700e-02, -4.1258e-02, -4.7061e-02, -2.5461e-02,  3.2541e-02,\n",
       "                       3.1728e-02, -1.3340e-02,  2.8644e-02,  3.8813e-02,  2.9229e-02,\n",
       "                       2.8110e-02, -4.2120e-02, -4.6256e-02,  1.4812e-02, -3.9197e-02,\n",
       "                      -2.5537e-02,  5.8857e-02, -2.7664e-02, -1.6702e-02,  4.3299e-02,\n",
       "                       5.1380e-02, -6.7343e-02, -3.6691e-02, -4.7283e-02,  5.7823e-02,\n",
       "                       2.6507e-02, -5.9050e-02, -1.9896e-02,  9.8381e-03, -1.6927e-02,\n",
       "                       5.4292e-02,  1.6880e-02,  2.7725e-02,  2.4721e-02,  2.8778e-02,\n",
       "                      -3.5966e-02,  2.9308e-02,  3.1416e-02,  5.5100e-02, -1.2596e-02,\n",
       "                       5.0163e-02,  6.2728e-02, -3.5948e-02, -8.7975e-03, -3.1213e-03,\n",
       "                      -4.6352e-02, -9.2010e-03, -5.9738e-02,  1.1806e-02,  3.1297e-02,\n",
       "                      -5.2561e-02,  4.5850e-02,  5.9114e-02,  2.6227e-02, -1.1859e-02,\n",
       "                      -1.5785e-02, -1.2335e-03,  2.0334e-02,  4.7195e-03, -5.4255e-02,\n",
       "                      -1.5606e-02,  1.5212e-04, -2.9419e-02,  5.3652e-02, -2.0411e-02,\n",
       "                       1.1300e-02,  4.6549e-02,  6.9746e-03, -9.5069e-02,  5.1753e-03,\n",
       "                      -5.3541e-02,  1.1265e-02, -3.6500e-02, -4.2993e-02,  2.1158e-02,\n",
       "                       4.7270e-02,  1.4339e-02,  6.4085e-03,  5.8342e-02,  4.2975e-02,\n",
       "                       6.0384e-02,  3.8637e-02, -2.5819e-02,  6.6542e-02,  5.8047e-02,\n",
       "                      -4.2506e-02,  4.7329e-02,  5.9958e-02,  7.0318e-03, -4.0518e-02,\n",
       "                      -2.8172e-02,  6.5639e-02,  2.5410e-02, -4.6235e-03, -6.6115e-02,\n",
       "                       6.1318e-02,  6.0724e-03,  4.1327e-02, -2.7147e-02, -2.6645e-02,\n",
       "                       4.1204e-03,  3.5357e-02, -4.6362e-02,  5.5350e-03,  4.2461e-02,\n",
       "                       3.0421e-02, -3.1871e-02,  4.6043e-02,  1.2514e-02, -5.5632e-02,\n",
       "                       1.1449e-02,  2.4064e-02, -2.9863e-02, -9.7646e-03, -1.1080e-02,\n",
       "                       1.4037e-02, -3.5664e-02,  3.7541e-03,  1.5423e-02, -7.4700e-03,\n",
       "                       3.2427e-02,  1.7276e-02, -3.1773e-02, -5.9099e-02, -2.5348e-02,\n",
       "                       1.3553e-02, -4.9134e-02, -3.0531e-02,  3.8869e-02, -5.5698e-03,\n",
       "                      -7.2202e-03, -6.1937e-02, -1.2661e-01,  7.5330e-02,  3.9023e-02,\n",
       "                      -3.9222e-02,  5.2026e-02,  7.5642e-03,  6.0083e-02,  4.7765e-03,\n",
       "                       4.8418e-02, -3.5720e-02, -9.1025e-03, -2.3259e-02,  5.6814e-03,\n",
       "                       4.8258e-02,  3.3583e-02, -1.2593e-02, -5.6528e-02, -6.4573e-02,\n",
       "                      -7.7524e-04,  5.4365e-02,  3.4250e-02, -4.6892e-03, -3.7887e-02,\n",
       "                       5.3076e-02,  5.2033e-02, -3.3993e-02,  7.0937e-03,  2.2198e-02,\n",
       "                      -2.3422e-02])),\n",
       "             ('updateNetwork.layers.4.weight',\n",
       "              tensor([0.9760, 1.0358, 0.9643, 0.9856, 0.9747, 0.9896, 0.9863, 0.9658, 0.9780,\n",
       "                      0.9612, 0.9973, 1.0006, 0.9630, 0.9636, 1.0220, 0.9448, 0.9847, 0.9848,\n",
       "                      1.0313, 0.9728, 0.9603, 0.9887, 1.1011, 0.9961, 0.9859, 1.0974, 1.0149,\n",
       "                      0.9874, 0.9612, 0.9907, 0.9968, 1.0394, 0.9572, 0.9906, 0.9843, 0.9859,\n",
       "                      0.9817, 0.9947, 0.9642, 0.9954, 0.9769, 0.9670, 0.9768, 1.0000, 0.9749,\n",
       "                      0.9603, 0.9735, 0.9550, 1.0497, 1.0145, 1.0164, 0.9907, 0.9660, 0.9844,\n",
       "                      0.9680, 0.9769, 1.0288, 1.1191, 0.9824, 0.9724, 0.9976, 1.0368, 0.9878,\n",
       "                      1.0170, 0.9645, 0.9728, 1.0512, 1.0170, 1.0000, 1.0136, 0.9866, 0.9629,\n",
       "                      0.9711, 0.9785, 0.9793, 1.0569, 0.9886, 0.9882, 0.9574, 0.9385, 0.9651,\n",
       "                      0.9826, 0.9718, 1.0466, 0.9845, 0.9531, 1.0688, 1.0370, 0.9905, 1.0415,\n",
       "                      1.0000, 0.9741, 1.0179, 0.9455, 1.0084, 0.9652, 0.9998, 0.9976, 1.1129,\n",
       "                      0.9664, 1.0199, 0.9674, 0.9941, 0.9750, 0.9739, 1.0936, 1.0023, 0.9797,\n",
       "                      1.0160, 0.9916, 1.0261, 0.9600, 0.9813, 0.9891, 1.1547, 0.9551, 1.0353,\n",
       "                      0.9891, 1.0531, 0.9858, 0.9598, 0.9968, 0.9491, 0.9780, 0.9514, 0.9622,\n",
       "                      0.9614, 1.0026, 0.9720, 0.9976, 0.9870, 0.9895, 0.9740, 0.9769, 0.9661,\n",
       "                      1.0000, 0.9723, 1.1918, 0.9756, 0.9757, 0.9813, 0.9870, 1.0038, 1.0057,\n",
       "                      1.0042, 0.9597, 0.9562, 0.9572, 0.9860, 0.9992, 0.9674, 0.9901, 0.9440,\n",
       "                      0.9950, 0.9759, 1.0105, 0.9473, 1.0093, 0.9585, 0.9657, 0.9870, 0.9628,\n",
       "                      0.9825, 1.0000, 1.0241, 1.0378, 0.9939, 0.9756, 0.9714, 0.9948, 0.9640,\n",
       "                      0.9235, 0.9786, 1.0451, 1.0438, 0.9637, 0.9732, 1.0408, 0.9968, 0.9725,\n",
       "                      1.0000, 0.9804, 1.0269, 1.0485, 1.0160, 0.9634, 1.0038, 1.0167, 0.9699,\n",
       "                      0.9833, 0.9987, 0.9880, 0.9786, 0.9754, 1.0856, 1.0202, 0.9773, 0.9294,\n",
       "                      1.0165, 0.9566, 0.9632, 1.0310, 0.9682, 0.9803, 1.0333, 1.0182, 0.9861,\n",
       "                      0.9753, 0.9788, 1.0430, 0.9907, 0.9540, 1.0196, 1.0047, 0.9802, 1.0165,\n",
       "                      1.0154, 1.0962, 0.9548, 0.9882, 1.0081, 0.9588, 1.0189, 0.9875, 1.0592,\n",
       "                      1.0109, 1.0135, 0.9939, 0.9501, 0.9879, 0.9741, 0.9729, 1.0035, 1.0069,\n",
       "                      1.0270, 1.0031, 0.9695, 0.9584, 0.9900, 0.9522, 0.9684, 1.0137, 0.9527,\n",
       "                      0.9416, 0.9930, 0.9828, 0.9991, 0.9830, 0.9715, 0.9600, 0.9749, 0.9820,\n",
       "                      0.9723, 1.0040, 0.9785, 1.0049])),\n",
       "             ('updateNetwork.layers.4.bias',\n",
       "              tensor([-0.0372, -0.0429, -0.0488, -0.0495, -0.0419, -0.0235, -0.0294, -0.0342,\n",
       "                      -0.0352, -0.0370, -0.0149, -0.0448, -0.0254, -0.0295, -0.0314, -0.0383,\n",
       "                      -0.0199, -0.0569, -0.0346, -0.0282, -0.0262, -0.0256, -0.0383, -0.0232,\n",
       "                      -0.0236, -0.0782, -0.0145, -0.0319, -0.0384, -0.0259, -0.0506, -0.0518,\n",
       "                      -0.0368, -0.0548, -0.0462, -0.0429, -0.0144, -0.0232, -0.0225, -0.0113,\n",
       "                      -0.0187, -0.0355, -0.0432,  0.0000,  0.0005, -0.0344, -0.0193, -0.0645,\n",
       "                      -0.0677, -0.0663, -0.0539, -0.0352, -0.0218, -0.0348, -0.0184, -0.0399,\n",
       "                      -0.0250, -0.0855, -0.0494, -0.0308, -0.0945, -0.0384, -0.0312, -0.0864,\n",
       "                      -0.0352, -0.0109, -0.0544, -0.0218,  0.0000, -0.0677, -0.0163, -0.0353,\n",
       "                      -0.0217,  0.1020, -0.0401, -0.0991, -0.0280, -0.0370, -0.0406, -0.0822,\n",
       "                      -0.0528, -0.0230, -0.0365, -0.0626, -0.0491, -0.0472, -0.0409, -0.0392,\n",
       "                      -0.0033, -0.0715,  0.0000, -0.0244, -0.0549, -0.0339, -0.0492, -0.0345,\n",
       "                      -0.0468, -0.0549,  0.1485, -0.0411, -0.0739, -0.0222, -0.0177, -0.0257,\n",
       "                      -0.0229, -0.0593, -0.0346, -0.0179, -0.0816, -0.0549, -0.1114, -0.0268,\n",
       "                      -0.0982, -0.0381, -0.0511, -0.0340, -0.0823, -0.0458, -0.0669, -0.0259,\n",
       "                      -0.0864, -0.0583, -0.0413, -0.0348, -0.0241, -0.0321, -0.0438, -0.0333,\n",
       "                      -0.0346, -0.0262, -0.0227, -0.0142, -0.0497, -0.0265, -0.0243, -0.0766,\n",
       "                      -0.0310, -0.0010, -0.0419, -0.0194, -0.0187, -0.0169, -0.0466, -0.0333,\n",
       "                      -0.0212, -0.0322, -0.0400, -0.0326, -0.0203, -0.0361, -0.0129, -0.0441,\n",
       "                      -0.0325, -0.0415, -0.0787, -0.0424, -0.0675, -0.0498, -0.0450, -0.0209,\n",
       "                      -0.0815, -0.0238, -0.0552,  0.0000, -0.0295, -0.0526, -0.0686, -0.0259,\n",
       "                      -0.0430, -0.0290, -0.0616, -0.0384, -0.0388, -0.0514, -0.1003, -0.0198,\n",
       "                      -0.0549, -0.0750, -0.0095, -0.0293,  0.0000, -0.0639, -0.0389, -0.1186,\n",
       "                      -0.0470, -0.0377, -0.0056, -0.0373, -0.0424, -0.0464, -0.0102, -0.0486,\n",
       "                      -0.0235, -0.0212, -0.0543, -0.0134, -0.0275, -0.0548, -0.0580, -0.0278,\n",
       "                      -0.0615, -0.0351, -0.0185, -0.0209, -0.0282, -0.0493, -0.0396, -0.0514,\n",
       "                      -0.0325, -0.0428, -0.0735, -0.0273, -0.0526, -0.0288, -0.0236, -0.0645,\n",
       "                      -0.0447, -0.0187, -0.1079, -0.0827, -0.0685, -0.0454, -0.0380, -0.0283,\n",
       "                      -0.0494, -0.1039, -0.0732, -0.0081, -0.0170, -0.0288, -0.0200, -0.0410,\n",
       "                      -0.0290, -0.0250, -0.0830, -0.0451, -0.0320, -0.0456, -0.0279, -0.0120,\n",
       "                      -0.0351, -0.0423, -0.0336, -0.0421, -0.0374, -0.0233, -0.0258, -0.0283,\n",
       "                      -0.0281, -0.0473, -0.0565, -0.0249, -0.0702, -0.0481, -0.0494, -0.0381])),\n",
       "             ('updateNetwork.layers.6.weight',\n",
       "              tensor([[-0.0072, -0.0156,  0.0577,  ..., -0.0540,  0.0256,  0.0350],\n",
       "                      [ 0.0243, -0.0103,  0.0048,  ...,  0.0429,  0.0165, -0.0506],\n",
       "                      [ 0.0111,  0.0636, -0.0047,  ...,  0.0399, -0.0392, -0.0198],\n",
       "                      ...,\n",
       "                      [ 0.0031,  0.1053, -0.0456,  ..., -0.0751, -0.0558,  0.0544],\n",
       "                      [-0.0588, -0.0055,  0.0328,  ..., -0.0294, -0.0584,  0.0157],\n",
       "                      [ 0.0671,  0.0709,  0.0087,  ...,  0.0326, -0.0006, -0.0799]])),\n",
       "             ('updateNetwork.layers.6.bias',\n",
       "              tensor([-0.0158, -0.0081,  0.0197, -0.0108,  0.0223, -0.0057, -0.0278, -0.0463,\n",
       "                      -0.0506,  0.0449,  0.0351,  0.0176, -0.0518, -0.0082, -0.0343,  0.0487,\n",
       "                      -0.0188,  0.0027,  0.0552,  0.0366, -0.0218, -0.0407, -0.0287, -0.0626,\n",
       "                      -0.0363, -0.0312, -0.0286, -0.0249,  0.0427, -0.0552, -0.0104, -0.0360,\n",
       "                      -0.0088,  0.0030,  0.0014, -0.0030, -0.0136, -0.0036, -0.0270,  0.0391,\n",
       "                      -0.0154, -0.0134, -0.0412,  0.0021, -0.0009,  0.0519, -0.0488,  0.0432,\n",
       "                       0.0604,  0.0603,  0.0513,  0.0325, -0.0262, -0.0031, -0.0551, -0.0546,\n",
       "                       0.0224, -0.0515, -0.0341,  0.0498, -0.0154,  0.0447,  0.0291,  0.0392])),\n",
       "             ('outputNetwork.layers.0.weight',\n",
       "              tensor([[-0.0665, -0.0028,  0.1205,  ...,  0.0685, -0.0907, -0.0469],\n",
       "                      [ 0.0070,  0.1512, -0.0728,  ...,  0.1123,  0.0441,  0.0306],\n",
       "                      [-0.0514,  0.0840, -0.1434,  ..., -0.1375,  0.1609,  0.0716],\n",
       "                      ...,\n",
       "                      [ 0.0888,  0.0156,  0.1168,  ..., -0.0209,  0.0452, -0.0040],\n",
       "                      [ 0.0970,  0.0280, -0.0646,  ..., -0.0899,  0.0324, -0.1567],\n",
       "                      [-0.0517,  0.0014, -0.1228,  ..., -0.0769,  0.1213,  0.1100]])),\n",
       "             ('outputNetwork.layers.0.bias',\n",
       "              tensor([ 0.0540,  0.0935,  0.0631,  0.0374,  0.0442,  0.0534, -0.0500, -0.0355,\n",
       "                      -0.0739,  0.1160, -0.0709,  0.0515,  0.0942,  0.0926, -0.0437,  0.0852,\n",
       "                       0.0308, -0.1011, -0.0027,  0.0929, -0.0988,  0.0697, -0.0225,  0.0619,\n",
       "                       0.0169,  0.0745,  0.0102,  0.0601, -0.1112, -0.0172, -0.1307,  0.0327,\n",
       "                      -0.1057, -0.0025,  0.0151,  0.0464, -0.0956, -0.0520,  0.0891,  0.0292,\n",
       "                       0.0212,  0.0588,  0.0396,  0.0513,  0.0944,  0.0216,  0.0470, -0.1151,\n",
       "                       0.0034,  0.0261, -0.0946, -0.0386, -0.0979, -0.0031, -0.0274, -0.0737,\n",
       "                       0.1051,  0.1087,  0.1270,  0.1203, -0.0874, -0.0644,  0.0255, -0.0705,\n",
       "                      -0.0261,  0.0491, -0.0332, -0.1007,  0.1228,  0.1052, -0.0269,  0.0596,\n",
       "                       0.0332, -0.0998,  0.0409, -0.1199, -0.0670,  0.0386, -0.0960,  0.0871,\n",
       "                      -0.1017, -0.0591,  0.0953, -0.0739,  0.0428, -0.0023,  0.0552,  0.0788,\n",
       "                      -0.0589,  0.0275,  0.1115,  0.1037, -0.0118,  0.0691, -0.0162, -0.1142,\n",
       "                       0.0413,  0.0401,  0.0957, -0.0203, -0.0331, -0.0434,  0.0164,  0.0371,\n",
       "                      -0.0193,  0.0875,  0.0331, -0.1375,  0.0127,  0.0186, -0.0381,  0.0129,\n",
       "                       0.0486,  0.1268,  0.1086, -0.0819,  0.0909,  0.0495,  0.0622,  0.0904,\n",
       "                       0.1036,  0.1081, -0.1079, -0.0006, -0.0344, -0.0986, -0.0357,  0.0138,\n",
       "                       0.0330,  0.0312,  0.1254, -0.0285,  0.0696,  0.0670,  0.0531,  0.0658,\n",
       "                      -0.0732,  0.0533, -0.0190,  0.0335, -0.0317,  0.0599,  0.0469, -0.0833,\n",
       "                       0.0448, -0.0339, -0.0814, -0.1141,  0.1126, -0.1057, -0.0035,  0.1070,\n",
       "                      -0.0789, -0.0257, -0.0310,  0.0818,  0.0781,  0.0187, -0.0962,  0.0199,\n",
       "                      -0.0457, -0.0439, -0.1133, -0.0327, -0.0873, -0.0308, -0.0210, -0.0843,\n",
       "                      -0.0190,  0.1247,  0.0207, -0.0896,  0.0785, -0.0666, -0.0701, -0.0868,\n",
       "                       0.0039,  0.0985,  0.0514,  0.0327, -0.0051,  0.0574, -0.0375, -0.0199,\n",
       "                       0.0091,  0.0595,  0.0562, -0.0819,  0.0484,  0.0429, -0.0057,  0.0279,\n",
       "                       0.0562, -0.1380,  0.0786,  0.0144, -0.0710, -0.0348,  0.0478, -0.0909,\n",
       "                       0.0246,  0.0056, -0.0875,  0.0819, -0.0150, -0.0992,  0.0840,  0.0642,\n",
       "                      -0.0979, -0.0731,  0.0767,  0.1086,  0.0087, -0.0671, -0.0479, -0.0007,\n",
       "                      -0.1115, -0.0837,  0.1008, -0.0040, -0.0514, -0.0480, -0.0081, -0.1136,\n",
       "                       0.0355,  0.0180, -0.0292, -0.0643, -0.0477, -0.0211,  0.0683,  0.0310,\n",
       "                      -0.0494, -0.0753, -0.0667,  0.0911, -0.0836, -0.1043, -0.0498, -0.0314,\n",
       "                      -0.0566,  0.0226, -0.0466, -0.0002,  0.0189, -0.0531,  0.1032,  0.0792,\n",
       "                       0.1009,  0.0630,  0.0646,  0.1131,  0.0551,  0.0772, -0.0019,  0.1139])),\n",
       "             ('outputNetwork.layers.1.weight',\n",
       "              tensor([1.0132, 0.9990, 1.0156, 1.0100, 1.0136, 1.0012, 1.0001, 1.0396, 1.0812,\n",
       "                      0.9958, 1.0483, 1.0162, 1.0159, 0.9852, 1.0296, 0.9834, 1.0167, 1.1503,\n",
       "                      1.0914, 1.0134, 1.0723, 0.9901, 0.9851, 0.9888, 1.0180, 1.0093, 1.0054,\n",
       "                      0.9682, 1.0228, 1.0086, 1.0671, 1.0069, 1.0593, 1.0350, 1.1279, 0.9806,\n",
       "                      1.0535, 1.0373, 0.9908, 0.9767, 1.0028, 0.9993, 1.0932, 0.9788, 0.9926,\n",
       "                      1.0004, 1.0257, 0.9882, 0.9951, 1.0463, 1.0237, 1.0189, 1.0608, 1.0201,\n",
       "                      1.0254, 1.0371, 0.9980, 1.0127, 0.9921, 0.9643, 1.0038, 1.0387, 0.9890,\n",
       "                      1.0157, 1.0193, 0.9945, 0.9871, 1.0163, 0.9929, 1.0020, 1.0306, 1.0007,\n",
       "                      1.0619, 1.1595, 0.9508, 1.0233, 1.0429, 1.0410, 1.0256, 1.0049, 0.9783,\n",
       "                      1.0730, 0.9540, 1.0079, 0.9946, 1.0556, 1.0090, 0.9761, 1.0795, 1.0401,\n",
       "                      1.0171, 0.9982, 1.0200, 1.0036, 1.0653, 1.0006, 1.0464, 1.0119, 1.0065,\n",
       "                      1.0403, 0.9985, 1.0092, 1.0400, 1.0244, 1.0108, 0.9742, 0.9859, 1.2008,\n",
       "                      0.9934, 0.9816, 1.0267, 0.9914, 1.0333, 1.0030, 1.0035, 0.9964, 0.9785,\n",
       "                      0.9870, 0.9839, 0.9843, 0.9988, 0.9993, 1.0870, 1.0562, 0.9969, 1.0303,\n",
       "                      1.0197, 1.0407, 0.9949, 0.9848, 1.0352, 1.0163, 0.9827, 0.9968, 0.9811,\n",
       "                      1.0100, 1.0524, 0.9959, 1.0020, 0.9863, 1.0069, 0.9892, 1.0083, 1.0277,\n",
       "                      1.0137, 1.0378, 1.0178, 1.0889, 0.9804, 1.0149, 1.0378, 0.9854, 1.0516,\n",
       "                      0.9820, 1.0800, 0.9848, 0.9996, 1.0080, 1.0239, 1.0012, 1.0290, 0.9899,\n",
       "                      1.0909, 1.0143, 0.9991, 1.0070, 1.0268, 1.0219, 0.9929, 0.9659, 1.0032,\n",
       "                      1.0221, 1.0265, 1.1075, 1.0652, 1.0277, 0.9876, 1.0146, 1.0261, 1.0148,\n",
       "                      0.9981, 0.9698, 1.0030, 0.9906, 1.0252, 1.0137, 1.0169, 1.0845, 0.9761,\n",
       "                      0.9745, 1.1076, 0.9795, 0.9960, 1.0116, 0.9861, 0.9906, 1.0307, 1.1055,\n",
       "                      0.9817, 1.0936, 1.0004, 0.9751, 1.0137, 1.0267, 0.9916, 1.0401, 1.0303,\n",
       "                      0.9858, 1.0494, 1.0729, 1.0097, 0.9788, 1.0101, 1.0128, 1.0037, 0.9968,\n",
       "                      1.0280, 1.0188, 0.9955, 0.9902, 0.9939, 0.9979, 1.0166, 1.1720, 0.9897,\n",
       "                      0.9660, 1.0011, 1.0288, 1.0101, 1.0656, 0.9893, 0.9879, 1.0040, 1.0354,\n",
       "                      0.9970, 1.0094, 1.0612, 1.0070, 1.0313, 0.9956, 1.0636, 1.0220, 1.0277,\n",
       "                      1.1439, 0.9962, 1.0256, 0.9782, 0.9896, 1.0036, 0.9797, 1.0318, 0.9755,\n",
       "                      1.0017, 0.9880, 1.0096, 0.9753])),\n",
       "             ('outputNetwork.layers.1.bias',\n",
       "              tensor([-0.0561, -0.0254, -0.0184, -0.0181, -0.0186, -0.0986, -0.0236, -0.0256,\n",
       "                       0.0066, -0.0264, -0.0332, -0.0240, -0.0385, -0.0199, -0.0264, -0.0174,\n",
       "                      -0.0417, -0.0315, -0.0726, -0.0105, -0.0291, -0.0185, -0.0388, -0.0875,\n",
       "                      -0.0743, -0.0205, -0.0115, -0.0284,  0.0066,  0.0005, -0.0667, -0.0158,\n",
       "                      -0.0459, -0.0603,  0.0298, -0.0488, -0.0558, -0.0019, -0.0200, -0.0399,\n",
       "                      -0.0081, -0.0064, -0.0613, -0.0390, -0.0197, -0.0390, -0.0321, -0.1311,\n",
       "                      -0.0415, -0.0580, -0.0585, -0.0162, -0.0775, -0.0650, -0.0354, -0.0724,\n",
       "                      -0.0436, -0.0270, -0.0020, -0.0469, -0.0312,  0.0110, -0.0342, -0.0457,\n",
       "                      -0.0181, -0.0581, -0.0457, -0.0118, -0.0070, -0.0258, -0.0181, -0.0731,\n",
       "                      -0.0558, -0.0521, -0.0610, -0.0344, -0.0094, -0.0411, -0.0257, -0.0392,\n",
       "                      -0.0564, -0.0135, -0.0492, -0.0039, -0.0123, -0.0077, -0.0018, -0.0285,\n",
       "                      -0.0244,  0.0045, -0.0238, -0.0278, -0.0252, -0.0477, -0.0225, -0.0183,\n",
       "                      -0.0456,  0.0016, -0.0329, -0.0488, -0.0507,  0.0015, -0.0067, -0.0468,\n",
       "                      -0.0009, -0.0617, -0.0176, -0.0507, -0.0398, -0.0587, -0.0122, -0.0193,\n",
       "                      -0.0727, -0.0037, -0.0199, -0.0179, -0.0281, -0.0268, -0.0158, -0.0323,\n",
       "                      -0.0280, -0.0069, -0.0333, -0.0093, -0.0346,  0.0045, -0.0626, -0.0138,\n",
       "                      -0.0252, -0.0256,  0.0132, -0.0436, -0.0118, -0.0228, -0.0478, -0.0207,\n",
       "                      -0.0353, -0.0185, -0.0074, -0.0181, -0.0027, -0.0245, -0.0287, -0.0354,\n",
       "                      -0.0419, -0.0113, -0.0294, -0.0248, -0.0470, -0.0175, -0.0072, -0.0234,\n",
       "                      -0.0137, -0.0088, -0.0548, -0.0410, -0.0388, -0.0170, -0.0653, -0.0191,\n",
       "                      -0.0080, -0.0392, -0.0293, -0.0181, -0.0577,  0.0108, -0.0263, -0.0221,\n",
       "                      -0.0179, -0.0270, -0.0374,  0.0023,  0.0074, -0.0545, -0.0443, -0.0786,\n",
       "                      -0.0180, -0.0681,  0.0098, -0.0101, -0.0299, -0.0137, -0.0393, -0.0090,\n",
       "                      -0.0053, -0.0357, -0.0115, -0.0638, -0.0397, -0.0614, -0.0588, -0.0011,\n",
       "                      -0.0231, -0.0634, -0.0023, -0.0296,  0.0284, -0.0128, -0.0326, -0.0366,\n",
       "                      -0.0224, -0.0878, -0.0450, -0.0193, -0.0418,  0.0040, -0.0554, -0.0527,\n",
       "                       0.0130, -0.0698, -0.0055, -0.0323, -0.0318,  0.0010, -0.0491, -0.0158,\n",
       "                      -0.0283, -0.0569, -0.0077, -0.0404, -0.0499, -0.0004, -0.0169, -0.0054,\n",
       "                      -0.0078, -0.0271, -0.0520, -0.0069, -0.0122, -0.0521, -0.0543, -0.0464,\n",
       "                      -0.0064,  0.0030, -0.0355, -0.0450, -0.0466, -0.0158,  0.0157, -0.0023,\n",
       "                      -0.0147, -0.0070, -0.0065, -0.0599, -0.0406,  0.0115, -0.0373, -0.0228,\n",
       "                      -0.0047, -0.0349, -0.0253, -0.0193, -0.0691, -0.0573, -0.0172, -0.0324])),\n",
       "             ('outputNetwork.layers.3.weight',\n",
       "              tensor([[ 0.0796, -0.0192,  0.0277,  ..., -0.0075,  0.0615, -0.0641],\n",
       "                      [-0.0162,  0.0162,  0.0348,  ..., -0.0360, -0.0018,  0.0472],\n",
       "                      [ 0.0449, -0.0030,  0.0196,  ...,  0.0366, -0.0186, -0.0148],\n",
       "                      ...,\n",
       "                      [ 0.0381,  0.0544, -0.0485,  ...,  0.0503, -0.0488, -0.0084],\n",
       "                      [ 0.0145,  0.0431, -0.0418,  ...,  0.0652, -0.0723, -0.0612],\n",
       "                      [ 0.0633,  0.0049,  0.0156,  ...,  0.0839, -0.0645, -0.0258]])),\n",
       "             ('outputNetwork.layers.3.bias',\n",
       "              tensor([ 3.2382e-02, -2.3715e-02,  3.0994e-02, -1.0282e-02,  1.7172e-02,\n",
       "                      -4.6252e-02,  2.6199e-02,  1.8172e-02,  3.2106e-02,  2.2140e-02,\n",
       "                      -1.4789e-02,  1.9112e-02,  4.7422e-02, -3.0418e-03,  6.7297e-02,\n",
       "                       7.0641e-02, -2.6352e-02,  4.2133e-02,  6.3764e-02,  8.0611e-03,\n",
       "                       1.2237e-02, -1.8929e-02, -6.6419e-02, -2.5626e-03, -5.9213e-02,\n",
       "                      -1.1481e-02, -4.0648e-02,  3.7828e-02, -6.6184e-03, -1.5461e-02,\n",
       "                      -4.2417e-04, -9.5780e-03,  5.0509e-02,  2.6747e-02,  6.4802e-02,\n",
       "                      -2.8519e-02, -4.8688e-02,  7.3854e-03, -5.2029e-02,  8.1307e-02,\n",
       "                       1.6725e-02,  4.2659e-02, -1.9041e-02, -2.2582e-02, -1.8475e-02,\n",
       "                      -6.1655e-02,  8.0136e-03, -3.7554e-02, -2.5841e-02, -7.2601e-02,\n",
       "                       1.9312e-02,  4.2830e-03,  3.4466e-02,  1.2035e-02,  4.5187e-02,\n",
       "                      -1.4713e-02, -1.0645e-02,  5.4671e-02, -5.3748e-02,  3.8652e-03,\n",
       "                       2.3884e-02, -2.9299e-02,  5.8865e-02, -2.4087e-02, -2.6824e-02,\n",
       "                      -1.4545e-02,  2.2650e-02,  3.9680e-02,  7.0620e-02, -2.2153e-02,\n",
       "                       2.1359e-05, -2.2895e-02, -6.0220e-02, -2.0460e-02, -8.7380e-03,\n",
       "                       6.8783e-02, -5.9927e-02,  4.4359e-02,  1.3852e-02,  2.5651e-02,\n",
       "                      -7.7092e-03,  1.9584e-02, -4.0058e-02,  3.1453e-02, -2.6510e-02,\n",
       "                       5.2851e-02,  4.8775e-02, -4.6440e-03, -1.4148e-02,  5.0004e-02,\n",
       "                       3.5461e-02,  2.0800e-02,  5.7109e-02, -2.1466e-02, -1.0476e-03,\n",
       "                      -2.0606e-02, -4.0896e-02,  5.2777e-02,  1.9994e-02,  2.2017e-02,\n",
       "                      -1.4468e-02, -1.8528e-02,  5.8617e-02,  1.9635e-02,  2.8686e-02,\n",
       "                       2.6923e-02, -2.0734e-02,  4.8481e-02, -4.4174e-03,  2.7488e-02,\n",
       "                       3.1789e-02, -1.4466e-02,  4.1037e-02,  2.1978e-03, -6.8544e-02,\n",
       "                      -1.1730e-02,  5.0872e-02, -1.5302e-02, -5.0771e-02, -5.0329e-03,\n",
       "                       3.9907e-02,  4.2948e-02, -4.7302e-04, -4.5193e-02, -2.3647e-02,\n",
       "                      -1.4367e-02, -3.3563e-02,  4.2103e-02,  4.1940e-02,  3.8173e-02,\n",
       "                       6.2067e-02, -4.8647e-02, -6.2562e-02,  5.5153e-02,  1.5841e-02,\n",
       "                       1.9091e-02,  2.0345e-02, -3.5847e-03,  4.4199e-02,  5.8397e-02,\n",
       "                      -2.6730e-02, -2.5083e-02,  4.0535e-02,  3.9088e-03,  3.0281e-03,\n",
       "                      -2.7322e-02, -6.0565e-03,  5.1367e-02, -5.2744e-02,  4.0177e-02,\n",
       "                       4.0955e-02, -6.4675e-02,  3.6087e-02, -2.4356e-03,  4.2444e-02,\n",
       "                      -2.9013e-02, -1.7404e-02,  8.8637e-03,  4.0621e-02, -4.5905e-03,\n",
       "                      -6.8854e-03,  1.1428e-02,  9.0338e-03,  4.0910e-02, -4.2695e-02,\n",
       "                       4.7717e-02,  1.9352e-02, -1.4131e-02, -5.4051e-03, -1.2761e-02,\n",
       "                      -3.4234e-02, -6.1879e-02, -5.0090e-02, -1.1359e-02, -1.0491e-03,\n",
       "                       2.1819e-02, -5.7944e-02, -4.9643e-02, -4.9712e-02,  5.7393e-02,\n",
       "                      -6.5251e-03, -2.6494e-02, -3.7457e-02,  9.8850e-03,  5.3717e-02,\n",
       "                      -1.9206e-02,  1.0539e-02,  5.6664e-03, -1.8619e-02,  4.3919e-02,\n",
       "                      -1.8136e-02,  6.8067e-03,  4.1339e-03,  7.3948e-03, -3.4975e-02,\n",
       "                      -1.7748e-02, -3.4281e-02, -3.6601e-02, -4.3651e-02,  2.8201e-02,\n",
       "                      -5.3534e-02,  4.5370e-02, -5.6818e-02,  5.1298e-02,  2.7637e-02,\n",
       "                      -5.1155e-02, -3.3992e-02,  1.6329e-02,  2.9549e-02, -1.2200e-02,\n",
       "                      -5.8300e-03, -2.4615e-02, -9.8637e-03, -3.3344e-02,  2.7120e-02,\n",
       "                       1.1251e-02,  2.4052e-02,  3.8189e-02, -4.8095e-02,  4.1852e-02,\n",
       "                       5.1808e-02, -1.0648e-02,  2.1600e-02, -1.3686e-02, -4.6533e-02,\n",
       "                      -2.6660e-02, -3.1695e-02, -2.8346e-02, -4.3361e-02, -6.4287e-03,\n",
       "                       7.4829e-02, -2.3416e-02,  1.3083e-03,  6.1897e-02,  8.7921e-03,\n",
       "                      -6.3228e-02,  2.3071e-02,  6.1427e-02, -3.0858e-02,  3.4997e-02,\n",
       "                       3.1126e-02, -6.8906e-03,  3.4391e-02,  3.0718e-02,  1.8207e-02,\n",
       "                       6.1261e-02,  3.7488e-02, -1.0713e-02, -3.8622e-02, -1.0542e-03,\n",
       "                       4.2715e-02, -1.6890e-02,  5.5745e-02, -2.1280e-02, -5.0327e-02,\n",
       "                       4.8197e-02])),\n",
       "             ('outputNetwork.layers.4.weight',\n",
       "              tensor([1.0319, 1.0734, 1.0086, 1.2455, 1.0294, 1.0208, 0.9981, 1.0252, 1.0471,\n",
       "                      1.0676, 1.1096, 1.0344, 1.1091, 1.0735, 1.0626, 1.0456, 1.3177, 1.0521,\n",
       "                      1.1151, 1.0233, 1.1064, 1.1590, 0.9881, 1.1593, 1.0307, 1.1613, 1.2222,\n",
       "                      1.2036, 1.0335, 1.1665, 1.0848, 1.0280, 1.2163, 1.0373, 1.0610, 1.0157,\n",
       "                      1.0262, 1.0383, 1.1908, 1.1808, 1.0072, 0.9999, 1.0769, 1.0659, 1.0510,\n",
       "                      1.0870, 1.0483, 1.0544, 1.0660, 1.0304, 1.0437, 1.1143, 1.0458, 1.0262,\n",
       "                      1.0185, 1.1005, 1.0134, 1.0202, 1.0297, 1.0457, 1.0544, 1.0569, 1.0648,\n",
       "                      1.6465, 1.0443, 1.0982, 1.0183, 1.0596, 1.1107, 1.0688, 1.0129, 1.0145,\n",
       "                      1.1532, 1.0393, 1.1754, 1.0513, 1.0160, 1.0982, 1.2486, 1.0526, 1.0138,\n",
       "                      1.0300, 1.1728, 1.0420, 1.2010, 1.0074, 1.0772, 1.5214, 1.0335, 1.0808,\n",
       "                      0.9844, 0.9942, 1.0459, 1.0594, 1.1963, 1.0599, 1.1204, 1.0152, 1.0199,\n",
       "                      1.2755, 0.9917, 0.9863, 1.0351, 1.0736, 1.1073, 1.0184, 1.0173, 0.9454,\n",
       "                      1.0324, 0.9883, 1.0434, 1.1576, 1.1178, 1.0977, 1.0306, 1.0805, 1.0575,\n",
       "                      1.0488, 1.0469, 1.0115, 1.0409, 1.0081, 1.1165, 1.0407, 1.0013, 1.1492,\n",
       "                      0.9991, 1.0718, 1.1493, 1.0624, 1.0434, 1.0497, 1.0502, 1.0223, 1.0550,\n",
       "                      1.0886, 1.0770, 1.0286, 1.0522, 1.0426, 1.0490, 1.0969, 1.0732, 1.0486,\n",
       "                      1.0512, 1.0137, 1.0133, 1.2226, 1.0277, 1.0718, 1.0776, 1.1654, 0.9664,\n",
       "                      1.0923, 1.2603, 1.2902, 1.0797, 1.1163, 1.0193, 1.0850, 1.0730, 1.0643,\n",
       "                      1.0353, 1.0404, 1.0585, 1.0407, 1.1800, 1.0039, 1.0409, 1.0911, 1.0428,\n",
       "                      1.3534, 1.1016, 1.0490, 1.0069, 1.1267, 1.4211, 1.2065, 1.0077, 1.2823,\n",
       "                      1.1266, 1.0996, 1.0500, 1.0134, 1.0829, 1.0910, 1.0846, 1.0247, 0.9893,\n",
       "                      1.0963, 1.0527, 1.0455, 1.0744, 1.0917, 1.0636, 1.0809, 1.1342, 1.0786,\n",
       "                      1.1748, 1.3518, 1.0546, 1.0684, 1.1922, 1.0288, 1.2095, 1.0589, 1.0295,\n",
       "                      1.1444, 1.2491, 1.2282, 1.0154, 1.1045, 1.0325, 1.0241, 1.2493, 0.9915,\n",
       "                      1.0511, 1.0424, 0.9975, 1.0797, 1.0476, 1.0519, 1.0249, 0.9685, 1.1698,\n",
       "                      1.1756, 1.0620, 1.1225, 1.0788, 1.4028, 1.2523, 1.0192, 1.0993, 1.0296,\n",
       "                      1.0916, 1.0655, 1.0413, 1.0582, 1.0370, 1.0569, 1.4267, 1.0487, 1.0754,\n",
       "                      1.4540, 1.1456, 1.1101, 1.1091, 1.0157, 1.0047, 1.1275, 1.1223, 1.2752,\n",
       "                      1.0449, 1.0598, 1.0612, 1.0702])),\n",
       "             ('outputNetwork.layers.4.bias',\n",
       "              tensor([ 0.0115,  0.0430, -0.0410, -0.0568,  0.0354,  0.0036,  0.0214,  0.0150,\n",
       "                       0.0179,  0.0278,  0.0124, -0.0050, -0.0090,  0.0554,  0.0519,  0.0289,\n",
       "                      -0.0664,  0.0197,  0.0996,  0.0115,  0.0407,  0.0715, -0.0152,  0.0398,\n",
       "                      -0.0061,  0.0278, -0.0401,  0.0396,  0.0286,  0.0189,  0.0035,  0.0292,\n",
       "                       0.0004,  0.0264,  0.0284,  0.0248,  0.0072,  0.0312, -0.0032,  0.0172,\n",
       "                      -0.0135, -0.0045,  0.0310,  0.0178,  0.0278,  0.0234,  0.0219,  0.0182,\n",
       "                       0.0054, -0.0519, -0.0052,  0.0719,  0.0133,  0.0054,  0.0156,  0.0042,\n",
       "                      -0.0754,  0.0254,  0.0265,  0.0079, -0.0200,  0.0413,  0.0362, -0.0695,\n",
       "                       0.0170,  0.0049,  0.0132,  0.0378,  0.0569,  0.0367, -0.0193,  0.0008,\n",
       "                       0.0595, -0.0060,  0.0105,  0.0376, -0.0079, -0.0195,  0.0002,  0.0242,\n",
       "                       0.0102, -0.0010, -0.0535,  0.0137,  0.0194, -0.0338,  0.0013, -0.0765,\n",
       "                       0.0009,  0.0163, -0.0029, -0.0269,  0.0355,  0.0452, -0.0409,  0.0452,\n",
       "                      -0.0040,  0.0252,  0.0252, -0.0198, -0.0142, -0.0403,  0.0219, -0.0734,\n",
       "                      -0.0071, -0.0672,  0.0100, -0.0420, -0.0132, -0.0212,  0.0015, -0.0159,\n",
       "                       0.0010, -0.0148, -0.0003,  0.0181,  0.0104,  0.0181,  0.0314,  0.0099,\n",
       "                      -0.0027, -0.0647,  0.0623,  0.0309,  0.0052,  0.0003, -0.0053,  0.0235,\n",
       "                       0.0097,  0.0286,  0.0186, -0.0232, -0.0011,  0.0139,  0.0335,  0.0392,\n",
       "                       0.0294, -0.0124, -0.0130,  0.0258, -0.0437,  0.0289, -0.0298,  0.0311,\n",
       "                       0.0368, -0.0012,  0.0211, -0.0055,  0.0013,  0.0475,  0.0489, -0.0831,\n",
       "                      -0.0112,  0.0493,  0.0350,  0.0964,  0.0368,  0.0566, -0.0026,  0.0027,\n",
       "                       0.0517,  0.0051,  0.0396,  0.0126,  0.0140, -0.0042, -0.0443, -0.0039,\n",
       "                       0.0160,  0.0527,  0.0305,  0.0730,  0.0417,  0.0380, -0.0221,  0.0191,\n",
       "                      -0.0368,  0.0817,  0.0034, -0.0248,  0.0331,  0.0551,  0.0187, -0.0265,\n",
       "                       0.0417,  0.0284, -0.0055,  0.0222, -0.0402,  0.0257,  0.0332, -0.0124,\n",
       "                       0.0521, -0.0068,  0.0006,  0.0088, -0.0154, -0.0065,  0.0155, -0.0078,\n",
       "                       0.0311,  0.0429, -0.0385,  0.0147, -0.0241,  0.0097, -0.0023,  0.0539,\n",
       "                      -0.0124,  0.0845, -0.0079,  0.0610,  0.0313,  0.0339, -0.0096, -0.0037,\n",
       "                       0.0199,  0.0396, -0.0052,  0.0372,  0.0123,  0.0246, -0.0042, -0.0143,\n",
       "                      -0.0426,  0.0186, -0.0012, -0.0482,  0.0267, -0.0311,  0.0866,  0.0108,\n",
       "                      -0.0142,  0.0276,  0.0261, -0.0810,  0.0285,  0.0211,  0.0300,  0.0354,\n",
       "                       0.0164, -0.0019,  0.0038, -0.0604,  0.0180, -0.0012,  0.0140,  0.0141,\n",
       "                       0.0069, -0.0508, -0.0109, -0.0006,  0.0367,  0.0246,  0.0053,  0.0335])),\n",
       "             ('outputNetwork.layers.6.weight',\n",
       "              tensor([[ 0.0373,  0.1125, -0.0334,  ...,  0.0948, -0.0699,  0.1309],\n",
       "                      [-0.0505,  0.0284, -0.0236,  ..., -0.0412,  0.0781, -0.0480],\n",
       "                      [ 0.0703,  0.0019, -0.0150,  ...,  0.0099,  0.1919,  0.0642],\n",
       "                      ...,\n",
       "                      [-0.0132, -0.0038, -0.0687,  ...,  0.0367,  0.0704,  0.0185],\n",
       "                      [ 0.0855,  0.1009, -0.0907,  ...,  0.0593,  0.0728,  0.0201],\n",
       "                      [ 0.0325,  0.0941, -0.0138,  ..., -0.0371,  0.0760,  0.0443]])),\n",
       "             ('outputNetwork.layers.6.bias',\n",
       "              tensor([-0.0147,  0.0124, -0.0068, -0.0538, -0.0030, -0.0707,  0.0690]))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderGNN.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
