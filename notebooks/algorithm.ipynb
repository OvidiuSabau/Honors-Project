{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda1e128-0977-4954-9c4d-6d111739620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dacbd82-c4b1-43d1-b7ff-fa4717bd0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import torch.autograd\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.markers as markers\n",
    "import pybullet as p \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import dgl\n",
    "import morphsim as m\n",
    "from graphenvs import HalfCheetahGraphEnv\n",
    "import itertools\n",
    "import queue\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7902809-4054-48a5-b605-78264c0e8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkInverseDynamics(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        hidden_sizes,\n",
    "        with_batch_norm=False,\n",
    "        activation=None\n",
    "    ):\n",
    "        super(NetworkInverseDynamics, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Linear(self.input_size, hidden_sizes[0]))\n",
    "        if with_batch_norm:\n",
    "            self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[0])))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            if with_batch_norm:\n",
    "                self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[i+1])))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_sizes[len(hidden_sizes) - 1], self.output_size))\n",
    "        \n",
    "        if activation is not None:\n",
    "            self.layers.append(activation())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b13c22-6b04-48fd-9cda-79d281a11cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNInverseDynamics(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputNetwork,\n",
    "        messageNetwork,\n",
    "        updateNetwork,\n",
    "        outputNetwork,\n",
    "        numMessagePassingIterations,\n",
    "        withInputNetwork = True\n",
    "    ):\n",
    "        \n",
    "        super(GNNInverseDynamics, self).__init__()\n",
    "                \n",
    "        self.inputNetwork = inputNetwork\n",
    "        self.messageNetwork = messageNetwork\n",
    "        self.updateNetwork = updateNetwork\n",
    "        self.outputNetwork = outputNetwork\n",
    "        \n",
    "        self.numMessagePassingIterations = numMessagePassingIterations\n",
    "        self.withInputNetwork = withInputNetwork\n",
    "        \n",
    "    def inputFunction(self, nodes):\n",
    "        return {'state' : self.inputNetwork(nodes.data['input'])}\n",
    "    \n",
    "    def messageFunction(self, edges):\n",
    "        \n",
    "        batchSize = edges.src['state'].shape[1]\n",
    "        edgeData = edges.data['feature'].repeat(batchSize, 1).T.unsqueeze(-1)\n",
    "        nodeInput = edges.src['input']\n",
    "        \n",
    "        return {'m' : self.messageNetwork(torch.cat((edges.src['state'], edgeData, nodeInput), -1))}\n",
    "    \n",
    "    def updateFunction(self, nodes):\n",
    "        return {'state': self.updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}\n",
    "    \n",
    "    def outputFunction(self, nodes):\n",
    "        \n",
    "        return {'output': self.outputNetwork(nodes.data['state'])}\n",
    "\n",
    "\n",
    "    def forward(self, graph, state):\n",
    "        \n",
    "        self.update_states_in_graph(graph, state)\n",
    "        \n",
    "        if self.withInputNetwork:\n",
    "            graph.apply_nodes(self.inputFunction)\n",
    "        \n",
    "        for messagePassingIteration in range(self.numMessagePassingIterations):\n",
    "            graph.update_all(self.messageFunction, dgl.function.mean('m', 'm_hat'), self.updateFunction)\n",
    "        \n",
    "        graph.apply_nodes(self.outputFunction)\n",
    "        \n",
    "        output = graph.ndata['output']\n",
    "        output = output.squeeze(-1).mean(0)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    def update_states_in_graph(self, graph, state):\n",
    "        if len(state.shape) == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        \n",
    "        numGraphFeature = 6\n",
    "        numGlobalStateInformation = 5\n",
    "        numLocalStateInformation = 2\n",
    "        numStateVar = state.shape[1] // 2\n",
    "        globalInformation = torch.cat((state[:, 0:5], state[:, numStateVar:numStateVar+5]), -1)\n",
    "        \n",
    "        numNodes = (numStateVar - 5) // 2\n",
    "\n",
    "        nodeData = torch.empty((numNodes, state.shape[0], numGraphFeature + 2 * numGlobalStateInformation + 2 * numLocalStateInformation)).to(device)\n",
    "        for nodeIdx in range(numNodes):\n",
    "\n",
    "            # Assign global features from graph\n",
    "            nodeData[nodeIdx, :, :6] = graph.ndata['feature'][nodeIdx]\n",
    "            # Assign local state information\n",
    "            nodeData[nodeIdx, :, 16] = state[:, 5 + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 17] = state[:, 5 + numNodes + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 18] = state[:, numStateVar + 5 + nodeIdx]\n",
    "            nodeData[nodeIdx, :, 19] = state[:, numStateVar + 5 + numNodes + nodeIdx]\n",
    "\n",
    "        # Assdign global state information\n",
    "        nodeData[:, :, 6:16] = globalInformation\n",
    "        \n",
    "        if self.withInputNetwork:\n",
    "            graph.ndata['input'] = nodeData        \n",
    "        \n",
    "        else:\n",
    "            graph.ndata['state'] = nodeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d808bf-b65b-4a87-9be6-dfa016b585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        hidden_sizes,\n",
    "        batch_size=256, # Needed only for batch norm\n",
    "        with_batch_norm=False,\n",
    "        activation=None\n",
    "    ):\n",
    "        super(NetworkAutoEncoder, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Linear(self.input_size, hidden_sizes[0]))\n",
    "        if with_batch_norm:\n",
    "#             self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "            self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[0])))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            if with_batch_norm:\n",
    "#                 self.layers.append(nn.BatchNorm1d(batch_size))\n",
    "                self.layers.append(nn.LayerNorm(normalized_shape=(hidden_sizes[i+1])))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_sizes[len(hidden_sizes) - 1], self.output_size))\n",
    "        \n",
    "        if activation is not None:\n",
    "            self.layers.append(activation())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eef77e3-523a-4d58-8336-09a22ac2b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNeuralNetworkAutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            inputNetwork,\n",
    "            messageNetwork,\n",
    "            updateNetwork,\n",
    "            outputNetwork,\n",
    "            numMessagePassingIterations,\n",
    "            encoder=True\n",
    "    ):\n",
    "\n",
    "        super(GraphNeuralNetworkAutoEncoder, self).__init__()\n",
    "\n",
    "        self.inputNetwork = inputNetwork\n",
    "        self.messageNetwork = messageNetwork\n",
    "        self.updateNetwork = updateNetwork\n",
    "        self.outputNetwork = outputNetwork\n",
    "\n",
    "        self.numMessagePassingIterations = numMessagePassingIterations\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def inputFunction(self, nodes):\n",
    "        return {'state': self.inputNetwork(nodes.data['input'])}\n",
    "\n",
    "    def messageFunction(self, edges):\n",
    "\n",
    "        batchSize = edges.src['state'].shape[1]\n",
    "        edgeData = edges.data['feature'].repeat(batchSize, 1).T.unsqueeze(-1)\n",
    "        nodeInput = edges.src['input']\n",
    "\n",
    "        #         print(edges.src['state'].shape)\n",
    "        #         print(nodeInput.shape)\n",
    "        return {'m': self.messageNetwork(torch.cat((edges.src['state'], edgeData, nodeInput), -1))}\n",
    "\n",
    "    def updateFunction(self, nodes):\n",
    "        return {'state': self.updateNetwork(torch.cat((nodes.data['m_hat'], nodes.data['state']), -1))}\n",
    "\n",
    "    def outputFunction(self, nodes):\n",
    "\n",
    "        #         numNodes, batchSize, stateSize = graph.ndata['state'].shape\n",
    "        #         return self.outputNetwork.forward(graph.ndata['state'])\n",
    "        return {'output': self.outputNetwork(nodes.data['state'])}\n",
    "\n",
    "    def forward(self, graph, state):\n",
    "\n",
    "        self.update_states_in_graph(graph, state)\n",
    "\n",
    "        graph.apply_nodes(self.inputFunction)\n",
    "\n",
    "        for messagePassingIteration in range(self.numMessagePassingIterations):\n",
    "            graph.update_all(self.messageFunction, dgl.function.max('m', 'm_hat'), self.updateFunction)\n",
    "\n",
    "        graph.apply_nodes(self.outputFunction)\n",
    "\n",
    "        output = graph.ndata['output']\n",
    "\n",
    "        if self.encoder:\n",
    "            output = F.normalize(output, dim=-1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def update_states_in_graph(self, graph, state):\n",
    "\n",
    "        if self.encoder:\n",
    "            if len(state.shape) == 1:\n",
    "                state = state.unsqueeze(0)\n",
    "\n",
    "            numGraphFeature = 6\n",
    "            numGlobalStateInformation = 5\n",
    "            numLocalStateInformation = 2\n",
    "            numStateVar = state.shape[1]\n",
    "            globalInformation = state[:, 0:5]\n",
    "            batch_size = state.shape[0]\n",
    "            numNodes = (numStateVar - 5) // 2\n",
    "\n",
    "            nodeData = torch.empty(\n",
    "                (numNodes, batch_size, numGraphFeature + numGlobalStateInformation + numLocalStateInformation)).to(\n",
    "                device)\n",
    "\n",
    "            nodeData[:, :, 0:numGlobalStateInformation] = globalInformation\n",
    "            for nodeIdx in range(numNodes):\n",
    "                # Assign local state information\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation] = state[:, 5 + nodeIdx]\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation + 1] = state[:, 5 + numNodes + nodeIdx]\n",
    "                # Assign global features from graph\n",
    "                nodeData[nodeIdx, :, numGlobalStateInformation + 2: numGlobalStateInformation + 2 + numGraphFeature] = \\\n",
    "                graph.ndata['feature'][nodeIdx]\n",
    "\n",
    "            graph.ndata['input'] = nodeData\n",
    "\n",
    "        else:\n",
    "            numNodes, batchSize, inputSize = state.shape\n",
    "            nodeData = torch.empty((numNodes, batchSize, inputSize + 6)).to(device)\n",
    "            nodeData[:, :, :inputSize] = state\n",
    "            nodeData[:, :, inputSize: inputSize + 6] = graph.ndata['feature'].unsqueeze(dim=1).repeat_interleave(\n",
    "                batchSize, dim=1)\n",
    "            #             for nodeIdx in range(numNodes):\n",
    "            #                 nodeData[nodeIdx, :, inputSize : inputSize + 6] = graph.ndata['feature'][nodeIdx]\n",
    "\n",
    "            graph.ndata['input'] = nodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a4f0e25-c6a4-4da7-88b6-4687efa53cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "*************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovi/anaconda3/envs/honors-project/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "NoneType: None\n"
     ]
    }
   ],
   "source": [
    "states = {}\n",
    "actions = {}\n",
    "rewards = {}\n",
    "next_states = {}\n",
    "dones = {}\n",
    "env = {}\n",
    "\n",
    "for morphIdx in [5]:\n",
    "\n",
    "    prefix = '../datasets/{}/'.format(morphIdx)\n",
    "    \n",
    "    states[morphIdx] = torch.from_numpy(np.load(prefix + 'states_array.npy'))\n",
    "    actions[morphIdx] = torch.from_numpy(np.load(prefix + 'actions_array.npy'))\n",
    "    rewards[morphIdx] = torch.from_numpy(np.load(prefix + 'rewards_array.npy'))\n",
    "    next_states[morphIdx] = torch.from_numpy(np.load(prefix + 'next_states_array.npy'))\n",
    "    dones[morphIdx] = torch.from_numpy(np.load(prefix + 'dones_array.npy'))\n",
    "    \n",
    "    env[morphIdx] = HalfCheetahGraphEnv(None)\n",
    "    env[morphIdx].set_morphology(morphIdx)\n",
    "    env[morphIdx].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98478513-7dda-4f69-b016-8cccd53b222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewGraph(env, morphIdx):\n",
    "    return env[morphIdx].get_graph()._get_dgl_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f87e59-9338-44cd-8947-d7f5dd222e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_sphere(samples=1):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (3. - math.sqrt(5.))  # golden angle in radians\n",
    "\n",
    "    for i in range(samples):\n",
    "        y = 1 - (i / float(samples - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "\n",
    "        points.append((x, y, z))\n",
    "\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f6a479-536e-4a71-ba83-fb400692ff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [256, 256]\n",
    "\n",
    "inputSize = 13\n",
    "stateSize = 64\n",
    "messageSize = 64\n",
    "latentSize = 3\n",
    "numMessagePassingIterations = 6\n",
    "with_batch_norm = True\n",
    "\n",
    "# # Encoder Networks\n",
    "encoderInputNetwork = NetworkAutoEncoder(inputSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "encoderMessageNetwork = NetworkAutoEncoder(stateSize + inputSize + 1, messageSize, hidden_sizes, with_batch_norm=with_batch_norm, activation=nn.Tanh)\n",
    "encoderUpdateNetwork = NetworkAutoEncoder(stateSize + messageSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "encoderOutputNetwork = NetworkAutoEncoder(stateSize, latentSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "encoderGNN = GraphNeuralNetworkAutoEncoder(encoderInputNetwork, encoderMessageNetwork, encoderUpdateNetwork, encoderOutputNetwork, numMessagePassingIterations, encoder=True).to(device)\n",
    "\n",
    "# # Decoder Networks\n",
    "decoderInputNetwork = NetworkAutoEncoder(latentSize + 6, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderMessageNetwork = NetworkAutoEncoder(stateSize + latentSize + 7, messageSize, hidden_sizes, with_batch_norm=with_batch_norm, activation=nn.Tanh)\n",
    "decoderUpdateNetwork = NetworkAutoEncoder(stateSize + messageSize, stateSize, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderOutputNetwork = NetworkAutoEncoder(stateSize, 7, hidden_sizes, with_batch_norm=with_batch_norm)\n",
    "decoderGNN = GraphNeuralNetworkAutoEncoder(decoderInputNetwork, decoderMessageNetwork, decoderUpdateNetwork, decoderOutputNetwork, numMessagePassingIterations, encoder=False).to(device)\n",
    "\n",
    "# encoderGNN.load_state_dict(torch.load('../models/new/4-latent-single-GNN-AutoEncoder/5/0.0-1.5/encoderGNN.pt'))\n",
    "# decoderGNN.load_state_dict(torch.load('../models/new/4-latent-single-GNN-AutoEncoder/5/0.0-1.5/decoderGNN.pt'))\n",
    "\n",
    "print(encoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/0.4-1.33/' + 'encoderGNN.pt')))\n",
    "print(decoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/0.4-1.33/' + 'decoderGNN.pt')))\n",
    "\n",
    "# print(encoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/no-contrastive/' + 'encoderGNN.pt')))\n",
    "# print(decoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/no-contrastive/' + 'decoderGNN.pt')))\n",
    "\n",
    "\n",
    "# print(encoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/no-contrastive/' + 'encoderGNN.pt')))\n",
    "# print(decoderGNN.load_state_dict(torch.load('../models/new/3-latent-single-GNN-AutoEncoder/5/no-contrastive/' + 'decoderGNN.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebebf44-efd1-4ced-b5bf-e5a030b3b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_sizes = [256, 256]\n",
    "\n",
    "inputSize = 20\n",
    "stateSize = 64\n",
    "messageSize = 64\n",
    "outputSize = 1\n",
    "numMessagePassingIterations = 6\n",
    "with_batch_norm = True\n",
    "\n",
    "inputNetwork = NetworkInverseDynamics(inputSize, stateSize, hidden_sizes, with_batch_norm)\n",
    "messageNetwork = NetworkInverseDynamics(stateSize + inputSize + 1, messageSize, hidden_sizes, with_batch_norm, nn.Tanh)\n",
    "updateNetwork = NetworkInverseDynamics(stateSize + messageSize, stateSize, hidden_sizes, with_batch_norm)\n",
    "outputNetwork = NetworkInverseDynamics(stateSize, outputSize, hidden_sizes, with_batch_norm, nn.Sigmoid)\n",
    "\n",
    "inverseDynamics = GNNInverseDynamics(inputNetwork, messageNetwork, updateNetwork, outputNetwork, numMessagePassingIterations).to(device)\n",
    "inverseDynamics.load_state_dict(torch.load('mixed-delta-validTransition.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f20ec3-a505-4520-966e-d3c69a92d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructStateFromGraph(graph_data):\n",
    "    num_nodes, batch_size, data_size = graph_data.shape\n",
    "    output = torch.empty((batch_size, 5 + 2 * num_nodes))\n",
    "    output[:, :5] = graph_data[:, :, :5].mean(dim=0)\n",
    "    output[:, 5 : 5 + num_nodes] = graph_data[:, :, 5].T\n",
    "    output[:, 5 + num_nodes:] = graph_data[:, :, 6].T\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df96933-98d3-4935-972c-76e270ecba35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached iteration 1 with 1 states\n",
      "Reached iteration 251 with 825 states\n",
      "Reached iteration 501 with 1395 states\n",
      "Reached iteration 751 with 2079 states\n",
      "Reached iteration 1001 with 2592 states\n",
      "Reached iteration 1251 with 3260 states\n",
      "Reached iteration 1501 with 3934 states\n",
      "Reached iteration 1751 with 4525 states\n",
      "Reached iteration 2001 with 5095 states\n",
      "Reached iteration 2251 with 5866 states\n",
      "Reached iteration 2501 with 6587 states\n",
      "Reached iteration 2751 with 7126 states\n",
      "Reached iteration 3001 with 7817 states\n",
      "Reached iteration 3251 with 8573 states\n",
      "Reached iteration 3501 with 9340 states\n",
      "Reached iteration 3751 with 10019 states\n",
      "Reached iteration 4001 with 10745 states\n",
      "Reached iteration 4251 with 11478 states\n",
      "Reached iteration 4501 with 12293 states\n",
      "Reached iteration 4751 with 13020 states\n",
      "Reached iteration 5001 with 13725 states\n",
      "Reached iteration 5251 with 14416 states\n",
      "Reached iteration 5501 with 15278 states\n",
      "Reached iteration 5751 with 15953 states\n",
      "Reached iteration 6001 with 16515 states\n",
      "Reached iteration 6251 with 17202 states\n",
      "Reached iteration 6501 with 18038 states\n",
      "Reached iteration 6751 with 18870 states\n",
      "Reached iteration 7001 with 19671 states\n",
      "Reached iteration 7251 with 20365 states\n",
      "Reached iteration 7501 with 20976 states\n",
      "Reached iteration 7751 with 21759 states\n",
      "Reached iteration 8001 with 22317 states\n",
      "Reached iteration 8251 with 23013 states\n",
      "Reached iteration 8501 with 23831 states\n",
      "Reached iteration 8751 with 24795 states\n",
      "Reached iteration 9001 with 25434 states\n",
      "Reached iteration 9251 with 26190 states\n",
      "Reached iteration 9501 with 26969 states\n",
      "Reached iteration 9751 with 27817 states\n",
      "Reached iteration 10001 with 28490 states\n"
     ]
    }
   ],
   "source": [
    "# !!!!\n",
    "# Construct Graph\n",
    "# !!!!\n",
    "\n",
    "morphIdx = 5 # Morphology of the Agent\n",
    "alpha = 0.4 # Largest distance expected between sequential states\n",
    "num_offsets = 128 # Number of states that we will `attempt` to add to the graph on every iteration\n",
    "transition_threshold = 0.95 # Lowest allowed likelihood for transition (as given by valid-transition-network) allowed in the graph\n",
    "num_samples = 10000 # Size of the subset of points we will choose from when deciding\n",
    "max_dst_threshold = 0.15\n",
    "min_dst_threshold = 0.03\n",
    "jitter_parameter = 5e-2 # Mean of the distribution from which to sample jitter; UNPROVEN\n",
    "\n",
    "# Just to get things started, randomly sample a state from the dataset, encode it, and then add it to the graph\n",
    "saved_states = []\n",
    "saved_encodings = []\n",
    "adjacency_list = []\n",
    "explored_state = []\n",
    "failed_encodings = []\n",
    "succesful_encodings = []\n",
    "success_rate = []\n",
    "within_range_list = []\n",
    "\n",
    "random_idx = np.random.choice(int(1e6))\n",
    "random_state = states[morphIdx][random_idx].cpu()\n",
    "g = getNewGraph(env, morphIdx)\n",
    "random_encoding = encoderGNN(g, random_state.unsqueeze(0))[:, 0].detach().cpu()\n",
    "saved_states.append(random_state)\n",
    "saved_encodings.append(random_encoding)\n",
    "explored_state.append(False)\n",
    "adjacency_list.append([])\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    i = 0\n",
    "    #     for i in range(50000):\n",
    "    while len(saved_states) < int(5e4):\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i % 250 == 1:\n",
    "            print('Reached iteration {} with {} states'.format(i, len(saved_states)))\n",
    "        \n",
    "        if i >= 100 and len(saved_states) == 1:\n",
    "            saved_states = []\n",
    "            saved_encodings = []\n",
    "            adjacency_list = []\n",
    "            explored_state = []\n",
    "            failed_encodings = []\n",
    "            succesful_encodings = []\n",
    "            success_rate = []\n",
    "            within_range_list = []\n",
    "\n",
    "            random_idx = np.random.choice(int(1e6))\n",
    "            random_state = torch.from_numpy(states[morphIdx][random_idx])\n",
    "            g = getNewGraph(env, morphIdx)\n",
    "            random_encoding = encoderGNN(g, random_state.unsqueeze(0))[:, 0].detach().cpu()\n",
    "            saved_states.append(random_state)\n",
    "            saved_encodings.append(random_encoding)\n",
    "            explored_state.append(False)\n",
    "            adjacency_list.append([])\n",
    "            i=0\n",
    "            print('Restarting...')\n",
    "        \n",
    "        # np array of size batch: min(len(saved_states), num_samples) \n",
    "        random_subset_indeces = np.random.choice(len(saved_states), size=min(len(saved_states), num_samples))\n",
    "        # tensor of shape (batch, 19)\n",
    "        random_subset_states = [saved_states[i] for i in random_subset_indeces]\n",
    "        # tensor of shape (batch, 7, 3)\n",
    "        random_subset_encodings = torch.stack([saved_encodings[i] for i in random_subset_indeces]).to(device)\n",
    "        # boolean tensor of shape (batch)\n",
    "        random_subset_explored = torch.BoolTensor([explored_state[i] for i in random_subset_indeces]).to(device)\n",
    "        # tensor of shape (7, batch, 3)\n",
    "        random_subset_encodings = random_subset_encodings.transpose(0, 1)\n",
    "        \n",
    "        \n",
    "        # tensor of size (7, batch, batch)\n",
    "        distances = torch.cdist(random_subset_encodings, random_subset_encodings)\n",
    "                \n",
    "        # New Way\n",
    "        num_neighbors = (distances.mean(0) <= alpha).sum(-1)\n",
    "        num_neighbors += distances.size(1) * random_subset_explored\n",
    "        fewest_neighbors_idx = torch.argmin(num_neighbors)\n",
    "        \n",
    "        # tensor of shape (batch, 7, 3)\n",
    "        random_subset_encodings = random_subset_encodings.transpose(0, 1)\n",
    "        current_encoding = random_subset_encodings[fewest_neighbors_idx]\n",
    "        current_state = random_subset_states[fewest_neighbors_idx]\n",
    "        \n",
    "        distances = None\n",
    "        num_neighbors = None\n",
    "        jitter = None\n",
    "        offsets = None\n",
    "        new_encodings = None\n",
    "        new_states = None\n",
    "        transitions = None\n",
    "        kept_states = None\n",
    "        kept_encodings = None\n",
    "        random_subset_states = None\n",
    "        random_subset_encodings = None\n",
    "        random_subset_explored = None\n",
    "        torch.cuda.empty_cache()            \n",
    "        \n",
    "        # tensor of shape (7, batch, 3)\n",
    "        \n",
    "        current_encoding_avg_dst = torch.cdist(current_encoding, current_encoding).mean()\n",
    "        offsets = torch.normal(0, 1, (1, num_offsets, current_encoding.size(1))).repeat(current_encoding.size(0), 1, 1).to(device)\n",
    "        \n",
    "        jitter = torch.normal(0, jitter_parameter, size=offsets.size()).to(device)\n",
    "        offsets += jitter\n",
    "        offsets = F.normalize(offsets, dim=-1)\n",
    "        offsets *= alpha\n",
    "        \n",
    "        # Convert coordinates from sphere into global ones, and project onto original sphere\n",
    "        new_encodings = current_encoding.unsqueeze(1) - offsets\n",
    "        new_encodings = F.normalize(new_encodings, dim=-1)\n",
    "        \n",
    "        \n",
    "        tmp_dst = torch.cdist(new_encodings.transpose(0,1), new_encodings.transpose(0,1)).mean(-1).mean(-1)\n",
    "        \n",
    "        under_max_dst = tmp_dst < max_dst_threshold\n",
    "        over_min_dst = tmp_dst > min_dst_threshold\n",
    "        within_dst_range = under_max_dst *over_min_dst\n",
    "\n",
    "        within_range_list.append(within_dst_range.sum() / num_offsets)        \n",
    "        new_encodings = new_encodings[:, within_dst_range]\n",
    "        new_encodings = new_encodings.to(device)\n",
    "        \n",
    "        g = getNewGraph(env, morphIdx)\n",
    "        new_states = decoderGNN(g, new_encodings)\n",
    "        new_states[:, :, :5] = new_states[:, :, :5].mean(dim=0)\n",
    "        new_states = reconstructStateFromGraph(new_states)\n",
    "        transitions = current_state.repeat(new_states.size(0), 2)\n",
    "        transitions [:, transitions.size(1) // 2:] -= new_states\n",
    "\n",
    "        g = getNewGraph(env, morphIdx)\n",
    "        probabilities = inverseDynamics(g, transitions).cpu()\n",
    "        \n",
    "        valid_transition_indeces = probabilities > transition_threshold\n",
    "\n",
    "        kept_states = new_states[valid_transition_indeces]\n",
    "        kept_encodings = new_encodings[:, valid_transition_indeces]\n",
    "        \n",
    "        fewest_neighbors_idx_global = random_subset_indeces[fewest_neighbors_idx]\n",
    "        explored_state[fewest_neighbors_idx_global] = True\n",
    "        adjacency_list[fewest_neighbors_idx_global].extend(range(len(saved_states), len(saved_states) + kept_states.size(0)))\n",
    "        \n",
    "        current_encoding = current_encoding.cpu()\n",
    "        if kept_states.size(0) == 0:\n",
    "            failed_encodings.append(current_encoding)\n",
    "        else:\n",
    "            succesful_encodings.append(current_encoding)\n",
    "        \n",
    "        success_rate.append(kept_states.size(0) / num_offsets)\n",
    "        \n",
    "        kept_states = kept_states.cpu()\n",
    "        kept_encodings = kept_encodings.cpu()\n",
    "        for new_idx in range(kept_states.size(0)):\n",
    "            saved_states.append(kept_states[new_idx])\n",
    "            saved_encodings.append(kept_encodings[:, new_idx])\n",
    "            explored_state.append(False)\n",
    "            adjacency_list.append([])\n",
    "        \n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7930f013-65db-4b5b-9b1c-5ffec307c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.is_tensor(saved_encodings):\n",
    "    saved_encodings = torch.stack(saved_encodings)\n",
    "\n",
    "if not torch.is_tensor(saved_states):\n",
    "    saved_states = torch.stack(saved_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fdeba2-c31e-4788-aeb2-72a70139ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig:\n",
    "    plt.close(fig)\n",
    "fig = plt.figure()\n",
    "within_range_list = torch.tensor(within_range_list)\n",
    "plt.plot(np.arange(within_range_list.size(0)), uniform_filter1d(within_range_list, size=128))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c22a568d-d48e-42a1-8013-e0a16d73f58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(torch.stack(saved_encodings), 'saved_encodings_1e6')\n",
    "# torch.save(torch.stack(saved_states), 'saved_states_1e6')\n",
    "# with open('adjecency_list_1e6', 'wb') as file:\n",
    "#     pickle.dump(adjacency_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20d9cb9d-cf3b-449d-b2af-5fd07fbbd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_encodings = torch.load('saved_encodings_1e6').to(device)\n",
    "saved_states = torch.load('saved_states_1e6').to(device)\n",
    "with open('adjecency_list_1e6', 'rb') as file:\n",
    "    adjacency_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ee5dcc6-90f1-4487-920b-79e98f793c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81c1b921b6c4875b6cfc8db4cbb20c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.close(fig)\n",
    "fig = plt.figure()\n",
    "\n",
    "x = saved_encodings[:, 0, 0]\n",
    "y = saved_encodings[:, 0, 1]\n",
    "z = saved_encodings[:, 0, 2]\n",
    "\n",
    "ax = plt.axes(projection ='3d')\n",
    "ax.scatter3D(x, y, z, alpha=0.1)\n",
    "# for idx in range(100):\n",
    "#     ax.scatter3D(succesful_encodings[-idx, 0, 0], succesful_encodings[-idx, 0, 1], succesful_encodings[-idx, 0, 2], c='red')\n",
    "\n",
    "# for idx in range(100):\n",
    "#     ax.scatter3D(succesful_encodings[idx, 0, 0], succesful_encodings[idx, 0, 1], succesful_encodings[idx, 0, 2], c='green')\n",
    "\n",
    "# for idx in indices:\n",
    "#     ax.scatter3D(saved_encodings[idx, 0, 0], saved_encodings[idx, 0, 1], saved_encodings[idx, 0, 2], c='green')\n",
    "\n",
    "ax.view_init(elev=0, azim=45)\n",
    "fig.savefig('1-graph-sphere.png')\n",
    "\n",
    "ax.view_init(elev=30, azim=90)\n",
    "fig.savefig('2-graph-sphere.png')\n",
    "\n",
    "\n",
    "ax.view_init(elev=15, azim=0)\n",
    "fig.savefig('3-graph-sphere.png')\n",
    "\n",
    "ax.view_init(elev=90, azim=0)\n",
    "fig.savefig('4-graph-sphere.png')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e00d77c-d6b9-4512-810e-0ec879a63a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1ee2955d57494db289d68705029d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = torch.cdist(saved_encodings, saved_encodings).mean(-1).mean(-1).numpy()\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(np.arange(distances.shape[0]), np.log10(uniform_filter1d(distances, size=4096)))\n",
    "axs[1].boxplot(np.log10(distances))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8a4df6a-a065-4f2b-8c45-936e55ff7997",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0473aea373a4cf191f765c86aba6719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 92305 is out of bounds for dimension 0 with size 50002",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3c553377015b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 92305 is out of bounds for dimension 0 with size 50002"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    plt.close(fig)\n",
    "except:\n",
    "    pass\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "if not torch.is_tensor(saved_encodings):\n",
    "    saved_encodings = torch.stack(saved_encodings)\n",
    "\n",
    "batch_size, num_nodes, dimensionality = saved_encodings.shape\n",
    "ax = plt.axes(projection ='3d')\n",
    "random_idx = np.random.choice(int(1e5))\n",
    "sphere_skeleton = fibonacci_sphere(1000)\n",
    "\n",
    "ax.scatter3D(sphere_skeleton[:, 0], sphere_skeleton[:, 1], sphere_skeleton[:, 2], alpha=0.02)\n",
    "\n",
    "for node in range(num_nodes):\n",
    "    x = saved_encodings[random_idx, node, 0]\n",
    "    y = saved_encodings[random_idx, node, 1]\n",
    "    z = saved_encodings[random_idx, node, 2]\n",
    "\n",
    "    ax.scatter3D(x, y, z)\n",
    "\n",
    "ax.view_init(elev=0, azim=45)\n",
    "fig.savefig('one-state-all-dimensions/view1.png')\n",
    "\n",
    "ax.view_init(elev=30, azim=90)\n",
    "fig.savefig('one-state-all-dimensions/view2.png')\n",
    "\n",
    "\n",
    "ax.view_init(elev=15, azim=0)\n",
    "fig.savefig('one-state-all-dimensions/view3.png')\n",
    "\n",
    "ax.view_init(elev=90, azim=0)\n",
    "fig.savefig('one-state-all-dimensions/view4.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f35bfa2-3980-4d32-ae3e-3dc981e6f337",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31565554174505817 0.08468402922153473\n",
      "0.3255173258025794 0.10427697002887726\n",
      "0.3510498726671994 0.08252780884504318\n",
      "0.36165502126080984 0.09851332753896713\n",
      "0.37021095213548727 0.06532897055149078\n",
      "0.37191065732923806 0.0619584359228611\n",
      "0.37394992900795737 0.10268601030111313\n",
      "0.3750120293497547 0.07801061123609543\n",
      "0.37545736456748524 0.07362300902605057\n",
      "0.3769017676786426 0.07642907649278641\n",
      "0.3780011946544113 0.09347216784954071\n",
      "0.3791947771960488 0.0682683065533638\n",
      "0.38064690722856637 0.08713258802890778\n",
      "0.38295015723153397 0.06372345983982086\n",
      "0.38657553353577023 0.05872494727373123\n",
      "0.3880243956575652 0.0633518174290657\n",
      "0.38804781124472537 0.07083785533905029\n",
      "0.38924660810007455 0.07098906487226486\n",
      "0.39073408879923666 0.08038192242383957\n",
      "0.39139079762926793 0.09408371150493622\n",
      "0.3956888588529802 0.09944630414247513\n",
      "0.3965938772642021 0.10067739337682724\n",
      "0.39834836678336943 0.05604859068989754\n",
      "0.3989453734784868 0.059946928173303604\n",
      "0.3993954404678788 0.07223814725875854\n",
      "0.40290628337666634 0.07856340706348419\n",
      "0.4037896915243553 0.06196516752243042\n",
      "0.40413087646017637 0.08549972623586655\n",
      "0.4041567032725881 0.09739195555448532\n",
      "0.4077773431001674 0.09807313233613968\n",
      "0.40900009101877655 0.07577745616436005\n",
      "0.40945217855208743 0.09804172068834305\n",
      "0.41027361246773475 0.10032317787408829\n",
      "0.4118243788394351 0.09141647815704346\n",
      "0.4128632628321859 0.09425489604473114\n",
      "0.4152759243495725 0.09128296375274658\n",
      "0.4183329546210232 0.062392909079790115\n",
      "0.41870198246991824 0.09712632745504379\n",
      "0.4195507876704676 0.0713147297501564\n",
      "0.42052241939684953 0.09631042182445526\n",
      "0.42089992059514314 0.076823391020298\n",
      "0.42145945487500996 0.04278532788157463\n",
      "0.4225798312277551 0.06428266316652298\n",
      "0.42681531561085645 0.09083495289087296\n",
      "0.42968569367381493 0.09154901653528214\n",
      "0.4298240381516769 0.07518583536148071\n",
      "0.4309740401718508 0.08577512949705124\n",
      "0.4311073961485072 0.09346866607666016\n",
      "0.434722133293752 0.10167478770017624\n",
      "0.4363770258232203 0.0975978821516037\n",
      "0.43669267322117705 0.08572939783334732\n",
      "0.4368706912604113 0.09376693516969681\n",
      "0.4371620385078728 0.10359407961368561\n",
      "0.43823811637770366 0.06421221792697906\n",
      "0.4425406472594449 0.07033701241016388\n",
      "0.44408355834476865 0.0574822723865509\n",
      "0.44504137012569156 0.059976786375045776\n",
      "0.4451685706724612 0.09117990732192993\n",
      "0.44543071501185755 0.059145066887140274\n",
      "0.44647806796524053 0.10069849342107773\n",
      "0.4468738664437623 0.08825532346963882\n",
      "0.4478314249822136 0.0578949861228466\n",
      "0.44813842178717733 0.08096057921648026\n",
      "0.44861253390844336 0.10038052499294281\n",
      "0.4505946715206247 0.09224884957075119\n",
      "0.45125971669525716 0.08332958072423935\n",
      "0.45144921588580844 0.04773959890007973\n",
      "0.4516615175119993 0.10226154327392578\n",
      "0.45243399765891185 0.0748036727309227\n",
      "0.4554632222885659 0.05117080360651016\n",
      "0.45582425109486435 0.06807730346918106\n",
      "0.4559973729336585 0.0674472525715828\n",
      "0.45632166809038044 0.055708885192871094\n",
      "0.45758321596832835 0.09979449212551117\n",
      "0.4579301122237288 0.07301317900419235\n",
      "0.4600427305810223 0.09232226759195328\n",
      "0.460810904461719 0.09829477965831757\n",
      "0.46094957759457533 0.07074542343616486\n",
      "0.4617936089490989 0.08225848525762558\n",
      "0.46250838319643 0.0825570821762085\n",
      "0.462865868812205 0.06700114905834198\n",
      "0.4644204951057661 0.08381042629480362\n",
      "0.46653014016538635 0.08219181001186371\n",
      "0.4676357134836378 0.09517516195774078\n",
      "0.46774233682685196 0.05529752001166344\n",
      "0.4678047525325059 0.07157089561223984\n",
      "0.47164564921927005 0.07795316725969315\n",
      "0.471783538501229 0.10084878653287888\n",
      "0.4726709957799596 0.0635681226849556\n",
      "0.4731887930335656 0.1033291295170784\n",
      "0.47704598651403324 0.056890036910772324\n",
      "0.47762262218361695 0.06923533976078033\n",
      "0.47917502447542926 0.05009898915886879\n",
      "0.4800504804896249 0.0762973353266716\n",
      "0.48047663868069607 0.06478091329336166\n",
      "0.4816908597068721 0.08506761491298676\n",
      "0.48254893432104606 0.09800918400287628\n",
      "0.48284855482327865 0.09966198354959488\n",
      "0.48309944594685134 0.05567767843604088\n",
      "0.4856397492208892 0.05305105075240135\n"
     ]
    }
   ],
   "source": [
    "random_idx = np.random.choice(int(1e6))\n",
    "random_state = torch.from_numpy(states[morphIdx][random_idx]).unsqueeze(0)\n",
    "g = getNewGraph(env, morphIdx).cpu()\n",
    "random_encoding = encoderGNN(g, random_state)[:, 0].detach().cpu()\n",
    "encoding_dst = torch.norm(saved_encodings - random_encoding, dim=-1).mean(-1)\n",
    "encoding_dst_values, encoding_dst_indices = torch.topk(encoding_dst, k=1024, largest=False)\n",
    "g = getNewGraph(env, morphIdx).cpu()\n",
    "decoded_states = decoderGNN(g, saved_encodings[indices].transpose(0,1))\n",
    "decoded_states[:, :, :5] = decoded_states[:, :, :5].mean(dim=0)\n",
    "decoded_states = reconstructStateFromGraph(decoded_states)\n",
    "state_reconstructin_dst = ((decoded_states - random_state) ** 2).mean(-1)\n",
    "state_dst_values, state_dst_indices = torch.topk(state_reconstructin_dst, k=100, largest=False)\n",
    "for i in range(100):\n",
    "    print(state_dst_values[i].item(), encoding_dst_values[state_dst_indices[i]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51139f7b-95e8-4a2d-8a4e-99419e5534bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    random_indeces = np.random.choice(int(1e6), size=8192)\n",
    "    random_states = torch.from_numpy(states[morphIdx][random_indeces])\n",
    "    g1 = getNewGraph(env, morphIdx).cpu()\n",
    "    random_encodings = encoderGNN(g1, random_states)\n",
    "    g2 = getNewGraph(env, morphIdx).cpu()\n",
    "    states_reconstructed = decoderGNN(g2, random_encodings)\n",
    "    states_reconstructed[:, :, :5] = states_reconstructed[:, :, :5].mean(dim=0)\n",
    "    states_reconstructed = reconstructStateFromGraph(states_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b4567b8-e7fe-4254-bf84-32b61ef33cbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "alls = []\n",
    "states[morphIdx] = states[morphIdx].to(device)\n",
    "for i in range(saved_states.size(0)):\n",
    "    if i % 5000 == 0:\n",
    "        print(i)\n",
    "    min_dst = ((states[morphIdx] - saved_states[i].to(device)) ** 2).mean(-1).min()\n",
    "    alls.append(min_dst)\n",
    "\n",
    "if fig:\n",
    "    plt.close(fig)\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.boxplot(torch.stack(alls).cpu().numpy())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbe5e46-8b13-4d33-9e3d-93f9257f8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNodeToGraph(new_state, new_encoding, saved_encodings, saved_states, adjacency_list, encoderGNN, decoderGNN, \n",
    "                   inverseDynamics, device, env, morphIdx, alpha=0.4, batch_size=1024, transition_threshold=0.9, forwards=True):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        if new_encoding is None:\n",
    "            g = getNewGraph(env, morphIdx).to(device)\n",
    "            new_encoding = encoderGNN(g, new_state.unsqueeze(0)).squeeze(1)\n",
    "\n",
    "        # Check if node already exists in the graph\n",
    "\n",
    "#         smallest_mse_exisiting_states = ((saved_states - new_state) ** 2).mean(-1).min()\n",
    "#         if smallest_mse_exisiting_states <= 1e-6:\n",
    "#             print('State already exists')\n",
    "#             return\n",
    "\n",
    "        # tensor of size (len(saved_encodings),)\n",
    "        encoding_distances = torch.norm(saved_encodings - new_encoding, dim=-1).mean(-1)\n",
    "        boolean_indeces_within_range = encoding_distances <= alpha\n",
    "        indeces_within_range = torch.arange(end=saved_encodings.size(0))[boolean_indeces_within_range]\n",
    "        states_within_range = saved_states[indeces_within_range]\n",
    "                \n",
    "        num_batches = int(np.ceil((states_within_range.size(0) / batch_size)))\n",
    "        \n",
    "        valid_neighbors = []\n",
    "        for batch in range(num_batches):\n",
    "            \n",
    "            transition_states = states_within_range[batch * batch_size : (batch + 1) * batch_size]\n",
    "            \n",
    "            if forwards:\n",
    "                transitions = new_state.repeat(transition_states.size(0), 2)\n",
    "                transitions [:, transitions.size(1) // 2:] -= transition_states\n",
    "            else:\n",
    "                transitions = transition_states.repeat(1, 2)\n",
    "                transitions [:, transitions.size(1) // 2:] -= new_state\n",
    "                \n",
    "            g = getNewGraph(env, morphIdx).to(device)\n",
    "            probabilities = inverseDynamics(g, transitions)\n",
    "            boolean_valid_transition_indeces = probabilities > transition_threshold\n",
    "            possibile_batch_indeces = torch.arange(start=batch * batch_size, end=min((batch + 1) * batch_size, states_within_range.size(0)))\n",
    "            valid_batch_indeces = possibile_batch_indeces[boolean_valid_transition_indeces]\n",
    "            valid_global_indeces = indeces_within_range[valid_batch_indeces]\n",
    "            \n",
    "            valid_neighbors.extend(valid_batch_indeces.tolist())\n",
    "    \n",
    "    saved_encodings = torch.cat((saved_encodings, new_encoding.unsqueeze(0)), dim=0)\n",
    "    saved_states = torch.cat((saved_states, new_state.unsqueeze(0)), dim=0)\n",
    "    \n",
    "    if forwards:\n",
    "        adjacency_list.append(valid_neighbors)\n",
    "    else:\n",
    "        adjacency_list.append([])\n",
    "        new_state_idx = len(adjacency_list) - 1\n",
    "        for neigbor_idx in valid_neighbors:\n",
    "            adjacency_list[neigbor_idx].append(new_state_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a67a40ed-c1cd-4cef-985a-6fb9c20439e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = torch.from_numpy(states[morphIdx][1]).cuda()\n",
    "t0 = time.time()\n",
    "addNodeToGraph(new_state, None, saved_encodings, saved_states, adjacency_list, encoderGNN, decoderGNN, inverseDynamics, device, env, morphIdx, forwards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da907e53-5725-410f-bebe-01b55d0a9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = torch.from_numpy(states[morphIdx][999]).cuda()\n",
    "t0 = time.time()\n",
    "addNodeToGraph(new_state, None, saved_encodings, saved_states, adjacency_list, encoderGNN, decoderGNN, inverseDynamics, device, env, morphIdx, forwards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcaf3c30-988e-48bb-b5e2-c2596eb2b7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511a687717574a7db43b65e3da88d2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "is_zero = 0\n",
    "for l in adjacency_list:\n",
    "    lengths.append(len(l))\n",
    "    if len(l) == 0:\n",
    "        is_zero += 1\n",
    "        \n",
    "lengths = np.array(lengths)\n",
    "print(len(lengths) - is_zero)\n",
    "\n",
    "if fig:\n",
    "    plt.close(fig)\n",
    "fig = plt.figure()\n",
    "plt.boxplot(np.array(lengths))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "606a7cfe-bd4a-452f-9af9-aa0e08839333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(adjacency_list, start, end):\n",
    "    # maintain a queue of paths\n",
    "    queue = []\n",
    "    # push the first path into the queue\n",
    "    queue.append([start])\n",
    "    while queue:\n",
    "        # get the first path from the queue\n",
    "        path = queue.pop(0)\n",
    "        # get the last node from the path\n",
    "        node = path[-1]\n",
    "        # path found\n",
    "        if node == end:\n",
    "            return path\n",
    "        # enumerate all adjacent nodes, construct a \n",
    "        # new path and push it into the queue\n",
    "        neighbors = adjacency_list[node]\n",
    "        for adjacent in neighbors:\n",
    "            print(path)\n",
    "            new_path = list(path)\n",
    "            print(new_path)\n",
    "            new_path.append(adjacent)\n",
    "            queue.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44869db4-7a09-419c-bc42-c02a1ba198ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
